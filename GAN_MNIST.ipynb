{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmtakashi/acoustic_analysis/blob/master/GAN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "67J5BZCjls2J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://qiita.com/triwave33/items/1890ccc71fab6cbca87e\n",
        "from keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape, Flatten, Input\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class GAN():\n",
        "  def __init__(self):\n",
        "    # MNISTの入力サイズ\n",
        "    self.img_rows = 28\n",
        "    self.img_cols = 28\n",
        "    self.channels = 1\n",
        "    self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "\n",
        "    # 潜在変数の次元数\n",
        "    self.z_dim =100\n",
        "\n",
        "    optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "    # Discriminatorモデル\n",
        "    self.discriminator = self.build_discriminator()\n",
        "    self.discriminator.compile(loss='binary_crossentropy',\n",
        "                               optimizer=optimizer,\n",
        "                               metrics=['accuracy'])\n",
        "\n",
        "    # Generatorモデル\n",
        "    self.generator = self.build_generator()\n",
        "    # Generatorは単体では学習しないのでコンパイルは必要ない\n",
        "\n",
        "    self.combined = self.build_combined1()\n",
        "    self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "    \n",
        "  def build_generator(self):\n",
        "    noise_shape = (self.z_dim, )\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(256, input_shape=noise_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
        "    model.add(Reshape(self.img_shape))\n",
        "\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "  def build_discriminator(self):\n",
        "    img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Flatten(input_shape=img_shape))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "  def build_combined1(self):\n",
        "    self.discriminator.trainable = False\n",
        "    model = Sequential([self.generator, self.discriminator])\n",
        "    return model\n",
        "\n",
        "  def build_combined2(self):\n",
        "    z = Input(shape=(self.z_dim,))\n",
        "    img = self.generator(z)\n",
        "    self.discriminator.trainable = False\n",
        "    valid = self.discriminator(img)\n",
        "    model = Model(z, valid)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "  def train(self, epochs, batch_size=128, save_interval=50):\n",
        "\n",
        "    #　MNIST読み込み\n",
        "    from keras.datasets import mnist\n",
        "    (x_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "    # 正規化\n",
        "    x_train = x_train / 255.\n",
        "    # チャンネル次元を増やす\n",
        "    x_train = np.expand_dims(x_train, axis=3)\n",
        "\n",
        "    half_batch = int(batch_size / 2)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "      # -------------------------\n",
        "      # Discriminatorの学習\n",
        "      # -------------------------\n",
        "\n",
        "      # バッチサイズの半数をGeneratorから生成\n",
        "      noise = np.random.normal(0, 1, (half_batch, self.z_dim))\n",
        "      gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "      # バッチサイズの半数を教師データからピックアップ\n",
        "      idx = np.random.randint(0, x_train.shape[0], half_batch)\n",
        "      imgs = x_train[idx]\n",
        "\n",
        "      # Discriminatorを学習\n",
        "      # 本物データと偽物データは別々に学習させる\n",
        "      d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1))) # 本物\n",
        "      d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1))) # 偽物\n",
        "      # それぞれの損失関数を平均\n",
        "      d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "      # -----------------------\n",
        "      # Generatorの学習\n",
        "      # -----------------------\n",
        "\n",
        "      noise = np.random.normal(0, 1, (batch_size, self.z_dim))\n",
        "\n",
        "      # 生成データの正解データは本物\n",
        "      valid_y = np.array([1] * batch_size)\n",
        "\n",
        "      # Generatorを学習\n",
        "      g_loss = self.combined.train_on_batch(noise, valid_y)\n",
        "\n",
        "      # 進捗の表示\n",
        "      print(\"%d [ D loss: %f, acc.: %2.f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dCCGEfBjuuvL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7687
        },
        "outputId": "9dedbb3c-f051-4958-f3ba-38d246eac190"
      },
      "cell_type": "code",
      "source": [
        "model = GAN()\n",
        "model.train(epochs=400)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_14 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_90 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_66 (LeakyReLU)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_91 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_67 (LeakyReLU)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_92 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 533,505\n",
            "Trainable params: 533,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_93 (Dense)             (None, 256)               25856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_68 (LeakyReLU)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_94 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_69 (LeakyReLU)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_41 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_95 (Dense)             (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_70 (LeakyReLU)   (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense_96 (Dense)             (None, 784)               803600    \n",
            "_________________________________________________________________\n",
            "reshape_12 (Reshape)         (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 1,493,520\n",
            "Trainable params: 1,489,936\n",
            "Non-trainable params: 3,584\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 [ D loss: 0.830534, acc.:  6%] [G loss: 0.755106]\n",
            "1 [ D loss: 0.702389, acc.: 55%] [G loss: 0.795347]\n",
            "2 [ D loss: 0.565958, acc.: 79%] [G loss: 0.905910]\n",
            "3 [ D loss: 0.476690, acc.: 88%] [G loss: 0.987461]\n",
            "4 [ D loss: 0.425834, acc.: 90%] [G loss: 1.040646]\n",
            "5 [ D loss: 0.370454, acc.: 95%] [G loss: 1.123937]\n",
            "6 [ D loss: 0.357645, acc.: 96%] [G loss: 1.222459]\n",
            "7 [ D loss: 0.312498, acc.: 98%] [G loss: 1.317365]\n",
            "8 [ D loss: 0.298509, acc.: 97%] [G loss: 1.378426]\n",
            "9 [ D loss: 0.250113, acc.: 98%] [G loss: 1.478060]\n",
            "10 [ D loss: 0.232984, acc.: 99%] [G loss: 1.525517]\n",
            "11 [ D loss: 0.235929, acc.: 99%] [G loss: 1.603925]\n",
            "12 [ D loss: 0.196523, acc.: 99%] [G loss: 1.748913]\n",
            "13 [ D loss: 0.181352, acc.: 99%] [G loss: 1.795248]\n",
            "14 [ D loss: 0.172067, acc.: 100%] [G loss: 1.905810]\n",
            "15 [ D loss: 0.144358, acc.: 100%] [G loss: 1.928936]\n",
            "16 [ D loss: 0.141118, acc.: 100%] [G loss: 2.032755]\n",
            "17 [ D loss: 0.142047, acc.: 100%] [G loss: 2.042252]\n",
            "18 [ D loss: 0.126934, acc.: 99%] [G loss: 2.150100]\n",
            "19 [ D loss: 0.129182, acc.: 100%] [G loss: 2.185498]\n",
            "20 [ D loss: 0.122206, acc.: 100%] [G loss: 2.231553]\n",
            "21 [ D loss: 0.114045, acc.: 100%] [G loss: 2.300299]\n",
            "22 [ D loss: 0.111973, acc.: 100%] [G loss: 2.391098]\n",
            "23 [ D loss: 0.085987, acc.: 100%] [G loss: 2.445620]\n",
            "24 [ D loss: 0.080895, acc.: 100%] [G loss: 2.487198]\n",
            "25 [ D loss: 0.077951, acc.: 100%] [G loss: 2.501720]\n",
            "26 [ D loss: 0.088395, acc.: 100%] [G loss: 2.616688]\n",
            "27 [ D loss: 0.092042, acc.: 99%] [G loss: 2.606465]\n",
            "28 [ D loss: 0.077567, acc.: 100%] [G loss: 2.695161]\n",
            "29 [ D loss: 0.086870, acc.: 100%] [G loss: 2.758002]\n",
            "30 [ D loss: 0.089118, acc.: 100%] [G loss: 2.794081]\n",
            "31 [ D loss: 0.065606, acc.: 100%] [G loss: 2.895675]\n",
            "32 [ D loss: 0.092945, acc.: 100%] [G loss: 2.827471]\n",
            "33 [ D loss: 0.066191, acc.: 100%] [G loss: 2.927490]\n",
            "34 [ D loss: 0.069558, acc.: 100%] [G loss: 3.066624]\n",
            "35 [ D loss: 0.074912, acc.: 99%] [G loss: 3.056310]\n",
            "36 [ D loss: 0.081651, acc.: 99%] [G loss: 3.072585]\n",
            "37 [ D loss: 0.080005, acc.: 99%] [G loss: 3.076463]\n",
            "38 [ D loss: 0.075043, acc.: 100%] [G loss: 3.111851]\n",
            "39 [ D loss: 0.060234, acc.: 100%] [G loss: 3.148422]\n",
            "40 [ D loss: 0.063966, acc.: 100%] [G loss: 3.087545]\n",
            "41 [ D loss: 0.074408, acc.: 100%] [G loss: 3.128295]\n",
            "42 [ D loss: 0.082579, acc.: 99%] [G loss: 3.128385]\n",
            "43 [ D loss: 0.063020, acc.: 100%] [G loss: 3.362089]\n",
            "44 [ D loss: 0.058658, acc.: 100%] [G loss: 3.250151]\n",
            "45 [ D loss: 0.090520, acc.: 99%] [G loss: 3.268804]\n",
            "46 [ D loss: 0.133662, acc.: 96%] [G loss: 3.413644]\n",
            "47 [ D loss: 0.094271, acc.: 99%] [G loss: 3.569454]\n",
            "48 [ D loss: 0.095227, acc.: 99%] [G loss: 3.413117]\n",
            "49 [ D loss: 0.110065, acc.: 98%] [G loss: 3.481270]\n",
            "50 [ D loss: 0.093336, acc.: 98%] [G loss: 3.526143]\n",
            "51 [ D loss: 0.093855, acc.: 100%] [G loss: 3.540737]\n",
            "52 [ D loss: 0.110525, acc.: 98%] [G loss: 3.340124]\n",
            "53 [ D loss: 0.117592, acc.: 97%] [G loss: 3.561915]\n",
            "54 [ D loss: 0.145999, acc.: 95%] [G loss: 3.729955]\n",
            "55 [ D loss: 0.138149, acc.: 98%] [G loss: 3.722536]\n",
            "56 [ D loss: 0.147919, acc.: 95%] [G loss: 3.717211]\n",
            "57 [ D loss: 0.203195, acc.: 93%] [G loss: 3.546681]\n",
            "58 [ D loss: 0.119383, acc.: 97%] [G loss: 3.519114]\n",
            "59 [ D loss: 0.205028, acc.: 94%] [G loss: 3.443637]\n",
            "60 [ D loss: 0.186603, acc.: 96%] [G loss: 3.407105]\n",
            "61 [ D loss: 0.170687, acc.: 95%] [G loss: 3.395917]\n",
            "62 [ D loss: 0.175395, acc.: 94%] [G loss: 3.467097]\n",
            "63 [ D loss: 0.188196, acc.: 95%] [G loss: 3.515682]\n",
            "64 [ D loss: 0.426483, acc.: 83%] [G loss: 3.722177]\n",
            "65 [ D loss: 0.306771, acc.: 88%] [G loss: 3.732277]\n",
            "66 [ D loss: 0.381470, acc.: 84%] [G loss: 3.568919]\n",
            "67 [ D loss: 0.322333, acc.: 88%] [G loss: 3.554231]\n",
            "68 [ D loss: 0.237610, acc.: 92%] [G loss: 3.142180]\n",
            "69 [ D loss: 0.190091, acc.: 92%] [G loss: 2.838966]\n",
            "70 [ D loss: 0.173084, acc.: 98%] [G loss: 2.773499]\n",
            "71 [ D loss: 0.232054, acc.: 92%] [G loss: 2.716577]\n",
            "72 [ D loss: 0.264308, acc.: 90%] [G loss: 2.938355]\n",
            "73 [ D loss: 0.341109, acc.: 86%] [G loss: 3.449317]\n",
            "74 [ D loss: 0.331836, acc.: 88%] [G loss: 3.250250]\n",
            "75 [ D loss: 0.326708, acc.: 87%] [G loss: 3.098372]\n",
            "76 [ D loss: 0.406556, acc.: 80%] [G loss: 2.885853]\n",
            "77 [ D loss: 0.297845, acc.: 91%] [G loss: 2.943789]\n",
            "78 [ D loss: 0.492286, acc.: 77%] [G loss: 3.172678]\n",
            "79 [ D loss: 0.338055, acc.: 87%] [G loss: 3.321828]\n",
            "80 [ D loss: 0.491354, acc.: 77%] [G loss: 2.950096]\n",
            "81 [ D loss: 0.384095, acc.: 80%] [G loss: 2.855352]\n",
            "82 [ D loss: 0.381561, acc.: 84%] [G loss: 2.823654]\n",
            "83 [ D loss: 0.305055, acc.: 87%] [G loss: 2.617926]\n",
            "84 [ D loss: 0.357600, acc.: 84%] [G loss: 2.806453]\n",
            "85 [ D loss: 0.347458, acc.: 88%] [G loss: 2.838684]\n",
            "86 [ D loss: 0.362895, acc.: 84%] [G loss: 2.626877]\n",
            "87 [ D loss: 0.303933, acc.: 89%] [G loss: 2.543204]\n",
            "88 [ D loss: 0.285919, acc.: 91%] [G loss: 2.450930]\n",
            "89 [ D loss: 0.284665, acc.: 88%] [G loss: 2.569203]\n",
            "90 [ D loss: 0.369709, acc.: 84%] [G loss: 3.015599]\n",
            "91 [ D loss: 0.360916, acc.: 84%] [G loss: 2.727786]\n",
            "92 [ D loss: 0.391682, acc.: 80%] [G loss: 2.956199]\n",
            "93 [ D loss: 0.401712, acc.: 80%] [G loss: 3.029169]\n",
            "94 [ D loss: 0.382180, acc.: 84%] [G loss: 2.766768]\n",
            "95 [ D loss: 0.362396, acc.: 84%] [G loss: 2.627909]\n",
            "96 [ D loss: 0.384291, acc.: 80%] [G loss: 2.721321]\n",
            "97 [ D loss: 0.519611, acc.: 74%] [G loss: 2.492119]\n",
            "98 [ D loss: 0.413840, acc.: 81%] [G loss: 2.754337]\n",
            "99 [ D loss: 0.593464, acc.: 70%] [G loss: 2.688982]\n",
            "100 [ D loss: 0.614958, acc.: 67%] [G loss: 2.989299]\n",
            "101 [ D loss: 0.487513, acc.: 73%] [G loss: 2.743784]\n",
            "102 [ D loss: 0.611094, acc.: 72%] [G loss: 2.520951]\n",
            "103 [ D loss: 0.460449, acc.: 77%] [G loss: 2.521217]\n",
            "104 [ D loss: 0.452949, acc.: 80%] [G loss: 2.658945]\n",
            "105 [ D loss: 0.350804, acc.: 88%] [G loss: 2.791549]\n",
            "106 [ D loss: 0.413494, acc.: 80%] [G loss: 2.703635]\n",
            "107 [ D loss: 0.436536, acc.: 78%] [G loss: 2.630847]\n",
            "108 [ D loss: 0.508036, acc.: 73%] [G loss: 2.781850]\n",
            "109 [ D loss: 0.382648, acc.: 83%] [G loss: 2.930088]\n",
            "110 [ D loss: 0.531226, acc.: 70%] [G loss: 2.865045]\n",
            "111 [ D loss: 0.436913, acc.: 80%] [G loss: 2.815239]\n",
            "112 [ D loss: 0.491914, acc.: 76%] [G loss: 2.603794]\n",
            "113 [ D loss: 0.471858, acc.: 78%] [G loss: 2.614873]\n",
            "114 [ D loss: 0.433893, acc.: 80%] [G loss: 2.485842]\n",
            "115 [ D loss: 0.480990, acc.: 80%] [G loss: 2.857108]\n",
            "116 [ D loss: 0.537165, acc.: 75%] [G loss: 2.673419]\n",
            "117 [ D loss: 0.459211, acc.: 79%] [G loss: 2.544113]\n",
            "118 [ D loss: 0.469426, acc.: 73%] [G loss: 2.655065]\n",
            "119 [ D loss: 0.382136, acc.: 85%] [G loss: 2.593013]\n",
            "120 [ D loss: 0.582685, acc.: 68%] [G loss: 3.223067]\n",
            "121 [ D loss: 0.433778, acc.: 79%] [G loss: 2.974765]\n",
            "122 [ D loss: 0.514763, acc.: 73%] [G loss: 2.841256]\n",
            "123 [ D loss: 0.546837, acc.: 74%] [G loss: 2.671650]\n",
            "124 [ D loss: 0.542215, acc.: 73%] [G loss: 2.695627]\n",
            "125 [ D loss: 0.422001, acc.: 79%] [G loss: 2.548206]\n",
            "126 [ D loss: 0.545132, acc.: 73%] [G loss: 2.625129]\n",
            "127 [ D loss: 0.446526, acc.: 79%] [G loss: 2.713679]\n",
            "128 [ D loss: 0.473250, acc.: 78%] [G loss: 2.925534]\n",
            "129 [ D loss: 0.428420, acc.: 81%] [G loss: 2.751947]\n",
            "130 [ D loss: 0.467844, acc.: 74%] [G loss: 2.591913]\n",
            "131 [ D loss: 0.429084, acc.: 84%] [G loss: 2.511898]\n",
            "132 [ D loss: 0.524762, acc.: 74%] [G loss: 2.723186]\n",
            "133 [ D loss: 0.483682, acc.: 75%] [G loss: 2.558784]\n",
            "134 [ D loss: 0.572905, acc.: 66%] [G loss: 3.146552]\n",
            "135 [ D loss: 0.473800, acc.: 77%] [G loss: 2.861948]\n",
            "136 [ D loss: 0.538496, acc.: 69%] [G loss: 2.649652]\n",
            "137 [ D loss: 0.462307, acc.: 77%] [G loss: 2.652200]\n",
            "138 [ D loss: 0.458967, acc.: 77%] [G loss: 2.419335]\n",
            "139 [ D loss: 0.548936, acc.: 70%] [G loss: 2.494739]\n",
            "140 [ D loss: 0.483364, acc.: 77%] [G loss: 2.856807]\n",
            "141 [ D loss: 0.363163, acc.: 88%] [G loss: 2.631568]\n",
            "142 [ D loss: 0.556446, acc.: 70%] [G loss: 2.410998]\n",
            "143 [ D loss: 0.498305, acc.: 75%] [G loss: 2.992441]\n",
            "144 [ D loss: 0.436280, acc.: 80%] [G loss: 2.939218]\n",
            "145 [ D loss: 0.458132, acc.: 77%] [G loss: 2.897215]\n",
            "146 [ D loss: 0.487171, acc.: 73%] [G loss: 2.530718]\n",
            "147 [ D loss: 0.408690, acc.: 86%] [G loss: 2.332181]\n",
            "148 [ D loss: 0.404029, acc.: 82%] [G loss: 2.670680]\n",
            "149 [ D loss: 0.412174, acc.: 84%] [G loss: 2.797072]\n",
            "150 [ D loss: 0.459277, acc.: 80%] [G loss: 2.790000]\n",
            "151 [ D loss: 0.463725, acc.: 79%] [G loss: 2.674717]\n",
            "152 [ D loss: 0.428489, acc.: 83%] [G loss: 2.387826]\n",
            "153 [ D loss: 0.394589, acc.: 82%] [G loss: 2.584451]\n",
            "154 [ D loss: 0.385841, acc.: 85%] [G loss: 2.819507]\n",
            "155 [ D loss: 0.385239, acc.: 88%] [G loss: 2.837643]\n",
            "156 [ D loss: 0.406049, acc.: 81%] [G loss: 2.905242]\n",
            "157 [ D loss: 0.416759, acc.: 81%] [G loss: 2.688014]\n",
            "158 [ D loss: 0.485151, acc.: 77%] [G loss: 3.095911]\n",
            "159 [ D loss: 0.435158, acc.: 79%] [G loss: 2.712197]\n",
            "160 [ D loss: 0.512511, acc.: 75%] [G loss: 2.569308]\n",
            "161 [ D loss: 0.456912, acc.: 80%] [G loss: 3.093250]\n",
            "162 [ D loss: 0.416524, acc.: 78%] [G loss: 2.853603]\n",
            "163 [ D loss: 0.539613, acc.: 73%] [G loss: 2.568631]\n",
            "164 [ D loss: 0.463657, acc.: 79%] [G loss: 2.816706]\n",
            "165 [ D loss: 0.465181, acc.: 77%] [G loss: 2.987332]\n",
            "166 [ D loss: 0.438568, acc.: 78%] [G loss: 2.699271]\n",
            "167 [ D loss: 0.426920, acc.: 78%] [G loss: 2.661345]\n",
            "168 [ D loss: 0.445015, acc.: 81%] [G loss: 2.577049]\n",
            "169 [ D loss: 0.514035, acc.: 73%] [G loss: 2.729473]\n",
            "170 [ D loss: 0.434866, acc.: 78%] [G loss: 2.336102]\n",
            "171 [ D loss: 0.563259, acc.: 73%] [G loss: 2.949634]\n",
            "172 [ D loss: 0.488287, acc.: 76%] [G loss: 2.920213]\n",
            "173 [ D loss: 0.533303, acc.: 69%] [G loss: 2.633185]\n",
            "174 [ D loss: 0.454043, acc.: 81%] [G loss: 2.643462]\n",
            "175 [ D loss: 0.515429, acc.: 70%] [G loss: 2.912066]\n",
            "176 [ D loss: 0.520578, acc.: 73%] [G loss: 2.637114]\n",
            "177 [ D loss: 0.606447, acc.: 62%] [G loss: 2.761161]\n",
            "178 [ D loss: 0.535199, acc.: 70%] [G loss: 2.982261]\n",
            "179 [ D loss: 0.520476, acc.: 70%] [G loss: 2.905983]\n",
            "180 [ D loss: 0.625994, acc.: 66%] [G loss: 2.608144]\n",
            "181 [ D loss: 0.547835, acc.: 69%] [G loss: 2.720917]\n",
            "182 [ D loss: 0.537795, acc.: 73%] [G loss: 2.941145]\n",
            "183 [ D loss: 0.557044, acc.: 66%] [G loss: 2.538535]\n",
            "184 [ D loss: 0.604842, acc.: 66%] [G loss: 2.592513]\n",
            "185 [ D loss: 0.516590, acc.: 72%] [G loss: 2.921143]\n",
            "186 [ D loss: 0.619117, acc.: 62%] [G loss: 2.843172]\n",
            "187 [ D loss: 0.527640, acc.: 70%] [G loss: 2.698720]\n",
            "188 [ D loss: 0.642837, acc.: 59%] [G loss: 2.856688]\n",
            "189 [ D loss: 0.549645, acc.: 70%] [G loss: 2.454041]\n",
            "190 [ D loss: 0.647062, acc.: 66%] [G loss: 2.593388]\n",
            "191 [ D loss: 0.658269, acc.: 57%] [G loss: 2.997897]\n",
            "192 [ D loss: 0.547284, acc.: 66%] [G loss: 2.728624]\n",
            "193 [ D loss: 0.600796, acc.: 66%] [G loss: 2.453938]\n",
            "194 [ D loss: 0.612923, acc.: 66%] [G loss: 2.513021]\n",
            "195 [ D loss: 0.592933, acc.: 65%] [G loss: 2.764856]\n",
            "196 [ D loss: 0.625025, acc.: 61%] [G loss: 2.553009]\n",
            "197 [ D loss: 0.596428, acc.: 65%] [G loss: 2.513713]\n",
            "198 [ D loss: 0.628256, acc.: 60%] [G loss: 2.634111]\n",
            "199 [ D loss: 0.553270, acc.: 65%] [G loss: 2.490287]\n",
            "200 [ D loss: 0.653785, acc.: 58%] [G loss: 2.485611]\n",
            "201 [ D loss: 0.637704, acc.: 59%] [G loss: 2.714200]\n",
            "202 [ D loss: 0.596017, acc.: 60%] [G loss: 2.355802]\n",
            "203 [ D loss: 0.640625, acc.: 58%] [G loss: 2.320588]\n",
            "204 [ D loss: 0.724516, acc.: 48%] [G loss: 2.634909]\n",
            "205 [ D loss: 0.563755, acc.: 69%] [G loss: 2.622673]\n",
            "206 [ D loss: 0.595138, acc.: 58%] [G loss: 2.234393]\n",
            "207 [ D loss: 0.593901, acc.: 64%] [G loss: 2.580383]\n",
            "208 [ D loss: 0.640310, acc.: 53%] [G loss: 2.433426]\n",
            "209 [ D loss: 0.631540, acc.: 67%] [G loss: 2.582888]\n",
            "210 [ D loss: 0.611960, acc.: 62%] [G loss: 2.485995]\n",
            "211 [ D loss: 0.723148, acc.: 49%] [G loss: 2.377669]\n",
            "212 [ D loss: 0.665843, acc.: 57%] [G loss: 2.465028]\n",
            "213 [ D loss: 0.644225, acc.: 58%] [G loss: 2.193546]\n",
            "214 [ D loss: 0.697858, acc.: 57%] [G loss: 2.125037]\n",
            "215 [ D loss: 0.679302, acc.: 58%] [G loss: 2.179113]\n",
            "216 [ D loss: 0.584583, acc.: 69%] [G loss: 2.343675]\n",
            "217 [ D loss: 0.600307, acc.: 60%] [G loss: 2.215345]\n",
            "218 [ D loss: 0.663846, acc.: 59%] [G loss: 2.250042]\n",
            "219 [ D loss: 0.669806, acc.: 56%] [G loss: 2.211451]\n",
            "220 [ D loss: 0.663746, acc.: 59%] [G loss: 2.171807]\n",
            "221 [ D loss: 0.708024, acc.: 51%] [G loss: 2.242615]\n",
            "222 [ D loss: 0.612293, acc.: 63%] [G loss: 2.133897]\n",
            "223 [ D loss: 0.647340, acc.: 59%] [G loss: 2.214490]\n",
            "224 [ D loss: 0.623633, acc.: 68%] [G loss: 2.145322]\n",
            "225 [ D loss: 0.605676, acc.: 64%] [G loss: 2.032074]\n",
            "226 [ D loss: 0.570749, acc.: 63%] [G loss: 2.019613]\n",
            "227 [ D loss: 0.586391, acc.: 68%] [G loss: 2.069402]\n",
            "228 [ D loss: 0.619099, acc.: 62%] [G loss: 2.196381]\n",
            "229 [ D loss: 0.591298, acc.: 66%] [G loss: 2.173319]\n",
            "230 [ D loss: 0.592393, acc.: 65%] [G loss: 2.119790]\n",
            "231 [ D loss: 0.574619, acc.: 68%] [G loss: 2.069005]\n",
            "232 [ D loss: 0.649384, acc.: 62%] [G loss: 2.068841]\n",
            "233 [ D loss: 0.638096, acc.: 57%] [G loss: 2.079864]\n",
            "234 [ D loss: 0.595372, acc.: 64%] [G loss: 2.089802]\n",
            "235 [ D loss: 0.637287, acc.: 62%] [G loss: 2.058540]\n",
            "236 [ D loss: 0.629173, acc.: 65%] [G loss: 1.965778]\n",
            "237 [ D loss: 0.652352, acc.: 56%] [G loss: 1.923369]\n",
            "238 [ D loss: 0.608855, acc.: 62%] [G loss: 2.182967]\n",
            "239 [ D loss: 0.605560, acc.: 57%] [G loss: 1.895929]\n",
            "240 [ D loss: 0.719729, acc.: 52%] [G loss: 1.945420]\n",
            "241 [ D loss: 0.647721, acc.: 57%] [G loss: 1.819803]\n",
            "242 [ D loss: 0.689179, acc.: 55%] [G loss: 1.831814]\n",
            "243 [ D loss: 0.655275, acc.: 54%] [G loss: 2.004439]\n",
            "244 [ D loss: 0.654948, acc.: 58%] [G loss: 1.909927]\n",
            "245 [ D loss: 0.640838, acc.: 58%] [G loss: 1.931160]\n",
            "246 [ D loss: 0.629134, acc.: 58%] [G loss: 1.814817]\n",
            "247 [ D loss: 0.634298, acc.: 59%] [G loss: 1.866275]\n",
            "248 [ D loss: 0.625852, acc.: 62%] [G loss: 1.839381]\n",
            "249 [ D loss: 0.640473, acc.: 58%] [G loss: 1.881602]\n",
            "250 [ D loss: 0.628179, acc.: 57%] [G loss: 1.869673]\n",
            "251 [ D loss: 0.596425, acc.: 59%] [G loss: 1.822033]\n",
            "252 [ D loss: 0.640371, acc.: 60%] [G loss: 1.744726]\n",
            "253 [ D loss: 0.667378, acc.: 56%] [G loss: 1.793598]\n",
            "254 [ D loss: 0.606058, acc.: 62%] [G loss: 1.828240]\n",
            "255 [ D loss: 0.661480, acc.: 59%] [G loss: 1.701490]\n",
            "256 [ D loss: 0.623704, acc.: 59%] [G loss: 1.753621]\n",
            "257 [ D loss: 0.651501, acc.: 58%] [G loss: 1.773598]\n",
            "258 [ D loss: 0.606901, acc.: 59%] [G loss: 1.763432]\n",
            "259 [ D loss: 0.609062, acc.: 62%] [G loss: 1.787917]\n",
            "260 [ D loss: 0.630635, acc.: 59%] [G loss: 1.749273]\n",
            "261 [ D loss: 0.611296, acc.: 63%] [G loss: 1.772704]\n",
            "262 [ D loss: 0.607979, acc.: 65%] [G loss: 1.753894]\n",
            "263 [ D loss: 0.631294, acc.: 62%] [G loss: 1.785009]\n",
            "264 [ D loss: 0.621736, acc.: 59%] [G loss: 1.717111]\n",
            "265 [ D loss: 0.694956, acc.: 56%] [G loss: 1.749370]\n",
            "266 [ D loss: 0.643387, acc.: 58%] [G loss: 1.707600]\n",
            "267 [ D loss: 0.624272, acc.: 58%] [G loss: 1.773637]\n",
            "268 [ D loss: 0.614848, acc.: 61%] [G loss: 1.754738]\n",
            "269 [ D loss: 0.606868, acc.: 61%] [G loss: 1.684459]\n",
            "270 [ D loss: 0.649240, acc.: 60%] [G loss: 1.660628]\n",
            "271 [ D loss: 0.660343, acc.: 58%] [G loss: 1.675242]\n",
            "272 [ D loss: 0.684318, acc.: 55%] [G loss: 1.735433]\n",
            "273 [ D loss: 0.605520, acc.: 61%] [G loss: 1.739142]\n",
            "274 [ D loss: 0.675327, acc.: 58%] [G loss: 1.685342]\n",
            "275 [ D loss: 0.598867, acc.: 66%] [G loss: 1.809106]\n",
            "276 [ D loss: 0.634495, acc.: 58%] [G loss: 1.688893]\n",
            "277 [ D loss: 0.582305, acc.: 64%] [G loss: 1.764291]\n",
            "278 [ D loss: 0.605242, acc.: 62%] [G loss: 1.753739]\n",
            "279 [ D loss: 0.635535, acc.: 55%] [G loss: 1.684081]\n",
            "280 [ D loss: 0.638175, acc.: 58%] [G loss: 1.629580]\n",
            "281 [ D loss: 0.632928, acc.: 63%] [G loss: 1.645013]\n",
            "282 [ D loss: 0.640178, acc.: 59%] [G loss: 1.629989]\n",
            "283 [ D loss: 0.655330, acc.: 53%] [G loss: 1.669021]\n",
            "284 [ D loss: 0.642145, acc.: 59%] [G loss: 1.636362]\n",
            "285 [ D loss: 0.650564, acc.: 53%] [G loss: 1.582951]\n",
            "286 [ D loss: 0.655674, acc.: 53%] [G loss: 1.547570]\n",
            "287 [ D loss: 0.663764, acc.: 55%] [G loss: 1.577478]\n",
            "288 [ D loss: 0.602385, acc.: 62%] [G loss: 1.596464]\n",
            "289 [ D loss: 0.640274, acc.: 56%] [G loss: 1.590863]\n",
            "290 [ D loss: 0.628175, acc.: 59%] [G loss: 1.619652]\n",
            "291 [ D loss: 0.608520, acc.: 58%] [G loss: 1.636740]\n",
            "292 [ D loss: 0.636525, acc.: 56%] [G loss: 1.591808]\n",
            "293 [ D loss: 0.631576, acc.: 55%] [G loss: 1.622717]\n",
            "294 [ D loss: 0.575131, acc.: 65%] [G loss: 1.682439]\n",
            "295 [ D loss: 0.618429, acc.: 56%] [G loss: 1.608654]\n",
            "296 [ D loss: 0.596632, acc.: 63%] [G loss: 1.623756]\n",
            "297 [ D loss: 0.636886, acc.: 59%] [G loss: 1.525120]\n",
            "298 [ D loss: 0.608081, acc.: 61%] [G loss: 1.574982]\n",
            "299 [ D loss: 0.605760, acc.: 59%] [G loss: 1.553519]\n",
            "300 [ D loss: 0.612890, acc.: 59%] [G loss: 1.588312]\n",
            "301 [ D loss: 0.622383, acc.: 60%] [G loss: 1.499844]\n",
            "302 [ D loss: 0.607535, acc.: 62%] [G loss: 1.572346]\n",
            "303 [ D loss: 0.624658, acc.: 58%] [G loss: 1.603547]\n",
            "304 [ D loss: 0.636076, acc.: 55%] [G loss: 1.509988]\n",
            "305 [ D loss: 0.619482, acc.: 61%] [G loss: 1.557521]\n",
            "306 [ D loss: 0.668553, acc.: 54%] [G loss: 1.536957]\n",
            "307 [ D loss: 0.640163, acc.: 55%] [G loss: 1.542597]\n",
            "308 [ D loss: 0.607357, acc.: 62%] [G loss: 1.491519]\n",
            "309 [ D loss: 0.615758, acc.: 62%] [G loss: 1.482569]\n",
            "310 [ D loss: 0.640730, acc.: 54%] [G loss: 1.539742]\n",
            "311 [ D loss: 0.670365, acc.: 52%] [G loss: 1.458009]\n",
            "312 [ D loss: 0.645594, acc.: 59%] [G loss: 1.450278]\n",
            "313 [ D loss: 0.661941, acc.: 56%] [G loss: 1.417377]\n",
            "314 [ D loss: 0.628121, acc.: 55%] [G loss: 1.448523]\n",
            "315 [ D loss: 0.632278, acc.: 63%] [G loss: 1.539558]\n",
            "316 [ D loss: 0.639254, acc.: 55%] [G loss: 1.473641]\n",
            "317 [ D loss: 0.628632, acc.: 60%] [G loss: 1.470292]\n",
            "318 [ D loss: 0.651309, acc.: 55%] [G loss: 1.431671]\n",
            "319 [ D loss: 0.622723, acc.: 61%] [G loss: 1.452322]\n",
            "320 [ D loss: 0.642431, acc.: 59%] [G loss: 1.460017]\n",
            "321 [ D loss: 0.636955, acc.: 61%] [G loss: 1.415992]\n",
            "322 [ D loss: 0.638241, acc.: 61%] [G loss: 1.475983]\n",
            "323 [ D loss: 0.661630, acc.: 57%] [G loss: 1.468993]\n",
            "324 [ D loss: 0.619930, acc.: 61%] [G loss: 1.411797]\n",
            "325 [ D loss: 0.668069, acc.: 55%] [G loss: 1.388201]\n",
            "326 [ D loss: 0.622508, acc.: 62%] [G loss: 1.428957]\n",
            "327 [ D loss: 0.634499, acc.: 59%] [G loss: 1.440653]\n",
            "328 [ D loss: 0.635305, acc.: 61%] [G loss: 1.405746]\n",
            "329 [ D loss: 0.629686, acc.: 59%] [G loss: 1.407851]\n",
            "330 [ D loss: 0.646357, acc.: 55%] [G loss: 1.385097]\n",
            "331 [ D loss: 0.652492, acc.: 55%] [G loss: 1.382086]\n",
            "332 [ D loss: 0.618637, acc.: 61%] [G loss: 1.468268]\n",
            "333 [ D loss: 0.625063, acc.: 58%] [G loss: 1.472214]\n",
            "334 [ D loss: 0.630796, acc.: 57%] [G loss: 1.395074]\n",
            "335 [ D loss: 0.624535, acc.: 59%] [G loss: 1.371603]\n",
            "336 [ D loss: 0.611590, acc.: 62%] [G loss: 1.363001]\n",
            "337 [ D loss: 0.610769, acc.: 62%] [G loss: 1.411217]\n",
            "338 [ D loss: 0.621425, acc.: 54%] [G loss: 1.408764]\n",
            "339 [ D loss: 0.650039, acc.: 54%] [G loss: 1.389382]\n",
            "340 [ D loss: 0.603425, acc.: 62%] [G loss: 1.406467]\n",
            "341 [ D loss: 0.621273, acc.: 64%] [G loss: 1.372897]\n",
            "342 [ D loss: 0.620735, acc.: 61%] [G loss: 1.392453]\n",
            "343 [ D loss: 0.633287, acc.: 55%] [G loss: 1.377152]\n",
            "344 [ D loss: 0.617533, acc.: 60%] [G loss: 1.429566]\n",
            "345 [ D loss: 0.612365, acc.: 66%] [G loss: 1.386070]\n",
            "346 [ D loss: 0.629379, acc.: 60%] [G loss: 1.381165]\n",
            "347 [ D loss: 0.655696, acc.: 59%] [G loss: 1.330000]\n",
            "348 [ D loss: 0.611776, acc.: 66%] [G loss: 1.383395]\n",
            "349 [ D loss: 0.641940, acc.: 59%] [G loss: 1.370087]\n",
            "350 [ D loss: 0.640788, acc.: 60%] [G loss: 1.358181]\n",
            "351 [ D loss: 0.651820, acc.: 57%] [G loss: 1.352095]\n",
            "352 [ D loss: 0.646902, acc.: 59%] [G loss: 1.318378]\n",
            "353 [ D loss: 0.659652, acc.: 59%] [G loss: 1.297692]\n",
            "354 [ D loss: 0.666419, acc.: 59%] [G loss: 1.338275]\n",
            "355 [ D loss: 0.637946, acc.: 62%] [G loss: 1.362607]\n",
            "356 [ D loss: 0.661416, acc.: 59%] [G loss: 1.357031]\n",
            "357 [ D loss: 0.650545, acc.: 55%] [G loss: 1.308234]\n",
            "358 [ D loss: 0.635457, acc.: 60%] [G loss: 1.403323]\n",
            "359 [ D loss: 0.627224, acc.: 62%] [G loss: 1.352936]\n",
            "360 [ D loss: 0.638527, acc.: 59%] [G loss: 1.387222]\n",
            "361 [ D loss: 0.637136, acc.: 59%] [G loss: 1.412858]\n",
            "362 [ D loss: 0.619476, acc.: 65%] [G loss: 1.390121]\n",
            "363 [ D loss: 0.616974, acc.: 63%] [G loss: 1.405769]\n",
            "364 [ D loss: 0.612905, acc.: 61%] [G loss: 1.368192]\n",
            "365 [ D loss: 0.636994, acc.: 62%] [G loss: 1.371081]\n",
            "366 [ D loss: 0.605612, acc.: 65%] [G loss: 1.365006]\n",
            "367 [ D loss: 0.626672, acc.: 57%] [G loss: 1.355968]\n",
            "368 [ D loss: 0.595517, acc.: 66%] [G loss: 1.395142]\n",
            "369 [ D loss: 0.593552, acc.: 60%] [G loss: 1.383246]\n",
            "370 [ D loss: 0.638353, acc.: 57%] [G loss: 1.343132]\n",
            "371 [ D loss: 0.605955, acc.: 64%] [G loss: 1.320409]\n",
            "372 [ D loss: 0.625227, acc.: 64%] [G loss: 1.385514]\n",
            "373 [ D loss: 0.605127, acc.: 59%] [G loss: 1.373241]\n",
            "374 [ D loss: 0.632460, acc.: 61%] [G loss: 1.384476]\n",
            "375 [ D loss: 0.651114, acc.: 58%] [G loss: 1.314608]\n",
            "376 [ D loss: 0.617547, acc.: 64%] [G loss: 1.338612]\n",
            "377 [ D loss: 0.624935, acc.: 64%] [G loss: 1.284582]\n",
            "378 [ D loss: 0.618938, acc.: 62%] [G loss: 1.299277]\n",
            "379 [ D loss: 0.628770, acc.: 60%] [G loss: 1.379457]\n",
            "380 [ D loss: 0.616065, acc.: 64%] [G loss: 1.428556]\n",
            "381 [ D loss: 0.626548, acc.: 64%] [G loss: 1.373180]\n",
            "382 [ D loss: 0.656047, acc.: 61%] [G loss: 1.273767]\n",
            "383 [ D loss: 0.648341, acc.: 66%] [G loss: 1.243055]\n",
            "384 [ D loss: 0.629381, acc.: 62%] [G loss: 1.327251]\n",
            "385 [ D loss: 0.603058, acc.: 64%] [G loss: 1.348327]\n",
            "386 [ D loss: 0.614286, acc.: 62%] [G loss: 1.318468]\n",
            "387 [ D loss: 0.603354, acc.: 68%] [G loss: 1.338083]\n",
            "388 [ D loss: 0.627941, acc.: 62%] [G loss: 1.253305]\n",
            "389 [ D loss: 0.644088, acc.: 59%] [G loss: 1.245463]\n",
            "390 [ D loss: 0.646328, acc.: 57%] [G loss: 1.294355]\n",
            "391 [ D loss: 0.635385, acc.: 54%] [G loss: 1.289142]\n",
            "392 [ D loss: 0.636678, acc.: 59%] [G loss: 1.340091]\n",
            "393 [ D loss: 0.586782, acc.: 69%] [G loss: 1.385181]\n",
            "394 [ D loss: 0.577167, acc.: 67%] [G loss: 1.339635]\n",
            "395 [ D loss: 0.630698, acc.: 61%] [G loss: 1.290723]\n",
            "396 [ D loss: 0.647966, acc.: 60%] [G loss: 1.278626]\n",
            "397 [ D loss: 0.603706, acc.: 67%] [G loss: 1.319379]\n",
            "398 [ D loss: 0.599636, acc.: 67%] [G loss: 1.336065]\n",
            "399 [ D loss: 0.605573, acc.: 68%] [G loss: 1.320073]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-kzwwGA40AAT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "a8fb25b1-ab0a-4e4b-982a-3067deed4d88"
      },
      "cell_type": "code",
      "source": [
        "# 400 iteration\n",
        "generated_img = model.generator.predict(np.random.normal(0, 1, (10, 100)))\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 2))\n",
        "n =10\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(1, n, i + 1)\n",
        "    plt.imshow(np.squeeze(generated_img[i]))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAABsCAYAAAAyoVQIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f186e6c44e0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "qOZmQxZm9MBR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17887
        },
        "outputId": "b17d517a-96c3-41fc-837b-621d13956547"
      },
      "cell_type": "code",
      "source": [
        "model = GAN()\n",
        "model.train(epochs=1000)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_15 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_97 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_71 (LeakyReLU)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_98 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_72 (LeakyReLU)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_99 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 533,505\n",
            "Trainable params: 533,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_100 (Dense)            (None, 256)               25856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_73 (LeakyReLU)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_101 (Dense)            (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_74 (LeakyReLU)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_44 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_102 (Dense)            (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_75 (LeakyReLU)   (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_45 (Batc (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense_103 (Dense)            (None, 784)               803600    \n",
            "_________________________________________________________________\n",
            "reshape_13 (Reshape)         (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 1,493,520\n",
            "Trainable params: 1,489,936\n",
            "Non-trainable params: 3,584\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 [ D loss: 0.650426, acc.: 68%] [G loss: 0.746830]\n",
            "1 [ D loss: 0.612718, acc.: 68%] [G loss: 0.794291]\n",
            "2 [ D loss: 0.514570, acc.: 77%] [G loss: 0.890329]\n",
            "3 [ D loss: 0.403434, acc.: 91%] [G loss: 1.064851]\n",
            "4 [ D loss: 0.388591, acc.: 91%] [G loss: 1.142381]\n",
            "5 [ D loss: 0.314430, acc.: 98%] [G loss: 1.263888]\n",
            "6 [ D loss: 0.280230, acc.: 97%] [G loss: 1.353869]\n",
            "7 [ D loss: 0.260382, acc.: 100%] [G loss: 1.445542]\n",
            "8 [ D loss: 0.238112, acc.: 98%] [G loss: 1.525557]\n",
            "9 [ D loss: 0.216331, acc.: 99%] [G loss: 1.624096]\n",
            "10 [ D loss: 0.189460, acc.: 99%] [G loss: 1.694652]\n",
            "11 [ D loss: 0.193149, acc.: 100%] [G loss: 1.750156]\n",
            "12 [ D loss: 0.184444, acc.: 99%] [G loss: 1.846170]\n",
            "13 [ D loss: 0.150240, acc.: 100%] [G loss: 1.889411]\n",
            "14 [ D loss: 0.142256, acc.: 100%] [G loss: 1.995311]\n",
            "15 [ D loss: 0.143178, acc.: 100%] [G loss: 2.098474]\n",
            "16 [ D loss: 0.126450, acc.: 100%] [G loss: 2.183928]\n",
            "17 [ D loss: 0.106118, acc.: 100%] [G loss: 2.205107]\n",
            "18 [ D loss: 0.145411, acc.: 100%] [G loss: 2.345222]\n",
            "19 [ D loss: 0.088649, acc.: 100%] [G loss: 2.415515]\n",
            "20 [ D loss: 0.114310, acc.: 100%] [G loss: 2.435423]\n",
            "21 [ D loss: 0.082768, acc.: 100%] [G loss: 2.437003]\n",
            "22 [ D loss: 0.098237, acc.: 99%] [G loss: 2.506615]\n",
            "23 [ D loss: 0.076677, acc.: 100%] [G loss: 2.596488]\n",
            "24 [ D loss: 0.088401, acc.: 100%] [G loss: 2.647627]\n",
            "25 [ D loss: 0.070530, acc.: 100%] [G loss: 2.650848]\n",
            "26 [ D loss: 0.081193, acc.: 100%] [G loss: 2.691037]\n",
            "27 [ D loss: 0.087919, acc.: 100%] [G loss: 2.756618]\n",
            "28 [ D loss: 0.075078, acc.: 100%] [G loss: 2.792691]\n",
            "29 [ D loss: 0.072126, acc.: 100%] [G loss: 2.906641]\n",
            "30 [ D loss: 0.067837, acc.: 100%] [G loss: 2.931849]\n",
            "31 [ D loss: 0.070598, acc.: 100%] [G loss: 2.983716]\n",
            "32 [ D loss: 0.086534, acc.: 98%] [G loss: 3.100572]\n",
            "33 [ D loss: 0.052170, acc.: 100%] [G loss: 3.280805]\n",
            "34 [ D loss: 0.062454, acc.: 99%] [G loss: 3.231402]\n",
            "35 [ D loss: 0.057576, acc.: 100%] [G loss: 3.289144]\n",
            "36 [ D loss: 0.074486, acc.: 99%] [G loss: 3.261373]\n",
            "37 [ D loss: 0.079412, acc.: 99%] [G loss: 3.400151]\n",
            "38 [ D loss: 0.089389, acc.: 98%] [G loss: 3.461137]\n",
            "39 [ D loss: 0.073257, acc.: 100%] [G loss: 3.478911]\n",
            "40 [ D loss: 0.074166, acc.: 100%] [G loss: 3.356390]\n",
            "41 [ D loss: 0.086821, acc.: 100%] [G loss: 3.332712]\n",
            "42 [ D loss: 0.074049, acc.: 100%] [G loss: 3.506367]\n",
            "43 [ D loss: 0.077414, acc.: 100%] [G loss: 3.475425]\n",
            "44 [ D loss: 0.064323, acc.: 100%] [G loss: 3.482584]\n",
            "45 [ D loss: 0.072442, acc.: 100%] [G loss: 3.493523]\n",
            "46 [ D loss: 0.081693, acc.: 99%] [G loss: 3.446012]\n",
            "47 [ D loss: 0.136014, acc.: 97%] [G loss: 3.607209]\n",
            "48 [ D loss: 0.088898, acc.: 98%] [G loss: 3.591232]\n",
            "49 [ D loss: 0.110848, acc.: 98%] [G loss: 3.736748]\n",
            "50 [ D loss: 0.136274, acc.: 96%] [G loss: 3.833037]\n",
            "51 [ D loss: 0.169110, acc.: 97%] [G loss: 3.803089]\n",
            "52 [ D loss: 0.183040, acc.: 95%] [G loss: 3.596839]\n",
            "53 [ D loss: 0.143952, acc.: 98%] [G loss: 3.467865]\n",
            "54 [ D loss: 0.139691, acc.: 95%] [G loss: 3.542363]\n",
            "55 [ D loss: 0.179489, acc.: 95%] [G loss: 3.918241]\n",
            "56 [ D loss: 0.188867, acc.: 95%] [G loss: 3.865890]\n",
            "57 [ D loss: 0.208609, acc.: 93%] [G loss: 3.666832]\n",
            "58 [ D loss: 0.163654, acc.: 96%] [G loss: 3.585181]\n",
            "59 [ D loss: 0.155719, acc.: 96%] [G loss: 3.546653]\n",
            "60 [ D loss: 0.112612, acc.: 97%] [G loss: 3.383466]\n",
            "61 [ D loss: 0.197893, acc.: 92%] [G loss: 3.495415]\n",
            "62 [ D loss: 0.225908, acc.: 93%] [G loss: 3.751937]\n",
            "63 [ D loss: 0.315691, acc.: 88%] [G loss: 3.778392]\n",
            "64 [ D loss: 0.281811, acc.: 92%] [G loss: 3.695124]\n",
            "65 [ D loss: 0.205179, acc.: 94%] [G loss: 3.441614]\n",
            "66 [ D loss: 0.198156, acc.: 93%] [G loss: 3.480990]\n",
            "67 [ D loss: 0.231833, acc.: 91%] [G loss: 3.234653]\n",
            "68 [ D loss: 0.307240, acc.: 88%] [G loss: 3.320196]\n",
            "69 [ D loss: 0.316900, acc.: 87%] [G loss: 3.371084]\n",
            "70 [ D loss: 0.305065, acc.: 87%] [G loss: 3.292961]\n",
            "71 [ D loss: 0.319315, acc.: 87%] [G loss: 3.281854]\n",
            "72 [ D loss: 0.364320, acc.: 84%] [G loss: 3.409690]\n",
            "73 [ D loss: 0.288176, acc.: 92%] [G loss: 3.253635]\n",
            "74 [ D loss: 0.390144, acc.: 84%] [G loss: 3.302123]\n",
            "75 [ D loss: 0.373791, acc.: 85%] [G loss: 3.576471]\n",
            "76 [ D loss: 0.425964, acc.: 79%] [G loss: 3.418912]\n",
            "77 [ D loss: 0.324784, acc.: 86%] [G loss: 2.980592]\n",
            "78 [ D loss: 0.314726, acc.: 86%] [G loss: 3.075575]\n",
            "79 [ D loss: 0.388194, acc.: 82%] [G loss: 3.491946]\n",
            "80 [ D loss: 0.339899, acc.: 86%] [G loss: 3.522429]\n",
            "81 [ D loss: 0.408096, acc.: 81%] [G loss: 3.065487]\n",
            "82 [ D loss: 0.339936, acc.: 84%] [G loss: 3.090209]\n",
            "83 [ D loss: 0.368565, acc.: 85%] [G loss: 2.994290]\n",
            "84 [ D loss: 0.288984, acc.: 88%] [G loss: 3.179600]\n",
            "85 [ D loss: 0.342394, acc.: 86%] [G loss: 2.996305]\n",
            "86 [ D loss: 0.308468, acc.: 87%] [G loss: 2.623816]\n",
            "87 [ D loss: 0.348700, acc.: 83%] [G loss: 2.912634]\n",
            "88 [ D loss: 0.453282, acc.: 81%] [G loss: 3.119704]\n",
            "89 [ D loss: 0.352725, acc.: 84%] [G loss: 3.174128]\n",
            "90 [ D loss: 0.469612, acc.: 77%] [G loss: 2.923171]\n",
            "91 [ D loss: 0.422279, acc.: 78%] [G loss: 2.908564]\n",
            "92 [ D loss: 0.391720, acc.: 80%] [G loss: 2.869618]\n",
            "93 [ D loss: 0.436723, acc.: 77%] [G loss: 3.189023]\n",
            "94 [ D loss: 0.297395, acc.: 91%] [G loss: 3.160857]\n",
            "95 [ D loss: 0.424218, acc.: 78%] [G loss: 2.940711]\n",
            "96 [ D loss: 0.387761, acc.: 82%] [G loss: 2.696849]\n",
            "97 [ D loss: 0.266504, acc.: 95%] [G loss: 2.662600]\n",
            "98 [ D loss: 0.451904, acc.: 83%] [G loss: 3.171142]\n",
            "99 [ D loss: 0.417367, acc.: 84%] [G loss: 3.712007]\n",
            "100 [ D loss: 0.486968, acc.: 78%] [G loss: 3.580846]\n",
            "101 [ D loss: 0.492763, acc.: 73%] [G loss: 3.096957]\n",
            "102 [ D loss: 0.545293, acc.: 75%] [G loss: 3.088748]\n",
            "103 [ D loss: 0.375130, acc.: 87%] [G loss: 2.975245]\n",
            "104 [ D loss: 0.543168, acc.: 71%] [G loss: 2.883116]\n",
            "105 [ D loss: 0.590635, acc.: 69%] [G loss: 2.814692]\n",
            "106 [ D loss: 0.454195, acc.: 78%] [G loss: 2.749823]\n",
            "107 [ D loss: 0.402242, acc.: 83%] [G loss: 2.830611]\n",
            "108 [ D loss: 0.519271, acc.: 73%] [G loss: 2.662333]\n",
            "109 [ D loss: 0.385782, acc.: 85%] [G loss: 2.592192]\n",
            "110 [ D loss: 0.488240, acc.: 77%] [G loss: 2.857746]\n",
            "111 [ D loss: 0.535339, acc.: 76%] [G loss: 3.027868]\n",
            "112 [ D loss: 0.564815, acc.: 67%] [G loss: 2.699856]\n",
            "113 [ D loss: 0.429904, acc.: 80%] [G loss: 2.366557]\n",
            "114 [ D loss: 0.415753, acc.: 85%] [G loss: 2.468497]\n",
            "115 [ D loss: 0.425713, acc.: 82%] [G loss: 2.638516]\n",
            "116 [ D loss: 0.439989, acc.: 82%] [G loss: 2.568917]\n",
            "117 [ D loss: 0.443042, acc.: 77%] [G loss: 2.495685]\n",
            "118 [ D loss: 0.495097, acc.: 75%] [G loss: 2.764850]\n",
            "119 [ D loss: 0.520612, acc.: 73%] [G loss: 3.029811]\n",
            "120 [ D loss: 0.537170, acc.: 71%] [G loss: 2.839087]\n",
            "121 [ D loss: 0.449146, acc.: 77%] [G loss: 2.679186]\n",
            "122 [ D loss: 0.606467, acc.: 66%] [G loss: 2.814213]\n",
            "123 [ D loss: 0.505330, acc.: 73%] [G loss: 2.746876]\n",
            "124 [ D loss: 0.505572, acc.: 77%] [G loss: 2.823598]\n",
            "125 [ D loss: 0.500154, acc.: 73%] [G loss: 2.620150]\n",
            "126 [ D loss: 0.469301, acc.: 78%] [G loss: 2.690561]\n",
            "127 [ D loss: 0.394283, acc.: 84%] [G loss: 2.478492]\n",
            "128 [ D loss: 0.457285, acc.: 78%] [G loss: 2.511168]\n",
            "129 [ D loss: 0.414357, acc.: 80%] [G loss: 2.741380]\n",
            "130 [ D loss: 0.393352, acc.: 82%] [G loss: 2.704828]\n",
            "131 [ D loss: 0.468225, acc.: 80%] [G loss: 2.824413]\n",
            "132 [ D loss: 0.355745, acc.: 84%] [G loss: 2.860604]\n",
            "133 [ D loss: 0.408863, acc.: 80%] [G loss: 2.464368]\n",
            "134 [ D loss: 0.390548, acc.: 84%] [G loss: 2.581869]\n",
            "135 [ D loss: 0.462814, acc.: 77%] [G loss: 2.627563]\n",
            "136 [ D loss: 0.462399, acc.: 77%] [G loss: 2.921466]\n",
            "137 [ D loss: 0.360428, acc.: 86%] [G loss: 2.741135]\n",
            "138 [ D loss: 0.470431, acc.: 73%] [G loss: 2.743884]\n",
            "139 [ D loss: 0.426191, acc.: 83%] [G loss: 2.649937]\n",
            "140 [ D loss: 0.408888, acc.: 85%] [G loss: 2.626252]\n",
            "141 [ D loss: 0.417998, acc.: 84%] [G loss: 2.695879]\n",
            "142 [ D loss: 0.439394, acc.: 79%] [G loss: 2.477986]\n",
            "143 [ D loss: 0.398801, acc.: 84%] [G loss: 2.872530]\n",
            "144 [ D loss: 0.399069, acc.: 85%] [G loss: 2.845968]\n",
            "145 [ D loss: 0.433443, acc.: 86%] [G loss: 2.732327]\n",
            "146 [ D loss: 0.510523, acc.: 71%] [G loss: 2.985375]\n",
            "147 [ D loss: 0.480278, acc.: 74%] [G loss: 3.026010]\n",
            "148 [ D loss: 0.389813, acc.: 84%] [G loss: 2.677636]\n",
            "149 [ D loss: 0.470312, acc.: 78%] [G loss: 2.701015]\n",
            "150 [ D loss: 0.467551, acc.: 76%] [G loss: 2.655371]\n",
            "151 [ D loss: 0.457350, acc.: 76%] [G loss: 2.411706]\n",
            "152 [ D loss: 0.527675, acc.: 71%] [G loss: 2.501778]\n",
            "153 [ D loss: 0.464415, acc.: 80%] [G loss: 2.873816]\n",
            "154 [ D loss: 0.382540, acc.: 85%] [G loss: 2.678150]\n",
            "155 [ D loss: 0.463087, acc.: 79%] [G loss: 2.624085]\n",
            "156 [ D loss: 0.466356, acc.: 76%] [G loss: 2.661880]\n",
            "157 [ D loss: 0.453474, acc.: 80%] [G loss: 2.881293]\n",
            "158 [ D loss: 0.432536, acc.: 80%] [G loss: 2.860819]\n",
            "159 [ D loss: 0.434001, acc.: 79%] [G loss: 2.825871]\n",
            "160 [ D loss: 0.456361, acc.: 80%] [G loss: 2.843891]\n",
            "161 [ D loss: 0.411725, acc.: 79%] [G loss: 2.607746]\n",
            "162 [ D loss: 0.483792, acc.: 74%] [G loss: 2.578963]\n",
            "163 [ D loss: 0.499160, acc.: 78%] [G loss: 2.990636]\n",
            "164 [ D loss: 0.426956, acc.: 83%] [G loss: 2.870303]\n",
            "165 [ D loss: 0.453731, acc.: 77%] [G loss: 2.931825]\n",
            "166 [ D loss: 0.445353, acc.: 81%] [G loss: 2.921456]\n",
            "167 [ D loss: 0.474078, acc.: 74%] [G loss: 2.864259]\n",
            "168 [ D loss: 0.455764, acc.: 80%] [G loss: 2.795108]\n",
            "169 [ D loss: 0.440971, acc.: 78%] [G loss: 2.835004]\n",
            "170 [ D loss: 0.538944, acc.: 70%] [G loss: 2.728295]\n",
            "171 [ D loss: 0.447839, acc.: 81%] [G loss: 2.725519]\n",
            "172 [ D loss: 0.513798, acc.: 74%] [G loss: 2.641777]\n",
            "173 [ D loss: 0.484748, acc.: 79%] [G loss: 2.784839]\n",
            "174 [ D loss: 0.457848, acc.: 82%] [G loss: 2.752418]\n",
            "175 [ D loss: 0.630847, acc.: 61%] [G loss: 3.209633]\n",
            "176 [ D loss: 0.446209, acc.: 80%] [G loss: 3.375502]\n",
            "177 [ D loss: 0.510350, acc.: 70%] [G loss: 2.954323]\n",
            "178 [ D loss: 0.483291, acc.: 78%] [G loss: 2.899332]\n",
            "179 [ D loss: 0.436627, acc.: 82%] [G loss: 2.913607]\n",
            "180 [ D loss: 0.455909, acc.: 80%] [G loss: 2.833133]\n",
            "181 [ D loss: 0.489508, acc.: 77%] [G loss: 2.816023]\n",
            "182 [ D loss: 0.424304, acc.: 80%] [G loss: 2.748304]\n",
            "183 [ D loss: 0.495324, acc.: 77%] [G loss: 2.999494]\n",
            "184 [ D loss: 0.506105, acc.: 76%] [G loss: 3.009269]\n",
            "185 [ D loss: 0.477612, acc.: 77%] [G loss: 2.777005]\n",
            "186 [ D loss: 0.507368, acc.: 73%] [G loss: 2.934815]\n",
            "187 [ D loss: 0.528556, acc.: 70%] [G loss: 3.168607]\n",
            "188 [ D loss: 0.506794, acc.: 74%] [G loss: 3.025643]\n",
            "189 [ D loss: 0.483223, acc.: 75%] [G loss: 3.095543]\n",
            "190 [ D loss: 0.559190, acc.: 66%] [G loss: 2.834312]\n",
            "191 [ D loss: 0.554829, acc.: 66%] [G loss: 2.945840]\n",
            "192 [ D loss: 0.492544, acc.: 74%] [G loss: 3.061338]\n",
            "193 [ D loss: 0.512444, acc.: 75%] [G loss: 2.965704]\n",
            "194 [ D loss: 0.467196, acc.: 76%] [G loss: 3.023356]\n",
            "195 [ D loss: 0.590963, acc.: 70%] [G loss: 2.835967]\n",
            "196 [ D loss: 0.497147, acc.: 77%] [G loss: 2.824442]\n",
            "197 [ D loss: 0.542385, acc.: 70%] [G loss: 2.703064]\n",
            "198 [ D loss: 0.478191, acc.: 74%] [G loss: 2.729986]\n",
            "199 [ D loss: 0.574945, acc.: 67%] [G loss: 2.827338]\n",
            "200 [ D loss: 0.633461, acc.: 58%] [G loss: 2.637267]\n",
            "201 [ D loss: 0.586209, acc.: 62%] [G loss: 2.447389]\n",
            "202 [ D loss: 0.576934, acc.: 69%] [G loss: 2.942962]\n",
            "203 [ D loss: 0.508419, acc.: 70%] [G loss: 2.899946]\n",
            "204 [ D loss: 0.524398, acc.: 69%] [G loss: 2.666218]\n",
            "205 [ D loss: 0.588233, acc.: 66%] [G loss: 2.722816]\n",
            "206 [ D loss: 0.549641, acc.: 72%] [G loss: 2.715393]\n",
            "207 [ D loss: 0.572837, acc.: 69%] [G loss: 2.817620]\n",
            "208 [ D loss: 0.515030, acc.: 71%] [G loss: 2.632743]\n",
            "209 [ D loss: 0.573638, acc.: 65%] [G loss: 2.827113]\n",
            "210 [ D loss: 0.492070, acc.: 74%] [G loss: 2.629142]\n",
            "211 [ D loss: 0.536543, acc.: 77%] [G loss: 2.492252]\n",
            "212 [ D loss: 0.587949, acc.: 66%] [G loss: 3.063608]\n",
            "213 [ D loss: 0.532971, acc.: 70%] [G loss: 2.671220]\n",
            "214 [ D loss: 0.624234, acc.: 64%] [G loss: 2.711080]\n",
            "215 [ D loss: 0.488244, acc.: 79%] [G loss: 2.656752]\n",
            "216 [ D loss: 0.645178, acc.: 59%] [G loss: 2.888235]\n",
            "217 [ D loss: 0.504295, acc.: 73%] [G loss: 2.783979]\n",
            "218 [ D loss: 0.580978, acc.: 66%] [G loss: 2.729675]\n",
            "219 [ D loss: 0.640419, acc.: 60%] [G loss: 2.942792]\n",
            "220 [ D loss: 0.583813, acc.: 69%] [G loss: 2.673625]\n",
            "221 [ D loss: 0.563432, acc.: 71%] [G loss: 2.526648]\n",
            "222 [ D loss: 0.566124, acc.: 70%] [G loss: 2.531592]\n",
            "223 [ D loss: 0.546455, acc.: 69%] [G loss: 2.463296]\n",
            "224 [ D loss: 0.590793, acc.: 66%] [G loss: 2.619433]\n",
            "225 [ D loss: 0.559189, acc.: 65%] [G loss: 2.606337]\n",
            "226 [ D loss: 0.546485, acc.: 70%] [G loss: 2.654690]\n",
            "227 [ D loss: 0.572179, acc.: 70%] [G loss: 2.649102]\n",
            "228 [ D loss: 0.571430, acc.: 65%] [G loss: 2.498435]\n",
            "229 [ D loss: 0.609762, acc.: 63%] [G loss: 2.489935]\n",
            "230 [ D loss: 0.574795, acc.: 67%] [G loss: 2.496049]\n",
            "231 [ D loss: 0.629950, acc.: 62%] [G loss: 2.349962]\n",
            "232 [ D loss: 0.611897, acc.: 60%] [G loss: 2.395805]\n",
            "233 [ D loss: 0.634200, acc.: 56%] [G loss: 2.599691]\n",
            "234 [ D loss: 0.547375, acc.: 70%] [G loss: 2.429397]\n",
            "235 [ D loss: 0.634913, acc.: 59%] [G loss: 2.518966]\n",
            "236 [ D loss: 0.522964, acc.: 74%] [G loss: 2.310645]\n",
            "237 [ D loss: 0.626225, acc.: 66%] [G loss: 2.326313]\n",
            "238 [ D loss: 0.600670, acc.: 63%] [G loss: 2.549015]\n",
            "239 [ D loss: 0.614918, acc.: 64%] [G loss: 2.401628]\n",
            "240 [ D loss: 0.681367, acc.: 59%] [G loss: 2.364855]\n",
            "241 [ D loss: 0.633062, acc.: 64%] [G loss: 2.464913]\n",
            "242 [ D loss: 0.647700, acc.: 63%] [G loss: 2.595840]\n",
            "243 [ D loss: 0.612835, acc.: 61%] [G loss: 2.532417]\n",
            "244 [ D loss: 0.622934, acc.: 63%] [G loss: 2.275371]\n",
            "245 [ D loss: 0.646236, acc.: 59%] [G loss: 2.179996]\n",
            "246 [ D loss: 0.582649, acc.: 64%] [G loss: 2.233982]\n",
            "247 [ D loss: 0.600042, acc.: 64%] [G loss: 2.219851]\n",
            "248 [ D loss: 0.645627, acc.: 61%] [G loss: 2.258547]\n",
            "249 [ D loss: 0.585609, acc.: 64%] [G loss: 2.365162]\n",
            "250 [ D loss: 0.601218, acc.: 66%] [G loss: 2.459417]\n",
            "251 [ D loss: 0.553656, acc.: 62%] [G loss: 2.413514]\n",
            "252 [ D loss: 0.579819, acc.: 67%] [G loss: 2.243865]\n",
            "253 [ D loss: 0.585817, acc.: 65%] [G loss: 2.223300]\n",
            "254 [ D loss: 0.611767, acc.: 66%] [G loss: 2.273286]\n",
            "255 [ D loss: 0.638158, acc.: 61%] [G loss: 2.290262]\n",
            "256 [ D loss: 0.668911, acc.: 58%] [G loss: 2.168108]\n",
            "257 [ D loss: 0.614063, acc.: 66%] [G loss: 2.077722]\n",
            "258 [ D loss: 0.600135, acc.: 68%] [G loss: 2.232512]\n",
            "259 [ D loss: 0.551922, acc.: 66%] [G loss: 2.118488]\n",
            "260 [ D loss: 0.613408, acc.: 62%] [G loss: 2.084267]\n",
            "261 [ D loss: 0.613077, acc.: 62%] [G loss: 2.146588]\n",
            "262 [ D loss: 0.563378, acc.: 67%] [G loss: 1.830091]\n",
            "263 [ D loss: 0.626246, acc.: 61%] [G loss: 2.040557]\n",
            "264 [ D loss: 0.588421, acc.: 62%] [G loss: 2.225160]\n",
            "265 [ D loss: 0.589003, acc.: 63%] [G loss: 2.142201]\n",
            "266 [ D loss: 0.592740, acc.: 61%] [G loss: 2.193223]\n",
            "267 [ D loss: 0.571570, acc.: 62%] [G loss: 2.155161]\n",
            "268 [ D loss: 0.626784, acc.: 62%] [G loss: 1.975172]\n",
            "269 [ D loss: 0.645636, acc.: 57%] [G loss: 2.036620]\n",
            "270 [ D loss: 0.594058, acc.: 67%] [G loss: 2.237001]\n",
            "271 [ D loss: 0.679567, acc.: 49%] [G loss: 2.106114]\n",
            "272 [ D loss: 0.626863, acc.: 61%] [G loss: 1.931001]\n",
            "273 [ D loss: 0.697657, acc.: 52%] [G loss: 1.927885]\n",
            "274 [ D loss: 0.621289, acc.: 63%] [G loss: 1.906712]\n",
            "275 [ D loss: 0.629066, acc.: 59%] [G loss: 1.974715]\n",
            "276 [ D loss: 0.646248, acc.: 59%] [G loss: 1.987964]\n",
            "277 [ D loss: 0.638894, acc.: 56%] [G loss: 2.003202]\n",
            "278 [ D loss: 0.626176, acc.: 59%] [G loss: 2.156988]\n",
            "279 [ D loss: 0.617887, acc.: 59%] [G loss: 2.047081]\n",
            "280 [ D loss: 0.595198, acc.: 63%] [G loss: 1.962215]\n",
            "281 [ D loss: 0.647582, acc.: 59%] [G loss: 1.972185]\n",
            "282 [ D loss: 0.647817, acc.: 61%] [G loss: 1.941432]\n",
            "283 [ D loss: 0.632075, acc.: 61%] [G loss: 2.008779]\n",
            "284 [ D loss: 0.651966, acc.: 57%] [G loss: 2.008796]\n",
            "285 [ D loss: 0.632506, acc.: 59%] [G loss: 1.957450]\n",
            "286 [ D loss: 0.687295, acc.: 56%] [G loss: 1.948560]\n",
            "287 [ D loss: 0.606827, acc.: 68%] [G loss: 2.034175]\n",
            "288 [ D loss: 0.649109, acc.: 56%] [G loss: 1.963330]\n",
            "289 [ D loss: 0.606384, acc.: 66%] [G loss: 1.802356]\n",
            "290 [ D loss: 0.669658, acc.: 59%] [G loss: 1.769418]\n",
            "291 [ D loss: 0.649594, acc.: 63%] [G loss: 1.938932]\n",
            "292 [ D loss: 0.623791, acc.: 63%] [G loss: 1.854198]\n",
            "293 [ D loss: 0.568682, acc.: 67%] [G loss: 1.818079]\n",
            "294 [ D loss: 0.616942, acc.: 61%] [G loss: 1.798352]\n",
            "295 [ D loss: 0.637758, acc.: 59%] [G loss: 1.739167]\n",
            "296 [ D loss: 0.602041, acc.: 66%] [G loss: 1.830336]\n",
            "297 [ D loss: 0.599196, acc.: 64%] [G loss: 1.814029]\n",
            "298 [ D loss: 0.605374, acc.: 67%] [G loss: 1.869100]\n",
            "299 [ D loss: 0.598122, acc.: 62%] [G loss: 1.761879]\n",
            "300 [ D loss: 0.594451, acc.: 64%] [G loss: 1.835567]\n",
            "301 [ D loss: 0.622273, acc.: 59%] [G loss: 1.889485]\n",
            "302 [ D loss: 0.570685, acc.: 64%] [G loss: 1.825503]\n",
            "303 [ D loss: 0.633942, acc.: 62%] [G loss: 1.741731]\n",
            "304 [ D loss: 0.605870, acc.: 63%] [G loss: 1.767379]\n",
            "305 [ D loss: 0.642185, acc.: 56%] [G loss: 1.797761]\n",
            "306 [ D loss: 0.607534, acc.: 62%] [G loss: 1.878171]\n",
            "307 [ D loss: 0.615562, acc.: 58%] [G loss: 1.795825]\n",
            "308 [ D loss: 0.601017, acc.: 66%] [G loss: 1.760091]\n",
            "309 [ D loss: 0.624188, acc.: 62%] [G loss: 1.732998]\n",
            "310 [ D loss: 0.593183, acc.: 62%] [G loss: 1.846421]\n",
            "311 [ D loss: 0.570773, acc.: 69%] [G loss: 1.780115]\n",
            "312 [ D loss: 0.622490, acc.: 62%] [G loss: 1.771968]\n",
            "313 [ D loss: 0.641824, acc.: 66%] [G loss: 1.731380]\n",
            "314 [ D loss: 0.595675, acc.: 64%] [G loss: 1.798650]\n",
            "315 [ D loss: 0.640329, acc.: 61%] [G loss: 1.740804]\n",
            "316 [ D loss: 0.616380, acc.: 61%] [G loss: 1.778012]\n",
            "317 [ D loss: 0.615636, acc.: 58%] [G loss: 1.601997]\n",
            "318 [ D loss: 0.610069, acc.: 63%] [G loss: 1.635236]\n",
            "319 [ D loss: 0.576704, acc.: 68%] [G loss: 1.659460]\n",
            "320 [ D loss: 0.595769, acc.: 64%] [G loss: 1.706211]\n",
            "321 [ D loss: 0.604964, acc.: 61%] [G loss: 1.781408]\n",
            "322 [ D loss: 0.576667, acc.: 62%] [G loss: 1.673924]\n",
            "323 [ D loss: 0.619285, acc.: 56%] [G loss: 1.682771]\n",
            "324 [ D loss: 0.603054, acc.: 65%] [G loss: 1.671481]\n",
            "325 [ D loss: 0.613271, acc.: 55%] [G loss: 1.702072]\n",
            "326 [ D loss: 0.574073, acc.: 64%] [G loss: 1.728214]\n",
            "327 [ D loss: 0.624924, acc.: 59%] [G loss: 1.741703]\n",
            "328 [ D loss: 0.557181, acc.: 66%] [G loss: 1.768965]\n",
            "329 [ D loss: 0.635512, acc.: 52%] [G loss: 1.692675]\n",
            "330 [ D loss: 0.590386, acc.: 62%] [G loss: 1.597180]\n",
            "331 [ D loss: 0.594406, acc.: 63%] [G loss: 1.648165]\n",
            "332 [ D loss: 0.620039, acc.: 58%] [G loss: 1.583439]\n",
            "333 [ D loss: 0.588519, acc.: 66%] [G loss: 1.706335]\n",
            "334 [ D loss: 0.603573, acc.: 62%] [G loss: 1.663005]\n",
            "335 [ D loss: 0.612122, acc.: 63%] [G loss: 1.631438]\n",
            "336 [ D loss: 0.586995, acc.: 66%] [G loss: 1.688068]\n",
            "337 [ D loss: 0.607396, acc.: 67%] [G loss: 1.719226]\n",
            "338 [ D loss: 0.663443, acc.: 52%] [G loss: 1.712251]\n",
            "339 [ D loss: 0.612047, acc.: 58%] [G loss: 1.596401]\n",
            "340 [ D loss: 0.639266, acc.: 59%] [G loss: 1.551881]\n",
            "341 [ D loss: 0.615664, acc.: 62%] [G loss: 1.629266]\n",
            "342 [ D loss: 0.608087, acc.: 65%] [G loss: 1.608275]\n",
            "343 [ D loss: 0.573895, acc.: 65%] [G loss: 1.711627]\n",
            "344 [ D loss: 0.578503, acc.: 66%] [G loss: 1.645422]\n",
            "345 [ D loss: 0.648701, acc.: 53%] [G loss: 1.638655]\n",
            "346 [ D loss: 0.604111, acc.: 62%] [G loss: 1.663219]\n",
            "347 [ D loss: 0.613006, acc.: 62%] [G loss: 1.603630]\n",
            "348 [ D loss: 0.589458, acc.: 63%] [G loss: 1.654068]\n",
            "349 [ D loss: 0.590883, acc.: 62%] [G loss: 1.582888]\n",
            "350 [ D loss: 0.597573, acc.: 61%] [G loss: 1.550439]\n",
            "351 [ D loss: 0.623890, acc.: 60%] [G loss: 1.604115]\n",
            "352 [ D loss: 0.641001, acc.: 59%] [G loss: 1.580481]\n",
            "353 [ D loss: 0.592569, acc.: 63%] [G loss: 1.677391]\n",
            "354 [ D loss: 0.602049, acc.: 59%] [G loss: 1.596374]\n",
            "355 [ D loss: 0.611827, acc.: 64%] [G loss: 1.585921]\n",
            "356 [ D loss: 0.618652, acc.: 61%] [G loss: 1.545253]\n",
            "357 [ D loss: 0.585945, acc.: 69%] [G loss: 1.565662]\n",
            "358 [ D loss: 0.597955, acc.: 64%] [G loss: 1.599363]\n",
            "359 [ D loss: 0.626495, acc.: 58%] [G loss: 1.481812]\n",
            "360 [ D loss: 0.623725, acc.: 60%] [G loss: 1.557148]\n",
            "361 [ D loss: 0.634857, acc.: 58%] [G loss: 1.581002]\n",
            "362 [ D loss: 0.623844, acc.: 63%] [G loss: 1.552927]\n",
            "363 [ D loss: 0.601660, acc.: 66%] [G loss: 1.602922]\n",
            "364 [ D loss: 0.576456, acc.: 66%] [G loss: 1.620147]\n",
            "365 [ D loss: 0.603542, acc.: 62%] [G loss: 1.609825]\n",
            "366 [ D loss: 0.636947, acc.: 59%] [G loss: 1.551260]\n",
            "367 [ D loss: 0.599947, acc.: 65%] [G loss: 1.621777]\n",
            "368 [ D loss: 0.612552, acc.: 62%] [G loss: 1.568644]\n",
            "369 [ D loss: 0.660113, acc.: 55%] [G loss: 1.486928]\n",
            "370 [ D loss: 0.614542, acc.: 66%] [G loss: 1.512377]\n",
            "371 [ D loss: 0.647280, acc.: 54%] [G loss: 1.489814]\n",
            "372 [ D loss: 0.654851, acc.: 55%] [G loss: 1.526613]\n",
            "373 [ D loss: 0.629360, acc.: 56%] [G loss: 1.502974]\n",
            "374 [ D loss: 0.623792, acc.: 62%] [G loss: 1.580489]\n",
            "375 [ D loss: 0.622309, acc.: 62%] [G loss: 1.637811]\n",
            "376 [ D loss: 0.633476, acc.: 61%] [G loss: 1.520262]\n",
            "377 [ D loss: 0.599125, acc.: 62%] [G loss: 1.544640]\n",
            "378 [ D loss: 0.605662, acc.: 59%] [G loss: 1.457638]\n",
            "379 [ D loss: 0.602466, acc.: 66%] [G loss: 1.514901]\n",
            "380 [ D loss: 0.619787, acc.: 58%] [G loss: 1.526208]\n",
            "381 [ D loss: 0.594560, acc.: 63%] [G loss: 1.504097]\n",
            "382 [ D loss: 0.578272, acc.: 70%] [G loss: 1.538542]\n",
            "383 [ D loss: 0.630818, acc.: 58%] [G loss: 1.512361]\n",
            "384 [ D loss: 0.597244, acc.: 64%] [G loss: 1.559337]\n",
            "385 [ D loss: 0.599324, acc.: 62%] [G loss: 1.533804]\n",
            "386 [ D loss: 0.596585, acc.: 67%] [G loss: 1.523985]\n",
            "387 [ D loss: 0.570000, acc.: 70%] [G loss: 1.546872]\n",
            "388 [ D loss: 0.625965, acc.: 58%] [G loss: 1.562466]\n",
            "389 [ D loss: 0.592003, acc.: 63%] [G loss: 1.588367]\n",
            "390 [ D loss: 0.607954, acc.: 61%] [G loss: 1.524447]\n",
            "391 [ D loss: 0.616040, acc.: 59%] [G loss: 1.479382]\n",
            "392 [ D loss: 0.614069, acc.: 64%] [G loss: 1.496571]\n",
            "393 [ D loss: 0.599422, acc.: 61%] [G loss: 1.473964]\n",
            "394 [ D loss: 0.622296, acc.: 59%] [G loss: 1.512976]\n",
            "395 [ D loss: 0.588034, acc.: 67%] [G loss: 1.524926]\n",
            "396 [ D loss: 0.622941, acc.: 59%] [G loss: 1.476511]\n",
            "397 [ D loss: 0.616207, acc.: 62%] [G loss: 1.463183]\n",
            "398 [ D loss: 0.604422, acc.: 66%] [G loss: 1.520028]\n",
            "399 [ D loss: 0.614070, acc.: 63%] [G loss: 1.409688]\n",
            "400 [ D loss: 0.615446, acc.: 59%] [G loss: 1.448707]\n",
            "401 [ D loss: 0.593986, acc.: 63%] [G loss: 1.471583]\n",
            "402 [ D loss: 0.547688, acc.: 66%] [G loss: 1.495070]\n",
            "403 [ D loss: 0.647638, acc.: 57%] [G loss: 1.364753]\n",
            "404 [ D loss: 0.592055, acc.: 65%] [G loss: 1.450346]\n",
            "405 [ D loss: 0.637755, acc.: 61%] [G loss: 1.431772]\n",
            "406 [ D loss: 0.582672, acc.: 71%] [G loss: 1.440322]\n",
            "407 [ D loss: 0.628255, acc.: 61%] [G loss: 1.458573]\n",
            "408 [ D loss: 0.603370, acc.: 63%] [G loss: 1.396997]\n",
            "409 [ D loss: 0.630748, acc.: 60%] [G loss: 1.391510]\n",
            "410 [ D loss: 0.619492, acc.: 62%] [G loss: 1.427461]\n",
            "411 [ D loss: 0.618172, acc.: 64%] [G loss: 1.437311]\n",
            "412 [ D loss: 0.599810, acc.: 65%] [G loss: 1.406552]\n",
            "413 [ D loss: 0.641222, acc.: 59%] [G loss: 1.396359]\n",
            "414 [ D loss: 0.619315, acc.: 64%] [G loss: 1.351115]\n",
            "415 [ D loss: 0.632696, acc.: 60%] [G loss: 1.385682]\n",
            "416 [ D loss: 0.629053, acc.: 58%] [G loss: 1.414577]\n",
            "417 [ D loss: 0.606976, acc.: 62%] [G loss: 1.475788]\n",
            "418 [ D loss: 0.625525, acc.: 60%] [G loss: 1.393763]\n",
            "419 [ D loss: 0.608848, acc.: 63%] [G loss: 1.360539]\n",
            "420 [ D loss: 0.643264, acc.: 62%] [G loss: 1.451213]\n",
            "421 [ D loss: 0.614396, acc.: 62%] [G loss: 1.467992]\n",
            "422 [ D loss: 0.602934, acc.: 62%] [G loss: 1.402551]\n",
            "423 [ D loss: 0.592653, acc.: 64%] [G loss: 1.439990]\n",
            "424 [ D loss: 0.595348, acc.: 63%] [G loss: 1.384142]\n",
            "425 [ D loss: 0.634346, acc.: 55%] [G loss: 1.356111]\n",
            "426 [ D loss: 0.616693, acc.: 66%] [G loss: 1.394494]\n",
            "427 [ D loss: 0.601760, acc.: 69%] [G loss: 1.409786]\n",
            "428 [ D loss: 0.614284, acc.: 66%] [G loss: 1.426183]\n",
            "429 [ D loss: 0.623717, acc.: 63%] [G loss: 1.359909]\n",
            "430 [ D loss: 0.617390, acc.: 66%] [G loss: 1.311539]\n",
            "431 [ D loss: 0.633544, acc.: 62%] [G loss: 1.382958]\n",
            "432 [ D loss: 0.646148, acc.: 56%] [G loss: 1.345102]\n",
            "433 [ D loss: 0.593796, acc.: 71%] [G loss: 1.381766]\n",
            "434 [ D loss: 0.632440, acc.: 61%] [G loss: 1.362659]\n",
            "435 [ D loss: 0.628974, acc.: 66%] [G loss: 1.339810]\n",
            "436 [ D loss: 0.595257, acc.: 66%] [G loss: 1.415709]\n",
            "437 [ D loss: 0.585354, acc.: 66%] [G loss: 1.475155]\n",
            "438 [ D loss: 0.597579, acc.: 65%] [G loss: 1.424829]\n",
            "439 [ D loss: 0.628999, acc.: 64%] [G loss: 1.359008]\n",
            "440 [ D loss: 0.603215, acc.: 66%] [G loss: 1.368794]\n",
            "441 [ D loss: 0.605880, acc.: 62%] [G loss: 1.395146]\n",
            "442 [ D loss: 0.623371, acc.: 61%] [G loss: 1.403405]\n",
            "443 [ D loss: 0.611629, acc.: 59%] [G loss: 1.374750]\n",
            "444 [ D loss: 0.602070, acc.: 67%] [G loss: 1.467325]\n",
            "445 [ D loss: 0.603399, acc.: 62%] [G loss: 1.422146]\n",
            "446 [ D loss: 0.606191, acc.: 67%] [G loss: 1.364286]\n",
            "447 [ D loss: 0.628576, acc.: 65%] [G loss: 1.415988]\n",
            "448 [ D loss: 0.591030, acc.: 66%] [G loss: 1.523535]\n",
            "449 [ D loss: 0.563733, acc.: 71%] [G loss: 1.535016]\n",
            "450 [ D loss: 0.555439, acc.: 69%] [G loss: 1.470998]\n",
            "451 [ D loss: 0.581977, acc.: 73%] [G loss: 1.383941]\n",
            "452 [ D loss: 0.593683, acc.: 65%] [G loss: 1.379713]\n",
            "453 [ D loss: 0.590378, acc.: 67%] [G loss: 1.291267]\n",
            "454 [ D loss: 0.578403, acc.: 70%] [G loss: 1.354933]\n",
            "455 [ D loss: 0.559751, acc.: 73%] [G loss: 1.465847]\n",
            "456 [ D loss: 0.585908, acc.: 65%] [G loss: 1.511583]\n",
            "457 [ D loss: 0.661961, acc.: 54%] [G loss: 1.321198]\n",
            "458 [ D loss: 0.622436, acc.: 60%] [G loss: 1.297953]\n",
            "459 [ D loss: 0.600863, acc.: 66%] [G loss: 1.392599]\n",
            "460 [ D loss: 0.569360, acc.: 72%] [G loss: 1.483361]\n",
            "461 [ D loss: 0.592326, acc.: 70%] [G loss: 1.381839]\n",
            "462 [ D loss: 0.637704, acc.: 67%] [G loss: 1.238392]\n",
            "463 [ D loss: 0.596703, acc.: 75%] [G loss: 1.349422]\n",
            "464 [ D loss: 0.601072, acc.: 68%] [G loss: 1.445051]\n",
            "465 [ D loss: 0.600364, acc.: 66%] [G loss: 1.441194]\n",
            "466 [ D loss: 0.637530, acc.: 65%] [G loss: 1.343991]\n",
            "467 [ D loss: 0.587751, acc.: 71%] [G loss: 1.404251]\n",
            "468 [ D loss: 0.630333, acc.: 60%] [G loss: 1.356172]\n",
            "469 [ D loss: 0.604766, acc.: 68%] [G loss: 1.298710]\n",
            "470 [ D loss: 0.631594, acc.: 68%] [G loss: 1.241914]\n",
            "471 [ D loss: 0.594452, acc.: 70%] [G loss: 1.283526]\n",
            "472 [ D loss: 0.589837, acc.: 70%] [G loss: 1.390576]\n",
            "473 [ D loss: 0.643316, acc.: 55%] [G loss: 1.361499]\n",
            "474 [ D loss: 0.605450, acc.: 66%] [G loss: 1.398355]\n",
            "475 [ D loss: 0.571541, acc.: 69%] [G loss: 1.467899]\n",
            "476 [ D loss: 0.569702, acc.: 67%] [G loss: 1.458424]\n",
            "477 [ D loss: 0.570068, acc.: 73%] [G loss: 1.377674]\n",
            "478 [ D loss: 0.572280, acc.: 71%] [G loss: 1.366961]\n",
            "479 [ D loss: 0.638351, acc.: 61%] [G loss: 1.262470]\n",
            "480 [ D loss: 0.587951, acc.: 76%] [G loss: 1.331834]\n",
            "481 [ D loss: 0.588056, acc.: 72%] [G loss: 1.406682]\n",
            "482 [ D loss: 0.587119, acc.: 70%] [G loss: 1.425352]\n",
            "483 [ D loss: 0.551224, acc.: 77%] [G loss: 1.459786]\n",
            "484 [ D loss: 0.560464, acc.: 70%] [G loss: 1.498509]\n",
            "485 [ D loss: 0.530345, acc.: 81%] [G loss: 1.369083]\n",
            "486 [ D loss: 0.597679, acc.: 72%] [G loss: 1.255405]\n",
            "487 [ D loss: 0.627994, acc.: 66%] [G loss: 1.283350]\n",
            "488 [ D loss: 0.602013, acc.: 70%] [G loss: 1.411223]\n",
            "489 [ D loss: 0.594641, acc.: 67%] [G loss: 1.462865]\n",
            "490 [ D loss: 0.562841, acc.: 70%] [G loss: 1.495656]\n",
            "491 [ D loss: 0.614140, acc.: 68%] [G loss: 1.429661]\n",
            "492 [ D loss: 0.549160, acc.: 76%] [G loss: 1.444982]\n",
            "493 [ D loss: 0.578571, acc.: 74%] [G loss: 1.437660]\n",
            "494 [ D loss: 0.623594, acc.: 63%] [G loss: 1.345677]\n",
            "495 [ D loss: 0.616262, acc.: 64%] [G loss: 1.400068]\n",
            "496 [ D loss: 0.603591, acc.: 64%] [G loss: 1.387504]\n",
            "497 [ D loss: 0.582587, acc.: 72%] [G loss: 1.330518]\n",
            "498 [ D loss: 0.625855, acc.: 67%] [G loss: 1.281220]\n",
            "499 [ D loss: 0.584805, acc.: 70%] [G loss: 1.478873]\n",
            "500 [ D loss: 0.616203, acc.: 64%] [G loss: 1.429998]\n",
            "501 [ D loss: 0.597617, acc.: 66%] [G loss: 1.461797]\n",
            "502 [ D loss: 0.553697, acc.: 70%] [G loss: 1.562091]\n",
            "503 [ D loss: 0.553885, acc.: 70%] [G loss: 1.507808]\n",
            "504 [ D loss: 0.587811, acc.: 73%] [G loss: 1.422258]\n",
            "505 [ D loss: 0.582575, acc.: 70%] [G loss: 1.380245]\n",
            "506 [ D loss: 0.583962, acc.: 69%] [G loss: 1.330284]\n",
            "507 [ D loss: 0.621380, acc.: 70%] [G loss: 1.294376]\n",
            "508 [ D loss: 0.628389, acc.: 63%] [G loss: 1.354797]\n",
            "509 [ D loss: 0.586418, acc.: 63%] [G loss: 1.470591]\n",
            "510 [ D loss: 0.558100, acc.: 69%] [G loss: 1.538197]\n",
            "511 [ D loss: 0.563641, acc.: 72%] [G loss: 1.411779]\n",
            "512 [ D loss: 0.591214, acc.: 76%] [G loss: 1.297493]\n",
            "513 [ D loss: 0.608429, acc.: 68%] [G loss: 1.295562]\n",
            "514 [ D loss: 0.643325, acc.: 61%] [G loss: 1.294912]\n",
            "515 [ D loss: 0.623437, acc.: 61%] [G loss: 1.327953]\n",
            "516 [ D loss: 0.563602, acc.: 75%] [G loss: 1.403823]\n",
            "517 [ D loss: 0.578315, acc.: 70%] [G loss: 1.511127]\n",
            "518 [ D loss: 0.530758, acc.: 80%] [G loss: 1.401342]\n",
            "519 [ D loss: 0.572938, acc.: 75%] [G loss: 1.444662]\n",
            "520 [ D loss: 0.534425, acc.: 73%] [G loss: 1.638848]\n",
            "521 [ D loss: 0.508716, acc.: 74%] [G loss: 1.853721]\n",
            "522 [ D loss: 0.519761, acc.: 75%] [G loss: 1.462191]\n",
            "523 [ D loss: 0.618918, acc.: 76%] [G loss: 1.275629]\n",
            "524 [ D loss: 0.587768, acc.: 74%] [G loss: 1.323079]\n",
            "525 [ D loss: 0.525354, acc.: 84%] [G loss: 1.531759]\n",
            "526 [ D loss: 0.547995, acc.: 70%] [G loss: 1.677041]\n",
            "527 [ D loss: 0.542114, acc.: 73%] [G loss: 1.601605]\n",
            "528 [ D loss: 0.559707, acc.: 80%] [G loss: 1.370269]\n",
            "529 [ D loss: 0.590076, acc.: 75%] [G loss: 1.419862]\n",
            "530 [ D loss: 0.550606, acc.: 73%] [G loss: 1.466373]\n",
            "531 [ D loss: 0.568492, acc.: 71%] [G loss: 1.401583]\n",
            "532 [ D loss: 0.532867, acc.: 74%] [G loss: 1.537606]\n",
            "533 [ D loss: 0.495338, acc.: 78%] [G loss: 1.724617]\n",
            "534 [ D loss: 0.494794, acc.: 74%] [G loss: 1.796933]\n",
            "535 [ D loss: 0.494978, acc.: 81%] [G loss: 1.592737]\n",
            "536 [ D loss: 0.608320, acc.: 70%] [G loss: 1.180119]\n",
            "537 [ D loss: 0.611680, acc.: 66%] [G loss: 1.316507]\n",
            "538 [ D loss: 0.508351, acc.: 77%] [G loss: 1.742964]\n",
            "539 [ D loss: 0.553681, acc.: 71%] [G loss: 1.675243]\n",
            "540 [ D loss: 0.519337, acc.: 73%] [G loss: 1.535385]\n",
            "541 [ D loss: 0.560517, acc.: 77%] [G loss: 1.368345]\n",
            "542 [ D loss: 0.509336, acc.: 83%] [G loss: 1.583069]\n",
            "543 [ D loss: 0.514806, acc.: 82%] [G loss: 1.519050]\n",
            "544 [ D loss: 0.590446, acc.: 70%] [G loss: 1.436502]\n",
            "545 [ D loss: 0.556971, acc.: 73%] [G loss: 1.515825]\n",
            "546 [ D loss: 0.517613, acc.: 77%] [G loss: 1.681355]\n",
            "547 [ D loss: 0.475220, acc.: 82%] [G loss: 1.697271]\n",
            "548 [ D loss: 0.588094, acc.: 74%] [G loss: 1.390932]\n",
            "549 [ D loss: 0.483417, acc.: 83%] [G loss: 1.791687]\n",
            "550 [ D loss: 0.459880, acc.: 84%] [G loss: 1.926155]\n",
            "551 [ D loss: 0.599377, acc.: 71%] [G loss: 1.455587]\n",
            "552 [ D loss: 0.559890, acc.: 82%] [G loss: 1.453959]\n",
            "553 [ D loss: 0.560660, acc.: 77%] [G loss: 1.510133]\n",
            "554 [ D loss: 0.521986, acc.: 79%] [G loss: 1.636141]\n",
            "555 [ D loss: 0.514822, acc.: 79%] [G loss: 1.854356]\n",
            "556 [ D loss: 0.482566, acc.: 82%] [G loss: 1.851186]\n",
            "557 [ D loss: 0.486093, acc.: 88%] [G loss: 1.745855]\n",
            "558 [ D loss: 0.455162, acc.: 82%] [G loss: 2.046205]\n",
            "559 [ D loss: 0.460616, acc.: 88%] [G loss: 1.675860]\n",
            "560 [ D loss: 0.513816, acc.: 86%] [G loss: 1.519038]\n",
            "561 [ D loss: 0.486242, acc.: 91%] [G loss: 1.655043]\n",
            "562 [ D loss: 0.491410, acc.: 80%] [G loss: 2.153700]\n",
            "563 [ D loss: 0.417529, acc.: 88%] [G loss: 2.273803]\n",
            "564 [ D loss: 0.446552, acc.: 91%] [G loss: 1.625589]\n",
            "565 [ D loss: 0.539434, acc.: 80%] [G loss: 1.450946]\n",
            "566 [ D loss: 0.439669, acc.: 88%] [G loss: 1.847320]\n",
            "567 [ D loss: 0.429569, acc.: 84%] [G loss: 1.956825]\n",
            "568 [ D loss: 0.498945, acc.: 85%] [G loss: 1.552755]\n",
            "569 [ D loss: 0.541503, acc.: 81%] [G loss: 1.578426]\n",
            "570 [ D loss: 0.453612, acc.: 91%] [G loss: 1.877733]\n",
            "571 [ D loss: 0.418733, acc.: 85%] [G loss: 2.062761]\n",
            "572 [ D loss: 0.476095, acc.: 83%] [G loss: 1.834720]\n",
            "573 [ D loss: 0.463072, acc.: 86%] [G loss: 1.877605]\n",
            "574 [ D loss: 0.413549, acc.: 91%] [G loss: 1.855932]\n",
            "575 [ D loss: 0.449724, acc.: 88%] [G loss: 1.856864]\n",
            "576 [ D loss: 0.417594, acc.: 95%] [G loss: 1.960308]\n",
            "577 [ D loss: 0.483485, acc.: 82%] [G loss: 1.702209]\n",
            "578 [ D loss: 0.433351, acc.: 93%] [G loss: 1.951092]\n",
            "579 [ D loss: 0.479782, acc.: 88%] [G loss: 1.710692]\n",
            "580 [ D loss: 0.510552, acc.: 78%] [G loss: 1.852961]\n",
            "581 [ D loss: 0.415745, acc.: 88%] [G loss: 2.121682]\n",
            "582 [ D loss: 0.469016, acc.: 88%] [G loss: 1.774544]\n",
            "583 [ D loss: 0.444939, acc.: 91%] [G loss: 1.792847]\n",
            "584 [ D loss: 0.436705, acc.: 82%] [G loss: 2.033357]\n",
            "585 [ D loss: 0.427846, acc.: 90%] [G loss: 2.113618]\n",
            "586 [ D loss: 0.441839, acc.: 90%] [G loss: 1.952100]\n",
            "587 [ D loss: 0.467130, acc.: 93%] [G loss: 1.819815]\n",
            "588 [ D loss: 0.476650, acc.: 94%] [G loss: 1.830063]\n",
            "589 [ D loss: 0.473735, acc.: 84%] [G loss: 1.947023]\n",
            "590 [ D loss: 0.433308, acc.: 86%] [G loss: 2.054691]\n",
            "591 [ D loss: 0.537727, acc.: 82%] [G loss: 1.597786]\n",
            "592 [ D loss: 0.451941, acc.: 87%] [G loss: 2.091286]\n",
            "593 [ D loss: 0.428988, acc.: 84%] [G loss: 2.886829]\n",
            "594 [ D loss: 0.382206, acc.: 91%] [G loss: 2.592529]\n",
            "595 [ D loss: 0.526975, acc.: 79%] [G loss: 1.663854]\n",
            "596 [ D loss: 0.530802, acc.: 84%] [G loss: 1.654263]\n",
            "597 [ D loss: 0.472711, acc.: 85%] [G loss: 2.170964]\n",
            "598 [ D loss: 0.400293, acc.: 86%] [G loss: 2.566415]\n",
            "599 [ D loss: 0.432513, acc.: 84%] [G loss: 2.151652]\n",
            "600 [ D loss: 0.426082, acc.: 92%] [G loss: 1.652625]\n",
            "601 [ D loss: 0.479800, acc.: 83%] [G loss: 1.946179]\n",
            "602 [ D loss: 0.365226, acc.: 94%] [G loss: 2.866554]\n",
            "603 [ D loss: 0.342813, acc.: 94%] [G loss: 2.714691]\n",
            "604 [ D loss: 0.479767, acc.: 80%] [G loss: 1.787180]\n",
            "605 [ D loss: 0.474381, acc.: 86%] [G loss: 1.630840]\n",
            "606 [ D loss: 0.452403, acc.: 89%] [G loss: 1.916337]\n",
            "607 [ D loss: 0.412991, acc.: 86%] [G loss: 2.418341]\n",
            "608 [ D loss: 0.360366, acc.: 92%] [G loss: 2.472596]\n",
            "609 [ D loss: 0.407301, acc.: 93%] [G loss: 2.064755]\n",
            "610 [ D loss: 0.412022, acc.: 91%] [G loss: 2.023739]\n",
            "611 [ D loss: 0.361119, acc.: 95%] [G loss: 2.438288]\n",
            "612 [ D loss: 0.455467, acc.: 87%] [G loss: 1.934503]\n",
            "613 [ D loss: 0.379712, acc.: 92%] [G loss: 2.271632]\n",
            "614 [ D loss: 0.378667, acc.: 94%] [G loss: 2.395970]\n",
            "615 [ D loss: 0.385731, acc.: 91%] [G loss: 2.348155]\n",
            "616 [ D loss: 0.457108, acc.: 88%] [G loss: 1.802357]\n",
            "617 [ D loss: 0.452430, acc.: 88%] [G loss: 2.248485]\n",
            "618 [ D loss: 0.375182, acc.: 90%] [G loss: 3.252470]\n",
            "619 [ D loss: 0.394802, acc.: 92%] [G loss: 2.483613]\n",
            "620 [ D loss: 0.346278, acc.: 96%] [G loss: 2.539207]\n",
            "621 [ D loss: 0.389052, acc.: 93%] [G loss: 2.277552]\n",
            "622 [ D loss: 0.376696, acc.: 91%] [G loss: 2.602732]\n",
            "623 [ D loss: 0.379393, acc.: 94%] [G loss: 2.400989]\n",
            "624 [ D loss: 0.367451, acc.: 95%] [G loss: 2.490093]\n",
            "625 [ D loss: 0.351877, acc.: 95%] [G loss: 2.825481]\n",
            "626 [ D loss: 0.376942, acc.: 91%] [G loss: 2.841366]\n",
            "627 [ D loss: 0.347909, acc.: 94%] [G loss: 2.368765]\n",
            "628 [ D loss: 0.470617, acc.: 80%] [G loss: 1.943736]\n",
            "629 [ D loss: 0.417720, acc.: 86%] [G loss: 2.203288]\n",
            "630 [ D loss: 0.345951, acc.: 95%] [G loss: 2.731055]\n",
            "631 [ D loss: 0.365700, acc.: 91%] [G loss: 2.293415]\n",
            "632 [ D loss: 0.430727, acc.: 91%] [G loss: 2.142241]\n",
            "633 [ D loss: 0.386153, acc.: 91%] [G loss: 2.040029]\n",
            "634 [ D loss: 0.370814, acc.: 92%] [G loss: 2.170538]\n",
            "635 [ D loss: 0.323081, acc.: 95%] [G loss: 2.541835]\n",
            "636 [ D loss: 0.347345, acc.: 91%] [G loss: 2.900360]\n",
            "637 [ D loss: 0.465845, acc.: 84%] [G loss: 2.257025]\n",
            "638 [ D loss: 0.397881, acc.: 92%] [G loss: 2.336230]\n",
            "639 [ D loss: 0.371464, acc.: 91%] [G loss: 2.520615]\n",
            "640 [ D loss: 0.402859, acc.: 91%] [G loss: 2.878103]\n",
            "641 [ D loss: 0.323425, acc.: 94%] [G loss: 3.306030]\n",
            "642 [ D loss: 0.368664, acc.: 92%] [G loss: 2.349533]\n",
            "643 [ D loss: 0.291140, acc.: 95%] [G loss: 2.846508]\n",
            "644 [ D loss: 0.353679, acc.: 91%] [G loss: 2.341046]\n",
            "645 [ D loss: 0.444887, acc.: 84%] [G loss: 2.119794]\n",
            "646 [ D loss: 0.377160, acc.: 92%] [G loss: 2.867038]\n",
            "647 [ D loss: 0.300740, acc.: 95%] [G loss: 3.536373]\n",
            "648 [ D loss: 0.335771, acc.: 93%] [G loss: 2.633461]\n",
            "649 [ D loss: 0.539392, acc.: 73%] [G loss: 1.856761]\n",
            "650 [ D loss: 0.343207, acc.: 94%] [G loss: 2.436404]\n",
            "651 [ D loss: 0.368795, acc.: 88%] [G loss: 3.840901]\n",
            "652 [ D loss: 0.356673, acc.: 93%] [G loss: 2.611968]\n",
            "653 [ D loss: 0.436449, acc.: 89%] [G loss: 2.249950]\n",
            "654 [ D loss: 0.340406, acc.: 96%] [G loss: 2.470196]\n",
            "655 [ D loss: 0.321322, acc.: 94%] [G loss: 2.933086]\n",
            "656 [ D loss: 0.356651, acc.: 91%] [G loss: 2.678319]\n",
            "657 [ D loss: 0.442507, acc.: 85%] [G loss: 1.905804]\n",
            "658 [ D loss: 0.470553, acc.: 88%] [G loss: 2.283754]\n",
            "659 [ D loss: 0.364892, acc.: 90%] [G loss: 3.813226]\n",
            "660 [ D loss: 0.344935, acc.: 86%] [G loss: 4.134568]\n",
            "661 [ D loss: 0.471745, acc.: 80%] [G loss: 2.147673]\n",
            "662 [ D loss: 0.354433, acc.: 91%] [G loss: 2.480831]\n",
            "663 [ D loss: 0.390512, acc.: 87%] [G loss: 2.633688]\n",
            "664 [ D loss: 0.346088, acc.: 92%] [G loss: 2.738595]\n",
            "665 [ D loss: 0.361845, acc.: 91%] [G loss: 2.555540]\n",
            "666 [ D loss: 0.370619, acc.: 92%] [G loss: 2.765024]\n",
            "667 [ D loss: 0.369376, acc.: 90%] [G loss: 2.633398]\n",
            "668 [ D loss: 0.337413, acc.: 88%] [G loss: 3.122072]\n",
            "669 [ D loss: 0.345040, acc.: 92%] [G loss: 2.322721]\n",
            "670 [ D loss: 0.520933, acc.: 81%] [G loss: 2.016213]\n",
            "671 [ D loss: 0.433372, acc.: 91%] [G loss: 2.458278]\n",
            "672 [ D loss: 0.376545, acc.: 83%] [G loss: 2.948687]\n",
            "673 [ D loss: 0.339052, acc.: 92%] [G loss: 3.187146]\n",
            "674 [ D loss: 0.373832, acc.: 90%] [G loss: 2.479648]\n",
            "675 [ D loss: 0.368114, acc.: 91%] [G loss: 2.394349]\n",
            "676 [ D loss: 0.398860, acc.: 88%] [G loss: 2.639601]\n",
            "677 [ D loss: 0.334374, acc.: 92%] [G loss: 4.368079]\n",
            "678 [ D loss: 0.244784, acc.: 98%] [G loss: 5.461791]\n",
            "679 [ D loss: 0.511286, acc.: 75%] [G loss: 1.662744]\n",
            "680 [ D loss: 0.390361, acc.: 89%] [G loss: 2.807903]\n",
            "681 [ D loss: 0.278339, acc.: 96%] [G loss: 4.766139]\n",
            "682 [ D loss: 0.365218, acc.: 89%] [G loss: 2.701851]\n",
            "683 [ D loss: 0.401573, acc.: 87%] [G loss: 2.801856]\n",
            "684 [ D loss: 0.314407, acc.: 92%] [G loss: 3.407111]\n",
            "685 [ D loss: 0.358758, acc.: 90%] [G loss: 2.723672]\n",
            "686 [ D loss: 0.355197, acc.: 91%] [G loss: 2.508808]\n",
            "687 [ D loss: 0.363980, acc.: 98%] [G loss: 2.662022]\n",
            "688 [ D loss: 0.338696, acc.: 95%] [G loss: 2.322268]\n",
            "689 [ D loss: 0.432972, acc.: 87%] [G loss: 2.317895]\n",
            "690 [ D loss: 0.394542, acc.: 89%] [G loss: 3.076832]\n",
            "691 [ D loss: 0.301136, acc.: 95%] [G loss: 3.984377]\n",
            "692 [ D loss: 0.291799, acc.: 96%] [G loss: 3.350849]\n",
            "693 [ D loss: 0.442382, acc.: 84%] [G loss: 2.421453]\n",
            "694 [ D loss: 0.369548, acc.: 90%] [G loss: 2.902415]\n",
            "695 [ D loss: 0.351154, acc.: 92%] [G loss: 2.939822]\n",
            "696 [ D loss: 0.307491, acc.: 92%] [G loss: 3.330602]\n",
            "697 [ D loss: 0.330374, acc.: 96%] [G loss: 2.617681]\n",
            "698 [ D loss: 0.409685, acc.: 87%] [G loss: 2.376571]\n",
            "699 [ D loss: 0.367247, acc.: 90%] [G loss: 3.095141]\n",
            "700 [ D loss: 0.296914, acc.: 94%] [G loss: 3.536597]\n",
            "701 [ D loss: 0.312659, acc.: 93%] [G loss: 3.065641]\n",
            "702 [ D loss: 0.311738, acc.: 93%] [G loss: 2.688366]\n",
            "703 [ D loss: 0.334068, acc.: 93%] [G loss: 2.655803]\n",
            "704 [ D loss: 0.315103, acc.: 94%] [G loss: 2.790046]\n",
            "705 [ D loss: 0.264378, acc.: 97%] [G loss: 3.266044]\n",
            "706 [ D loss: 0.351616, acc.: 90%] [G loss: 3.127573]\n",
            "707 [ D loss: 0.374087, acc.: 88%] [G loss: 2.634314]\n",
            "708 [ D loss: 0.326378, acc.: 94%] [G loss: 2.883016]\n",
            "709 [ D loss: 0.334438, acc.: 91%] [G loss: 3.364380]\n",
            "710 [ D loss: 0.370553, acc.: 90%] [G loss: 2.721022]\n",
            "711 [ D loss: 0.320202, acc.: 95%] [G loss: 3.253811]\n",
            "712 [ D loss: 0.298502, acc.: 94%] [G loss: 3.861534]\n",
            "713 [ D loss: 0.355068, acc.: 91%] [G loss: 2.779011]\n",
            "714 [ D loss: 0.298554, acc.: 93%] [G loss: 2.690093]\n",
            "715 [ D loss: 0.324191, acc.: 93%] [G loss: 3.352390]\n",
            "716 [ D loss: 0.322990, acc.: 91%] [G loss: 3.445591]\n",
            "717 [ D loss: 0.370816, acc.: 89%] [G loss: 2.496794]\n",
            "718 [ D loss: 0.353571, acc.: 91%] [G loss: 2.688214]\n",
            "719 [ D loss: 0.325174, acc.: 96%] [G loss: 1.977303]\n",
            "720 [ D loss: 0.345643, acc.: 94%] [G loss: 2.393799]\n",
            "721 [ D loss: 0.370615, acc.: 88%] [G loss: 3.061697]\n",
            "722 [ D loss: 0.319985, acc.: 94%] [G loss: 4.499582]\n",
            "723 [ D loss: 0.296866, acc.: 94%] [G loss: 3.823498]\n",
            "724 [ D loss: 0.362687, acc.: 94%] [G loss: 2.330642]\n",
            "725 [ D loss: 0.408904, acc.: 88%] [G loss: 2.408037]\n",
            "726 [ D loss: 0.468885, acc.: 83%] [G loss: 2.672341]\n",
            "727 [ D loss: 0.368106, acc.: 89%] [G loss: 3.336734]\n",
            "728 [ D loss: 0.310961, acc.: 92%] [G loss: 3.919330]\n",
            "729 [ D loss: 0.377096, acc.: 89%] [G loss: 2.351966]\n",
            "730 [ D loss: 0.382902, acc.: 86%] [G loss: 3.345829]\n",
            "731 [ D loss: 0.320426, acc.: 91%] [G loss: 3.162170]\n",
            "732 [ D loss: 0.374978, acc.: 91%] [G loss: 3.045842]\n",
            "733 [ D loss: 0.303880, acc.: 97%] [G loss: 2.987810]\n",
            "734 [ D loss: 0.408282, acc.: 88%] [G loss: 2.642545]\n",
            "735 [ D loss: 0.420934, acc.: 86%] [G loss: 2.352293]\n",
            "736 [ D loss: 0.431728, acc.: 83%] [G loss: 2.698773]\n",
            "737 [ D loss: 0.445078, acc.: 79%] [G loss: 3.102526]\n",
            "738 [ D loss: 0.325721, acc.: 93%] [G loss: 3.570678]\n",
            "739 [ D loss: 0.433286, acc.: 83%] [G loss: 2.974163]\n",
            "740 [ D loss: 0.323976, acc.: 92%] [G loss: 3.443446]\n",
            "741 [ D loss: 0.377654, acc.: 93%] [G loss: 3.078280]\n",
            "742 [ D loss: 0.306643, acc.: 95%] [G loss: 3.741088]\n",
            "743 [ D loss: 0.244630, acc.: 97%] [G loss: 3.965607]\n",
            "744 [ D loss: 0.337468, acc.: 91%] [G loss: 2.828343]\n",
            "745 [ D loss: 0.349763, acc.: 88%] [G loss: 4.189687]\n",
            "746 [ D loss: 0.340672, acc.: 91%] [G loss: 3.690857]\n",
            "747 [ D loss: 0.310165, acc.: 91%] [G loss: 3.338367]\n",
            "748 [ D loss: 0.351214, acc.: 91%] [G loss: 2.564413]\n",
            "749 [ D loss: 0.344806, acc.: 91%] [G loss: 2.650672]\n",
            "750 [ D loss: 0.365857, acc.: 90%] [G loss: 3.335063]\n",
            "751 [ D loss: 0.277047, acc.: 98%] [G loss: 3.643077]\n",
            "752 [ D loss: 0.276472, acc.: 92%] [G loss: 3.039980]\n",
            "753 [ D loss: 0.292717, acc.: 95%] [G loss: 3.109021]\n",
            "754 [ D loss: 0.268503, acc.: 96%] [G loss: 2.901505]\n",
            "755 [ D loss: 0.369259, acc.: 87%] [G loss: 3.171011]\n",
            "756 [ D loss: 0.308140, acc.: 92%] [G loss: 3.385738]\n",
            "757 [ D loss: 0.293260, acc.: 94%] [G loss: 3.357225]\n",
            "758 [ D loss: 0.275638, acc.: 93%] [G loss: 3.509861]\n",
            "759 [ D loss: 0.284478, acc.: 92%] [G loss: 3.289572]\n",
            "760 [ D loss: 0.292898, acc.: 92%] [G loss: 3.246387]\n",
            "761 [ D loss: 0.371777, acc.: 88%] [G loss: 3.221351]\n",
            "762 [ D loss: 0.274084, acc.: 95%] [G loss: 3.837073]\n",
            "763 [ D loss: 0.335134, acc.: 93%] [G loss: 3.361183]\n",
            "764 [ D loss: 0.265239, acc.: 94%] [G loss: 4.351020]\n",
            "765 [ D loss: 0.370111, acc.: 91%] [G loss: 2.871631]\n",
            "766 [ D loss: 0.296451, acc.: 95%] [G loss: 2.603445]\n",
            "767 [ D loss: 0.392154, acc.: 88%] [G loss: 3.261491]\n",
            "768 [ D loss: 0.392417, acc.: 89%] [G loss: 3.058026]\n",
            "769 [ D loss: 0.322242, acc.: 90%] [G loss: 3.239398]\n",
            "770 [ D loss: 0.248722, acc.: 97%] [G loss: 3.717985]\n",
            "771 [ D loss: 0.392140, acc.: 84%] [G loss: 2.790705]\n",
            "772 [ D loss: 0.349959, acc.: 95%] [G loss: 2.915920]\n",
            "773 [ D loss: 0.306844, acc.: 94%] [G loss: 3.248848]\n",
            "774 [ D loss: 0.255188, acc.: 95%] [G loss: 3.503267]\n",
            "775 [ D loss: 0.419437, acc.: 85%] [G loss: 2.633503]\n",
            "776 [ D loss: 0.397792, acc.: 83%] [G loss: 2.829126]\n",
            "777 [ D loss: 0.334946, acc.: 90%] [G loss: 2.925371]\n",
            "778 [ D loss: 0.253154, acc.: 98%] [G loss: 4.156481]\n",
            "779 [ D loss: 0.240537, acc.: 95%] [G loss: 4.314272]\n",
            "780 [ D loss: 0.496358, acc.: 77%] [G loss: 2.878726]\n",
            "781 [ D loss: 0.443677, acc.: 77%] [G loss: 2.995903]\n",
            "782 [ D loss: 0.313402, acc.: 91%] [G loss: 4.274302]\n",
            "783 [ D loss: 0.288664, acc.: 93%] [G loss: 3.793416]\n",
            "784 [ D loss: 0.267218, acc.: 94%] [G loss: 3.533850]\n",
            "785 [ D loss: 0.373659, acc.: 87%] [G loss: 2.523298]\n",
            "786 [ D loss: 0.407032, acc.: 82%] [G loss: 2.663973]\n",
            "787 [ D loss: 0.324188, acc.: 89%] [G loss: 2.948665]\n",
            "788 [ D loss: 0.275786, acc.: 97%] [G loss: 3.133093]\n",
            "789 [ D loss: 0.334483, acc.: 92%] [G loss: 2.807253]\n",
            "790 [ D loss: 0.295415, acc.: 96%] [G loss: 4.053106]\n",
            "791 [ D loss: 0.295832, acc.: 95%] [G loss: 3.574151]\n",
            "792 [ D loss: 0.311593, acc.: 91%] [G loss: 3.305449]\n",
            "793 [ D loss: 0.291319, acc.: 94%] [G loss: 3.125631]\n",
            "794 [ D loss: 0.295067, acc.: 97%] [G loss: 2.885924]\n",
            "795 [ D loss: 0.244740, acc.: 98%] [G loss: 3.144102]\n",
            "796 [ D loss: 0.242297, acc.: 99%] [G loss: 2.747979]\n",
            "797 [ D loss: 0.286510, acc.: 93%] [G loss: 3.296883]\n",
            "798 [ D loss: 0.348306, acc.: 87%] [G loss: 3.906072]\n",
            "799 [ D loss: 0.310333, acc.: 90%] [G loss: 4.405366]\n",
            "800 [ D loss: 0.258547, acc.: 96%] [G loss: 3.829614]\n",
            "801 [ D loss: 0.217745, acc.: 99%] [G loss: 4.402992]\n",
            "802 [ D loss: 0.306952, acc.: 88%] [G loss: 3.854769]\n",
            "803 [ D loss: 0.367752, acc.: 85%] [G loss: 4.088618]\n",
            "804 [ D loss: 0.247464, acc.: 97%] [G loss: 5.244455]\n",
            "805 [ D loss: 0.289260, acc.: 94%] [G loss: 3.113005]\n",
            "806 [ D loss: 0.360591, acc.: 88%] [G loss: 2.933346]\n",
            "807 [ D loss: 0.210156, acc.: 98%] [G loss: 4.036814]\n",
            "808 [ D loss: 0.333302, acc.: 90%] [G loss: 3.342552]\n",
            "809 [ D loss: 0.424418, acc.: 82%] [G loss: 3.503124]\n",
            "810 [ D loss: 0.313150, acc.: 93%] [G loss: 3.232049]\n",
            "811 [ D loss: 0.238000, acc.: 96%] [G loss: 3.597877]\n",
            "812 [ D loss: 0.303604, acc.: 91%] [G loss: 3.772447]\n",
            "813 [ D loss: 0.219654, acc.: 97%] [G loss: 3.932948]\n",
            "814 [ D loss: 0.271069, acc.: 92%] [G loss: 2.896341]\n",
            "815 [ D loss: 0.359699, acc.: 84%] [G loss: 2.638662]\n",
            "816 [ D loss: 0.270689, acc.: 95%] [G loss: 3.930118]\n",
            "817 [ D loss: 0.242172, acc.: 98%] [G loss: 4.131744]\n",
            "818 [ D loss: 0.238727, acc.: 97%] [G loss: 3.350383]\n",
            "819 [ D loss: 0.357121, acc.: 87%] [G loss: 3.587460]\n",
            "820 [ D loss: 0.229249, acc.: 98%] [G loss: 3.480019]\n",
            "821 [ D loss: 0.384832, acc.: 85%] [G loss: 3.377720]\n",
            "822 [ D loss: 0.241272, acc.: 98%] [G loss: 3.756951]\n",
            "823 [ D loss: 0.302846, acc.: 95%] [G loss: 3.562546]\n",
            "824 [ D loss: 0.239775, acc.: 98%] [G loss: 3.412622]\n",
            "825 [ D loss: 0.419174, acc.: 79%] [G loss: 3.205050]\n",
            "826 [ D loss: 0.331396, acc.: 92%] [G loss: 3.210843]\n",
            "827 [ D loss: 0.287783, acc.: 93%] [G loss: 3.192041]\n",
            "828 [ D loss: 0.255185, acc.: 98%] [G loss: 3.606404]\n",
            "829 [ D loss: 0.277208, acc.: 95%] [G loss: 2.822664]\n",
            "830 [ D loss: 0.396235, acc.: 85%] [G loss: 3.166740]\n",
            "831 [ D loss: 0.294149, acc.: 95%] [G loss: 3.596295]\n",
            "832 [ D loss: 0.406787, acc.: 82%] [G loss: 3.226309]\n",
            "833 [ D loss: 0.198105, acc.: 98%] [G loss: 4.872158]\n",
            "834 [ D loss: 0.261326, acc.: 93%] [G loss: 3.498246]\n",
            "835 [ D loss: 0.285348, acc.: 91%] [G loss: 4.703699]\n",
            "836 [ D loss: 0.381186, acc.: 86%] [G loss: 4.202705]\n",
            "837 [ D loss: 0.255463, acc.: 98%] [G loss: 5.190592]\n",
            "838 [ D loss: 0.236971, acc.: 98%] [G loss: 3.746181]\n",
            "839 [ D loss: 0.265874, acc.: 97%] [G loss: 4.134946]\n",
            "840 [ D loss: 0.210780, acc.: 98%] [G loss: 3.569772]\n",
            "841 [ D loss: 0.293385, acc.: 91%] [G loss: 3.609725]\n",
            "842 [ D loss: 0.212613, acc.: 97%] [G loss: 5.295969]\n",
            "843 [ D loss: 0.204491, acc.: 96%] [G loss: 4.303370]\n",
            "844 [ D loss: 0.276207, acc.: 91%] [G loss: 3.812202]\n",
            "845 [ D loss: 0.459114, acc.: 78%] [G loss: 4.174552]\n",
            "846 [ D loss: 0.279492, acc.: 95%] [G loss: 4.019434]\n",
            "847 [ D loss: 0.250072, acc.: 95%] [G loss: 4.021502]\n",
            "848 [ D loss: 0.279759, acc.: 93%] [G loss: 3.600187]\n",
            "849 [ D loss: 0.214058, acc.: 95%] [G loss: 3.666253]\n",
            "850 [ D loss: 0.457965, acc.: 79%] [G loss: 3.283517]\n",
            "851 [ D loss: 0.213454, acc.: 96%] [G loss: 3.739261]\n",
            "852 [ D loss: 0.218238, acc.: 95%] [G loss: 5.242270]\n",
            "853 [ D loss: 0.241941, acc.: 95%] [G loss: 3.747745]\n",
            "854 [ D loss: 0.399820, acc.: 79%] [G loss: 2.698283]\n",
            "855 [ D loss: 0.265473, acc.: 98%] [G loss: 3.530514]\n",
            "856 [ D loss: 0.220064, acc.: 95%] [G loss: 4.682536]\n",
            "857 [ D loss: 0.278301, acc.: 94%] [G loss: 3.483716]\n",
            "858 [ D loss: 0.219362, acc.: 96%] [G loss: 4.213065]\n",
            "859 [ D loss: 0.447986, acc.: 79%] [G loss: 4.025586]\n",
            "860 [ D loss: 0.260357, acc.: 97%] [G loss: 3.519805]\n",
            "861 [ D loss: 0.334267, acc.: 97%] [G loss: 2.893052]\n",
            "862 [ D loss: 0.229071, acc.: 98%] [G loss: 3.788855]\n",
            "863 [ D loss: 0.200202, acc.: 96%] [G loss: 5.320501]\n",
            "864 [ D loss: 0.273569, acc.: 91%] [G loss: 4.753222]\n",
            "865 [ D loss: 0.258650, acc.: 91%] [G loss: 4.557211]\n",
            "866 [ D loss: 0.553304, acc.: 70%] [G loss: 3.002475]\n",
            "867 [ D loss: 0.308203, acc.: 95%] [G loss: 3.696855]\n",
            "868 [ D loss: 0.306591, acc.: 92%] [G loss: 4.768891]\n",
            "869 [ D loss: 0.237462, acc.: 95%] [G loss: 3.594919]\n",
            "870 [ D loss: 0.247051, acc.: 95%] [G loss: 3.654590]\n",
            "871 [ D loss: 0.198442, acc.: 96%] [G loss: 5.062440]\n",
            "872 [ D loss: 0.444668, acc.: 78%] [G loss: 4.525511]\n",
            "873 [ D loss: 0.227838, acc.: 96%] [G loss: 4.157449]\n",
            "874 [ D loss: 0.424025, acc.: 82%] [G loss: 3.163995]\n",
            "875 [ D loss: 0.287666, acc.: 92%] [G loss: 4.581004]\n",
            "876 [ D loss: 0.387895, acc.: 84%] [G loss: 2.892210]\n",
            "877 [ D loss: 0.332648, acc.: 89%] [G loss: 3.491527]\n",
            "878 [ D loss: 0.149872, acc.: 100%] [G loss: 8.227429]\n",
            "879 [ D loss: 0.375749, acc.: 82%] [G loss: 2.443527]\n",
            "880 [ D loss: 0.296289, acc.: 91%] [G loss: 3.126976]\n",
            "881 [ D loss: 0.278457, acc.: 90%] [G loss: 4.280914]\n",
            "882 [ D loss: 0.229686, acc.: 96%] [G loss: 4.039257]\n",
            "883 [ D loss: 0.210856, acc.: 98%] [G loss: 4.048664]\n",
            "884 [ D loss: 0.166409, acc.: 99%] [G loss: 3.672942]\n",
            "885 [ D loss: 0.332807, acc.: 87%] [G loss: 3.164349]\n",
            "886 [ D loss: 0.194006, acc.: 98%] [G loss: 3.726316]\n",
            "887 [ D loss: 0.261683, acc.: 92%] [G loss: 3.127102]\n",
            "888 [ D loss: 0.224267, acc.: 98%] [G loss: 3.431950]\n",
            "889 [ D loss: 0.156931, acc.: 98%] [G loss: 5.605621]\n",
            "890 [ D loss: 0.287560, acc.: 91%] [G loss: 4.143387]\n",
            "891 [ D loss: 0.269045, acc.: 92%] [G loss: 2.893955]\n",
            "892 [ D loss: 0.488697, acc.: 74%] [G loss: 4.354782]\n",
            "893 [ D loss: 0.276955, acc.: 95%] [G loss: 5.307054]\n",
            "894 [ D loss: 0.381309, acc.: 88%] [G loss: 2.787483]\n",
            "895 [ D loss: 0.252222, acc.: 96%] [G loss: 3.934985]\n",
            "896 [ D loss: 0.194685, acc.: 98%] [G loss: 5.213800]\n",
            "897 [ D loss: 0.265023, acc.: 89%] [G loss: 4.160782]\n",
            "898 [ D loss: 0.193856, acc.: 98%] [G loss: 4.606770]\n",
            "899 [ D loss: 0.335859, acc.: 87%] [G loss: 4.024009]\n",
            "900 [ D loss: 0.530291, acc.: 79%] [G loss: 4.035572]\n",
            "901 [ D loss: 0.245477, acc.: 91%] [G loss: 5.099597]\n",
            "902 [ D loss: 0.275988, acc.: 93%] [G loss: 3.981720]\n",
            "903 [ D loss: 0.335240, acc.: 90%] [G loss: 4.516658]\n",
            "904 [ D loss: 0.227548, acc.: 98%] [G loss: 3.702277]\n",
            "905 [ D loss: 0.156811, acc.: 99%] [G loss: 5.850449]\n",
            "906 [ D loss: 0.310780, acc.: 93%] [G loss: 3.317402]\n",
            "907 [ D loss: 0.361113, acc.: 86%] [G loss: 3.729138]\n",
            "908 [ D loss: 0.223591, acc.: 97%] [G loss: 5.206488]\n",
            "909 [ D loss: 0.260012, acc.: 93%] [G loss: 3.130308]\n",
            "910 [ D loss: 0.440135, acc.: 73%] [G loss: 3.549799]\n",
            "911 [ D loss: 0.262673, acc.: 95%] [G loss: 4.091337]\n",
            "912 [ D loss: 0.271738, acc.: 93%] [G loss: 3.273663]\n",
            "913 [ D loss: 0.278371, acc.: 91%] [G loss: 3.443256]\n",
            "914 [ D loss: 0.273524, acc.: 96%] [G loss: 3.221310]\n",
            "915 [ D loss: 0.265295, acc.: 95%] [G loss: 4.307896]\n",
            "916 [ D loss: 0.233842, acc.: 94%] [G loss: 5.672660]\n",
            "917 [ D loss: 0.715770, acc.: 69%] [G loss: 3.276973]\n",
            "918 [ D loss: 0.351632, acc.: 86%] [G loss: 6.049635]\n",
            "919 [ D loss: 0.312101, acc.: 91%] [G loss: 4.413752]\n",
            "920 [ D loss: 0.254932, acc.: 96%] [G loss: 4.691188]\n",
            "921 [ D loss: 0.293886, acc.: 87%] [G loss: 4.040124]\n",
            "922 [ D loss: 0.534827, acc.: 73%] [G loss: 2.807889]\n",
            "923 [ D loss: 0.364054, acc.: 87%] [G loss: 3.907155]\n",
            "924 [ D loss: 0.347841, acc.: 92%] [G loss: 4.310783]\n",
            "925 [ D loss: 0.268132, acc.: 95%] [G loss: 3.228398]\n",
            "926 [ D loss: 0.215099, acc.: 98%] [G loss: 4.644132]\n",
            "927 [ D loss: 0.331014, acc.: 90%] [G loss: 3.606991]\n",
            "928 [ D loss: 0.187987, acc.: 98%] [G loss: 6.152676]\n",
            "929 [ D loss: 0.691260, acc.: 70%] [G loss: 3.548283]\n",
            "930 [ D loss: 0.221195, acc.: 97%] [G loss: 6.169037]\n",
            "931 [ D loss: 0.412784, acc.: 82%] [G loss: 4.360380]\n",
            "932 [ D loss: 0.462636, acc.: 76%] [G loss: 3.214670]\n",
            "933 [ D loss: 0.359142, acc.: 86%] [G loss: 3.366410]\n",
            "934 [ D loss: 0.216779, acc.: 97%] [G loss: 5.080851]\n",
            "935 [ D loss: 0.176488, acc.: 98%] [G loss: 5.672272]\n",
            "936 [ D loss: 0.299597, acc.: 90%] [G loss: 2.928949]\n",
            "937 [ D loss: 0.395326, acc.: 77%] [G loss: 3.508228]\n",
            "938 [ D loss: 0.345428, acc.: 86%] [G loss: 3.922162]\n",
            "939 [ D loss: 0.379887, acc.: 80%] [G loss: 3.761364]\n",
            "940 [ D loss: 0.228779, acc.: 96%] [G loss: 4.974432]\n",
            "941 [ D loss: 0.204440, acc.: 98%] [G loss: 4.744455]\n",
            "942 [ D loss: 0.459833, acc.: 75%] [G loss: 2.328868]\n",
            "943 [ D loss: 0.385844, acc.: 81%] [G loss: 2.817571]\n",
            "944 [ D loss: 0.404361, acc.: 80%] [G loss: 3.835429]\n",
            "945 [ D loss: 0.240677, acc.: 96%] [G loss: 3.847206]\n",
            "946 [ D loss: 0.264962, acc.: 95%] [G loss: 3.422251]\n",
            "947 [ D loss: 0.219557, acc.: 94%] [G loss: 4.478991]\n",
            "948 [ D loss: 0.279775, acc.: 91%] [G loss: 3.761765]\n",
            "949 [ D loss: 0.495563, acc.: 76%] [G loss: 2.474671]\n",
            "950 [ D loss: 0.363438, acc.: 83%] [G loss: 3.569605]\n",
            "951 [ D loss: 0.257244, acc.: 94%] [G loss: 5.050155]\n",
            "952 [ D loss: 0.542803, acc.: 72%] [G loss: 2.455881]\n",
            "953 [ D loss: 0.394234, acc.: 81%] [G loss: 4.538848]\n",
            "954 [ D loss: 0.363616, acc.: 80%] [G loss: 4.813297]\n",
            "955 [ D loss: 0.343901, acc.: 92%] [G loss: 3.039907]\n",
            "956 [ D loss: 0.207160, acc.: 98%] [G loss: 4.238736]\n",
            "957 [ D loss: 0.229603, acc.: 95%] [G loss: 3.639255]\n",
            "958 [ D loss: 0.293373, acc.: 91%] [G loss: 3.580937]\n",
            "959 [ D loss: 0.336064, acc.: 88%] [G loss: 3.469730]\n",
            "960 [ D loss: 0.335741, acc.: 88%] [G loss: 3.562829]\n",
            "961 [ D loss: 0.431657, acc.: 81%] [G loss: 3.297630]\n",
            "962 [ D loss: 0.172582, acc.: 100%] [G loss: 5.784207]\n",
            "963 [ D loss: 0.412687, acc.: 80%] [G loss: 3.953651]\n",
            "964 [ D loss: 0.192024, acc.: 95%] [G loss: 5.708806]\n",
            "965 [ D loss: 0.280689, acc.: 94%] [G loss: 3.593622]\n",
            "966 [ D loss: 0.453566, acc.: 78%] [G loss: 3.816351]\n",
            "967 [ D loss: 0.383071, acc.: 80%] [G loss: 4.538124]\n",
            "968 [ D loss: 0.244426, acc.: 93%] [G loss: 6.858325]\n",
            "969 [ D loss: 0.488542, acc.: 76%] [G loss: 3.814269]\n",
            "970 [ D loss: 0.175366, acc.: 98%] [G loss: 5.229213]\n",
            "971 [ D loss: 0.363701, acc.: 85%] [G loss: 5.110918]\n",
            "972 [ D loss: 0.523555, acc.: 76%] [G loss: 3.212302]\n",
            "973 [ D loss: 0.332264, acc.: 85%] [G loss: 3.484428]\n",
            "974 [ D loss: 0.396036, acc.: 80%] [G loss: 2.845773]\n",
            "975 [ D loss: 0.234100, acc.: 96%] [G loss: 4.141244]\n",
            "976 [ D loss: 0.169226, acc.: 98%] [G loss: 7.491430]\n",
            "977 [ D loss: 0.437746, acc.: 75%] [G loss: 2.508823]\n",
            "978 [ D loss: 0.382971, acc.: 82%] [G loss: 3.795906]\n",
            "979 [ D loss: 0.378185, acc.: 81%] [G loss: 4.418823]\n",
            "980 [ D loss: 0.206326, acc.: 96%] [G loss: 4.395793]\n",
            "981 [ D loss: 0.223224, acc.: 96%] [G loss: 3.982275]\n",
            "982 [ D loss: 0.338751, acc.: 84%] [G loss: 4.203505]\n",
            "983 [ D loss: 0.463140, acc.: 77%] [G loss: 3.317253]\n",
            "984 [ D loss: 0.402117, acc.: 80%] [G loss: 3.666340]\n",
            "985 [ D loss: 0.272247, acc.: 93%] [G loss: 3.783016]\n",
            "986 [ D loss: 0.202005, acc.: 97%] [G loss: 6.189239]\n",
            "987 [ D loss: 0.290623, acc.: 88%] [G loss: 4.136153]\n",
            "988 [ D loss: 0.487411, acc.: 80%] [G loss: 4.937204]\n",
            "989 [ D loss: 0.567967, acc.: 71%] [G loss: 4.874370]\n",
            "990 [ D loss: 0.336477, acc.: 90%] [G loss: 3.965893]\n",
            "991 [ D loss: 0.259541, acc.: 91%] [G loss: 4.848881]\n",
            "992 [ D loss: 0.196034, acc.: 97%] [G loss: 5.128448]\n",
            "993 [ D loss: 0.480391, acc.: 77%] [G loss: 3.389759]\n",
            "994 [ D loss: 0.376478, acc.: 84%] [G loss: 3.380312]\n",
            "995 [ D loss: 0.218529, acc.: 95%] [G loss: 6.028758]\n",
            "996 [ D loss: 0.726833, acc.: 66%] [G loss: 4.062562]\n",
            "997 [ D loss: 0.309129, acc.: 87%] [G loss: 4.760581]\n",
            "998 [ D loss: 0.300637, acc.: 92%] [G loss: 6.148870]\n",
            "999 [ D loss: 0.648383, acc.: 64%] [G loss: 2.994937]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mzFS0Us6-AaZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "1c4cb4b9-f315-4c6b-a9f0-9d200f241e26"
      },
      "cell_type": "code",
      "source": [
        "# 1000 iteration\n",
        "generated_img = model.generator.predict(np.random.normal(0, 1, (10, 100)))\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 2))\n",
        "n =10\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(1, n, i + 1)\n",
        "    plt.imshow(np.squeeze(generated_img[i]))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAABsCAYAAAAyoVQIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f186daffef0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "c1WfuFWp-BJ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85887
        },
        "outputId": "1283cb28-22bb-49b7-bb24-d86c1bd9f9fe"
      },
      "cell_type": "code",
      "source": [
        "model = GAN()\n",
        "model.train(epochs=5000)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_16 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_104 (Dense)            (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_76 (LeakyReLU)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_105 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_77 (LeakyReLU)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_106 (Dense)            (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 533,505\n",
            "Trainable params: 533,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_107 (Dense)            (None, 256)               25856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_78 (LeakyReLU)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_46 (Batc (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_108 (Dense)            (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_79 (LeakyReLU)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_47 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_109 (Dense)            (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_80 (LeakyReLU)   (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_48 (Batc (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense_110 (Dense)            (None, 784)               803600    \n",
            "_________________________________________________________________\n",
            "reshape_14 (Reshape)         (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 1,493,520\n",
            "Trainable params: 1,489,936\n",
            "Non-trainable params: 3,584\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 [ D loss: 0.745118, acc.: 25%] [G loss: 0.720588]\n",
            "1 [ D loss: 0.718380, acc.: 59%] [G loss: 0.748566]\n",
            "2 [ D loss: 0.570051, acc.: 75%] [G loss: 0.844547]\n",
            "3 [ D loss: 0.453935, acc.: 88%] [G loss: 0.956982]\n",
            "4 [ D loss: 0.482131, acc.: 80%] [G loss: 1.104053]\n",
            "5 [ D loss: 0.369860, acc.: 96%] [G loss: 1.219124]\n",
            "6 [ D loss: 0.321054, acc.: 96%] [G loss: 1.315813]\n",
            "7 [ D loss: 0.306236, acc.: 98%] [G loss: 1.355426]\n",
            "8 [ D loss: 0.261622, acc.: 98%] [G loss: 1.468564]\n",
            "9 [ D loss: 0.239889, acc.: 100%] [G loss: 1.563174]\n",
            "10 [ D loss: 0.209400, acc.: 100%] [G loss: 1.580536]\n",
            "11 [ D loss: 0.193943, acc.: 100%] [G loss: 1.658775]\n",
            "12 [ D loss: 0.189588, acc.: 100%] [G loss: 1.757692]\n",
            "13 [ D loss: 0.176261, acc.: 100%] [G loss: 1.828839]\n",
            "14 [ D loss: 0.162281, acc.: 99%] [G loss: 1.873948]\n",
            "15 [ D loss: 0.171595, acc.: 100%] [G loss: 1.994511]\n",
            "16 [ D loss: 0.142139, acc.: 100%] [G loss: 2.147608]\n",
            "17 [ D loss: 0.131660, acc.: 100%] [G loss: 2.171350]\n",
            "18 [ D loss: 0.124949, acc.: 100%] [G loss: 2.125986]\n",
            "19 [ D loss: 0.127008, acc.: 100%] [G loss: 2.239960]\n",
            "20 [ D loss: 0.123796, acc.: 100%] [G loss: 2.348320]\n",
            "21 [ D loss: 0.114540, acc.: 100%] [G loss: 2.386329]\n",
            "22 [ D loss: 0.097768, acc.: 100%] [G loss: 2.448088]\n",
            "23 [ D loss: 0.103335, acc.: 100%] [G loss: 2.522677]\n",
            "24 [ D loss: 0.091352, acc.: 100%] [G loss: 2.625906]\n",
            "25 [ D loss: 0.087757, acc.: 100%] [G loss: 2.576296]\n",
            "26 [ D loss: 0.076404, acc.: 100%] [G loss: 2.713105]\n",
            "27 [ D loss: 0.071327, acc.: 100%] [G loss: 2.662906]\n",
            "28 [ D loss: 0.084256, acc.: 100%] [G loss: 2.743119]\n",
            "29 [ D loss: 0.081288, acc.: 100%] [G loss: 2.855104]\n",
            "30 [ D loss: 0.077987, acc.: 100%] [G loss: 2.809801]\n",
            "31 [ D loss: 0.073573, acc.: 100%] [G loss: 2.834475]\n",
            "32 [ D loss: 0.082818, acc.: 99%] [G loss: 2.928953]\n",
            "33 [ D loss: 0.063756, acc.: 100%] [G loss: 3.017605]\n",
            "34 [ D loss: 0.068806, acc.: 100%] [G loss: 2.991932]\n",
            "35 [ D loss: 0.057995, acc.: 100%] [G loss: 3.000895]\n",
            "36 [ D loss: 0.077037, acc.: 100%] [G loss: 3.054844]\n",
            "37 [ D loss: 0.064186, acc.: 100%] [G loss: 3.160338]\n",
            "38 [ D loss: 0.087379, acc.: 100%] [G loss: 3.109722]\n",
            "39 [ D loss: 0.087559, acc.: 99%] [G loss: 3.266898]\n",
            "40 [ D loss: 0.079243, acc.: 98%] [G loss: 3.306884]\n",
            "41 [ D loss: 0.060882, acc.: 100%] [G loss: 3.405547]\n",
            "42 [ D loss: 0.070702, acc.: 100%] [G loss: 3.197136]\n",
            "43 [ D loss: 0.076701, acc.: 100%] [G loss: 3.342879]\n",
            "44 [ D loss: 0.087541, acc.: 98%] [G loss: 3.330651]\n",
            "45 [ D loss: 0.071120, acc.: 100%] [G loss: 3.366546]\n",
            "46 [ D loss: 0.104163, acc.: 97%] [G loss: 3.509176]\n",
            "47 [ D loss: 0.106565, acc.: 100%] [G loss: 3.586488]\n",
            "48 [ D loss: 0.135496, acc.: 97%] [G loss: 3.633234]\n",
            "49 [ D loss: 0.144735, acc.: 98%] [G loss: 3.629689]\n",
            "50 [ D loss: 0.165989, acc.: 95%] [G loss: 3.738660]\n",
            "51 [ D loss: 0.177595, acc.: 95%] [G loss: 3.603253]\n",
            "52 [ D loss: 0.181505, acc.: 93%] [G loss: 3.468507]\n",
            "53 [ D loss: 0.162567, acc.: 97%] [G loss: 3.946754]\n",
            "54 [ D loss: 0.268119, acc.: 88%] [G loss: 3.827775]\n",
            "55 [ D loss: 0.231194, acc.: 92%] [G loss: 3.975637]\n",
            "56 [ D loss: 0.289869, acc.: 88%] [G loss: 4.015928]\n",
            "57 [ D loss: 0.336116, acc.: 87%] [G loss: 3.834930]\n",
            "58 [ D loss: 0.182509, acc.: 95%] [G loss: 3.456940]\n",
            "59 [ D loss: 0.208533, acc.: 95%] [G loss: 3.408760]\n",
            "60 [ D loss: 0.170462, acc.: 95%] [G loss: 3.389978]\n",
            "61 [ D loss: 0.219847, acc.: 93%] [G loss: 3.391966]\n",
            "62 [ D loss: 0.247210, acc.: 91%] [G loss: 3.620262]\n",
            "63 [ D loss: 0.270961, acc.: 88%] [G loss: 3.773214]\n",
            "64 [ D loss: 0.234847, acc.: 93%] [G loss: 3.257724]\n",
            "65 [ D loss: 0.281633, acc.: 90%] [G loss: 2.915456]\n",
            "66 [ D loss: 0.278446, acc.: 91%] [G loss: 2.976935]\n",
            "67 [ D loss: 0.223226, acc.: 92%] [G loss: 3.328068]\n",
            "68 [ D loss: 0.421057, acc.: 80%] [G loss: 3.589694]\n",
            "69 [ D loss: 0.376618, acc.: 81%] [G loss: 3.255038]\n",
            "70 [ D loss: 0.333792, acc.: 85%] [G loss: 2.808640]\n",
            "71 [ D loss: 0.259495, acc.: 91%] [G loss: 2.819459]\n",
            "72 [ D loss: 0.275350, acc.: 88%] [G loss: 2.693322]\n",
            "73 [ D loss: 0.225946, acc.: 94%] [G loss: 2.926276]\n",
            "74 [ D loss: 0.243011, acc.: 93%] [G loss: 2.901878]\n",
            "75 [ D loss: 0.364126, acc.: 84%] [G loss: 2.866419]\n",
            "76 [ D loss: 0.578457, acc.: 73%] [G loss: 3.091485]\n",
            "77 [ D loss: 0.322382, acc.: 85%] [G loss: 2.753750]\n",
            "78 [ D loss: 0.384070, acc.: 82%] [G loss: 2.724966]\n",
            "79 [ D loss: 0.480339, acc.: 79%] [G loss: 2.912733]\n",
            "80 [ D loss: 0.315448, acc.: 91%] [G loss: 2.998852]\n",
            "81 [ D loss: 0.485986, acc.: 77%] [G loss: 2.779541]\n",
            "82 [ D loss: 0.352979, acc.: 84%] [G loss: 2.475253]\n",
            "83 [ D loss: 0.306087, acc.: 84%] [G loss: 2.626617]\n",
            "84 [ D loss: 0.314882, acc.: 84%] [G loss: 2.993056]\n",
            "85 [ D loss: 0.316760, acc.: 84%] [G loss: 3.214185]\n",
            "86 [ D loss: 0.303057, acc.: 88%] [G loss: 2.995262]\n",
            "87 [ D loss: 0.390929, acc.: 82%] [G loss: 2.902762]\n",
            "88 [ D loss: 0.282927, acc.: 89%] [G loss: 2.730506]\n",
            "89 [ D loss: 0.301794, acc.: 88%] [G loss: 2.800732]\n",
            "90 [ D loss: 0.330777, acc.: 84%] [G loss: 2.717093]\n",
            "91 [ D loss: 0.398315, acc.: 85%] [G loss: 3.116993]\n",
            "92 [ D loss: 0.342237, acc.: 89%] [G loss: 3.084361]\n",
            "93 [ D loss: 0.399737, acc.: 82%] [G loss: 3.033028]\n",
            "94 [ D loss: 0.268600, acc.: 93%] [G loss: 2.690625]\n",
            "95 [ D loss: 0.388192, acc.: 80%] [G loss: 2.896746]\n",
            "96 [ D loss: 0.349526, acc.: 87%] [G loss: 3.159354]\n",
            "97 [ D loss: 0.373186, acc.: 80%] [G loss: 2.923207]\n",
            "98 [ D loss: 0.433145, acc.: 80%] [G loss: 2.817987]\n",
            "99 [ D loss: 0.398395, acc.: 81%] [G loss: 3.107462]\n",
            "100 [ D loss: 0.459994, acc.: 74%] [G loss: 2.690182]\n",
            "101 [ D loss: 0.429738, acc.: 84%] [G loss: 2.646959]\n",
            "102 [ D loss: 0.416737, acc.: 82%] [G loss: 2.864432]\n",
            "103 [ D loss: 0.492896, acc.: 73%] [G loss: 3.302526]\n",
            "104 [ D loss: 0.432021, acc.: 77%] [G loss: 3.481400]\n",
            "105 [ D loss: 0.520285, acc.: 78%] [G loss: 2.890736]\n",
            "106 [ D loss: 0.386374, acc.: 80%] [G loss: 2.608806]\n",
            "107 [ D loss: 0.373879, acc.: 84%] [G loss: 2.666436]\n",
            "108 [ D loss: 0.310325, acc.: 90%] [G loss: 2.570632]\n",
            "109 [ D loss: 0.364109, acc.: 87%] [G loss: 2.840716]\n",
            "110 [ D loss: 0.285459, acc.: 92%] [G loss: 2.720083]\n",
            "111 [ D loss: 0.363644, acc.: 88%] [G loss: 2.784527]\n",
            "112 [ D loss: 0.425150, acc.: 82%] [G loss: 2.798543]\n",
            "113 [ D loss: 0.490082, acc.: 77%] [G loss: 3.224461]\n",
            "114 [ D loss: 0.496248, acc.: 71%] [G loss: 3.071046]\n",
            "115 [ D loss: 0.502374, acc.: 72%] [G loss: 2.880140]\n",
            "116 [ D loss: 0.308718, acc.: 89%] [G loss: 2.569734]\n",
            "117 [ D loss: 0.467000, acc.: 77%] [G loss: 2.986455]\n",
            "118 [ D loss: 0.368144, acc.: 84%] [G loss: 2.719779]\n",
            "119 [ D loss: 0.468762, acc.: 77%] [G loss: 2.755418]\n",
            "120 [ D loss: 0.430383, acc.: 81%] [G loss: 2.806219]\n",
            "121 [ D loss: 0.456260, acc.: 77%] [G loss: 2.550292]\n",
            "122 [ D loss: 0.462866, acc.: 77%] [G loss: 2.555848]\n",
            "123 [ D loss: 0.502118, acc.: 73%] [G loss: 2.554746]\n",
            "124 [ D loss: 0.428492, acc.: 82%] [G loss: 2.709000]\n",
            "125 [ D loss: 0.419090, acc.: 80%] [G loss: 2.371359]\n",
            "126 [ D loss: 0.433187, acc.: 80%] [G loss: 2.640729]\n",
            "127 [ D loss: 0.450025, acc.: 81%] [G loss: 2.515132]\n",
            "128 [ D loss: 0.513847, acc.: 76%] [G loss: 3.132295]\n",
            "129 [ D loss: 0.469880, acc.: 76%] [G loss: 3.013416]\n",
            "130 [ D loss: 0.508254, acc.: 70%] [G loss: 2.786400]\n",
            "131 [ D loss: 0.395703, acc.: 88%] [G loss: 2.660767]\n",
            "132 [ D loss: 0.457822, acc.: 77%] [G loss: 2.896935]\n",
            "133 [ D loss: 0.355152, acc.: 86%] [G loss: 2.624712]\n",
            "134 [ D loss: 0.411733, acc.: 79%] [G loss: 2.451807]\n",
            "135 [ D loss: 0.407545, acc.: 84%] [G loss: 2.707957]\n",
            "136 [ D loss: 0.381165, acc.: 84%] [G loss: 2.796510]\n",
            "137 [ D loss: 0.515546, acc.: 75%] [G loss: 2.917331]\n",
            "138 [ D loss: 0.436119, acc.: 80%] [G loss: 2.702770]\n",
            "139 [ D loss: 0.464464, acc.: 80%] [G loss: 2.515554]\n",
            "140 [ D loss: 0.463537, acc.: 80%] [G loss: 2.840779]\n",
            "141 [ D loss: 0.481171, acc.: 74%] [G loss: 2.589783]\n",
            "142 [ D loss: 0.418908, acc.: 81%] [G loss: 2.726533]\n",
            "143 [ D loss: 0.472160, acc.: 78%] [G loss: 2.869140]\n",
            "144 [ D loss: 0.451456, acc.: 79%] [G loss: 2.910161]\n",
            "145 [ D loss: 0.428305, acc.: 83%] [G loss: 2.653206]\n",
            "146 [ D loss: 0.427358, acc.: 80%] [G loss: 2.517455]\n",
            "147 [ D loss: 0.383388, acc.: 88%] [G loss: 2.704745]\n",
            "148 [ D loss: 0.460069, acc.: 78%] [G loss: 3.012780]\n",
            "149 [ D loss: 0.443883, acc.: 80%] [G loss: 2.592869]\n",
            "150 [ D loss: 0.450261, acc.: 81%] [G loss: 2.739269]\n",
            "151 [ D loss: 0.421989, acc.: 82%] [G loss: 2.807701]\n",
            "152 [ D loss: 0.465870, acc.: 73%] [G loss: 2.994313]\n",
            "153 [ D loss: 0.439114, acc.: 79%] [G loss: 2.749051]\n",
            "154 [ D loss: 0.468712, acc.: 73%] [G loss: 2.732453]\n",
            "155 [ D loss: 0.409479, acc.: 82%] [G loss: 2.839853]\n",
            "156 [ D loss: 0.416862, acc.: 82%] [G loss: 2.857951]\n",
            "157 [ D loss: 0.411605, acc.: 81%] [G loss: 2.953425]\n",
            "158 [ D loss: 0.464163, acc.: 80%] [G loss: 2.892236]\n",
            "159 [ D loss: 0.404867, acc.: 82%] [G loss: 2.783319]\n",
            "160 [ D loss: 0.530456, acc.: 70%] [G loss: 2.833390]\n",
            "161 [ D loss: 0.508052, acc.: 79%] [G loss: 2.870149]\n",
            "162 [ D loss: 0.500987, acc.: 76%] [G loss: 2.752342]\n",
            "163 [ D loss: 0.472991, acc.: 78%] [G loss: 2.679744]\n",
            "164 [ D loss: 0.490529, acc.: 77%] [G loss: 2.995284]\n",
            "165 [ D loss: 0.467365, acc.: 78%] [G loss: 2.690455]\n",
            "166 [ D loss: 0.474674, acc.: 79%] [G loss: 2.888977]\n",
            "167 [ D loss: 0.488652, acc.: 76%] [G loss: 2.999706]\n",
            "168 [ D loss: 0.496846, acc.: 71%] [G loss: 2.440913]\n",
            "169 [ D loss: 0.411569, acc.: 88%] [G loss: 2.663411]\n",
            "170 [ D loss: 0.447736, acc.: 80%] [G loss: 2.911450]\n",
            "171 [ D loss: 0.507909, acc.: 73%] [G loss: 2.884964]\n",
            "172 [ D loss: 0.529416, acc.: 70%] [G loss: 2.881921]\n",
            "173 [ D loss: 0.479433, acc.: 72%] [G loss: 2.756118]\n",
            "174 [ D loss: 0.530712, acc.: 73%] [G loss: 2.558217]\n",
            "175 [ D loss: 0.518589, acc.: 74%] [G loss: 2.680678]\n",
            "176 [ D loss: 0.550648, acc.: 76%] [G loss: 3.007630]\n",
            "177 [ D loss: 0.539004, acc.: 67%] [G loss: 2.651939]\n",
            "178 [ D loss: 0.487888, acc.: 78%] [G loss: 2.960380]\n",
            "179 [ D loss: 0.466709, acc.: 74%] [G loss: 2.542153]\n",
            "180 [ D loss: 0.590427, acc.: 66%] [G loss: 2.820359]\n",
            "181 [ D loss: 0.438776, acc.: 81%] [G loss: 2.893762]\n",
            "182 [ D loss: 0.580593, acc.: 64%] [G loss: 2.631227]\n",
            "183 [ D loss: 0.618892, acc.: 63%] [G loss: 2.597538]\n",
            "184 [ D loss: 0.568771, acc.: 66%] [G loss: 2.747973]\n",
            "185 [ D loss: 0.606338, acc.: 64%] [G loss: 2.465370]\n",
            "186 [ D loss: 0.591077, acc.: 66%] [G loss: 2.628080]\n",
            "187 [ D loss: 0.636710, acc.: 63%] [G loss: 2.845435]\n",
            "188 [ D loss: 0.544257, acc.: 70%] [G loss: 2.849416]\n",
            "189 [ D loss: 0.529895, acc.: 67%] [G loss: 2.434903]\n",
            "190 [ D loss: 0.656220, acc.: 58%] [G loss: 2.458092]\n",
            "191 [ D loss: 0.625346, acc.: 61%] [G loss: 2.908932]\n",
            "192 [ D loss: 0.544221, acc.: 66%] [G loss: 2.833610]\n",
            "193 [ D loss: 0.619695, acc.: 59%] [G loss: 2.427362]\n",
            "194 [ D loss: 0.528154, acc.: 72%] [G loss: 2.441920]\n",
            "195 [ D loss: 0.641978, acc.: 58%] [G loss: 2.628994]\n",
            "196 [ D loss: 0.568369, acc.: 66%] [G loss: 2.407475]\n",
            "197 [ D loss: 0.649932, acc.: 65%] [G loss: 2.528762]\n",
            "198 [ D loss: 0.558395, acc.: 68%] [G loss: 2.661847]\n",
            "199 [ D loss: 0.539970, acc.: 70%] [G loss: 2.699542]\n",
            "200 [ D loss: 0.634993, acc.: 66%] [G loss: 2.640462]\n",
            "201 [ D loss: 0.615352, acc.: 61%] [G loss: 2.424897]\n",
            "202 [ D loss: 0.555534, acc.: 68%] [G loss: 2.564675]\n",
            "203 [ D loss: 0.576684, acc.: 64%] [G loss: 2.515194]\n",
            "204 [ D loss: 0.597105, acc.: 70%] [G loss: 2.501597]\n",
            "205 [ D loss: 0.726464, acc.: 51%] [G loss: 2.725065]\n",
            "206 [ D loss: 0.535991, acc.: 71%] [G loss: 2.468053]\n",
            "207 [ D loss: 0.684809, acc.: 52%] [G loss: 2.306756]\n",
            "208 [ D loss: 0.625205, acc.: 62%] [G loss: 2.304874]\n",
            "209 [ D loss: 0.559113, acc.: 70%] [G loss: 2.282605]\n",
            "210 [ D loss: 0.652087, acc.: 59%] [G loss: 2.396476]\n",
            "211 [ D loss: 0.605317, acc.: 68%] [G loss: 2.395435]\n",
            "212 [ D loss: 0.594750, acc.: 66%] [G loss: 2.408752]\n",
            "213 [ D loss: 0.701981, acc.: 59%] [G loss: 2.411319]\n",
            "214 [ D loss: 0.623580, acc.: 58%] [G loss: 2.277702]\n",
            "215 [ D loss: 0.670776, acc.: 62%] [G loss: 2.164157]\n",
            "216 [ D loss: 0.692084, acc.: 55%] [G loss: 2.429340]\n",
            "217 [ D loss: 0.633441, acc.: 67%] [G loss: 2.397561]\n",
            "218 [ D loss: 0.635916, acc.: 61%] [G loss: 2.322672]\n",
            "219 [ D loss: 0.668545, acc.: 57%] [G loss: 2.295852]\n",
            "220 [ D loss: 0.620976, acc.: 62%] [G loss: 2.219162]\n",
            "221 [ D loss: 0.574122, acc.: 68%] [G loss: 2.296479]\n",
            "222 [ D loss: 0.629755, acc.: 59%] [G loss: 2.306912]\n",
            "223 [ D loss: 0.662120, acc.: 53%] [G loss: 2.391369]\n",
            "224 [ D loss: 0.600030, acc.: 67%] [G loss: 2.202997]\n",
            "225 [ D loss: 0.688235, acc.: 51%] [G loss: 2.042077]\n",
            "226 [ D loss: 0.640957, acc.: 59%] [G loss: 2.164772]\n",
            "227 [ D loss: 0.645748, acc.: 61%] [G loss: 2.296864]\n",
            "228 [ D loss: 0.669926, acc.: 54%] [G loss: 2.178212]\n",
            "229 [ D loss: 0.642871, acc.: 66%] [G loss: 2.149505]\n",
            "230 [ D loss: 0.622469, acc.: 64%] [G loss: 2.056520]\n",
            "231 [ D loss: 0.574498, acc.: 66%] [G loss: 2.150932]\n",
            "232 [ D loss: 0.600136, acc.: 63%] [G loss: 2.232587]\n",
            "233 [ D loss: 0.576057, acc.: 65%] [G loss: 2.070899]\n",
            "234 [ D loss: 0.569848, acc.: 67%] [G loss: 2.204608]\n",
            "235 [ D loss: 0.601458, acc.: 61%] [G loss: 2.177145]\n",
            "236 [ D loss: 0.636314, acc.: 61%] [G loss: 2.131033]\n",
            "237 [ D loss: 0.593612, acc.: 63%] [G loss: 2.214403]\n",
            "238 [ D loss: 0.629700, acc.: 59%] [G loss: 2.137413]\n",
            "239 [ D loss: 0.626392, acc.: 62%] [G loss: 1.977826]\n",
            "240 [ D loss: 0.613121, acc.: 65%] [G loss: 1.983766]\n",
            "241 [ D loss: 0.595055, acc.: 67%] [G loss: 1.977747]\n",
            "242 [ D loss: 0.644082, acc.: 62%] [G loss: 2.034906]\n",
            "243 [ D loss: 0.614911, acc.: 62%] [G loss: 2.035749]\n",
            "244 [ D loss: 0.623771, acc.: 57%] [G loss: 2.144558]\n",
            "245 [ D loss: 0.587176, acc.: 61%] [G loss: 2.085294]\n",
            "246 [ D loss: 0.655365, acc.: 62%] [G loss: 1.879541]\n",
            "247 [ D loss: 0.650065, acc.: 61%] [G loss: 1.852484]\n",
            "248 [ D loss: 0.645324, acc.: 58%] [G loss: 1.963814]\n",
            "249 [ D loss: 0.653982, acc.: 57%] [G loss: 1.989438]\n",
            "250 [ D loss: 0.660783, acc.: 59%] [G loss: 1.939273]\n",
            "251 [ D loss: 0.559593, acc.: 68%] [G loss: 1.936441]\n",
            "252 [ D loss: 0.605388, acc.: 62%] [G loss: 1.942783]\n",
            "253 [ D loss: 0.643990, acc.: 58%] [G loss: 1.925578]\n",
            "254 [ D loss: 0.635781, acc.: 60%] [G loss: 1.972422]\n",
            "255 [ D loss: 0.641916, acc.: 57%] [G loss: 2.037323]\n",
            "256 [ D loss: 0.627520, acc.: 55%] [G loss: 1.932714]\n",
            "257 [ D loss: 0.568525, acc.: 67%] [G loss: 2.017794]\n",
            "258 [ D loss: 0.607167, acc.: 60%] [G loss: 2.044353]\n",
            "259 [ D loss: 0.609512, acc.: 62%] [G loss: 1.863804]\n",
            "260 [ D loss: 0.680205, acc.: 55%] [G loss: 1.937335]\n",
            "261 [ D loss: 0.665293, acc.: 61%] [G loss: 1.907490]\n",
            "262 [ D loss: 0.662315, acc.: 60%] [G loss: 1.807665]\n",
            "263 [ D loss: 0.659794, acc.: 55%] [G loss: 1.859367]\n",
            "264 [ D loss: 0.613224, acc.: 61%] [G loss: 1.845760]\n",
            "265 [ D loss: 0.615575, acc.: 61%] [G loss: 1.985914]\n",
            "266 [ D loss: 0.691692, acc.: 57%] [G loss: 1.876733]\n",
            "267 [ D loss: 0.654425, acc.: 56%] [G loss: 1.869134]\n",
            "268 [ D loss: 0.661186, acc.: 55%] [G loss: 1.739513]\n",
            "269 [ D loss: 0.590348, acc.: 64%] [G loss: 1.748506]\n",
            "270 [ D loss: 0.654793, acc.: 52%] [G loss: 1.810536]\n",
            "271 [ D loss: 0.600255, acc.: 56%] [G loss: 1.754091]\n",
            "272 [ D loss: 0.601066, acc.: 58%] [G loss: 1.729614]\n",
            "273 [ D loss: 0.642872, acc.: 60%] [G loss: 1.721184]\n",
            "274 [ D loss: 0.692382, acc.: 57%] [G loss: 1.681384]\n",
            "275 [ D loss: 0.626844, acc.: 58%] [G loss: 1.843511]\n",
            "276 [ D loss: 0.633970, acc.: 61%] [G loss: 1.819545]\n",
            "277 [ D loss: 0.632828, acc.: 59%] [G loss: 1.741229]\n",
            "278 [ D loss: 0.593351, acc.: 65%] [G loss: 1.747673]\n",
            "279 [ D loss: 0.676972, acc.: 51%] [G loss: 1.810890]\n",
            "280 [ D loss: 0.636156, acc.: 57%] [G loss: 1.768911]\n",
            "281 [ D loss: 0.649350, acc.: 55%] [G loss: 1.685319]\n",
            "282 [ D loss: 0.606819, acc.: 62%] [G loss: 1.741323]\n",
            "283 [ D loss: 0.639269, acc.: 57%] [G loss: 1.671221]\n",
            "284 [ D loss: 0.649589, acc.: 60%] [G loss: 1.703357]\n",
            "285 [ D loss: 0.615224, acc.: 62%] [G loss: 1.792203]\n",
            "286 [ D loss: 0.617475, acc.: 55%] [G loss: 1.790093]\n",
            "287 [ D loss: 0.607650, acc.: 63%] [G loss: 1.772390]\n",
            "288 [ D loss: 0.642911, acc.: 62%] [G loss: 1.710921]\n",
            "289 [ D loss: 0.568371, acc.: 63%] [G loss: 1.676009]\n",
            "290 [ D loss: 0.628558, acc.: 61%] [G loss: 1.672535]\n",
            "291 [ D loss: 0.643522, acc.: 48%] [G loss: 1.712189]\n",
            "292 [ D loss: 0.624909, acc.: 62%] [G loss: 1.696151]\n",
            "293 [ D loss: 0.635360, acc.: 59%] [G loss: 1.651694]\n",
            "294 [ D loss: 0.656456, acc.: 62%] [G loss: 1.712563]\n",
            "295 [ D loss: 0.628402, acc.: 63%] [G loss: 1.662813]\n",
            "296 [ D loss: 0.626998, acc.: 62%] [G loss: 1.692570]\n",
            "297 [ D loss: 0.690829, acc.: 55%] [G loss: 1.476879]\n",
            "298 [ D loss: 0.648020, acc.: 59%] [G loss: 1.532687]\n",
            "299 [ D loss: 0.612645, acc.: 62%] [G loss: 1.557053]\n",
            "300 [ D loss: 0.611024, acc.: 64%] [G loss: 1.593332]\n",
            "301 [ D loss: 0.616966, acc.: 60%] [G loss: 1.563863]\n",
            "302 [ D loss: 0.621596, acc.: 58%] [G loss: 1.515900]\n",
            "303 [ D loss: 0.656471, acc.: 55%] [G loss: 1.572500]\n",
            "304 [ D loss: 0.637588, acc.: 59%] [G loss: 1.569334]\n",
            "305 [ D loss: 0.628750, acc.: 61%] [G loss: 1.638682]\n",
            "306 [ D loss: 0.632411, acc.: 61%] [G loss: 1.599185]\n",
            "307 [ D loss: 0.636126, acc.: 59%] [G loss: 1.613026]\n",
            "308 [ D loss: 0.615659, acc.: 62%] [G loss: 1.575987]\n",
            "309 [ D loss: 0.659008, acc.: 59%] [G loss: 1.527075]\n",
            "310 [ D loss: 0.643140, acc.: 62%] [G loss: 1.451542]\n",
            "311 [ D loss: 0.632157, acc.: 61%] [G loss: 1.442664]\n",
            "312 [ D loss: 0.602993, acc.: 64%] [G loss: 1.519737]\n",
            "313 [ D loss: 0.619558, acc.: 62%] [G loss: 1.531843]\n",
            "314 [ D loss: 0.685886, acc.: 53%] [G loss: 1.526706]\n",
            "315 [ D loss: 0.663757, acc.: 55%] [G loss: 1.529715]\n",
            "316 [ D loss: 0.631827, acc.: 60%] [G loss: 1.508772]\n",
            "317 [ D loss: 0.637434, acc.: 63%] [G loss: 1.521592]\n",
            "318 [ D loss: 0.644469, acc.: 61%] [G loss: 1.530848]\n",
            "319 [ D loss: 0.623864, acc.: 60%] [G loss: 1.517206]\n",
            "320 [ D loss: 0.643961, acc.: 59%] [G loss: 1.460880]\n",
            "321 [ D loss: 0.662218, acc.: 54%] [G loss: 1.472409]\n",
            "322 [ D loss: 0.652562, acc.: 57%] [G loss: 1.412884]\n",
            "323 [ D loss: 0.707473, acc.: 48%] [G loss: 1.373324]\n",
            "324 [ D loss: 0.624953, acc.: 60%] [G loss: 1.441075]\n",
            "325 [ D loss: 0.644913, acc.: 55%] [G loss: 1.486438]\n",
            "326 [ D loss: 0.664836, acc.: 57%] [G loss: 1.517020]\n",
            "327 [ D loss: 0.663854, acc.: 56%] [G loss: 1.452962]\n",
            "328 [ D loss: 0.690996, acc.: 54%] [G loss: 1.402602]\n",
            "329 [ D loss: 0.660350, acc.: 57%] [G loss: 1.352843]\n",
            "330 [ D loss: 0.667875, acc.: 54%] [G loss: 1.381789]\n",
            "331 [ D loss: 0.625620, acc.: 62%] [G loss: 1.392950]\n",
            "332 [ D loss: 0.595959, acc.: 66%] [G loss: 1.509473]\n",
            "333 [ D loss: 0.641766, acc.: 55%] [G loss: 1.425204]\n",
            "334 [ D loss: 0.611672, acc.: 59%] [G loss: 1.447806]\n",
            "335 [ D loss: 0.621504, acc.: 62%] [G loss: 1.429681]\n",
            "336 [ D loss: 0.626302, acc.: 57%] [G loss: 1.348845]\n",
            "337 [ D loss: 0.681616, acc.: 52%] [G loss: 1.380496]\n",
            "338 [ D loss: 0.624971, acc.: 64%] [G loss: 1.370621]\n",
            "339 [ D loss: 0.645665, acc.: 56%] [G loss: 1.374454]\n",
            "340 [ D loss: 0.620380, acc.: 59%] [G loss: 1.435849]\n",
            "341 [ D loss: 0.633777, acc.: 57%] [G loss: 1.417565]\n",
            "342 [ D loss: 0.645360, acc.: 55%] [G loss: 1.383846]\n",
            "343 [ D loss: 0.635768, acc.: 55%] [G loss: 1.378122]\n",
            "344 [ D loss: 0.617272, acc.: 60%] [G loss: 1.432996]\n",
            "345 [ D loss: 0.622174, acc.: 60%] [G loss: 1.429830]\n",
            "346 [ D loss: 0.630061, acc.: 59%] [G loss: 1.385945]\n",
            "347 [ D loss: 0.618544, acc.: 58%] [G loss: 1.366871]\n",
            "348 [ D loss: 0.644905, acc.: 54%] [G loss: 1.354009]\n",
            "349 [ D loss: 0.648011, acc.: 53%] [G loss: 1.362453]\n",
            "350 [ D loss: 0.614847, acc.: 63%] [G loss: 1.381393]\n",
            "351 [ D loss: 0.600492, acc.: 59%] [G loss: 1.454983]\n",
            "352 [ D loss: 0.612941, acc.: 61%] [G loss: 1.403474]\n",
            "353 [ D loss: 0.595904, acc.: 62%] [G loss: 1.420223]\n",
            "354 [ D loss: 0.622946, acc.: 59%] [G loss: 1.480646]\n",
            "355 [ D loss: 0.623366, acc.: 58%] [G loss: 1.433553]\n",
            "356 [ D loss: 0.609030, acc.: 62%] [G loss: 1.429135]\n",
            "357 [ D loss: 0.642208, acc.: 59%] [G loss: 1.410367]\n",
            "358 [ D loss: 0.618191, acc.: 59%] [G loss: 1.361159]\n",
            "359 [ D loss: 0.652614, acc.: 55%] [G loss: 1.387460]\n",
            "360 [ D loss: 0.637420, acc.: 53%] [G loss: 1.361130]\n",
            "361 [ D loss: 0.597261, acc.: 66%] [G loss: 1.400361]\n",
            "362 [ D loss: 0.644107, acc.: 58%] [G loss: 1.379277]\n",
            "363 [ D loss: 0.653154, acc.: 56%] [G loss: 1.334186]\n",
            "364 [ D loss: 0.620341, acc.: 62%] [G loss: 1.405799]\n",
            "365 [ D loss: 0.599111, acc.: 65%] [G loss: 1.466779]\n",
            "366 [ D loss: 0.664758, acc.: 52%] [G loss: 1.316638]\n",
            "367 [ D loss: 0.648186, acc.: 54%] [G loss: 1.351732]\n",
            "368 [ D loss: 0.610881, acc.: 60%] [G loss: 1.401279]\n",
            "369 [ D loss: 0.625188, acc.: 55%] [G loss: 1.360479]\n",
            "370 [ D loss: 0.631718, acc.: 56%] [G loss: 1.343215]\n",
            "371 [ D loss: 0.604817, acc.: 61%] [G loss: 1.389391]\n",
            "372 [ D loss: 0.611256, acc.: 57%] [G loss: 1.383192]\n",
            "373 [ D loss: 0.664156, acc.: 48%] [G loss: 1.348183]\n",
            "374 [ D loss: 0.599856, acc.: 59%] [G loss: 1.362782]\n",
            "375 [ D loss: 0.632723, acc.: 58%] [G loss: 1.361252]\n",
            "376 [ D loss: 0.598929, acc.: 59%] [G loss: 1.352520]\n",
            "377 [ D loss: 0.620478, acc.: 59%] [G loss: 1.392158]\n",
            "378 [ D loss: 0.604727, acc.: 57%] [G loss: 1.393604]\n",
            "379 [ D loss: 0.592175, acc.: 62%] [G loss: 1.389032]\n",
            "380 [ D loss: 0.607881, acc.: 59%] [G loss: 1.390949]\n",
            "381 [ D loss: 0.614439, acc.: 53%] [G loss: 1.362345]\n",
            "382 [ D loss: 0.594562, acc.: 62%] [G loss: 1.387191]\n",
            "383 [ D loss: 0.611617, acc.: 60%] [G loss: 1.353138]\n",
            "384 [ D loss: 0.579094, acc.: 64%] [G loss: 1.407377]\n",
            "385 [ D loss: 0.639176, acc.: 58%] [G loss: 1.384935]\n",
            "386 [ D loss: 0.646268, acc.: 51%] [G loss: 1.372565]\n",
            "387 [ D loss: 0.624210, acc.: 60%] [G loss: 1.361553]\n",
            "388 [ D loss: 0.596733, acc.: 64%] [G loss: 1.350773]\n",
            "389 [ D loss: 0.617704, acc.: 62%] [G loss: 1.327699]\n",
            "390 [ D loss: 0.616705, acc.: 61%] [G loss: 1.324221]\n",
            "391 [ D loss: 0.618969, acc.: 62%] [G loss: 1.350938]\n",
            "392 [ D loss: 0.600147, acc.: 64%] [G loss: 1.328594]\n",
            "393 [ D loss: 0.650993, acc.: 55%] [G loss: 1.292316]\n",
            "394 [ D loss: 0.606511, acc.: 66%] [G loss: 1.361167]\n",
            "395 [ D loss: 0.619676, acc.: 61%] [G loss: 1.293769]\n",
            "396 [ D loss: 0.641662, acc.: 54%] [G loss: 1.288814]\n",
            "397 [ D loss: 0.660217, acc.: 59%] [G loss: 1.253942]\n",
            "398 [ D loss: 0.632193, acc.: 62%] [G loss: 1.294205]\n",
            "399 [ D loss: 0.647192, acc.: 57%] [G loss: 1.305540]\n",
            "400 [ D loss: 0.634211, acc.: 61%] [G loss: 1.318668]\n",
            "401 [ D loss: 0.661512, acc.: 59%] [G loss: 1.301519]\n",
            "402 [ D loss: 0.647351, acc.: 61%] [G loss: 1.298462]\n",
            "403 [ D loss: 0.630634, acc.: 59%] [G loss: 1.276235]\n",
            "404 [ D loss: 0.655695, acc.: 57%] [G loss: 1.258346]\n",
            "405 [ D loss: 0.634616, acc.: 59%] [G loss: 1.282651]\n",
            "406 [ D loss: 0.639272, acc.: 62%] [G loss: 1.263248]\n",
            "407 [ D loss: 0.616263, acc.: 62%] [G loss: 1.307493]\n",
            "408 [ D loss: 0.653487, acc.: 57%] [G loss: 1.272437]\n",
            "409 [ D loss: 0.614342, acc.: 62%] [G loss: 1.295521]\n",
            "410 [ D loss: 0.597242, acc.: 65%] [G loss: 1.319535]\n",
            "411 [ D loss: 0.624295, acc.: 62%] [G loss: 1.335135]\n",
            "412 [ D loss: 0.643810, acc.: 60%] [G loss: 1.346717]\n",
            "413 [ D loss: 0.625329, acc.: 62%] [G loss: 1.334573]\n",
            "414 [ D loss: 0.602430, acc.: 70%] [G loss: 1.329890]\n",
            "415 [ D loss: 0.636828, acc.: 60%] [G loss: 1.296805]\n",
            "416 [ D loss: 0.615335, acc.: 65%] [G loss: 1.325003]\n",
            "417 [ D loss: 0.617292, acc.: 59%] [G loss: 1.318201]\n",
            "418 [ D loss: 0.603917, acc.: 64%] [G loss: 1.272322]\n",
            "419 [ D loss: 0.625278, acc.: 62%] [G loss: 1.306801]\n",
            "420 [ D loss: 0.621033, acc.: 63%] [G loss: 1.297384]\n",
            "421 [ D loss: 0.590227, acc.: 63%] [G loss: 1.304316]\n",
            "422 [ D loss: 0.608043, acc.: 65%] [G loss: 1.320321]\n",
            "423 [ D loss: 0.613796, acc.: 62%] [G loss: 1.366943]\n",
            "424 [ D loss: 0.664120, acc.: 57%] [G loss: 1.342640]\n",
            "425 [ D loss: 0.639625, acc.: 59%] [G loss: 1.276309]\n",
            "426 [ D loss: 0.599282, acc.: 68%] [G loss: 1.247236]\n",
            "427 [ D loss: 0.624575, acc.: 71%] [G loss: 1.295994]\n",
            "428 [ D loss: 0.627979, acc.: 62%] [G loss: 1.274797]\n",
            "429 [ D loss: 0.620883, acc.: 62%] [G loss: 1.269594]\n",
            "430 [ D loss: 0.674625, acc.: 53%] [G loss: 1.225753]\n",
            "431 [ D loss: 0.597497, acc.: 66%] [G loss: 1.264193]\n",
            "432 [ D loss: 0.609364, acc.: 69%] [G loss: 1.347118]\n",
            "433 [ D loss: 0.604710, acc.: 66%] [G loss: 1.334764]\n",
            "434 [ D loss: 0.606060, acc.: 61%] [G loss: 1.379900]\n",
            "435 [ D loss: 0.634788, acc.: 64%] [G loss: 1.268442]\n",
            "436 [ D loss: 0.595980, acc.: 68%] [G loss: 1.286243]\n",
            "437 [ D loss: 0.584471, acc.: 68%] [G loss: 1.279221]\n",
            "438 [ D loss: 0.633765, acc.: 59%] [G loss: 1.249313]\n",
            "439 [ D loss: 0.632352, acc.: 56%] [G loss: 1.250826]\n",
            "440 [ D loss: 0.613838, acc.: 58%] [G loss: 1.325707]\n",
            "441 [ D loss: 0.647309, acc.: 48%] [G loss: 1.258225]\n",
            "442 [ D loss: 0.644291, acc.: 57%] [G loss: 1.216929]\n",
            "443 [ D loss: 0.658474, acc.: 55%] [G loss: 1.207116]\n",
            "444 [ D loss: 0.617514, acc.: 67%] [G loss: 1.288207]\n",
            "445 [ D loss: 0.621067, acc.: 64%] [G loss: 1.255656]\n",
            "446 [ D loss: 0.609360, acc.: 59%] [G loss: 1.275472]\n",
            "447 [ D loss: 0.609281, acc.: 61%] [G loss: 1.278743]\n",
            "448 [ D loss: 0.603892, acc.: 58%] [G loss: 1.265574]\n",
            "449 [ D loss: 0.610849, acc.: 60%] [G loss: 1.277861]\n",
            "450 [ D loss: 0.654442, acc.: 51%] [G loss: 1.269560]\n",
            "451 [ D loss: 0.611052, acc.: 64%] [G loss: 1.237797]\n",
            "452 [ D loss: 0.612838, acc.: 65%] [G loss: 1.257572]\n",
            "453 [ D loss: 0.626476, acc.: 66%] [G loss: 1.234663]\n",
            "454 [ D loss: 0.596640, acc.: 68%] [G loss: 1.253249]\n",
            "455 [ D loss: 0.603933, acc.: 60%] [G loss: 1.224284]\n",
            "456 [ D loss: 0.634882, acc.: 59%] [G loss: 1.177082]\n",
            "457 [ D loss: 0.597948, acc.: 65%] [G loss: 1.235779]\n",
            "458 [ D loss: 0.598330, acc.: 68%] [G loss: 1.326816]\n",
            "459 [ D loss: 0.620255, acc.: 59%] [G loss: 1.270723]\n",
            "460 [ D loss: 0.633523, acc.: 63%] [G loss: 1.196999]\n",
            "461 [ D loss: 0.604924, acc.: 70%] [G loss: 1.272487]\n",
            "462 [ D loss: 0.619905, acc.: 65%] [G loss: 1.225185]\n",
            "463 [ D loss: 0.646458, acc.: 63%] [G loss: 1.217190]\n",
            "464 [ D loss: 0.625096, acc.: 64%] [G loss: 1.217373]\n",
            "465 [ D loss: 0.619324, acc.: 58%] [G loss: 1.205474]\n",
            "466 [ D loss: 0.600826, acc.: 62%] [G loss: 1.255568]\n",
            "467 [ D loss: 0.613322, acc.: 69%] [G loss: 1.253368]\n",
            "468 [ D loss: 0.631666, acc.: 60%] [G loss: 1.257620]\n",
            "469 [ D loss: 0.622083, acc.: 68%] [G loss: 1.230762]\n",
            "470 [ D loss: 0.580647, acc.: 73%] [G loss: 1.275581]\n",
            "471 [ D loss: 0.627973, acc.: 62%] [G loss: 1.208953]\n",
            "472 [ D loss: 0.587163, acc.: 70%] [G loss: 1.269497]\n",
            "473 [ D loss: 0.607403, acc.: 59%] [G loss: 1.312791]\n",
            "474 [ D loss: 0.607911, acc.: 61%] [G loss: 1.371185]\n",
            "475 [ D loss: 0.602461, acc.: 62%] [G loss: 1.256779]\n",
            "476 [ D loss: 0.618820, acc.: 74%] [G loss: 1.198290]\n",
            "477 [ D loss: 0.607543, acc.: 72%] [G loss: 1.209709]\n",
            "478 [ D loss: 0.582916, acc.: 70%] [G loss: 1.275559]\n",
            "479 [ D loss: 0.597455, acc.: 62%] [G loss: 1.285956]\n",
            "480 [ D loss: 0.598534, acc.: 70%] [G loss: 1.294295]\n",
            "481 [ D loss: 0.639746, acc.: 60%] [G loss: 1.239239]\n",
            "482 [ D loss: 0.648684, acc.: 63%] [G loss: 1.193410]\n",
            "483 [ D loss: 0.591544, acc.: 69%] [G loss: 1.278107]\n",
            "484 [ D loss: 0.588671, acc.: 69%] [G loss: 1.375342]\n",
            "485 [ D loss: 0.634060, acc.: 63%] [G loss: 1.316563]\n",
            "486 [ D loss: 0.624140, acc.: 65%] [G loss: 1.252764]\n",
            "487 [ D loss: 0.613521, acc.: 65%] [G loss: 1.236509]\n",
            "488 [ D loss: 0.599190, acc.: 69%] [G loss: 1.292304]\n",
            "489 [ D loss: 0.612683, acc.: 66%] [G loss: 1.307882]\n",
            "490 [ D loss: 0.608249, acc.: 69%] [G loss: 1.283559]\n",
            "491 [ D loss: 0.618281, acc.: 68%] [G loss: 1.243324]\n",
            "492 [ D loss: 0.643733, acc.: 61%] [G loss: 1.202526]\n",
            "493 [ D loss: 0.621219, acc.: 74%] [G loss: 1.153355]\n",
            "494 [ D loss: 0.609245, acc.: 76%] [G loss: 1.229970]\n",
            "495 [ D loss: 0.616738, acc.: 62%] [G loss: 1.305206]\n",
            "496 [ D loss: 0.626674, acc.: 61%] [G loss: 1.313535]\n",
            "497 [ D loss: 0.584307, acc.: 71%] [G loss: 1.381981]\n",
            "498 [ D loss: 0.565931, acc.: 70%] [G loss: 1.421355]\n",
            "499 [ D loss: 0.552204, acc.: 72%] [G loss: 1.395239]\n",
            "500 [ D loss: 0.592710, acc.: 73%] [G loss: 1.278307]\n",
            "501 [ D loss: 0.620996, acc.: 72%] [G loss: 1.204192]\n",
            "502 [ D loss: 0.606174, acc.: 68%] [G loss: 1.191667]\n",
            "503 [ D loss: 0.620106, acc.: 65%] [G loss: 1.269170]\n",
            "504 [ D loss: 0.629131, acc.: 59%] [G loss: 1.254955]\n",
            "505 [ D loss: 0.581791, acc.: 69%] [G loss: 1.327488]\n",
            "506 [ D loss: 0.586566, acc.: 69%] [G loss: 1.387790]\n",
            "507 [ D loss: 0.557082, acc.: 74%] [G loss: 1.346212]\n",
            "508 [ D loss: 0.614560, acc.: 67%] [G loss: 1.229921]\n",
            "509 [ D loss: 0.603084, acc.: 66%] [G loss: 1.236253]\n",
            "510 [ D loss: 0.608457, acc.: 68%] [G loss: 1.281971]\n",
            "511 [ D loss: 0.568452, acc.: 65%] [G loss: 1.440976]\n",
            "512 [ D loss: 0.548653, acc.: 75%] [G loss: 1.486643]\n",
            "513 [ D loss: 0.561643, acc.: 73%] [G loss: 1.368568]\n",
            "514 [ D loss: 0.615616, acc.: 72%] [G loss: 1.150385]\n",
            "515 [ D loss: 0.596190, acc.: 79%] [G loss: 1.240749]\n",
            "516 [ D loss: 0.585253, acc.: 72%] [G loss: 1.331670]\n",
            "517 [ D loss: 0.566943, acc.: 70%] [G loss: 1.498007]\n",
            "518 [ D loss: 0.552966, acc.: 68%] [G loss: 1.471091]\n",
            "519 [ D loss: 0.602017, acc.: 66%] [G loss: 1.355273]\n",
            "520 [ D loss: 0.569431, acc.: 73%] [G loss: 1.374688]\n",
            "521 [ D loss: 0.541974, acc.: 78%] [G loss: 1.515075]\n",
            "522 [ D loss: 0.529054, acc.: 79%] [G loss: 1.496899]\n",
            "523 [ D loss: 0.610259, acc.: 72%] [G loss: 1.279545]\n",
            "524 [ D loss: 0.591472, acc.: 76%] [G loss: 1.255298]\n",
            "525 [ D loss: 0.571868, acc.: 76%] [G loss: 1.352550]\n",
            "526 [ D loss: 0.587605, acc.: 66%] [G loss: 1.391464]\n",
            "527 [ D loss: 0.581720, acc.: 68%] [G loss: 1.357868]\n",
            "528 [ D loss: 0.598525, acc.: 67%] [G loss: 1.310948]\n",
            "529 [ D loss: 0.544246, acc.: 78%] [G loss: 1.401852]\n",
            "530 [ D loss: 0.554238, acc.: 70%] [G loss: 1.513188]\n",
            "531 [ D loss: 0.504101, acc.: 80%] [G loss: 1.568327]\n",
            "532 [ D loss: 0.526081, acc.: 80%] [G loss: 1.598531]\n",
            "533 [ D loss: 0.561443, acc.: 73%] [G loss: 1.396302]\n",
            "534 [ D loss: 0.583481, acc.: 74%] [G loss: 1.207417]\n",
            "535 [ D loss: 0.628745, acc.: 63%] [G loss: 1.204202]\n",
            "536 [ D loss: 0.600438, acc.: 69%] [G loss: 1.323196]\n",
            "537 [ D loss: 0.567378, acc.: 70%] [G loss: 1.441143]\n",
            "538 [ D loss: 0.557681, acc.: 77%] [G loss: 1.427727]\n",
            "539 [ D loss: 0.545167, acc.: 77%] [G loss: 1.363732]\n",
            "540 [ D loss: 0.510409, acc.: 83%] [G loss: 1.611994]\n",
            "541 [ D loss: 0.490235, acc.: 76%] [G loss: 1.660295]\n",
            "542 [ D loss: 0.514931, acc.: 88%] [G loss: 1.385956]\n",
            "543 [ D loss: 0.574490, acc.: 77%] [G loss: 1.298950]\n",
            "544 [ D loss: 0.524132, acc.: 83%] [G loss: 1.476303]\n",
            "545 [ D loss: 0.520811, acc.: 77%] [G loss: 1.509326]\n",
            "546 [ D loss: 0.544687, acc.: 73%] [G loss: 1.513662]\n",
            "547 [ D loss: 0.510688, acc.: 73%] [G loss: 1.486963]\n",
            "548 [ D loss: 0.512672, acc.: 79%] [G loss: 1.413667]\n",
            "549 [ D loss: 0.530457, acc.: 86%] [G loss: 1.503834]\n",
            "550 [ D loss: 0.445610, acc.: 86%] [G loss: 2.053355]\n",
            "551 [ D loss: 0.449504, acc.: 88%] [G loss: 2.140239]\n",
            "552 [ D loss: 0.508680, acc.: 94%] [G loss: 1.413721]\n",
            "553 [ D loss: 0.564084, acc.: 77%] [G loss: 1.310784]\n",
            "554 [ D loss: 0.496573, acc.: 84%] [G loss: 1.784811]\n",
            "555 [ D loss: 0.439638, acc.: 84%] [G loss: 2.160756]\n",
            "556 [ D loss: 0.488551, acc.: 82%] [G loss: 1.619168]\n",
            "557 [ D loss: 0.545139, acc.: 84%] [G loss: 1.407198]\n",
            "558 [ D loss: 0.541489, acc.: 80%] [G loss: 1.401444]\n",
            "559 [ D loss: 0.558525, acc.: 73%] [G loss: 1.524297]\n",
            "560 [ D loss: 0.478421, acc.: 80%] [G loss: 1.785352]\n",
            "561 [ D loss: 0.521200, acc.: 81%] [G loss: 1.694870]\n",
            "562 [ D loss: 0.536311, acc.: 78%] [G loss: 1.739640]\n",
            "563 [ D loss: 0.491259, acc.: 84%] [G loss: 1.790137]\n",
            "564 [ D loss: 0.532283, acc.: 73%] [G loss: 1.582535]\n",
            "565 [ D loss: 0.437210, acc.: 88%] [G loss: 1.732400]\n",
            "566 [ D loss: 0.444772, acc.: 88%] [G loss: 1.807021]\n",
            "567 [ D loss: 0.514305, acc.: 87%] [G loss: 1.524464]\n",
            "568 [ D loss: 0.481992, acc.: 89%] [G loss: 1.608846]\n",
            "569 [ D loss: 0.489791, acc.: 80%] [G loss: 1.731361]\n",
            "570 [ D loss: 0.469684, acc.: 82%] [G loss: 2.040287]\n",
            "571 [ D loss: 0.441799, acc.: 88%] [G loss: 1.792361]\n",
            "572 [ D loss: 0.443542, acc.: 88%] [G loss: 1.972193]\n",
            "573 [ D loss: 0.486333, acc.: 81%] [G loss: 2.341366]\n",
            "574 [ D loss: 0.471042, acc.: 90%] [G loss: 1.728469]\n",
            "575 [ D loss: 0.507731, acc.: 85%] [G loss: 1.407690]\n",
            "576 [ D loss: 0.513350, acc.: 84%] [G loss: 1.579349]\n",
            "577 [ D loss: 0.405094, acc.: 89%] [G loss: 2.133739]\n",
            "578 [ D loss: 0.468631, acc.: 82%] [G loss: 2.070893]\n",
            "579 [ D loss: 0.498797, acc.: 79%] [G loss: 1.645081]\n",
            "580 [ D loss: 0.498778, acc.: 84%] [G loss: 1.638916]\n",
            "581 [ D loss: 0.426759, acc.: 88%] [G loss: 2.078181]\n",
            "582 [ D loss: 0.479543, acc.: 87%] [G loss: 1.986933]\n",
            "583 [ D loss: 0.443917, acc.: 88%] [G loss: 1.808851]\n",
            "584 [ D loss: 0.460323, acc.: 88%] [G loss: 1.755982]\n",
            "585 [ D loss: 0.457593, acc.: 84%] [G loss: 1.946398]\n",
            "586 [ D loss: 0.439377, acc.: 88%] [G loss: 1.969749]\n",
            "587 [ D loss: 0.415671, acc.: 92%] [G loss: 2.415940]\n",
            "588 [ D loss: 0.452637, acc.: 85%] [G loss: 2.189568]\n",
            "589 [ D loss: 0.477315, acc.: 94%] [G loss: 1.748886]\n",
            "590 [ D loss: 0.474322, acc.: 88%] [G loss: 1.861302]\n",
            "591 [ D loss: 0.423604, acc.: 86%] [G loss: 2.151480]\n",
            "592 [ D loss: 0.413642, acc.: 88%] [G loss: 2.095977]\n",
            "593 [ D loss: 0.449408, acc.: 93%] [G loss: 1.735146]\n",
            "594 [ D loss: 0.457136, acc.: 92%] [G loss: 1.734016]\n",
            "595 [ D loss: 0.460423, acc.: 88%] [G loss: 1.887964]\n",
            "596 [ D loss: 0.427658, acc.: 90%] [G loss: 2.398851]\n",
            "597 [ D loss: 0.412554, acc.: 90%] [G loss: 2.378016]\n",
            "598 [ D loss: 0.551365, acc.: 78%] [G loss: 1.624879]\n",
            "599 [ D loss: 0.479246, acc.: 88%] [G loss: 1.751883]\n",
            "600 [ D loss: 0.457490, acc.: 81%] [G loss: 2.106928]\n",
            "601 [ D loss: 0.445826, acc.: 85%] [G loss: 2.489371]\n",
            "602 [ D loss: 0.447031, acc.: 86%] [G loss: 2.148104]\n",
            "603 [ D loss: 0.381373, acc.: 93%] [G loss: 2.631022]\n",
            "604 [ D loss: 0.397610, acc.: 94%] [G loss: 1.942193]\n",
            "605 [ D loss: 0.435331, acc.: 89%] [G loss: 1.695688]\n",
            "606 [ D loss: 0.427368, acc.: 92%] [G loss: 1.906226]\n",
            "607 [ D loss: 0.427194, acc.: 90%] [G loss: 1.958187]\n",
            "608 [ D loss: 0.421864, acc.: 93%] [G loss: 2.246897]\n",
            "609 [ D loss: 0.368874, acc.: 94%] [G loss: 2.411920]\n",
            "610 [ D loss: 0.443099, acc.: 86%] [G loss: 2.209126]\n",
            "611 [ D loss: 0.391939, acc.: 90%] [G loss: 2.237554]\n",
            "612 [ D loss: 0.412213, acc.: 91%] [G loss: 2.053728]\n",
            "613 [ D loss: 0.429381, acc.: 91%] [G loss: 1.927349]\n",
            "614 [ D loss: 0.445621, acc.: 90%] [G loss: 1.889108]\n",
            "615 [ D loss: 0.402695, acc.: 91%] [G loss: 2.326019]\n",
            "616 [ D loss: 0.448595, acc.: 86%] [G loss: 2.631650]\n",
            "617 [ D loss: 0.390081, acc.: 90%] [G loss: 2.534141]\n",
            "618 [ D loss: 0.444704, acc.: 88%] [G loss: 1.817025]\n",
            "619 [ D loss: 0.430357, acc.: 90%] [G loss: 2.223508]\n",
            "620 [ D loss: 0.380381, acc.: 93%] [G loss: 2.753073]\n",
            "621 [ D loss: 0.374047, acc.: 96%] [G loss: 2.065558]\n",
            "622 [ D loss: 0.402922, acc.: 90%] [G loss: 2.111441]\n",
            "623 [ D loss: 0.416693, acc.: 88%] [G loss: 1.934006]\n",
            "624 [ D loss: 0.448215, acc.: 89%] [G loss: 2.032015]\n",
            "625 [ D loss: 0.430189, acc.: 88%] [G loss: 2.312935]\n",
            "626 [ D loss: 0.393632, acc.: 90%] [G loss: 2.459455]\n",
            "627 [ D loss: 0.360072, acc.: 95%] [G loss: 2.429724]\n",
            "628 [ D loss: 0.470558, acc.: 89%] [G loss: 1.750718]\n",
            "629 [ D loss: 0.431065, acc.: 95%] [G loss: 1.998095]\n",
            "630 [ D loss: 0.449743, acc.: 81%] [G loss: 2.680048]\n",
            "631 [ D loss: 0.362214, acc.: 91%] [G loss: 4.018348]\n",
            "632 [ D loss: 0.378310, acc.: 88%] [G loss: 2.569946]\n",
            "633 [ D loss: 0.336607, acc.: 94%] [G loss: 2.864715]\n",
            "634 [ D loss: 0.410155, acc.: 87%] [G loss: 2.339833]\n",
            "635 [ D loss: 0.365467, acc.: 95%] [G loss: 2.339602]\n",
            "636 [ D loss: 0.387518, acc.: 94%] [G loss: 2.343550]\n",
            "637 [ D loss: 0.503021, acc.: 80%] [G loss: 1.992447]\n",
            "638 [ D loss: 0.409802, acc.: 89%] [G loss: 2.435604]\n",
            "639 [ D loss: 0.395559, acc.: 88%] [G loss: 3.216570]\n",
            "640 [ D loss: 0.350074, acc.: 91%] [G loss: 2.880177]\n",
            "641 [ D loss: 0.492995, acc.: 83%] [G loss: 1.715076]\n",
            "642 [ D loss: 0.371766, acc.: 96%] [G loss: 2.271650]\n",
            "643 [ D loss: 0.340725, acc.: 96%] [G loss: 2.810355]\n",
            "644 [ D loss: 0.356357, acc.: 91%] [G loss: 2.567911]\n",
            "645 [ D loss: 0.370640, acc.: 90%] [G loss: 2.360778]\n",
            "646 [ D loss: 0.449251, acc.: 88%] [G loss: 2.245509]\n",
            "647 [ D loss: 0.332635, acc.: 97%] [G loss: 2.893116]\n",
            "648 [ D loss: 0.368834, acc.: 91%] [G loss: 2.701872]\n",
            "649 [ D loss: 0.337701, acc.: 97%] [G loss: 3.107176]\n",
            "650 [ D loss: 0.369175, acc.: 95%] [G loss: 2.108893]\n",
            "651 [ D loss: 0.390027, acc.: 94%] [G loss: 2.253847]\n",
            "652 [ D loss: 0.406029, acc.: 88%] [G loss: 2.832539]\n",
            "653 [ D loss: 0.364866, acc.: 89%] [G loss: 3.781187]\n",
            "654 [ D loss: 0.371242, acc.: 92%] [G loss: 2.484138]\n",
            "655 [ D loss: 0.376786, acc.: 95%] [G loss: 2.182968]\n",
            "656 [ D loss: 0.380013, acc.: 93%] [G loss: 2.188801]\n",
            "657 [ D loss: 0.361256, acc.: 91%] [G loss: 2.580146]\n",
            "658 [ D loss: 0.379005, acc.: 91%] [G loss: 2.483632]\n",
            "659 [ D loss: 0.371147, acc.: 91%] [G loss: 2.311909]\n",
            "660 [ D loss: 0.313523, acc.: 95%] [G loss: 2.733956]\n",
            "661 [ D loss: 0.388405, acc.: 90%] [G loss: 2.785570]\n",
            "662 [ D loss: 0.322130, acc.: 93%] [G loss: 3.356752]\n",
            "663 [ D loss: 0.380552, acc.: 89%] [G loss: 2.886420]\n",
            "664 [ D loss: 0.332999, acc.: 96%] [G loss: 2.266965]\n",
            "665 [ D loss: 0.413060, acc.: 92%] [G loss: 2.082004]\n",
            "666 [ D loss: 0.396191, acc.: 91%] [G loss: 2.363339]\n",
            "667 [ D loss: 0.342657, acc.: 93%] [G loss: 2.942780]\n",
            "668 [ D loss: 0.372789, acc.: 88%] [G loss: 2.706902]\n",
            "669 [ D loss: 0.380152, acc.: 92%] [G loss: 2.308832]\n",
            "670 [ D loss: 0.497995, acc.: 76%] [G loss: 3.114116]\n",
            "671 [ D loss: 0.336916, acc.: 91%] [G loss: 2.906830]\n",
            "672 [ D loss: 0.396429, acc.: 91%] [G loss: 2.453340]\n",
            "673 [ D loss: 0.405954, acc.: 90%] [G loss: 2.535332]\n",
            "674 [ D loss: 0.338908, acc.: 98%] [G loss: 2.748049]\n",
            "675 [ D loss: 0.405372, acc.: 89%] [G loss: 2.452436]\n",
            "676 [ D loss: 0.336787, acc.: 94%] [G loss: 3.551178]\n",
            "677 [ D loss: 0.328761, acc.: 96%] [G loss: 2.823251]\n",
            "678 [ D loss: 0.437352, acc.: 85%] [G loss: 2.719577]\n",
            "679 [ D loss: 0.379727, acc.: 89%] [G loss: 2.977782]\n",
            "680 [ D loss: 0.389369, acc.: 89%] [G loss: 2.549652]\n",
            "681 [ D loss: 0.291564, acc.: 95%] [G loss: 3.032172]\n",
            "682 [ D loss: 0.314990, acc.: 94%] [G loss: 2.651049]\n",
            "683 [ D loss: 0.361037, acc.: 91%] [G loss: 2.784289]\n",
            "684 [ D loss: 0.403065, acc.: 87%] [G loss: 2.915584]\n",
            "685 [ D loss: 0.411216, acc.: 84%] [G loss: 2.762990]\n",
            "686 [ D loss: 0.348385, acc.: 93%] [G loss: 2.981852]\n",
            "687 [ D loss: 0.384485, acc.: 85%] [G loss: 2.733822]\n",
            "688 [ D loss: 0.335448, acc.: 94%] [G loss: 3.343600]\n",
            "689 [ D loss: 0.283687, acc.: 100%] [G loss: 3.067654]\n",
            "690 [ D loss: 0.369629, acc.: 92%] [G loss: 2.106647]\n",
            "691 [ D loss: 0.407763, acc.: 84%] [G loss: 2.380445]\n",
            "692 [ D loss: 0.308243, acc.: 95%] [G loss: 3.811273]\n",
            "693 [ D loss: 0.299116, acc.: 95%] [G loss: 3.739450]\n",
            "694 [ D loss: 0.403622, acc.: 85%] [G loss: 2.341954]\n",
            "695 [ D loss: 0.374172, acc.: 88%] [G loss: 2.913847]\n",
            "696 [ D loss: 0.317362, acc.: 94%] [G loss: 3.320794]\n",
            "697 [ D loss: 0.320677, acc.: 93%] [G loss: 2.942441]\n",
            "698 [ D loss: 0.380971, acc.: 89%] [G loss: 2.527080]\n",
            "699 [ D loss: 0.299708, acc.: 98%] [G loss: 2.706299]\n",
            "700 [ D loss: 0.320327, acc.: 96%] [G loss: 2.788185]\n",
            "701 [ D loss: 0.309096, acc.: 98%] [G loss: 3.003650]\n",
            "702 [ D loss: 0.338911, acc.: 95%] [G loss: 2.564643]\n",
            "703 [ D loss: 0.403044, acc.: 82%] [G loss: 2.732531]\n",
            "704 [ D loss: 0.319968, acc.: 91%] [G loss: 3.495595]\n",
            "705 [ D loss: 0.345705, acc.: 92%] [G loss: 3.207639]\n",
            "706 [ D loss: 0.285638, acc.: 97%] [G loss: 3.220273]\n",
            "707 [ D loss: 0.299452, acc.: 97%] [G loss: 2.807943]\n",
            "708 [ D loss: 0.311906, acc.: 96%] [G loss: 3.018475]\n",
            "709 [ D loss: 0.293483, acc.: 96%] [G loss: 3.389824]\n",
            "710 [ D loss: 0.404330, acc.: 81%] [G loss: 3.071717]\n",
            "711 [ D loss: 0.374449, acc.: 86%] [G loss: 2.821267]\n",
            "712 [ D loss: 0.304228, acc.: 94%] [G loss: 3.057191]\n",
            "713 [ D loss: 0.325359, acc.: 94%] [G loss: 3.103186]\n",
            "714 [ D loss: 0.275539, acc.: 98%] [G loss: 3.691539]\n",
            "715 [ D loss: 0.331545, acc.: 93%] [G loss: 2.395148]\n",
            "716 [ D loss: 0.351573, acc.: 95%] [G loss: 2.398028]\n",
            "717 [ D loss: 0.386542, acc.: 91%] [G loss: 2.627823]\n",
            "718 [ D loss: 0.287436, acc.: 96%] [G loss: 3.225098]\n",
            "719 [ D loss: 0.283001, acc.: 95%] [G loss: 3.016820]\n",
            "720 [ D loss: 0.407810, acc.: 80%] [G loss: 2.744674]\n",
            "721 [ D loss: 0.318571, acc.: 94%] [G loss: 3.637390]\n",
            "722 [ D loss: 0.320246, acc.: 91%] [G loss: 3.821785]\n",
            "723 [ D loss: 0.327474, acc.: 96%] [G loss: 3.311557]\n",
            "724 [ D loss: 0.282626, acc.: 98%] [G loss: 3.340228]\n",
            "725 [ D loss: 0.296608, acc.: 95%] [G loss: 2.810927]\n",
            "726 [ D loss: 0.253627, acc.: 99%] [G loss: 2.772025]\n",
            "727 [ D loss: 0.298879, acc.: 95%] [G loss: 2.735614]\n",
            "728 [ D loss: 0.297710, acc.: 98%] [G loss: 3.002130]\n",
            "729 [ D loss: 0.269689, acc.: 98%] [G loss: 3.143645]\n",
            "730 [ D loss: 0.258240, acc.: 97%] [G loss: 4.043377]\n",
            "731 [ D loss: 0.347132, acc.: 87%] [G loss: 4.366759]\n",
            "732 [ D loss: 0.368745, acc.: 85%] [G loss: 3.070228]\n",
            "733 [ D loss: 0.339266, acc.: 94%] [G loss: 3.404402]\n",
            "734 [ D loss: 0.377798, acc.: 88%] [G loss: 3.040195]\n",
            "735 [ D loss: 0.311746, acc.: 95%] [G loss: 3.704636]\n",
            "736 [ D loss: 0.307071, acc.: 93%] [G loss: 3.878444]\n",
            "737 [ D loss: 0.271130, acc.: 96%] [G loss: 3.092219]\n",
            "738 [ D loss: 0.307012, acc.: 95%] [G loss: 3.142224]\n",
            "739 [ D loss: 0.315354, acc.: 92%] [G loss: 3.443172]\n",
            "740 [ D loss: 0.291587, acc.: 93%] [G loss: 4.012874]\n",
            "741 [ D loss: 0.322530, acc.: 96%] [G loss: 2.707844]\n",
            "742 [ D loss: 0.292227, acc.: 97%] [G loss: 2.846135]\n",
            "743 [ D loss: 0.260446, acc.: 98%] [G loss: 3.090893]\n",
            "744 [ D loss: 0.276138, acc.: 97%] [G loss: 3.299775]\n",
            "745 [ D loss: 0.347123, acc.: 90%] [G loss: 3.244630]\n",
            "746 [ D loss: 0.313562, acc.: 93%] [G loss: 3.603049]\n",
            "747 [ D loss: 0.370904, acc.: 91%] [G loss: 2.721841]\n",
            "748 [ D loss: 0.310387, acc.: 98%] [G loss: 3.498157]\n",
            "749 [ D loss: 0.271155, acc.: 95%] [G loss: 3.982360]\n",
            "750 [ D loss: 0.305588, acc.: 94%] [G loss: 3.524216]\n",
            "751 [ D loss: 0.269399, acc.: 97%] [G loss: 2.748204]\n",
            "752 [ D loss: 0.342618, acc.: 90%] [G loss: 3.017387]\n",
            "753 [ D loss: 0.291965, acc.: 94%] [G loss: 3.293478]\n",
            "754 [ D loss: 0.259582, acc.: 95%] [G loss: 4.664806]\n",
            "755 [ D loss: 0.260466, acc.: 98%] [G loss: 4.231129]\n",
            "756 [ D loss: 0.508829, acc.: 74%] [G loss: 2.969895]\n",
            "757 [ D loss: 0.241453, acc.: 98%] [G loss: 4.186202]\n",
            "758 [ D loss: 0.267685, acc.: 95%] [G loss: 4.273490]\n",
            "759 [ D loss: 0.228341, acc.: 97%] [G loss: 2.872355]\n",
            "760 [ D loss: 0.370174, acc.: 84%] [G loss: 2.981921]\n",
            "761 [ D loss: 0.217457, acc.: 98%] [G loss: 3.745862]\n",
            "762 [ D loss: 0.286970, acc.: 97%] [G loss: 3.300768]\n",
            "763 [ D loss: 0.234900, acc.: 98%] [G loss: 4.014797]\n",
            "764 [ D loss: 0.297525, acc.: 95%] [G loss: 3.511842]\n",
            "765 [ D loss: 0.191381, acc.: 100%] [G loss: 4.029442]\n",
            "766 [ D loss: 0.232990, acc.: 98%] [G loss: 3.724887]\n",
            "767 [ D loss: 0.341107, acc.: 91%] [G loss: 4.652325]\n",
            "768 [ D loss: 0.304015, acc.: 91%] [G loss: 3.354376]\n",
            "769 [ D loss: 0.262030, acc.: 95%] [G loss: 3.417368]\n",
            "770 [ D loss: 0.297124, acc.: 93%] [G loss: 3.410760]\n",
            "771 [ D loss: 0.226962, acc.: 99%] [G loss: 3.620752]\n",
            "772 [ D loss: 0.311171, acc.: 93%] [G loss: 2.882588]\n",
            "773 [ D loss: 0.261999, acc.: 94%] [G loss: 4.715161]\n",
            "774 [ D loss: 0.260451, acc.: 94%] [G loss: 3.555762]\n",
            "775 [ D loss: 0.469779, acc.: 74%] [G loss: 2.585243]\n",
            "776 [ D loss: 0.315704, acc.: 98%] [G loss: 2.923045]\n",
            "777 [ D loss: 0.235081, acc.: 97%] [G loss: 3.921780]\n",
            "778 [ D loss: 0.233638, acc.: 95%] [G loss: 3.698740]\n",
            "779 [ D loss: 0.237170, acc.: 96%] [G loss: 3.192836]\n",
            "780 [ D loss: 0.244103, acc.: 97%] [G loss: 3.514395]\n",
            "781 [ D loss: 0.250576, acc.: 94%] [G loss: 3.767112]\n",
            "782 [ D loss: 0.244625, acc.: 96%] [G loss: 3.933806]\n",
            "783 [ D loss: 0.244575, acc.: 95%] [G loss: 4.323649]\n",
            "784 [ D loss: 0.322547, acc.: 88%] [G loss: 3.434230]\n",
            "785 [ D loss: 0.258670, acc.: 95%] [G loss: 4.039494]\n",
            "786 [ D loss: 0.270522, acc.: 96%] [G loss: 3.223269]\n",
            "787 [ D loss: 0.253677, acc.: 95%] [G loss: 2.867930]\n",
            "788 [ D loss: 0.268350, acc.: 96%] [G loss: 3.234662]\n",
            "789 [ D loss: 0.218725, acc.: 97%] [G loss: 4.017366]\n",
            "790 [ D loss: 0.275089, acc.: 94%] [G loss: 3.810323]\n",
            "791 [ D loss: 0.286600, acc.: 92%] [G loss: 3.478967]\n",
            "792 [ D loss: 0.244111, acc.: 98%] [G loss: 4.429632]\n",
            "793 [ D loss: 0.283058, acc.: 94%] [G loss: 4.638735]\n",
            "794 [ D loss: 0.251821, acc.: 96%] [G loss: 4.091421]\n",
            "795 [ D loss: 0.258487, acc.: 96%] [G loss: 3.802492]\n",
            "796 [ D loss: 0.272933, acc.: 95%] [G loss: 3.510338]\n",
            "797 [ D loss: 0.228726, acc.: 97%] [G loss: 3.609931]\n",
            "798 [ D loss: 0.260492, acc.: 95%] [G loss: 3.380212]\n",
            "799 [ D loss: 0.331172, acc.: 90%] [G loss: 3.450996]\n",
            "800 [ D loss: 0.267560, acc.: 97%] [G loss: 4.084798]\n",
            "801 [ D loss: 0.286465, acc.: 96%] [G loss: 3.796393]\n",
            "802 [ D loss: 0.258683, acc.: 98%] [G loss: 3.223721]\n",
            "803 [ D loss: 0.210865, acc.: 98%] [G loss: 4.354846]\n",
            "804 [ D loss: 0.207117, acc.: 96%] [G loss: 4.871435]\n",
            "805 [ D loss: 0.399464, acc.: 84%] [G loss: 4.264065]\n",
            "806 [ D loss: 0.273908, acc.: 96%] [G loss: 4.862496]\n",
            "807 [ D loss: 0.240240, acc.: 95%] [G loss: 3.982343]\n",
            "808 [ D loss: 0.383993, acc.: 86%] [G loss: 2.619785]\n",
            "809 [ D loss: 0.301689, acc.: 95%] [G loss: 3.353688]\n",
            "810 [ D loss: 0.205375, acc.: 98%] [G loss: 5.449265]\n",
            "811 [ D loss: 0.274419, acc.: 95%] [G loss: 3.191497]\n",
            "812 [ D loss: 0.288258, acc.: 90%] [G loss: 6.191004]\n",
            "813 [ D loss: 0.332918, acc.: 95%] [G loss: 3.200191]\n",
            "814 [ D loss: 0.247674, acc.: 95%] [G loss: 4.813039]\n",
            "815 [ D loss: 0.296810, acc.: 95%] [G loss: 3.341889]\n",
            "816 [ D loss: 0.304361, acc.: 93%] [G loss: 4.097468]\n",
            "817 [ D loss: 0.339999, acc.: 92%] [G loss: 4.370148]\n",
            "818 [ D loss: 0.227607, acc.: 98%] [G loss: 4.510908]\n",
            "819 [ D loss: 0.227648, acc.: 98%] [G loss: 3.868267]\n",
            "820 [ D loss: 0.264441, acc.: 94%] [G loss: 3.354235]\n",
            "821 [ D loss: 0.288482, acc.: 96%] [G loss: 3.875607]\n",
            "822 [ D loss: 0.262403, acc.: 95%] [G loss: 4.214293]\n",
            "823 [ D loss: 0.234084, acc.: 95%] [G loss: 4.786119]\n",
            "824 [ D loss: 0.329880, acc.: 88%] [G loss: 3.236897]\n",
            "825 [ D loss: 0.248289, acc.: 96%] [G loss: 4.175486]\n",
            "826 [ D loss: 0.349919, acc.: 87%] [G loss: 3.526954]\n",
            "827 [ D loss: 0.255904, acc.: 93%] [G loss: 5.966605]\n",
            "828 [ D loss: 0.250349, acc.: 95%] [G loss: 4.310982]\n",
            "829 [ D loss: 0.164510, acc.: 97%] [G loss: 7.190854]\n",
            "830 [ D loss: 0.444500, acc.: 76%] [G loss: 3.522388]\n",
            "831 [ D loss: 0.198240, acc.: 96%] [G loss: 8.952761]\n",
            "832 [ D loss: 0.225361, acc.: 97%] [G loss: 5.955806]\n",
            "833 [ D loss: 0.348078, acc.: 86%] [G loss: 3.600099]\n",
            "834 [ D loss: 0.259764, acc.: 93%] [G loss: 5.753454]\n",
            "835 [ D loss: 0.352544, acc.: 89%] [G loss: 3.555280]\n",
            "836 [ D loss: 0.192345, acc.: 98%] [G loss: 7.198882]\n",
            "837 [ D loss: 0.452765, acc.: 79%] [G loss: 3.962957]\n",
            "838 [ D loss: 0.195897, acc.: 97%] [G loss: 8.110138]\n",
            "839 [ D loss: 0.203955, acc.: 96%] [G loss: 6.188132]\n",
            "840 [ D loss: 0.289306, acc.: 91%] [G loss: 3.845163]\n",
            "841 [ D loss: 0.440695, acc.: 80%] [G loss: 5.480277]\n",
            "842 [ D loss: 0.359567, acc.: 84%] [G loss: 4.349223]\n",
            "843 [ D loss: 0.291087, acc.: 87%] [G loss: 6.538300]\n",
            "844 [ D loss: 0.199431, acc.: 99%] [G loss: 4.020230]\n",
            "845 [ D loss: 0.361588, acc.: 82%] [G loss: 4.244689]\n",
            "846 [ D loss: 0.243632, acc.: 97%] [G loss: 4.687446]\n",
            "847 [ D loss: 0.353579, acc.: 91%] [G loss: 3.558094]\n",
            "848 [ D loss: 0.207997, acc.: 100%] [G loss: 4.395413]\n",
            "849 [ D loss: 0.192946, acc.: 97%] [G loss: 6.082326]\n",
            "850 [ D loss: 0.535474, acc.: 70%] [G loss: 3.024263]\n",
            "851 [ D loss: 0.226276, acc.: 96%] [G loss: 4.839169]\n",
            "852 [ D loss: 0.213868, acc.: 96%] [G loss: 6.340741]\n",
            "853 [ D loss: 0.377995, acc.: 80%] [G loss: 2.656579]\n",
            "854 [ D loss: 0.277966, acc.: 94%] [G loss: 4.200375]\n",
            "855 [ D loss: 0.225247, acc.: 98%] [G loss: 5.352211]\n",
            "856 [ D loss: 0.330008, acc.: 89%] [G loss: 3.372410]\n",
            "857 [ D loss: 0.232307, acc.: 97%] [G loss: 4.028868]\n",
            "858 [ D loss: 0.216548, acc.: 96%] [G loss: 4.840610]\n",
            "859 [ D loss: 0.338228, acc.: 86%] [G loss: 4.058199]\n",
            "860 [ D loss: 0.402211, acc.: 81%] [G loss: 4.394462]\n",
            "861 [ D loss: 0.343138, acc.: 86%] [G loss: 4.604274]\n",
            "862 [ D loss: 0.386679, acc.: 81%] [G loss: 4.457188]\n",
            "863 [ D loss: 0.297744, acc.: 93%] [G loss: 3.791270]\n",
            "864 [ D loss: 0.229021, acc.: 98%] [G loss: 4.012493]\n",
            "865 [ D loss: 0.243289, acc.: 98%] [G loss: 3.317384]\n",
            "866 [ D loss: 0.154363, acc.: 100%] [G loss: 5.448488]\n",
            "867 [ D loss: 0.593508, acc.: 75%] [G loss: 2.825328]\n",
            "868 [ D loss: 0.335789, acc.: 86%] [G loss: 4.157770]\n",
            "869 [ D loss: 0.316535, acc.: 88%] [G loss: 3.552994]\n",
            "870 [ D loss: 0.226302, acc.: 98%] [G loss: 3.893115]\n",
            "871 [ D loss: 0.202792, acc.: 97%] [G loss: 5.021309]\n",
            "872 [ D loss: 0.447138, acc.: 71%] [G loss: 2.823057]\n",
            "873 [ D loss: 0.245721, acc.: 96%] [G loss: 4.262865]\n",
            "874 [ D loss: 0.368434, acc.: 87%] [G loss: 3.569522]\n",
            "875 [ D loss: 0.322110, acc.: 87%] [G loss: 3.671534]\n",
            "876 [ D loss: 0.221078, acc.: 95%] [G loss: 3.863922]\n",
            "877 [ D loss: 0.191394, acc.: 98%] [G loss: 3.943188]\n",
            "878 [ D loss: 0.327214, acc.: 91%] [G loss: 3.142087]\n",
            "879 [ D loss: 0.196941, acc.: 98%] [G loss: 4.638819]\n",
            "880 [ D loss: 0.212911, acc.: 98%] [G loss: 4.230118]\n",
            "881 [ D loss: 0.364564, acc.: 83%] [G loss: 3.275337]\n",
            "882 [ D loss: 0.500225, acc.: 74%] [G loss: 3.482658]\n",
            "883 [ D loss: 0.231529, acc.: 99%] [G loss: 4.496409]\n",
            "884 [ D loss: 0.237151, acc.: 96%] [G loss: 5.285962]\n",
            "885 [ D loss: 0.212945, acc.: 96%] [G loss: 4.203769]\n",
            "886 [ D loss: 0.346959, acc.: 91%] [G loss: 3.641722]\n",
            "887 [ D loss: 0.193986, acc.: 98%] [G loss: 4.683341]\n",
            "888 [ D loss: 0.205650, acc.: 97%] [G loss: 3.919559]\n",
            "889 [ D loss: 0.273822, acc.: 94%] [G loss: 4.106936]\n",
            "890 [ D loss: 0.223666, acc.: 95%] [G loss: 4.511175]\n",
            "891 [ D loss: 0.195457, acc.: 98%] [G loss: 4.000951]\n",
            "892 [ D loss: 0.269086, acc.: 91%] [G loss: 4.334745]\n",
            "893 [ D loss: 0.220503, acc.: 97%] [G loss: 3.578853]\n",
            "894 [ D loss: 0.265331, acc.: 93%] [G loss: 4.709065]\n",
            "895 [ D loss: 0.248578, acc.: 98%] [G loss: 4.014574]\n",
            "896 [ D loss: 0.282260, acc.: 95%] [G loss: 3.460947]\n",
            "897 [ D loss: 0.199163, acc.: 97%] [G loss: 4.191250]\n",
            "898 [ D loss: 0.259830, acc.: 93%] [G loss: 3.396646]\n",
            "899 [ D loss: 0.299602, acc.: 92%] [G loss: 3.235817]\n",
            "900 [ D loss: 0.216446, acc.: 98%] [G loss: 3.974285]\n",
            "901 [ D loss: 0.238964, acc.: 95%] [G loss: 4.832116]\n",
            "902 [ D loss: 0.217894, acc.: 95%] [G loss: 3.668046]\n",
            "903 [ D loss: 0.199337, acc.: 93%] [G loss: 5.537396]\n",
            "904 [ D loss: 0.497844, acc.: 78%] [G loss: 2.838917]\n",
            "905 [ D loss: 0.198835, acc.: 98%] [G loss: 6.780134]\n",
            "906 [ D loss: 0.239595, acc.: 97%] [G loss: 4.468317]\n",
            "907 [ D loss: 0.225843, acc.: 94%] [G loss: 6.672038]\n",
            "908 [ D loss: 0.426499, acc.: 80%] [G loss: 5.523392]\n",
            "909 [ D loss: 0.268925, acc.: 93%] [G loss: 5.306435]\n",
            "910 [ D loss: 0.382700, acc.: 85%] [G loss: 3.555046]\n",
            "911 [ D loss: 0.280385, acc.: 93%] [G loss: 6.963037]\n",
            "912 [ D loss: 0.251453, acc.: 98%] [G loss: 5.222569]\n",
            "913 [ D loss: 0.365655, acc.: 86%] [G loss: 3.728194]\n",
            "914 [ D loss: 0.262929, acc.: 94%] [G loss: 4.446954]\n",
            "915 [ D loss: 0.187316, acc.: 98%] [G loss: 5.633008]\n",
            "916 [ D loss: 0.418713, acc.: 75%] [G loss: 4.424513]\n",
            "917 [ D loss: 0.262821, acc.: 92%] [G loss: 5.824019]\n",
            "918 [ D loss: 0.762054, acc.: 69%] [G loss: 3.583255]\n",
            "919 [ D loss: 0.337367, acc.: 89%] [G loss: 4.793087]\n",
            "920 [ D loss: 0.252907, acc.: 92%] [G loss: 6.808228]\n",
            "921 [ D loss: 0.196520, acc.: 96%] [G loss: 4.717680]\n",
            "922 [ D loss: 0.394407, acc.: 81%] [G loss: 6.065245]\n",
            "923 [ D loss: 0.365521, acc.: 83%] [G loss: 3.833379]\n",
            "924 [ D loss: 0.251938, acc.: 95%] [G loss: 7.488229]\n",
            "925 [ D loss: 0.285326, acc.: 90%] [G loss: 5.032710]\n",
            "926 [ D loss: 0.183109, acc.: 98%] [G loss: 4.965022]\n",
            "927 [ D loss: 0.387685, acc.: 82%] [G loss: 2.866229]\n",
            "928 [ D loss: 0.185259, acc.: 98%] [G loss: 6.890741]\n",
            "929 [ D loss: 0.291634, acc.: 90%] [G loss: 4.644598]\n",
            "930 [ D loss: 0.187529, acc.: 97%] [G loss: 5.617995]\n",
            "931 [ D loss: 0.267863, acc.: 91%] [G loss: 6.710580]\n",
            "932 [ D loss: 0.457202, acc.: 77%] [G loss: 3.306551]\n",
            "933 [ D loss: 0.227593, acc.: 96%] [G loss: 4.823453]\n",
            "934 [ D loss: 0.262406, acc.: 95%] [G loss: 3.410203]\n",
            "935 [ D loss: 0.351878, acc.: 85%] [G loss: 3.945044]\n",
            "936 [ D loss: 0.200429, acc.: 99%] [G loss: 5.100886]\n",
            "937 [ D loss: 0.201562, acc.: 98%] [G loss: 4.537224]\n",
            "938 [ D loss: 0.171498, acc.: 98%] [G loss: 5.283064]\n",
            "939 [ D loss: 0.611326, acc.: 73%] [G loss: 3.571278]\n",
            "940 [ D loss: 0.295777, acc.: 91%] [G loss: 5.373154]\n",
            "941 [ D loss: 0.229176, acc.: 98%] [G loss: 4.209277]\n",
            "942 [ D loss: 0.199758, acc.: 97%] [G loss: 5.103708]\n",
            "943 [ D loss: 0.480742, acc.: 75%] [G loss: 3.170070]\n",
            "944 [ D loss: 0.385259, acc.: 80%] [G loss: 3.944689]\n",
            "945 [ D loss: 0.369792, acc.: 90%] [G loss: 3.877599]\n",
            "946 [ D loss: 0.214087, acc.: 96%] [G loss: 7.052118]\n",
            "947 [ D loss: 0.217181, acc.: 96%] [G loss: 5.902354]\n",
            "948 [ D loss: 0.252066, acc.: 93%] [G loss: 4.091724]\n",
            "949 [ D loss: 0.153660, acc.: 99%] [G loss: 4.729841]\n",
            "950 [ D loss: 0.128803, acc.: 98%] [G loss: 6.275181]\n",
            "951 [ D loss: 0.453500, acc.: 77%] [G loss: 3.556115]\n",
            "952 [ D loss: 0.412849, acc.: 79%] [G loss: 3.679638]\n",
            "953 [ D loss: 0.205441, acc.: 95%] [G loss: 6.180111]\n",
            "954 [ D loss: 0.198005, acc.: 98%] [G loss: 5.851809]\n",
            "955 [ D loss: 0.515910, acc.: 68%] [G loss: 3.356712]\n",
            "956 [ D loss: 0.233133, acc.: 95%] [G loss: 6.278177]\n",
            "957 [ D loss: 0.408717, acc.: 75%] [G loss: 2.878747]\n",
            "958 [ D loss: 0.310278, acc.: 91%] [G loss: 4.853448]\n",
            "959 [ D loss: 0.196505, acc.: 99%] [G loss: 3.451405]\n",
            "960 [ D loss: 0.135369, acc.: 99%] [G loss: 6.135230]\n",
            "961 [ D loss: 0.379077, acc.: 80%] [G loss: 3.088592]\n",
            "962 [ D loss: 0.403512, acc.: 80%] [G loss: 3.795319]\n",
            "963 [ D loss: 0.328892, acc.: 89%] [G loss: 3.654836]\n",
            "964 [ D loss: 0.221458, acc.: 97%] [G loss: 4.488357]\n",
            "965 [ D loss: 0.183186, acc.: 98%] [G loss: 6.764378]\n",
            "966 [ D loss: 0.210480, acc.: 94%] [G loss: 5.108489]\n",
            "967 [ D loss: 0.453032, acc.: 77%] [G loss: 5.294262]\n",
            "968 [ D loss: 0.435177, acc.: 83%] [G loss: 2.663103]\n",
            "969 [ D loss: 0.185622, acc.: 98%] [G loss: 5.450559]\n",
            "970 [ D loss: 0.243050, acc.: 95%] [G loss: 4.200473]\n",
            "971 [ D loss: 0.314642, acc.: 89%] [G loss: 3.648536]\n",
            "972 [ D loss: 0.192226, acc.: 96%] [G loss: 4.791296]\n",
            "973 [ D loss: 0.328908, acc.: 86%] [G loss: 3.782011]\n",
            "974 [ D loss: 0.380583, acc.: 86%] [G loss: 5.417244]\n",
            "975 [ D loss: 0.406212, acc.: 78%] [G loss: 3.245803]\n",
            "976 [ D loss: 0.241069, acc.: 95%] [G loss: 4.116052]\n",
            "977 [ D loss: 0.162696, acc.: 98%] [G loss: 5.544221]\n",
            "978 [ D loss: 0.186007, acc.: 95%] [G loss: 5.338982]\n",
            "979 [ D loss: 0.678817, acc.: 68%] [G loss: 2.195975]\n",
            "980 [ D loss: 0.196122, acc.: 99%] [G loss: 5.329582]\n",
            "981 [ D loss: 0.231612, acc.: 95%] [G loss: 6.442017]\n",
            "982 [ D loss: 0.532370, acc.: 71%] [G loss: 2.509629]\n",
            "983 [ D loss: 0.417289, acc.: 80%] [G loss: 2.905494]\n",
            "984 [ D loss: 0.393344, acc.: 83%] [G loss: 3.362092]\n",
            "985 [ D loss: 0.297076, acc.: 95%] [G loss: 3.561740]\n",
            "986 [ D loss: 0.214542, acc.: 96%] [G loss: 4.306863]\n",
            "987 [ D loss: 0.143561, acc.: 99%] [G loss: 8.418818]\n",
            "988 [ D loss: 0.212421, acc.: 96%] [G loss: 3.960278]\n",
            "989 [ D loss: 0.344628, acc.: 83%] [G loss: 3.300637]\n",
            "990 [ D loss: 0.467325, acc.: 76%] [G loss: 3.029033]\n",
            "991 [ D loss: 0.365137, acc.: 81%] [G loss: 4.270855]\n",
            "992 [ D loss: 0.244031, acc.: 94%] [G loss: 5.131638]\n",
            "993 [ D loss: 0.155085, acc.: 98%] [G loss: 8.466872]\n",
            "994 [ D loss: 0.579756, acc.: 73%] [G loss: 2.343185]\n",
            "995 [ D loss: 0.173647, acc.: 99%] [G loss: 5.460873]\n",
            "996 [ D loss: 0.277070, acc.: 92%] [G loss: 4.032661]\n",
            "997 [ D loss: 0.422277, acc.: 80%] [G loss: 3.457525]\n",
            "998 [ D loss: 0.393199, acc.: 81%] [G loss: 3.922553]\n",
            "999 [ D loss: 0.198659, acc.: 98%] [G loss: 7.269225]\n",
            "1000 [ D loss: 0.244245, acc.: 95%] [G loss: 4.829988]\n",
            "1001 [ D loss: 0.414817, acc.: 81%] [G loss: 3.121454]\n",
            "1002 [ D loss: 0.397298, acc.: 82%] [G loss: 3.497327]\n",
            "1003 [ D loss: 0.385889, acc.: 85%] [G loss: 3.520604]\n",
            "1004 [ D loss: 0.357699, acc.: 92%] [G loss: 2.872535]\n",
            "1005 [ D loss: 0.200764, acc.: 98%] [G loss: 5.794252]\n",
            "1006 [ D loss: 0.164347, acc.: 98%] [G loss: 5.846250]\n",
            "1007 [ D loss: 0.486506, acc.: 76%] [G loss: 2.951936]\n",
            "1008 [ D loss: 0.325913, acc.: 84%] [G loss: 3.279829]\n",
            "1009 [ D loss: 0.301579, acc.: 92%] [G loss: 3.435966]\n",
            "1010 [ D loss: 0.198560, acc.: 98%] [G loss: 5.719679]\n",
            "1011 [ D loss: 0.206593, acc.: 96%] [G loss: 3.918107]\n",
            "1012 [ D loss: 0.382165, acc.: 84%] [G loss: 3.181200]\n",
            "1013 [ D loss: 0.269526, acc.: 94%] [G loss: 4.287326]\n",
            "1014 [ D loss: 0.162589, acc.: 99%] [G loss: 5.143766]\n",
            "1015 [ D loss: 0.298216, acc.: 88%] [G loss: 4.620069]\n",
            "1016 [ D loss: 0.586952, acc.: 72%] [G loss: 2.633352]\n",
            "1017 [ D loss: 0.433108, acc.: 77%] [G loss: 3.222012]\n",
            "1018 [ D loss: 0.271385, acc.: 91%] [G loss: 4.672823]\n",
            "1019 [ D loss: 0.190864, acc.: 97%] [G loss: 4.878674]\n",
            "1020 [ D loss: 0.116988, acc.: 99%] [G loss: 5.948069]\n",
            "1021 [ D loss: 0.674110, acc.: 70%] [G loss: 3.014946]\n",
            "1022 [ D loss: 0.168293, acc.: 98%] [G loss: 5.122412]\n",
            "1023 [ D loss: 0.213282, acc.: 96%] [G loss: 4.754498]\n",
            "1024 [ D loss: 0.362971, acc.: 84%] [G loss: 3.614612]\n",
            "1025 [ D loss: 0.249976, acc.: 95%] [G loss: 5.256444]\n",
            "1026 [ D loss: 0.235306, acc.: 94%] [G loss: 4.529271]\n",
            "1027 [ D loss: 0.241449, acc.: 91%] [G loss: 5.087353]\n",
            "1028 [ D loss: 0.446956, acc.: 77%] [G loss: 3.142811]\n",
            "1029 [ D loss: 0.366289, acc.: 82%] [G loss: 4.068502]\n",
            "1030 [ D loss: 0.469094, acc.: 75%] [G loss: 4.052972]\n",
            "1031 [ D loss: 0.236876, acc.: 95%] [G loss: 6.319289]\n",
            "1032 [ D loss: 0.221814, acc.: 94%] [G loss: 4.962193]\n",
            "1033 [ D loss: 0.168831, acc.: 98%] [G loss: 6.127847]\n",
            "1034 [ D loss: 0.349961, acc.: 84%] [G loss: 3.929019]\n",
            "1035 [ D loss: 0.240365, acc.: 91%] [G loss: 4.137297]\n",
            "1036 [ D loss: 0.511812, acc.: 71%] [G loss: 3.356966]\n",
            "1037 [ D loss: 0.359967, acc.: 86%] [G loss: 3.363263]\n",
            "1038 [ D loss: 0.190041, acc.: 97%] [G loss: 6.471365]\n",
            "1039 [ D loss: 0.279442, acc.: 95%] [G loss: 3.596135]\n",
            "1040 [ D loss: 0.230653, acc.: 95%] [G loss: 3.792888]\n",
            "1041 [ D loss: 0.279080, acc.: 90%] [G loss: 4.938925]\n",
            "1042 [ D loss: 0.354533, acc.: 86%] [G loss: 5.334702]\n",
            "1043 [ D loss: 0.673190, acc.: 66%] [G loss: 2.543934]\n",
            "1044 [ D loss: 0.324176, acc.: 94%] [G loss: 4.051759]\n",
            "1045 [ D loss: 0.251984, acc.: 94%] [G loss: 5.346711]\n",
            "1046 [ D loss: 0.181656, acc.: 98%] [G loss: 5.030115]\n",
            "1047 [ D loss: 0.258201, acc.: 91%] [G loss: 4.767558]\n",
            "1048 [ D loss: 0.548556, acc.: 76%] [G loss: 3.255601]\n",
            "1049 [ D loss: 0.459354, acc.: 75%] [G loss: 4.321898]\n",
            "1050 [ D loss: 0.259265, acc.: 93%] [G loss: 3.630803]\n",
            "1051 [ D loss: 0.177202, acc.: 99%] [G loss: 5.083323]\n",
            "1052 [ D loss: 0.283033, acc.: 91%] [G loss: 3.432857]\n",
            "1053 [ D loss: 0.283205, acc.: 88%] [G loss: 4.877478]\n",
            "1054 [ D loss: 0.427734, acc.: 83%] [G loss: 3.374795]\n",
            "1055 [ D loss: 0.494938, acc.: 78%] [G loss: 3.382257]\n",
            "1056 [ D loss: 0.387155, acc.: 84%] [G loss: 3.454306]\n",
            "1057 [ D loss: 0.200476, acc.: 95%] [G loss: 7.175378]\n",
            "1058 [ D loss: 0.360714, acc.: 84%] [G loss: 3.584729]\n",
            "1059 [ D loss: 0.276585, acc.: 91%] [G loss: 4.479995]\n",
            "1060 [ D loss: 0.185262, acc.: 100%] [G loss: 5.328352]\n",
            "1061 [ D loss: 0.199519, acc.: 97%] [G loss: 5.467523]\n",
            "1062 [ D loss: 0.342199, acc.: 88%] [G loss: 3.956144]\n",
            "1063 [ D loss: 0.308449, acc.: 90%] [G loss: 5.049226]\n",
            "1064 [ D loss: 0.509440, acc.: 73%] [G loss: 3.806670]\n",
            "1065 [ D loss: 0.320000, acc.: 89%] [G loss: 5.740568]\n",
            "1066 [ D loss: 0.330533, acc.: 90%] [G loss: 4.401799]\n",
            "1067 [ D loss: 0.352478, acc.: 87%] [G loss: 4.225484]\n",
            "1068 [ D loss: 0.272920, acc.: 93%] [G loss: 3.771124]\n",
            "1069 [ D loss: 0.167780, acc.: 98%] [G loss: 5.516104]\n",
            "1070 [ D loss: 0.197778, acc.: 95%] [G loss: 4.010062]\n",
            "1071 [ D loss: 0.240178, acc.: 91%] [G loss: 5.137336]\n",
            "1072 [ D loss: 0.528074, acc.: 70%] [G loss: 3.590193]\n",
            "1073 [ D loss: 0.230498, acc.: 97%] [G loss: 5.295983]\n",
            "1074 [ D loss: 0.236150, acc.: 96%] [G loss: 4.305734]\n",
            "1075 [ D loss: 0.210373, acc.: 94%] [G loss: 5.327180]\n",
            "1076 [ D loss: 0.235103, acc.: 92%] [G loss: 4.385136]\n",
            "1077 [ D loss: 0.231775, acc.: 94%] [G loss: 3.438761]\n",
            "1078 [ D loss: 0.250362, acc.: 93%] [G loss: 5.422573]\n",
            "1079 [ D loss: 0.208678, acc.: 98%] [G loss: 4.055653]\n",
            "1080 [ D loss: 0.653642, acc.: 73%] [G loss: 3.348193]\n",
            "1081 [ D loss: 0.550626, acc.: 67%] [G loss: 3.100016]\n",
            "1082 [ D loss: 0.234582, acc.: 95%] [G loss: 4.344980]\n",
            "1083 [ D loss: 0.243996, acc.: 93%] [G loss: 4.200589]\n",
            "1084 [ D loss: 0.160922, acc.: 99%] [G loss: 6.530806]\n",
            "1085 [ D loss: 0.460908, acc.: 76%] [G loss: 3.845557]\n",
            "1086 [ D loss: 0.365867, acc.: 86%] [G loss: 4.400645]\n",
            "1087 [ D loss: 0.216661, acc.: 98%] [G loss: 4.647121]\n",
            "1088 [ D loss: 0.155580, acc.: 99%] [G loss: 5.069875]\n",
            "1089 [ D loss: 0.308680, acc.: 88%] [G loss: 3.711775]\n",
            "1090 [ D loss: 0.454874, acc.: 80%] [G loss: 3.733755]\n",
            "1091 [ D loss: 0.423142, acc.: 80%] [G loss: 4.314859]\n",
            "1092 [ D loss: 0.375873, acc.: 83%] [G loss: 3.353057]\n",
            "1093 [ D loss: 0.271523, acc.: 94%] [G loss: 4.477542]\n",
            "1094 [ D loss: 0.225526, acc.: 96%] [G loss: 4.529355]\n",
            "1095 [ D loss: 0.167095, acc.: 98%] [G loss: 7.186992]\n",
            "1096 [ D loss: 0.400208, acc.: 82%] [G loss: 4.658874]\n",
            "1097 [ D loss: 0.294862, acc.: 90%] [G loss: 3.745923]\n",
            "1098 [ D loss: 0.172468, acc.: 97%] [G loss: 5.544918]\n",
            "1099 [ D loss: 0.222947, acc.: 93%] [G loss: 5.750704]\n",
            "1100 [ D loss: 0.306025, acc.: 89%] [G loss: 4.277228]\n",
            "1101 [ D loss: 0.627215, acc.: 67%] [G loss: 3.226316]\n",
            "1102 [ D loss: 0.595276, acc.: 70%] [G loss: 3.518786]\n",
            "1103 [ D loss: 0.295899, acc.: 90%] [G loss: 3.852118]\n",
            "1104 [ D loss: 0.259544, acc.: 93%] [G loss: 3.577435]\n",
            "1105 [ D loss: 0.186005, acc.: 98%] [G loss: 4.848442]\n",
            "1106 [ D loss: 0.176740, acc.: 98%] [G loss: 3.433760]\n",
            "1107 [ D loss: 0.544227, acc.: 71%] [G loss: 3.461169]\n",
            "1108 [ D loss: 0.362291, acc.: 84%] [G loss: 4.993178]\n",
            "1109 [ D loss: 0.506028, acc.: 76%] [G loss: 3.923694]\n",
            "1110 [ D loss: 0.306286, acc.: 88%] [G loss: 5.699300]\n",
            "1111 [ D loss: 0.153474, acc.: 98%] [G loss: 7.649401]\n",
            "1112 [ D loss: 0.477346, acc.: 80%] [G loss: 3.518395]\n",
            "1113 [ D loss: 0.322880, acc.: 84%] [G loss: 4.472251]\n",
            "1114 [ D loss: 0.185382, acc.: 97%] [G loss: 5.620962]\n",
            "1115 [ D loss: 0.205437, acc.: 95%] [G loss: 4.502205]\n",
            "1116 [ D loss: 0.531490, acc.: 77%] [G loss: 3.466692]\n",
            "1117 [ D loss: 0.313529, acc.: 90%] [G loss: 4.210461]\n",
            "1118 [ D loss: 0.323118, acc.: 93%] [G loss: 3.109020]\n",
            "1119 [ D loss: 0.208343, acc.: 94%] [G loss: 4.911179]\n",
            "1120 [ D loss: 0.288100, acc.: 91%] [G loss: 4.766150]\n",
            "1121 [ D loss: 0.391166, acc.: 88%] [G loss: 4.388167]\n",
            "1122 [ D loss: 0.242256, acc.: 94%] [G loss: 5.028242]\n",
            "1123 [ D loss: 0.522660, acc.: 76%] [G loss: 4.141948]\n",
            "1124 [ D loss: 0.620130, acc.: 69%] [G loss: 3.514864]\n",
            "1125 [ D loss: 0.229177, acc.: 98%] [G loss: 3.542337]\n",
            "1126 [ D loss: 0.297625, acc.: 90%] [G loss: 4.532305]\n",
            "1127 [ D loss: 0.342613, acc.: 86%] [G loss: 4.041204]\n",
            "1128 [ D loss: 0.296915, acc.: 88%] [G loss: 3.852888]\n",
            "1129 [ D loss: 0.220490, acc.: 91%] [G loss: 3.272076]\n",
            "1130 [ D loss: 0.403520, acc.: 84%] [G loss: 3.392692]\n",
            "1131 [ D loss: 0.187940, acc.: 96%] [G loss: 4.548778]\n",
            "1132 [ D loss: 0.167179, acc.: 98%] [G loss: 4.701207]\n",
            "1133 [ D loss: 0.243801, acc.: 94%] [G loss: 3.693537]\n",
            "1134 [ D loss: 0.432978, acc.: 78%] [G loss: 3.551737]\n",
            "1135 [ D loss: 0.370412, acc.: 84%] [G loss: 3.980414]\n",
            "1136 [ D loss: 0.167633, acc.: 98%] [G loss: 5.098471]\n",
            "1137 [ D loss: 0.249499, acc.: 95%] [G loss: 3.332938]\n",
            "1138 [ D loss: 0.241851, acc.: 95%] [G loss: 4.288003]\n",
            "1139 [ D loss: 0.158365, acc.: 99%] [G loss: 4.823290]\n",
            "1140 [ D loss: 0.396731, acc.: 81%] [G loss: 3.175020]\n",
            "1141 [ D loss: 0.701651, acc.: 61%] [G loss: 2.066873]\n",
            "1142 [ D loss: 0.245597, acc.: 97%] [G loss: 3.583495]\n",
            "1143 [ D loss: 0.187026, acc.: 97%] [G loss: 8.381897]\n",
            "1144 [ D loss: 0.504136, acc.: 73%] [G loss: 3.003745]\n",
            "1145 [ D loss: 0.180185, acc.: 96%] [G loss: 5.742388]\n",
            "1146 [ D loss: 0.290351, acc.: 90%] [G loss: 5.123994]\n",
            "1147 [ D loss: 0.328557, acc.: 86%] [G loss: 5.160941]\n",
            "1148 [ D loss: 0.483262, acc.: 73%] [G loss: 2.752213]\n",
            "1149 [ D loss: 0.260646, acc.: 93%] [G loss: 5.520536]\n",
            "1150 [ D loss: 0.254142, acc.: 92%] [G loss: 4.800514]\n",
            "1151 [ D loss: 0.171736, acc.: 98%] [G loss: 5.859584]\n",
            "1152 [ D loss: 0.574627, acc.: 68%] [G loss: 2.989136]\n",
            "1153 [ D loss: 0.156460, acc.: 98%] [G loss: 5.892422]\n",
            "1154 [ D loss: 0.532980, acc.: 76%] [G loss: 3.960604]\n",
            "1155 [ D loss: 0.217117, acc.: 98%] [G loss: 3.798346]\n",
            "1156 [ D loss: 0.189417, acc.: 97%] [G loss: 5.917220]\n",
            "1157 [ D loss: 0.358214, acc.: 88%] [G loss: 3.984946]\n",
            "1158 [ D loss: 0.213067, acc.: 91%] [G loss: 5.189125]\n",
            "1159 [ D loss: 0.369644, acc.: 88%] [G loss: 3.163295]\n",
            "1160 [ D loss: 0.341953, acc.: 88%] [G loss: 3.778725]\n",
            "1161 [ D loss: 0.397561, acc.: 82%] [G loss: 3.300907]\n",
            "1162 [ D loss: 0.496665, acc.: 70%] [G loss: 3.249744]\n",
            "1163 [ D loss: 0.425465, acc.: 83%] [G loss: 3.179501]\n",
            "1164 [ D loss: 0.186185, acc.: 98%] [G loss: 6.157990]\n",
            "1165 [ D loss: 0.577847, acc.: 67%] [G loss: 2.715042]\n",
            "1166 [ D loss: 0.334266, acc.: 86%] [G loss: 4.098736]\n",
            "1167 [ D loss: 0.233887, acc.: 91%] [G loss: 7.441588]\n",
            "1168 [ D loss: 0.426108, acc.: 78%] [G loss: 4.808867]\n",
            "1169 [ D loss: 0.190210, acc.: 96%] [G loss: 6.679225]\n",
            "1170 [ D loss: 0.241765, acc.: 91%] [G loss: 4.457659]\n",
            "1171 [ D loss: 0.434244, acc.: 82%] [G loss: 3.081335]\n",
            "1172 [ D loss: 0.608305, acc.: 65%] [G loss: 2.816155]\n",
            "1173 [ D loss: 0.340271, acc.: 85%] [G loss: 3.644154]\n",
            "1174 [ D loss: 0.219447, acc.: 95%] [G loss: 6.178707]\n",
            "1175 [ D loss: 0.292598, acc.: 91%] [G loss: 4.180232]\n",
            "1176 [ D loss: 0.243582, acc.: 94%] [G loss: 3.400501]\n",
            "1177 [ D loss: 0.379498, acc.: 84%] [G loss: 3.627212]\n",
            "1178 [ D loss: 0.417264, acc.: 78%] [G loss: 2.536627]\n",
            "1179 [ D loss: 0.644780, acc.: 64%] [G loss: 2.910474]\n",
            "1180 [ D loss: 0.541381, acc.: 73%] [G loss: 2.817712]\n",
            "1181 [ D loss: 0.579737, acc.: 70%] [G loss: 2.613407]\n",
            "1182 [ D loss: 0.409826, acc.: 80%] [G loss: 3.714975]\n",
            "1183 [ D loss: 0.245213, acc.: 92%] [G loss: 6.089399]\n",
            "1184 [ D loss: 0.319971, acc.: 86%] [G loss: 4.560852]\n",
            "1185 [ D loss: 0.402394, acc.: 84%] [G loss: 2.424735]\n",
            "1186 [ D loss: 0.448505, acc.: 79%] [G loss: 3.716523]\n",
            "1187 [ D loss: 0.408883, acc.: 84%] [G loss: 3.084325]\n",
            "1188 [ D loss: 0.163285, acc.: 99%] [G loss: 6.244226]\n",
            "1189 [ D loss: 0.239090, acc.: 93%] [G loss: 4.101167]\n",
            "1190 [ D loss: 0.373204, acc.: 84%] [G loss: 2.426276]\n",
            "1191 [ D loss: 0.623931, acc.: 67%] [G loss: 2.422048]\n",
            "1192 [ D loss: 0.517956, acc.: 75%] [G loss: 2.596427]\n",
            "1193 [ D loss: 0.300769, acc.: 91%] [G loss: 3.653153]\n",
            "1194 [ D loss: 0.247724, acc.: 94%] [G loss: 3.596167]\n",
            "1195 [ D loss: 0.172031, acc.: 95%] [G loss: 5.355623]\n",
            "1196 [ D loss: 0.503860, acc.: 69%] [G loss: 2.481713]\n",
            "1197 [ D loss: 0.604947, acc.: 66%] [G loss: 2.711526]\n",
            "1198 [ D loss: 0.524440, acc.: 69%] [G loss: 2.836207]\n",
            "1199 [ D loss: 0.189490, acc.: 97%] [G loss: 5.767315]\n",
            "1200 [ D loss: 0.250833, acc.: 92%] [G loss: 3.746171]\n",
            "1201 [ D loss: 0.521300, acc.: 67%] [G loss: 2.576017]\n",
            "1202 [ D loss: 0.627908, acc.: 61%] [G loss: 2.249215]\n",
            "1203 [ D loss: 0.247233, acc.: 94%] [G loss: 6.683555]\n",
            "1204 [ D loss: 0.413460, acc.: 82%] [G loss: 2.980175]\n",
            "1205 [ D loss: 0.426628, acc.: 77%] [G loss: 2.886378]\n",
            "1206 [ D loss: 0.194836, acc.: 97%] [G loss: 4.558311]\n",
            "1207 [ D loss: 0.347786, acc.: 86%] [G loss: 2.700808]\n",
            "1208 [ D loss: 0.285055, acc.: 90%] [G loss: 4.201684]\n",
            "1209 [ D loss: 0.179954, acc.: 96%] [G loss: 5.061530]\n",
            "1210 [ D loss: 0.340805, acc.: 87%] [G loss: 3.480878]\n",
            "1211 [ D loss: 0.511391, acc.: 70%] [G loss: 2.436194]\n",
            "1212 [ D loss: 0.490895, acc.: 75%] [G loss: 3.925524]\n",
            "1213 [ D loss: 0.525044, acc.: 72%] [G loss: 2.959125]\n",
            "1214 [ D loss: 0.191685, acc.: 99%] [G loss: 5.212663]\n",
            "1215 [ D loss: 0.156830, acc.: 98%] [G loss: 7.024174]\n",
            "1216 [ D loss: 0.558570, acc.: 70%] [G loss: 2.424882]\n",
            "1217 [ D loss: 0.176682, acc.: 95%] [G loss: 4.547065]\n",
            "1218 [ D loss: 0.139272, acc.: 99%] [G loss: 5.400933]\n",
            "1219 [ D loss: 0.637783, acc.: 65%] [G loss: 2.570151]\n",
            "1220 [ D loss: 0.370473, acc.: 82%] [G loss: 3.287990]\n",
            "1221 [ D loss: 0.497257, acc.: 73%] [G loss: 2.931541]\n",
            "1222 [ D loss: 0.412115, acc.: 79%] [G loss: 3.268411]\n",
            "1223 [ D loss: 0.357295, acc.: 89%] [G loss: 3.050539]\n",
            "1224 [ D loss: 0.291946, acc.: 91%] [G loss: 3.872907]\n",
            "1225 [ D loss: 0.233130, acc.: 95%] [G loss: 3.616962]\n",
            "1226 [ D loss: 0.418400, acc.: 81%] [G loss: 2.604660]\n",
            "1227 [ D loss: 0.436335, acc.: 76%] [G loss: 3.124547]\n",
            "1228 [ D loss: 0.237152, acc.: 94%] [G loss: 3.514008]\n",
            "1229 [ D loss: 0.178282, acc.: 97%] [G loss: 5.440945]\n",
            "1230 [ D loss: 0.582217, acc.: 70%] [G loss: 2.685870]\n",
            "1231 [ D loss: 0.284157, acc.: 94%] [G loss: 3.326755]\n",
            "1232 [ D loss: 0.195330, acc.: 96%] [G loss: 7.488107]\n",
            "1233 [ D loss: 0.590105, acc.: 67%] [G loss: 2.167001]\n",
            "1234 [ D loss: 0.229500, acc.: 95%] [G loss: 3.290210]\n",
            "1235 [ D loss: 0.295628, acc.: 95%] [G loss: 3.756258]\n",
            "1236 [ D loss: 0.589987, acc.: 70%] [G loss: 2.129111]\n",
            "1237 [ D loss: 0.352667, acc.: 87%] [G loss: 3.477493]\n",
            "1238 [ D loss: 0.232805, acc.: 92%] [G loss: 5.962722]\n",
            "1239 [ D loss: 0.714875, acc.: 61%] [G loss: 1.849654]\n",
            "1240 [ D loss: 0.344417, acc.: 85%] [G loss: 5.250434]\n",
            "1241 [ D loss: 0.277466, acc.: 93%] [G loss: 5.917833]\n",
            "1242 [ D loss: 0.437681, acc.: 79%] [G loss: 4.518006]\n",
            "1243 [ D loss: 0.481829, acc.: 77%] [G loss: 2.048885]\n",
            "1244 [ D loss: 0.382668, acc.: 81%] [G loss: 3.730639]\n",
            "1245 [ D loss: 0.493988, acc.: 71%] [G loss: 2.612151]\n",
            "1246 [ D loss: 0.261937, acc.: 94%] [G loss: 4.221025]\n",
            "1247 [ D loss: 0.384039, acc.: 86%] [G loss: 3.377712]\n",
            "1248 [ D loss: 0.298183, acc.: 91%] [G loss: 2.881867]\n",
            "1249 [ D loss: 0.297193, acc.: 88%] [G loss: 4.066934]\n",
            "1250 [ D loss: 0.262299, acc.: 91%] [G loss: 3.976700]\n",
            "1251 [ D loss: 0.436285, acc.: 77%] [G loss: 3.564763]\n",
            "1252 [ D loss: 0.702799, acc.: 66%] [G loss: 2.282901]\n",
            "1253 [ D loss: 0.399679, acc.: 83%] [G loss: 3.286385]\n",
            "1254 [ D loss: 0.344032, acc.: 89%] [G loss: 3.711229]\n",
            "1255 [ D loss: 0.258661, acc.: 94%] [G loss: 3.933689]\n",
            "1256 [ D loss: 0.285979, acc.: 91%] [G loss: 5.411254]\n",
            "1257 [ D loss: 0.247827, acc.: 95%] [G loss: 3.506900]\n",
            "1258 [ D loss: 0.585011, acc.: 63%] [G loss: 2.514501]\n",
            "1259 [ D loss: 0.379194, acc.: 80%] [G loss: 2.676413]\n",
            "1260 [ D loss: 0.354360, acc.: 87%] [G loss: 3.884431]\n",
            "1261 [ D loss: 0.232257, acc.: 93%] [G loss: 4.452946]\n",
            "1262 [ D loss: 0.198104, acc.: 96%] [G loss: 3.984171]\n",
            "1263 [ D loss: 0.212684, acc.: 93%] [G loss: 3.706512]\n",
            "1264 [ D loss: 0.514128, acc.: 70%] [G loss: 2.358856]\n",
            "1265 [ D loss: 0.352086, acc.: 88%] [G loss: 2.712086]\n",
            "1266 [ D loss: 0.156714, acc.: 99%] [G loss: 5.988235]\n",
            "1267 [ D loss: 0.186473, acc.: 98%] [G loss: 4.029150]\n",
            "1268 [ D loss: 0.623816, acc.: 62%] [G loss: 2.565721]\n",
            "1269 [ D loss: 0.306548, acc.: 90%] [G loss: 3.080786]\n",
            "1270 [ D loss: 0.234723, acc.: 96%] [G loss: 3.549734]\n",
            "1271 [ D loss: 0.326580, acc.: 91%] [G loss: 2.908148]\n",
            "1272 [ D loss: 0.354043, acc.: 86%] [G loss: 2.436254]\n",
            "1273 [ D loss: 0.302325, acc.: 93%] [G loss: 2.854515]\n",
            "1274 [ D loss: 0.185677, acc.: 95%] [G loss: 3.813647]\n",
            "1275 [ D loss: 0.245512, acc.: 95%] [G loss: 3.684816]\n",
            "1276 [ D loss: 0.456083, acc.: 77%] [G loss: 2.917117]\n",
            "1277 [ D loss: 0.180472, acc.: 98%] [G loss: 4.770284]\n",
            "1278 [ D loss: 0.383498, acc.: 84%] [G loss: 2.649073]\n",
            "1279 [ D loss: 0.417043, acc.: 78%] [G loss: 2.884032]\n",
            "1280 [ D loss: 0.478916, acc.: 72%] [G loss: 2.641538]\n",
            "1281 [ D loss: 0.230802, acc.: 95%] [G loss: 3.533261]\n",
            "1282 [ D loss: 0.402738, acc.: 83%] [G loss: 3.020672]\n",
            "1283 [ D loss: 0.455812, acc.: 77%] [G loss: 3.252305]\n",
            "1284 [ D loss: 0.485870, acc.: 72%] [G loss: 2.894614]\n",
            "1285 [ D loss: 0.415303, acc.: 80%] [G loss: 3.141505]\n",
            "1286 [ D loss: 0.267076, acc.: 93%] [G loss: 3.510323]\n",
            "1287 [ D loss: 0.202785, acc.: 96%] [G loss: 6.064031]\n",
            "1288 [ D loss: 0.239900, acc.: 94%] [G loss: 4.004983]\n",
            "1289 [ D loss: 0.646349, acc.: 63%] [G loss: 2.041506]\n",
            "1290 [ D loss: 0.574367, acc.: 65%] [G loss: 2.347496]\n",
            "1291 [ D loss: 0.503639, acc.: 70%] [G loss: 2.949595]\n",
            "1292 [ D loss: 0.214630, acc.: 97%] [G loss: 4.363576]\n",
            "1293 [ D loss: 0.181104, acc.: 95%] [G loss: 6.780363]\n",
            "1294 [ D loss: 0.477761, acc.: 69%] [G loss: 2.542376]\n",
            "1295 [ D loss: 0.316019, acc.: 89%] [G loss: 2.671123]\n",
            "1296 [ D loss: 0.413795, acc.: 80%] [G loss: 2.845806]\n",
            "1297 [ D loss: 0.233915, acc.: 95%] [G loss: 3.550653]\n",
            "1298 [ D loss: 0.572799, acc.: 66%] [G loss: 2.277364]\n",
            "1299 [ D loss: 0.330864, acc.: 91%] [G loss: 4.281720]\n",
            "1300 [ D loss: 0.209208, acc.: 97%] [G loss: 6.804469]\n",
            "1301 [ D loss: 0.523467, acc.: 68%] [G loss: 4.062510]\n",
            "1302 [ D loss: 0.303924, acc.: 88%] [G loss: 4.582638]\n",
            "1303 [ D loss: 0.163117, acc.: 97%] [G loss: 5.776273]\n",
            "1304 [ D loss: 0.492015, acc.: 74%] [G loss: 2.733172]\n",
            "1305 [ D loss: 0.233472, acc.: 95%] [G loss: 5.013253]\n",
            "1306 [ D loss: 0.440511, acc.: 73%] [G loss: 2.665155]\n",
            "1307 [ D loss: 0.441215, acc.: 80%] [G loss: 2.685020]\n",
            "1308 [ D loss: 0.242877, acc.: 94%] [G loss: 3.984511]\n",
            "1309 [ D loss: 0.557353, acc.: 68%] [G loss: 2.414470]\n",
            "1310 [ D loss: 0.667840, acc.: 59%] [G loss: 2.299502]\n",
            "1311 [ D loss: 0.518579, acc.: 71%] [G loss: 1.906605]\n",
            "1312 [ D loss: 0.240422, acc.: 96%] [G loss: 4.364976]\n",
            "1313 [ D loss: 0.274513, acc.: 95%] [G loss: 3.363436]\n",
            "1314 [ D loss: 0.472498, acc.: 76%] [G loss: 2.518141]\n",
            "1315 [ D loss: 0.399106, acc.: 78%] [G loss: 2.694736]\n",
            "1316 [ D loss: 0.377067, acc.: 85%] [G loss: 2.522642]\n",
            "1317 [ D loss: 0.451800, acc.: 77%] [G loss: 2.030392]\n",
            "1318 [ D loss: 0.255668, acc.: 93%] [G loss: 3.788809]\n",
            "1319 [ D loss: 0.194903, acc.: 95%] [G loss: 4.074552]\n",
            "1320 [ D loss: 0.537161, acc.: 70%] [G loss: 3.050990]\n",
            "1321 [ D loss: 0.387375, acc.: 83%] [G loss: 3.006427]\n",
            "1322 [ D loss: 0.183821, acc.: 97%] [G loss: 6.123556]\n",
            "1323 [ D loss: 0.370857, acc.: 84%] [G loss: 3.120263]\n",
            "1324 [ D loss: 0.273348, acc.: 92%] [G loss: 3.485795]\n",
            "1325 [ D loss: 0.356450, acc.: 85%] [G loss: 3.146748]\n",
            "1326 [ D loss: 0.525151, acc.: 71%] [G loss: 2.753223]\n",
            "1327 [ D loss: 0.326904, acc.: 88%] [G loss: 3.071363]\n",
            "1328 [ D loss: 0.196356, acc.: 99%] [G loss: 5.022279]\n",
            "1329 [ D loss: 0.377960, acc.: 84%] [G loss: 2.212250]\n",
            "1330 [ D loss: 0.636200, acc.: 61%] [G loss: 2.712557]\n",
            "1331 [ D loss: 0.444593, acc.: 76%] [G loss: 4.176399]\n",
            "1332 [ D loss: 0.218560, acc.: 95%] [G loss: 7.574735]\n",
            "1333 [ D loss: 0.363126, acc.: 84%] [G loss: 3.128607]\n",
            "1334 [ D loss: 0.557828, acc.: 72%] [G loss: 2.677943]\n",
            "1335 [ D loss: 0.528631, acc.: 71%] [G loss: 2.142881]\n",
            "1336 [ D loss: 0.327453, acc.: 85%] [G loss: 3.873554]\n",
            "1337 [ D loss: 0.394747, acc.: 82%] [G loss: 3.856629]\n",
            "1338 [ D loss: 0.538331, acc.: 66%] [G loss: 1.914928]\n",
            "1339 [ D loss: 0.533390, acc.: 70%] [G loss: 1.999310]\n",
            "1340 [ D loss: 0.414081, acc.: 84%] [G loss: 3.244772]\n",
            "1341 [ D loss: 0.343161, acc.: 84%] [G loss: 7.286133]\n",
            "1342 [ D loss: 0.488150, acc.: 73%] [G loss: 2.576909]\n",
            "1343 [ D loss: 0.227654, acc.: 95%] [G loss: 3.213968]\n",
            "1344 [ D loss: 0.175899, acc.: 97%] [G loss: 4.316062]\n",
            "1345 [ D loss: 0.764297, acc.: 55%] [G loss: 1.761644]\n",
            "1346 [ D loss: 0.446024, acc.: 79%] [G loss: 2.837934]\n",
            "1347 [ D loss: 0.295428, acc.: 90%] [G loss: 3.625899]\n",
            "1348 [ D loss: 0.357007, acc.: 90%] [G loss: 4.107640]\n",
            "1349 [ D loss: 0.347424, acc.: 91%] [G loss: 2.246160]\n",
            "1350 [ D loss: 0.587001, acc.: 70%] [G loss: 2.656477]\n",
            "1351 [ D loss: 0.483090, acc.: 73%] [G loss: 2.393573]\n",
            "1352 [ D loss: 0.665689, acc.: 62%] [G loss: 2.120358]\n",
            "1353 [ D loss: 0.345733, acc.: 88%] [G loss: 3.148977]\n",
            "1354 [ D loss: 0.208391, acc.: 96%] [G loss: 5.382027]\n",
            "1355 [ D loss: 0.680110, acc.: 59%] [G loss: 1.264973]\n",
            "1356 [ D loss: 0.273979, acc.: 91%] [G loss: 4.389263]\n",
            "1357 [ D loss: 0.169526, acc.: 98%] [G loss: 3.957800]\n",
            "1358 [ D loss: 0.421021, acc.: 80%] [G loss: 3.397026]\n",
            "1359 [ D loss: 0.220130, acc.: 95%] [G loss: 6.204269]\n",
            "1360 [ D loss: 0.319676, acc.: 88%] [G loss: 3.610874]\n",
            "1361 [ D loss: 0.571826, acc.: 64%] [G loss: 2.749788]\n",
            "1362 [ D loss: 0.409893, acc.: 81%] [G loss: 3.874674]\n",
            "1363 [ D loss: 0.530875, acc.: 68%] [G loss: 2.428374]\n",
            "1364 [ D loss: 0.306718, acc.: 90%] [G loss: 4.004773]\n",
            "1365 [ D loss: 0.242708, acc.: 95%] [G loss: 3.850821]\n",
            "1366 [ D loss: 0.376555, acc.: 83%] [G loss: 2.402558]\n",
            "1367 [ D loss: 0.520358, acc.: 70%] [G loss: 2.019027]\n",
            "1368 [ D loss: 0.495764, acc.: 70%] [G loss: 2.036039]\n",
            "1369 [ D loss: 0.418761, acc.: 83%] [G loss: 2.874493]\n",
            "1370 [ D loss: 0.576149, acc.: 70%] [G loss: 2.277803]\n",
            "1371 [ D loss: 0.426073, acc.: 77%] [G loss: 3.498435]\n",
            "1372 [ D loss: 0.244767, acc.: 95%] [G loss: 2.765371]\n",
            "1373 [ D loss: 0.255942, acc.: 91%] [G loss: 4.048190]\n",
            "1374 [ D loss: 0.528992, acc.: 67%] [G loss: 2.641423]\n",
            "1375 [ D loss: 0.577959, acc.: 65%] [G loss: 1.803304]\n",
            "1376 [ D loss: 0.584652, acc.: 67%] [G loss: 2.285314]\n",
            "1377 [ D loss: 0.487887, acc.: 77%] [G loss: 2.518560]\n",
            "1378 [ D loss: 0.204622, acc.: 96%] [G loss: 4.917435]\n",
            "1379 [ D loss: 0.341757, acc.: 83%] [G loss: 3.406834]\n",
            "1380 [ D loss: 0.531402, acc.: 68%] [G loss: 2.338247]\n",
            "1381 [ D loss: 0.260909, acc.: 96%] [G loss: 3.167804]\n",
            "1382 [ D loss: 0.531014, acc.: 70%] [G loss: 2.697000]\n",
            "1383 [ D loss: 0.277264, acc.: 91%] [G loss: 3.119957]\n",
            "1384 [ D loss: 0.341741, acc.: 93%] [G loss: 2.804047]\n",
            "1385 [ D loss: 0.500951, acc.: 73%] [G loss: 2.894039]\n",
            "1386 [ D loss: 0.341534, acc.: 88%] [G loss: 3.118127]\n",
            "1387 [ D loss: 0.298387, acc.: 91%] [G loss: 3.071049]\n",
            "1388 [ D loss: 0.327481, acc.: 90%] [G loss: 2.933391]\n",
            "1389 [ D loss: 0.270114, acc.: 92%] [G loss: 3.798470]\n",
            "1390 [ D loss: 0.359004, acc.: 88%] [G loss: 2.456097]\n",
            "1391 [ D loss: 0.594720, acc.: 58%] [G loss: 2.151421]\n",
            "1392 [ D loss: 0.267866, acc.: 96%] [G loss: 3.585339]\n",
            "1393 [ D loss: 0.274428, acc.: 93%] [G loss: 3.241690]\n",
            "1394 [ D loss: 0.499671, acc.: 73%] [G loss: 3.501209]\n",
            "1395 [ D loss: 0.475145, acc.: 76%] [G loss: 2.945768]\n",
            "1396 [ D loss: 0.318120, acc.: 87%] [G loss: 4.209646]\n",
            "1397 [ D loss: 0.175031, acc.: 99%] [G loss: 3.437691]\n",
            "1398 [ D loss: 0.394602, acc.: 84%] [G loss: 3.001438]\n",
            "1399 [ D loss: 0.505045, acc.: 77%] [G loss: 2.763233]\n",
            "1400 [ D loss: 0.394358, acc.: 84%] [G loss: 4.182086]\n",
            "1401 [ D loss: 0.589828, acc.: 62%] [G loss: 2.571521]\n",
            "1402 [ D loss: 0.418528, acc.: 83%] [G loss: 2.277956]\n",
            "1403 [ D loss: 0.205141, acc.: 95%] [G loss: 4.813688]\n",
            "1404 [ D loss: 0.355018, acc.: 85%] [G loss: 2.679128]\n",
            "1405 [ D loss: 0.319715, acc.: 90%] [G loss: 3.876819]\n",
            "1406 [ D loss: 0.175950, acc.: 100%] [G loss: 3.334323]\n",
            "1407 [ D loss: 0.518663, acc.: 70%] [G loss: 2.683822]\n",
            "1408 [ D loss: 0.749121, acc.: 54%] [G loss: 1.897402]\n",
            "1409 [ D loss: 0.370433, acc.: 84%] [G loss: 3.142805]\n",
            "1410 [ D loss: 0.242329, acc.: 94%] [G loss: 5.400327]\n",
            "1411 [ D loss: 0.426726, acc.: 77%] [G loss: 4.504431]\n",
            "1412 [ D loss: 0.210088, acc.: 94%] [G loss: 3.728194]\n",
            "1413 [ D loss: 0.148917, acc.: 99%] [G loss: 5.444792]\n",
            "1414 [ D loss: 0.427950, acc.: 80%] [G loss: 2.032619]\n",
            "1415 [ D loss: 0.584173, acc.: 64%] [G loss: 1.913956]\n",
            "1416 [ D loss: 0.268363, acc.: 92%] [G loss: 3.338826]\n",
            "1417 [ D loss: 0.335373, acc.: 91%] [G loss: 3.274731]\n",
            "1418 [ D loss: 0.568388, acc.: 66%] [G loss: 2.162870]\n",
            "1419 [ D loss: 0.649373, acc.: 57%] [G loss: 1.854497]\n",
            "1420 [ D loss: 0.370193, acc.: 85%] [G loss: 4.288148]\n",
            "1421 [ D loss: 0.321856, acc.: 91%] [G loss: 2.756859]\n",
            "1422 [ D loss: 0.294131, acc.: 93%] [G loss: 3.256742]\n",
            "1423 [ D loss: 0.417295, acc.: 80%] [G loss: 2.023700]\n",
            "1424 [ D loss: 0.583694, acc.: 64%] [G loss: 2.013458]\n",
            "1425 [ D loss: 0.407512, acc.: 83%] [G loss: 2.678207]\n",
            "1426 [ D loss: 0.234238, acc.: 94%] [G loss: 4.889512]\n",
            "1427 [ D loss: 0.267037, acc.: 91%] [G loss: 3.918543]\n",
            "1428 [ D loss: 0.212021, acc.: 94%] [G loss: 4.888407]\n",
            "1429 [ D loss: 0.573492, acc.: 62%] [G loss: 2.154887]\n",
            "1430 [ D loss: 0.299532, acc.: 89%] [G loss: 4.196745]\n",
            "1431 [ D loss: 0.199494, acc.: 95%] [G loss: 4.490231]\n",
            "1432 [ D loss: 0.429604, acc.: 76%] [G loss: 3.367099]\n",
            "1433 [ D loss: 0.203762, acc.: 94%] [G loss: 6.983163]\n",
            "1434 [ D loss: 0.481660, acc.: 71%] [G loss: 2.464156]\n",
            "1435 [ D loss: 0.220986, acc.: 92%] [G loss: 4.133923]\n",
            "1436 [ D loss: 0.595841, acc.: 67%] [G loss: 2.027556]\n",
            "1437 [ D loss: 0.311018, acc.: 88%] [G loss: 3.663793]\n",
            "1438 [ D loss: 0.212059, acc.: 95%] [G loss: 5.631212]\n",
            "1439 [ D loss: 0.296568, acc.: 88%] [G loss: 4.719117]\n",
            "1440 [ D loss: 0.595437, acc.: 67%] [G loss: 3.275567]\n",
            "1441 [ D loss: 0.343214, acc.: 87%] [G loss: 3.481084]\n",
            "1442 [ D loss: 0.223663, acc.: 92%] [G loss: 5.057831]\n",
            "1443 [ D loss: 0.326655, acc.: 88%] [G loss: 2.815622]\n",
            "1444 [ D loss: 0.500764, acc.: 73%] [G loss: 1.992359]\n",
            "1445 [ D loss: 0.319780, acc.: 89%] [G loss: 4.291051]\n",
            "1446 [ D loss: 0.183157, acc.: 98%] [G loss: 4.475677]\n",
            "1447 [ D loss: 0.368754, acc.: 83%] [G loss: 3.365372]\n",
            "1448 [ D loss: 0.564251, acc.: 69%] [G loss: 3.054104]\n",
            "1449 [ D loss: 0.367132, acc.: 81%] [G loss: 2.856662]\n",
            "1450 [ D loss: 0.217948, acc.: 92%] [G loss: 3.607026]\n",
            "1451 [ D loss: 0.364966, acc.: 83%] [G loss: 4.022801]\n",
            "1452 [ D loss: 0.321642, acc.: 85%] [G loss: 3.779075]\n",
            "1453 [ D loss: 0.496241, acc.: 71%] [G loss: 3.078042]\n",
            "1454 [ D loss: 0.459157, acc.: 75%] [G loss: 2.856568]\n",
            "1455 [ D loss: 0.174981, acc.: 98%] [G loss: 4.189516]\n",
            "1456 [ D loss: 0.262111, acc.: 93%] [G loss: 3.312082]\n",
            "1457 [ D loss: 0.438811, acc.: 77%] [G loss: 2.886878]\n",
            "1458 [ D loss: 0.462779, acc.: 75%] [G loss: 3.394003]\n",
            "1459 [ D loss: 0.361391, acc.: 88%] [G loss: 2.710827]\n",
            "1460 [ D loss: 0.304958, acc.: 91%] [G loss: 4.084166]\n",
            "1461 [ D loss: 0.155672, acc.: 98%] [G loss: 7.143990]\n",
            "1462 [ D loss: 0.438333, acc.: 76%] [G loss: 2.203027]\n",
            "1463 [ D loss: 0.406605, acc.: 81%] [G loss: 3.184947]\n",
            "1464 [ D loss: 0.473134, acc.: 75%] [G loss: 3.085743]\n",
            "1465 [ D loss: 0.335509, acc.: 90%] [G loss: 2.244850]\n",
            "1466 [ D loss: 0.299699, acc.: 89%] [G loss: 3.589241]\n",
            "1467 [ D loss: 0.311049, acc.: 87%] [G loss: 3.483910]\n",
            "1468 [ D loss: 0.417901, acc.: 78%] [G loss: 2.451469]\n",
            "1469 [ D loss: 0.560387, acc.: 66%] [G loss: 3.016937]\n",
            "1470 [ D loss: 0.374952, acc.: 84%] [G loss: 3.394929]\n",
            "1471 [ D loss: 0.282689, acc.: 90%] [G loss: 4.682136]\n",
            "1472 [ D loss: 0.630179, acc.: 63%] [G loss: 2.049699]\n",
            "1473 [ D loss: 0.563145, acc.: 68%] [G loss: 1.969976]\n",
            "1474 [ D loss: 0.538303, acc.: 66%] [G loss: 1.909609]\n",
            "1475 [ D loss: 0.371540, acc.: 86%] [G loss: 3.644120]\n",
            "1476 [ D loss: 0.269256, acc.: 91%] [G loss: 4.415739]\n",
            "1477 [ D loss: 0.469514, acc.: 76%] [G loss: 2.099155]\n",
            "1478 [ D loss: 0.593121, acc.: 59%] [G loss: 2.465200]\n",
            "1479 [ D loss: 0.216204, acc.: 96%] [G loss: 4.652087]\n",
            "1480 [ D loss: 0.363384, acc.: 88%] [G loss: 2.819702]\n",
            "1481 [ D loss: 0.559423, acc.: 66%] [G loss: 2.889853]\n",
            "1482 [ D loss: 0.249068, acc.: 94%] [G loss: 2.449367]\n",
            "1483 [ D loss: 0.303669, acc.: 88%] [G loss: 3.214072]\n",
            "1484 [ D loss: 0.516393, acc.: 69%] [G loss: 4.116272]\n",
            "1485 [ D loss: 0.207261, acc.: 94%] [G loss: 4.487944]\n",
            "1486 [ D loss: 0.487172, acc.: 72%] [G loss: 2.810410]\n",
            "1487 [ D loss: 0.429853, acc.: 77%] [G loss: 3.192439]\n",
            "1488 [ D loss: 0.410777, acc.: 82%] [G loss: 3.216875]\n",
            "1489 [ D loss: 0.208790, acc.: 95%] [G loss: 4.991196]\n",
            "1490 [ D loss: 0.288773, acc.: 89%] [G loss: 2.907841]\n",
            "1491 [ D loss: 0.409011, acc.: 80%] [G loss: 2.552262]\n",
            "1492 [ D loss: 0.276166, acc.: 91%] [G loss: 3.121136]\n",
            "1493 [ D loss: 0.270437, acc.: 95%] [G loss: 2.102395]\n",
            "1494 [ D loss: 0.506302, acc.: 64%] [G loss: 2.153530]\n",
            "1495 [ D loss: 0.549780, acc.: 66%] [G loss: 1.894243]\n",
            "1496 [ D loss: 0.411851, acc.: 82%] [G loss: 3.024100]\n",
            "1497 [ D loss: 0.318246, acc.: 88%] [G loss: 2.984289]\n",
            "1498 [ D loss: 0.354199, acc.: 89%] [G loss: 3.439355]\n",
            "1499 [ D loss: 0.491806, acc.: 72%] [G loss: 3.719203]\n",
            "1500 [ D loss: 0.419604, acc.: 78%] [G loss: 6.643417]\n",
            "1501 [ D loss: 0.346305, acc.: 83%] [G loss: 5.284725]\n",
            "1502 [ D loss: 0.129202, acc.: 98%] [G loss: 4.360618]\n",
            "1503 [ D loss: 0.174081, acc.: 98%] [G loss: 2.977860]\n",
            "1504 [ D loss: 0.472041, acc.: 74%] [G loss: 2.574744]\n",
            "1505 [ D loss: 0.282289, acc.: 91%] [G loss: 4.970731]\n",
            "1506 [ D loss: 0.491515, acc.: 75%] [G loss: 3.997860]\n",
            "1507 [ D loss: 0.562754, acc.: 69%] [G loss: 3.265099]\n",
            "1508 [ D loss: 0.288211, acc.: 90%] [G loss: 5.106542]\n",
            "1509 [ D loss: 0.254981, acc.: 92%] [G loss: 6.070439]\n",
            "1510 [ D loss: 0.270277, acc.: 92%] [G loss: 5.044761]\n",
            "1511 [ D loss: 0.454073, acc.: 76%] [G loss: 3.053617]\n",
            "1512 [ D loss: 0.448959, acc.: 74%] [G loss: 2.802772]\n",
            "1513 [ D loss: 0.231882, acc.: 90%] [G loss: 4.631809]\n",
            "1514 [ D loss: 0.190663, acc.: 96%] [G loss: 4.684176]\n",
            "1515 [ D loss: 0.390947, acc.: 83%] [G loss: 2.544570]\n",
            "1516 [ D loss: 0.734926, acc.: 56%] [G loss: 1.878045]\n",
            "1517 [ D loss: 0.363832, acc.: 87%] [G loss: 2.611854]\n",
            "1518 [ D loss: 0.263251, acc.: 89%] [G loss: 6.840042]\n",
            "1519 [ D loss: 0.227121, acc.: 95%] [G loss: 3.239007]\n",
            "1520 [ D loss: 0.548438, acc.: 62%] [G loss: 1.497175]\n",
            "1521 [ D loss: 0.498185, acc.: 70%] [G loss: 2.238147]\n",
            "1522 [ D loss: 0.292632, acc.: 91%] [G loss: 3.060240]\n",
            "1523 [ D loss: 0.228742, acc.: 98%] [G loss: 4.429455]\n",
            "1524 [ D loss: 0.181194, acc.: 96%] [G loss: 4.476741]\n",
            "1525 [ D loss: 0.518162, acc.: 66%] [G loss: 3.196051]\n",
            "1526 [ D loss: 0.158103, acc.: 99%] [G loss: 3.902306]\n",
            "1527 [ D loss: 0.451251, acc.: 71%] [G loss: 2.684183]\n",
            "1528 [ D loss: 0.263364, acc.: 91%] [G loss: 5.177289]\n",
            "1529 [ D loss: 0.418463, acc.: 77%] [G loss: 3.755472]\n",
            "1530 [ D loss: 0.317751, acc.: 90%] [G loss: 2.854264]\n",
            "1531 [ D loss: 0.304348, acc.: 88%] [G loss: 5.139157]\n",
            "1532 [ D loss: 0.195478, acc.: 96%] [G loss: 5.198772]\n",
            "1533 [ D loss: 0.506079, acc.: 72%] [G loss: 1.843381]\n",
            "1534 [ D loss: 0.579358, acc.: 64%] [G loss: 2.392177]\n",
            "1535 [ D loss: 0.391177, acc.: 80%] [G loss: 1.877814]\n",
            "1536 [ D loss: 0.556851, acc.: 64%] [G loss: 1.658184]\n",
            "1537 [ D loss: 0.462522, acc.: 77%] [G loss: 2.217809]\n",
            "1538 [ D loss: 0.414724, acc.: 79%] [G loss: 2.752219]\n",
            "1539 [ D loss: 0.505890, acc.: 70%] [G loss: 1.948697]\n",
            "1540 [ D loss: 0.447330, acc.: 79%] [G loss: 3.043100]\n",
            "1541 [ D loss: 0.251393, acc.: 92%] [G loss: 4.679454]\n",
            "1542 [ D loss: 0.386590, acc.: 84%] [G loss: 2.395598]\n",
            "1543 [ D loss: 0.226428, acc.: 97%] [G loss: 2.835375]\n",
            "1544 [ D loss: 0.521288, acc.: 62%] [G loss: 2.297919]\n",
            "1545 [ D loss: 0.557304, acc.: 64%] [G loss: 3.200438]\n",
            "1546 [ D loss: 0.525939, acc.: 68%] [G loss: 2.547872]\n",
            "1547 [ D loss: 0.452437, acc.: 78%] [G loss: 3.099930]\n",
            "1548 [ D loss: 0.285406, acc.: 91%] [G loss: 6.244119]\n",
            "1549 [ D loss: 0.547540, acc.: 66%] [G loss: 2.805997]\n",
            "1550 [ D loss: 0.469597, acc.: 73%] [G loss: 5.164571]\n",
            "1551 [ D loss: 0.166751, acc.: 97%] [G loss: 8.443081]\n",
            "1552 [ D loss: 0.373451, acc.: 80%] [G loss: 6.703147]\n",
            "1553 [ D loss: 0.374173, acc.: 81%] [G loss: 5.193796]\n",
            "1554 [ D loss: 0.363541, acc.: 83%] [G loss: 2.929930]\n",
            "1555 [ D loss: 0.325939, acc.: 88%] [G loss: 3.911233]\n",
            "1556 [ D loss: 0.469404, acc.: 73%] [G loss: 2.695343]\n",
            "1557 [ D loss: 0.461156, acc.: 73%] [G loss: 2.391769]\n",
            "1558 [ D loss: 0.213972, acc.: 94%] [G loss: 4.216025]\n",
            "1559 [ D loss: 0.221367, acc.: 95%] [G loss: 3.013398]\n",
            "1560 [ D loss: 0.462091, acc.: 70%] [G loss: 2.853751]\n",
            "1561 [ D loss: 0.522124, acc.: 68%] [G loss: 1.762905]\n",
            "1562 [ D loss: 0.625313, acc.: 59%] [G loss: 2.043057]\n",
            "1563 [ D loss: 0.341632, acc.: 86%] [G loss: 4.086711]\n",
            "1564 [ D loss: 0.238513, acc.: 98%] [G loss: 2.737269]\n",
            "1565 [ D loss: 0.230055, acc.: 97%] [G loss: 4.119605]\n",
            "1566 [ D loss: 0.279976, acc.: 91%] [G loss: 4.473924]\n",
            "1567 [ D loss: 0.176957, acc.: 99%] [G loss: 2.682035]\n",
            "1568 [ D loss: 0.611084, acc.: 60%] [G loss: 3.010662]\n",
            "1569 [ D loss: 0.275757, acc.: 90%] [G loss: 2.886192]\n",
            "1570 [ D loss: 0.160203, acc.: 96%] [G loss: 4.631080]\n",
            "1571 [ D loss: 0.487122, acc.: 70%] [G loss: 2.061037]\n",
            "1572 [ D loss: 0.158567, acc.: 98%] [G loss: 3.992500]\n",
            "1573 [ D loss: 0.569382, acc.: 66%] [G loss: 2.194979]\n",
            "1574 [ D loss: 0.518769, acc.: 68%] [G loss: 1.950560]\n",
            "1575 [ D loss: 0.506923, acc.: 71%] [G loss: 2.612790]\n",
            "1576 [ D loss: 0.424888, acc.: 77%] [G loss: 3.470568]\n",
            "1577 [ D loss: 0.281374, acc.: 91%] [G loss: 3.674088]\n",
            "1578 [ D loss: 0.562035, acc.: 59%] [G loss: 2.020939]\n",
            "1579 [ D loss: 0.572117, acc.: 62%] [G loss: 2.182507]\n",
            "1580 [ D loss: 0.482938, acc.: 70%] [G loss: 2.628170]\n",
            "1581 [ D loss: 0.234874, acc.: 92%] [G loss: 6.934394]\n",
            "1582 [ D loss: 0.419941, acc.: 77%] [G loss: 3.853955]\n",
            "1583 [ D loss: 0.315058, acc.: 85%] [G loss: 4.063058]\n",
            "1584 [ D loss: 0.227921, acc.: 91%] [G loss: 4.197559]\n",
            "1585 [ D loss: 0.353080, acc.: 80%] [G loss: 4.310971]\n",
            "1586 [ D loss: 0.215702, acc.: 91%] [G loss: 4.435627]\n",
            "1587 [ D loss: 0.334238, acc.: 87%] [G loss: 4.072148]\n",
            "1588 [ D loss: 0.619365, acc.: 62%] [G loss: 1.191575]\n",
            "1589 [ D loss: 0.331491, acc.: 86%] [G loss: 4.027824]\n",
            "1590 [ D loss: 0.246158, acc.: 91%] [G loss: 6.504009]\n",
            "1591 [ D loss: 0.400512, acc.: 79%] [G loss: 2.626352]\n",
            "1592 [ D loss: 0.301407, acc.: 89%] [G loss: 4.073340]\n",
            "1593 [ D loss: 0.347086, acc.: 86%] [G loss: 4.466680]\n",
            "1594 [ D loss: 0.150356, acc.: 98%] [G loss: 5.405493]\n",
            "1595 [ D loss: 0.292347, acc.: 93%] [G loss: 3.139166]\n",
            "1596 [ D loss: 0.575825, acc.: 69%] [G loss: 2.058085]\n",
            "1597 [ D loss: 0.649278, acc.: 58%] [G loss: 2.020884]\n",
            "1598 [ D loss: 0.272068, acc.: 95%] [G loss: 2.852743]\n",
            "1599 [ D loss: 0.275174, acc.: 91%] [G loss: 3.675673]\n",
            "1600 [ D loss: 0.538794, acc.: 65%] [G loss: 2.006472]\n",
            "1601 [ D loss: 0.291274, acc.: 90%] [G loss: 2.202193]\n",
            "1602 [ D loss: 0.387125, acc.: 84%] [G loss: 3.356187]\n",
            "1603 [ D loss: 0.393881, acc.: 80%] [G loss: 3.629067]\n",
            "1604 [ D loss: 0.467976, acc.: 71%] [G loss: 2.399800]\n",
            "1605 [ D loss: 0.313230, acc.: 83%] [G loss: 2.457014]\n",
            "1606 [ D loss: 0.490177, acc.: 73%] [G loss: 3.271876]\n",
            "1607 [ D loss: 0.204664, acc.: 94%] [G loss: 3.710391]\n",
            "1608 [ D loss: 0.546877, acc.: 62%] [G loss: 2.418292]\n",
            "1609 [ D loss: 0.357444, acc.: 82%] [G loss: 2.954967]\n",
            "1610 [ D loss: 0.373490, acc.: 80%] [G loss: 3.479709]\n",
            "1611 [ D loss: 0.252395, acc.: 89%] [G loss: 2.645181]\n",
            "1612 [ D loss: 0.509938, acc.: 68%] [G loss: 2.246601]\n",
            "1613 [ D loss: 0.322505, acc.: 88%] [G loss: 3.736006]\n",
            "1614 [ D loss: 0.283351, acc.: 88%] [G loss: 4.314770]\n",
            "1615 [ D loss: 0.388575, acc.: 80%] [G loss: 4.629580]\n",
            "1616 [ D loss: 0.420707, acc.: 78%] [G loss: 3.646976]\n",
            "1617 [ D loss: 0.232010, acc.: 91%] [G loss: 3.498021]\n",
            "1618 [ D loss: 0.427163, acc.: 77%] [G loss: 3.361600]\n",
            "1619 [ D loss: 0.302976, acc.: 89%] [G loss: 2.940292]\n",
            "1620 [ D loss: 0.358774, acc.: 81%] [G loss: 3.990167]\n",
            "1621 [ D loss: 0.395524, acc.: 80%] [G loss: 2.771866]\n",
            "1622 [ D loss: 0.290339, acc.: 88%] [G loss: 4.291349]\n",
            "1623 [ D loss: 0.229490, acc.: 95%] [G loss: 4.381939]\n",
            "1624 [ D loss: 0.333767, acc.: 86%] [G loss: 2.947145]\n",
            "1625 [ D loss: 0.457595, acc.: 77%] [G loss: 2.107457]\n",
            "1626 [ D loss: 0.501543, acc.: 72%] [G loss: 2.426999]\n",
            "1627 [ D loss: 0.305034, acc.: 91%] [G loss: 3.319500]\n",
            "1628 [ D loss: 0.256431, acc.: 91%] [G loss: 6.332811]\n",
            "1629 [ D loss: 0.326299, acc.: 88%] [G loss: 2.659733]\n",
            "1630 [ D loss: 0.405610, acc.: 80%] [G loss: 3.491670]\n",
            "1631 [ D loss: 0.308796, acc.: 88%] [G loss: 3.726924]\n",
            "1632 [ D loss: 0.392467, acc.: 80%] [G loss: 4.857057]\n",
            "1633 [ D loss: 0.231320, acc.: 91%] [G loss: 6.505737]\n",
            "1634 [ D loss: 0.257700, acc.: 92%] [G loss: 3.874769]\n",
            "1635 [ D loss: 0.439423, acc.: 73%] [G loss: 2.977227]\n",
            "1636 [ D loss: 0.588353, acc.: 62%] [G loss: 2.165091]\n",
            "1637 [ D loss: 0.312460, acc.: 88%] [G loss: 4.524516]\n",
            "1638 [ D loss: 0.292923, acc.: 89%] [G loss: 4.189266]\n",
            "1639 [ D loss: 0.448169, acc.: 77%] [G loss: 2.576660]\n",
            "1640 [ D loss: 0.220595, acc.: 95%] [G loss: 2.764395]\n",
            "1641 [ D loss: 0.418480, acc.: 77%] [G loss: 2.609407]\n",
            "1642 [ D loss: 0.625621, acc.: 58%] [G loss: 2.098042]\n",
            "1643 [ D loss: 0.191709, acc.: 96%] [G loss: 3.473737]\n",
            "1644 [ D loss: 0.207815, acc.: 96%] [G loss: 2.533904]\n",
            "1645 [ D loss: 0.672874, acc.: 57%] [G loss: 2.007272]\n",
            "1646 [ D loss: 0.301147, acc.: 90%] [G loss: 4.418481]\n",
            "1647 [ D loss: 0.301926, acc.: 91%] [G loss: 2.514151]\n",
            "1648 [ D loss: 0.347913, acc.: 81%] [G loss: 3.470217]\n",
            "1649 [ D loss: 0.262256, acc.: 92%] [G loss: 3.542037]\n",
            "1650 [ D loss: 0.453770, acc.: 73%] [G loss: 3.043130]\n",
            "1651 [ D loss: 0.436160, acc.: 73%] [G loss: 2.548115]\n",
            "1652 [ D loss: 0.321421, acc.: 84%] [G loss: 2.187978]\n",
            "1653 [ D loss: 0.479900, acc.: 77%] [G loss: 3.572470]\n",
            "1654 [ D loss: 0.236045, acc.: 95%] [G loss: 2.295843]\n",
            "1655 [ D loss: 0.469997, acc.: 73%] [G loss: 3.710427]\n",
            "1656 [ D loss: 0.249422, acc.: 95%] [G loss: 5.069850]\n",
            "1657 [ D loss: 0.247969, acc.: 91%] [G loss: 5.973801]\n",
            "1658 [ D loss: 0.402006, acc.: 80%] [G loss: 2.171104]\n",
            "1659 [ D loss: 0.200403, acc.: 94%] [G loss: 3.381616]\n",
            "1660 [ D loss: 0.364767, acc.: 85%] [G loss: 3.791166]\n",
            "1661 [ D loss: 0.393199, acc.: 78%] [G loss: 3.777301]\n",
            "1662 [ D loss: 0.421773, acc.: 79%] [G loss: 4.169725]\n",
            "1663 [ D loss: 0.309189, acc.: 87%] [G loss: 3.428105]\n",
            "1664 [ D loss: 0.284282, acc.: 90%] [G loss: 2.636406]\n",
            "1665 [ D loss: 0.539517, acc.: 59%] [G loss: 2.305740]\n",
            "1666 [ D loss: 0.420859, acc.: 76%] [G loss: 2.260137]\n",
            "1667 [ D loss: 0.406851, acc.: 81%] [G loss: 3.171831]\n",
            "1668 [ D loss: 0.240314, acc.: 93%] [G loss: 5.694062]\n",
            "1669 [ D loss: 0.516894, acc.: 68%] [G loss: 2.000794]\n",
            "1670 [ D loss: 0.235733, acc.: 96%] [G loss: 3.731620]\n",
            "1671 [ D loss: 0.535210, acc.: 64%] [G loss: 1.769901]\n",
            "1672 [ D loss: 0.379976, acc.: 84%] [G loss: 4.087233]\n",
            "1673 [ D loss: 0.430519, acc.: 76%] [G loss: 2.583718]\n",
            "1674 [ D loss: 0.570433, acc.: 62%] [G loss: 2.682566]\n",
            "1675 [ D loss: 0.384938, acc.: 80%] [G loss: 3.257146]\n",
            "1676 [ D loss: 0.264036, acc.: 94%] [G loss: 3.062352]\n",
            "1677 [ D loss: 0.556399, acc.: 64%] [G loss: 1.814651]\n",
            "1678 [ D loss: 0.571457, acc.: 55%] [G loss: 2.169730]\n",
            "1679 [ D loss: 0.396266, acc.: 81%] [G loss: 2.762285]\n",
            "1680 [ D loss: 0.312945, acc.: 93%] [G loss: 2.556298]\n",
            "1681 [ D loss: 0.565832, acc.: 71%] [G loss: 2.488870]\n",
            "1682 [ D loss: 0.475732, acc.: 76%] [G loss: 1.794548]\n",
            "1683 [ D loss: 0.606933, acc.: 62%] [G loss: 2.388325]\n",
            "1684 [ D loss: 0.197514, acc.: 98%] [G loss: 3.747183]\n",
            "1685 [ D loss: 0.333316, acc.: 88%] [G loss: 3.175008]\n",
            "1686 [ D loss: 0.643964, acc.: 62%] [G loss: 3.236854]\n",
            "1687 [ D loss: 0.261759, acc.: 88%] [G loss: 4.300590]\n",
            "1688 [ D loss: 0.421396, acc.: 77%] [G loss: 2.445831]\n",
            "1689 [ D loss: 0.571722, acc.: 64%] [G loss: 2.418056]\n",
            "1690 [ D loss: 0.368037, acc.: 81%] [G loss: 4.089938]\n",
            "1691 [ D loss: 0.186475, acc.: 96%] [G loss: 3.929434]\n",
            "1692 [ D loss: 0.545460, acc.: 64%] [G loss: 3.060369]\n",
            "1693 [ D loss: 0.292416, acc.: 87%] [G loss: 5.807709]\n",
            "1694 [ D loss: 0.320063, acc.: 86%] [G loss: 4.510932]\n",
            "1695 [ D loss: 0.416457, acc.: 75%] [G loss: 1.863372]\n",
            "1696 [ D loss: 0.265320, acc.: 93%] [G loss: 3.075493]\n",
            "1697 [ D loss: 0.381962, acc.: 84%] [G loss: 2.899083]\n",
            "1698 [ D loss: 0.428025, acc.: 80%] [G loss: 3.397723]\n",
            "1699 [ D loss: 0.593291, acc.: 67%] [G loss: 3.860222]\n",
            "1700 [ D loss: 0.516329, acc.: 75%] [G loss: 3.567749]\n",
            "1701 [ D loss: 0.262774, acc.: 91%] [G loss: 6.204423]\n",
            "1702 [ D loss: 0.310890, acc.: 82%] [G loss: 2.689800]\n",
            "1703 [ D loss: 0.191692, acc.: 95%] [G loss: 4.417167]\n",
            "1704 [ D loss: 0.266951, acc.: 87%] [G loss: 3.658515]\n",
            "1705 [ D loss: 0.407282, acc.: 77%] [G loss: 1.841541]\n",
            "1706 [ D loss: 0.460803, acc.: 72%] [G loss: 2.513631]\n",
            "1707 [ D loss: 0.449272, acc.: 80%] [G loss: 4.699570]\n",
            "1708 [ D loss: 0.333287, acc.: 88%] [G loss: 4.119126]\n",
            "1709 [ D loss: 0.602496, acc.: 67%] [G loss: 2.715318]\n",
            "1710 [ D loss: 0.419691, acc.: 81%] [G loss: 3.527752]\n",
            "1711 [ D loss: 0.375460, acc.: 83%] [G loss: 4.708910]\n",
            "1712 [ D loss: 0.562199, acc.: 68%] [G loss: 2.117956]\n",
            "1713 [ D loss: 0.412078, acc.: 78%] [G loss: 1.891661]\n",
            "1714 [ D loss: 0.541242, acc.: 71%] [G loss: 2.510420]\n",
            "1715 [ D loss: 0.581112, acc.: 62%] [G loss: 1.771959]\n",
            "1716 [ D loss: 0.463634, acc.: 69%] [G loss: 4.017040]\n",
            "1717 [ D loss: 0.228172, acc.: 95%] [G loss: 6.700717]\n",
            "1718 [ D loss: 0.336807, acc.: 86%] [G loss: 2.657493]\n",
            "1719 [ D loss: 0.556412, acc.: 65%] [G loss: 1.961585]\n",
            "1720 [ D loss: 0.384988, acc.: 82%] [G loss: 2.832222]\n",
            "1721 [ D loss: 0.355297, acc.: 84%] [G loss: 2.569242]\n",
            "1722 [ D loss: 0.577057, acc.: 61%] [G loss: 2.236782]\n",
            "1723 [ D loss: 0.417075, acc.: 77%] [G loss: 2.837117]\n",
            "1724 [ D loss: 0.345153, acc.: 90%] [G loss: 2.973940]\n",
            "1725 [ D loss: 0.398296, acc.: 88%] [G loss: 2.410907]\n",
            "1726 [ D loss: 0.518714, acc.: 68%] [G loss: 2.871519]\n",
            "1727 [ D loss: 0.335889, acc.: 91%] [G loss: 3.036057]\n",
            "1728 [ D loss: 0.233956, acc.: 95%] [G loss: 4.335215]\n",
            "1729 [ D loss: 0.217733, acc.: 94%] [G loss: 3.268564]\n",
            "1730 [ D loss: 0.596970, acc.: 62%] [G loss: 1.694901]\n",
            "1731 [ D loss: 0.261925, acc.: 94%] [G loss: 3.208054]\n",
            "1732 [ D loss: 0.582688, acc.: 57%] [G loss: 2.134360]\n",
            "1733 [ D loss: 0.434318, acc.: 69%] [G loss: 2.559761]\n",
            "1734 [ D loss: 0.306233, acc.: 91%] [G loss: 3.493620]\n",
            "1735 [ D loss: 0.340654, acc.: 83%] [G loss: 3.660867]\n",
            "1736 [ D loss: 0.458475, acc.: 73%] [G loss: 3.188645]\n",
            "1737 [ D loss: 0.404816, acc.: 79%] [G loss: 3.183968]\n",
            "1738 [ D loss: 0.301933, acc.: 92%] [G loss: 4.320367]\n",
            "1739 [ D loss: 0.451221, acc.: 77%] [G loss: 4.473713]\n",
            "1740 [ D loss: 0.237334, acc.: 92%] [G loss: 4.137770]\n",
            "1741 [ D loss: 0.262163, acc.: 90%] [G loss: 4.475233]\n",
            "1742 [ D loss: 0.412337, acc.: 75%] [G loss: 3.127983]\n",
            "1743 [ D loss: 0.168172, acc.: 97%] [G loss: 7.412478]\n",
            "1744 [ D loss: 0.195672, acc.: 95%] [G loss: 2.777607]\n",
            "1745 [ D loss: 0.236694, acc.: 91%] [G loss: 5.009877]\n",
            "1746 [ D loss: 0.278112, acc.: 84%] [G loss: 3.916118]\n",
            "1747 [ D loss: 0.480819, acc.: 72%] [G loss: 2.188462]\n",
            "1748 [ D loss: 0.425987, acc.: 76%] [G loss: 2.916669]\n",
            "1749 [ D loss: 0.333204, acc.: 85%] [G loss: 6.138330]\n",
            "1750 [ D loss: 0.345368, acc.: 88%] [G loss: 1.874517]\n",
            "1751 [ D loss: 0.444683, acc.: 77%] [G loss: 2.339656]\n",
            "1752 [ D loss: 0.283791, acc.: 91%] [G loss: 4.318050]\n",
            "1753 [ D loss: 0.443881, acc.: 72%] [G loss: 1.921177]\n",
            "1754 [ D loss: 0.375474, acc.: 84%] [G loss: 1.970573]\n",
            "1755 [ D loss: 0.396379, acc.: 80%] [G loss: 3.203575]\n",
            "1756 [ D loss: 0.205562, acc.: 93%] [G loss: 5.076513]\n",
            "1757 [ D loss: 0.548857, acc.: 67%] [G loss: 1.658723]\n",
            "1758 [ D loss: 0.371523, acc.: 88%] [G loss: 2.659796]\n",
            "1759 [ D loss: 0.323078, acc.: 87%] [G loss: 4.328634]\n",
            "1760 [ D loss: 0.461512, acc.: 74%] [G loss: 2.503460]\n",
            "1761 [ D loss: 0.458592, acc.: 75%] [G loss: 2.167991]\n",
            "1762 [ D loss: 0.323642, acc.: 89%] [G loss: 2.219799]\n",
            "1763 [ D loss: 0.501641, acc.: 65%] [G loss: 2.575464]\n",
            "1764 [ D loss: 0.292983, acc.: 86%] [G loss: 3.628922]\n",
            "1765 [ D loss: 0.411763, acc.: 75%] [G loss: 2.556326]\n",
            "1766 [ D loss: 0.240353, acc.: 91%] [G loss: 4.083051]\n",
            "1767 [ D loss: 0.278639, acc.: 90%] [G loss: 4.430589]\n",
            "1768 [ D loss: 0.272340, acc.: 91%] [G loss: 3.745743]\n",
            "1769 [ D loss: 0.283525, acc.: 89%] [G loss: 3.409543]\n",
            "1770 [ D loss: 0.419423, acc.: 72%] [G loss: 2.328704]\n",
            "1771 [ D loss: 0.292608, acc.: 90%] [G loss: 2.430582]\n",
            "1772 [ D loss: 0.464614, acc.: 69%] [G loss: 1.937383]\n",
            "1773 [ D loss: 0.446097, acc.: 76%] [G loss: 3.157967]\n",
            "1774 [ D loss: 0.678230, acc.: 52%] [G loss: 1.860796]\n",
            "1775 [ D loss: 0.189348, acc.: 98%] [G loss: 4.055087]\n",
            "1776 [ D loss: 0.238231, acc.: 95%] [G loss: 3.617781]\n",
            "1777 [ D loss: 0.457476, acc.: 70%] [G loss: 2.317414]\n",
            "1778 [ D loss: 0.537285, acc.: 64%] [G loss: 1.915900]\n",
            "1779 [ D loss: 0.284618, acc.: 93%] [G loss: 2.522684]\n",
            "1780 [ D loss: 0.213645, acc.: 95%] [G loss: 4.014009]\n",
            "1781 [ D loss: 0.533892, acc.: 65%] [G loss: 2.577292]\n",
            "1782 [ D loss: 0.317195, acc.: 88%] [G loss: 1.682174]\n",
            "1783 [ D loss: 0.437006, acc.: 74%] [G loss: 2.954726]\n",
            "1784 [ D loss: 0.291823, acc.: 88%] [G loss: 4.098056]\n",
            "1785 [ D loss: 0.391674, acc.: 77%] [G loss: 3.007918]\n",
            "1786 [ D loss: 0.431459, acc.: 73%] [G loss: 1.990391]\n",
            "1787 [ D loss: 0.266048, acc.: 93%] [G loss: 3.347855]\n",
            "1788 [ D loss: 0.390628, acc.: 77%] [G loss: 1.669721]\n",
            "1789 [ D loss: 0.224657, acc.: 95%] [G loss: 3.653616]\n",
            "1790 [ D loss: 0.277537, acc.: 84%] [G loss: 3.688920]\n",
            "1791 [ D loss: 0.601097, acc.: 62%] [G loss: 1.506033]\n",
            "1792 [ D loss: 0.576746, acc.: 59%] [G loss: 1.829319]\n",
            "1793 [ D loss: 0.563705, acc.: 59%] [G loss: 1.731180]\n",
            "1794 [ D loss: 0.420297, acc.: 90%] [G loss: 2.364212]\n",
            "1795 [ D loss: 0.486070, acc.: 79%] [G loss: 3.163515]\n",
            "1796 [ D loss: 0.421658, acc.: 81%] [G loss: 3.064093]\n",
            "1797 [ D loss: 0.383779, acc.: 84%] [G loss: 1.958998]\n",
            "1798 [ D loss: 0.356804, acc.: 85%] [G loss: 2.925122]\n",
            "1799 [ D loss: 0.346866, acc.: 84%] [G loss: 3.092934]\n",
            "1800 [ D loss: 0.446156, acc.: 73%] [G loss: 3.256670]\n",
            "1801 [ D loss: 0.416966, acc.: 77%] [G loss: 1.824294]\n",
            "1802 [ D loss: 0.388578, acc.: 87%] [G loss: 3.673886]\n",
            "1803 [ D loss: 0.273635, acc.: 91%] [G loss: 3.916397]\n",
            "1804 [ D loss: 0.144769, acc.: 97%] [G loss: 4.669610]\n",
            "1805 [ D loss: 0.429344, acc.: 77%] [G loss: 3.212075]\n",
            "1806 [ D loss: 0.194566, acc.: 95%] [G loss: 6.124421]\n",
            "1807 [ D loss: 0.569655, acc.: 65%] [G loss: 1.881086]\n",
            "1808 [ D loss: 0.247350, acc.: 92%] [G loss: 6.830677]\n",
            "1809 [ D loss: 0.540026, acc.: 68%] [G loss: 1.842038]\n",
            "1810 [ D loss: 0.657822, acc.: 65%] [G loss: 2.768252]\n",
            "1811 [ D loss: 0.374836, acc.: 84%] [G loss: 2.116173]\n",
            "1812 [ D loss: 0.525248, acc.: 68%] [G loss: 2.560914]\n",
            "1813 [ D loss: 0.463534, acc.: 77%] [G loss: 2.264603]\n",
            "1814 [ D loss: 0.461635, acc.: 79%] [G loss: 1.865567]\n",
            "1815 [ D loss: 0.546435, acc.: 67%] [G loss: 2.440203]\n",
            "1816 [ D loss: 0.332583, acc.: 84%] [G loss: 3.619684]\n",
            "1817 [ D loss: 0.213492, acc.: 98%] [G loss: 5.684076]\n",
            "1818 [ D loss: 0.415239, acc.: 79%] [G loss: 3.366307]\n",
            "1819 [ D loss: 0.206984, acc.: 95%] [G loss: 5.976358]\n",
            "1820 [ D loss: 0.395948, acc.: 79%] [G loss: 1.981194]\n",
            "1821 [ D loss: 0.367817, acc.: 86%] [G loss: 1.621714]\n",
            "1822 [ D loss: 0.345717, acc.: 81%] [G loss: 2.416054]\n",
            "1823 [ D loss: 0.426008, acc.: 79%] [G loss: 2.486572]\n",
            "1824 [ D loss: 0.303723, acc.: 88%] [G loss: 3.640152]\n",
            "1825 [ D loss: 0.430310, acc.: 76%] [G loss: 2.014797]\n",
            "1826 [ D loss: 0.486461, acc.: 70%] [G loss: 2.491111]\n",
            "1827 [ D loss: 0.306789, acc.: 88%] [G loss: 2.922787]\n",
            "1828 [ D loss: 0.463121, acc.: 72%] [G loss: 2.323750]\n",
            "1829 [ D loss: 0.534887, acc.: 62%] [G loss: 2.751887]\n",
            "1830 [ D loss: 0.446791, acc.: 73%] [G loss: 2.522252]\n",
            "1831 [ D loss: 0.261708, acc.: 92%] [G loss: 5.228976]\n",
            "1832 [ D loss: 0.452027, acc.: 72%] [G loss: 2.532818]\n",
            "1833 [ D loss: 0.336342, acc.: 88%] [G loss: 2.949324]\n",
            "1834 [ D loss: 0.434444, acc.: 77%] [G loss: 2.078769]\n",
            "1835 [ D loss: 0.375120, acc.: 84%] [G loss: 2.717067]\n",
            "1836 [ D loss: 0.436807, acc.: 79%] [G loss: 2.402560]\n",
            "1837 [ D loss: 0.352618, acc.: 86%] [G loss: 4.580509]\n",
            "1838 [ D loss: 0.358351, acc.: 84%] [G loss: 3.634511]\n",
            "1839 [ D loss: 0.327151, acc.: 84%] [G loss: 3.390424]\n",
            "1840 [ D loss: 0.551875, acc.: 62%] [G loss: 3.025548]\n",
            "1841 [ D loss: 0.373646, acc.: 82%] [G loss: 2.603725]\n",
            "1842 [ D loss: 0.276611, acc.: 90%] [G loss: 5.417234]\n",
            "1843 [ D loss: 0.394753, acc.: 83%] [G loss: 2.879619]\n",
            "1844 [ D loss: 0.311782, acc.: 90%] [G loss: 3.590744]\n",
            "1845 [ D loss: 0.243877, acc.: 93%] [G loss: 4.056872]\n",
            "1846 [ D loss: 0.484105, acc.: 70%] [G loss: 1.865061]\n",
            "1847 [ D loss: 0.406509, acc.: 81%] [G loss: 2.557909]\n",
            "1848 [ D loss: 0.455374, acc.: 75%] [G loss: 1.859251]\n",
            "1849 [ D loss: 0.422749, acc.: 83%] [G loss: 2.215825]\n",
            "1850 [ D loss: 0.500972, acc.: 69%] [G loss: 1.871032]\n",
            "1851 [ D loss: 0.405233, acc.: 82%] [G loss: 3.113307]\n",
            "1852 [ D loss: 0.199547, acc.: 95%] [G loss: 4.479335]\n",
            "1853 [ D loss: 0.472766, acc.: 77%] [G loss: 1.802756]\n",
            "1854 [ D loss: 0.479757, acc.: 77%] [G loss: 1.553608]\n",
            "1855 [ D loss: 0.617278, acc.: 57%] [G loss: 1.345110]\n",
            "1856 [ D loss: 0.353357, acc.: 84%] [G loss: 3.238057]\n",
            "1857 [ D loss: 0.312430, acc.: 90%] [G loss: 4.035345]\n",
            "1858 [ D loss: 0.378606, acc.: 82%] [G loss: 3.614905]\n",
            "1859 [ D loss: 0.289499, acc.: 87%] [G loss: 5.340216]\n",
            "1860 [ D loss: 0.394481, acc.: 75%] [G loss: 3.711889]\n",
            "1861 [ D loss: 0.394598, acc.: 82%] [G loss: 5.297543]\n",
            "1862 [ D loss: 0.280887, acc.: 88%] [G loss: 5.237769]\n",
            "1863 [ D loss: 0.537409, acc.: 69%] [G loss: 2.313220]\n",
            "1864 [ D loss: 0.710216, acc.: 55%] [G loss: 2.263726]\n",
            "1865 [ D loss: 0.216185, acc.: 97%] [G loss: 5.200297]\n",
            "1866 [ D loss: 0.348503, acc.: 83%] [G loss: 4.435178]\n",
            "1867 [ D loss: 0.283400, acc.: 88%] [G loss: 6.423762]\n",
            "1868 [ D loss: 0.218029, acc.: 95%] [G loss: 7.776745]\n",
            "1869 [ D loss: 0.373111, acc.: 82%] [G loss: 6.803237]\n",
            "1870 [ D loss: 0.280034, acc.: 94%] [G loss: 3.431682]\n",
            "1871 [ D loss: 0.344809, acc.: 86%] [G loss: 4.282351]\n",
            "1872 [ D loss: 0.351261, acc.: 81%] [G loss: 3.175467]\n",
            "1873 [ D loss: 0.408864, acc.: 78%] [G loss: 2.615429]\n",
            "1874 [ D loss: 0.365308, acc.: 87%] [G loss: 3.516220]\n",
            "1875 [ D loss: 0.325689, acc.: 84%] [G loss: 4.945304]\n",
            "1876 [ D loss: 0.485354, acc.: 71%] [G loss: 2.035321]\n",
            "1877 [ D loss: 0.244140, acc.: 91%] [G loss: 3.802068]\n",
            "1878 [ D loss: 0.368738, acc.: 84%] [G loss: 6.663767]\n",
            "1879 [ D loss: 0.332012, acc.: 84%] [G loss: 3.216439]\n",
            "1880 [ D loss: 0.182720, acc.: 95%] [G loss: 9.628325]\n",
            "1881 [ D loss: 0.346774, acc.: 84%] [G loss: 3.162468]\n",
            "1882 [ D loss: 0.398285, acc.: 80%] [G loss: 2.469277]\n",
            "1883 [ D loss: 0.454381, acc.: 71%] [G loss: 2.409214]\n",
            "1884 [ D loss: 0.442179, acc.: 74%] [G loss: 1.591197]\n",
            "1885 [ D loss: 0.237791, acc.: 93%] [G loss: 3.035113]\n",
            "1886 [ D loss: 0.324577, acc.: 92%] [G loss: 3.598451]\n",
            "1887 [ D loss: 0.450022, acc.: 77%] [G loss: 2.733964]\n",
            "1888 [ D loss: 0.381701, acc.: 88%] [G loss: 2.544422]\n",
            "1889 [ D loss: 0.342292, acc.: 88%] [G loss: 2.293925]\n",
            "1890 [ D loss: 0.454551, acc.: 71%] [G loss: 2.196560]\n",
            "1891 [ D loss: 0.259708, acc.: 91%] [G loss: 5.963555]\n",
            "1892 [ D loss: 0.520987, acc.: 77%] [G loss: 1.603545]\n",
            "1893 [ D loss: 0.382085, acc.: 84%] [G loss: 2.235250]\n",
            "1894 [ D loss: 0.475072, acc.: 73%] [G loss: 2.656971]\n",
            "1895 [ D loss: 0.587253, acc.: 61%] [G loss: 2.007651]\n",
            "1896 [ D loss: 0.356641, acc.: 86%] [G loss: 3.271463]\n",
            "1897 [ D loss: 0.222607, acc.: 94%] [G loss: 4.113894]\n",
            "1898 [ D loss: 0.384054, acc.: 80%] [G loss: 4.833276]\n",
            "1899 [ D loss: 0.245051, acc.: 94%] [G loss: 3.815191]\n",
            "1900 [ D loss: 0.316990, acc.: 89%] [G loss: 3.905973]\n",
            "1901 [ D loss: 0.157594, acc.: 97%] [G loss: 6.081189]\n",
            "1902 [ D loss: 0.222872, acc.: 93%] [G loss: 2.993243]\n",
            "1903 [ D loss: 0.185054, acc.: 94%] [G loss: 3.589477]\n",
            "1904 [ D loss: 0.390116, acc.: 77%] [G loss: 1.937495]\n",
            "1905 [ D loss: 0.267757, acc.: 91%] [G loss: 4.841783]\n",
            "1906 [ D loss: 0.278718, acc.: 84%] [G loss: 3.931046]\n",
            "1907 [ D loss: 0.419754, acc.: 76%] [G loss: 2.058113]\n",
            "1908 [ D loss: 0.514075, acc.: 70%] [G loss: 1.971235]\n",
            "1909 [ D loss: 0.513128, acc.: 71%] [G loss: 2.200036]\n",
            "1910 [ D loss: 0.309972, acc.: 91%] [G loss: 3.746472]\n",
            "1911 [ D loss: 0.376860, acc.: 82%] [G loss: 2.799157]\n",
            "1912 [ D loss: 0.452654, acc.: 75%] [G loss: 2.797950]\n",
            "1913 [ D loss: 0.308177, acc.: 90%] [G loss: 2.260707]\n",
            "1914 [ D loss: 0.267284, acc.: 89%] [G loss: 5.070071]\n",
            "1915 [ D loss: 0.315862, acc.: 88%] [G loss: 3.572536]\n",
            "1916 [ D loss: 0.466015, acc.: 77%] [G loss: 2.018381]\n",
            "1917 [ D loss: 0.372849, acc.: 85%] [G loss: 3.807201]\n",
            "1918 [ D loss: 0.287233, acc.: 87%] [G loss: 2.398313]\n",
            "1919 [ D loss: 0.400978, acc.: 76%] [G loss: 3.385500]\n",
            "1920 [ D loss: 0.275553, acc.: 91%] [G loss: 5.090312]\n",
            "1921 [ D loss: 0.502104, acc.: 74%] [G loss: 3.330530]\n",
            "1922 [ D loss: 0.410383, acc.: 74%] [G loss: 3.083196]\n",
            "1923 [ D loss: 0.228016, acc.: 92%] [G loss: 4.864307]\n",
            "1924 [ D loss: 0.523493, acc.: 64%] [G loss: 2.154715]\n",
            "1925 [ D loss: 0.381845, acc.: 83%] [G loss: 1.671386]\n",
            "1926 [ D loss: 0.317486, acc.: 95%] [G loss: 4.385361]\n",
            "1927 [ D loss: 0.347065, acc.: 85%] [G loss: 3.443715]\n",
            "1928 [ D loss: 0.322476, acc.: 88%] [G loss: 3.232754]\n",
            "1929 [ D loss: 0.313378, acc.: 86%] [G loss: 3.456107]\n",
            "1930 [ D loss: 0.441705, acc.: 73%] [G loss: 2.749826]\n",
            "1931 [ D loss: 0.311047, acc.: 93%] [G loss: 3.326979]\n",
            "1932 [ D loss: 0.306582, acc.: 87%] [G loss: 2.830879]\n",
            "1933 [ D loss: 0.424251, acc.: 75%] [G loss: 2.744516]\n",
            "1934 [ D loss: 0.443256, acc.: 72%] [G loss: 2.067719]\n",
            "1935 [ D loss: 0.461297, acc.: 79%] [G loss: 4.371327]\n",
            "1936 [ D loss: 0.313641, acc.: 88%] [G loss: 6.620775]\n",
            "1937 [ D loss: 0.343394, acc.: 85%] [G loss: 3.550605]\n",
            "1938 [ D loss: 0.286507, acc.: 88%] [G loss: 7.325788]\n",
            "1939 [ D loss: 0.204642, acc.: 95%] [G loss: 4.639692]\n",
            "1940 [ D loss: 0.271996, acc.: 89%] [G loss: 3.180063]\n",
            "1941 [ D loss: 0.258508, acc.: 89%] [G loss: 3.297672]\n",
            "1942 [ D loss: 0.272611, acc.: 87%] [G loss: 3.192626]\n",
            "1943 [ D loss: 0.425281, acc.: 80%] [G loss: 2.303107]\n",
            "1944 [ D loss: 0.244705, acc.: 93%] [G loss: 3.408769]\n",
            "1945 [ D loss: 0.404914, acc.: 77%] [G loss: 2.675133]\n",
            "1946 [ D loss: 0.170757, acc.: 97%] [G loss: 4.559106]\n",
            "1947 [ D loss: 0.398516, acc.: 78%] [G loss: 2.288949]\n",
            "1948 [ D loss: 0.417582, acc.: 77%] [G loss: 2.440973]\n",
            "1949 [ D loss: 0.423631, acc.: 81%] [G loss: 2.300489]\n",
            "1950 [ D loss: 0.569080, acc.: 66%] [G loss: 1.744146]\n",
            "1951 [ D loss: 0.658457, acc.: 55%] [G loss: 2.067907]\n",
            "1952 [ D loss: 0.345456, acc.: 88%] [G loss: 2.871562]\n",
            "1953 [ D loss: 0.325842, acc.: 88%] [G loss: 5.374285]\n",
            "1954 [ D loss: 0.292347, acc.: 91%] [G loss: 4.163141]\n",
            "1955 [ D loss: 0.384429, acc.: 80%] [G loss: 2.734865]\n",
            "1956 [ D loss: 0.257448, acc.: 87%] [G loss: 3.223461]\n",
            "1957 [ D loss: 0.456369, acc.: 75%] [G loss: 1.951816]\n",
            "1958 [ D loss: 0.523856, acc.: 64%] [G loss: 2.330471]\n",
            "1959 [ D loss: 0.289212, acc.: 91%] [G loss: 3.889161]\n",
            "1960 [ D loss: 0.512856, acc.: 70%] [G loss: 2.333988]\n",
            "1961 [ D loss: 0.547776, acc.: 65%] [G loss: 2.007770]\n",
            "1962 [ D loss: 0.395915, acc.: 88%] [G loss: 2.462370]\n",
            "1963 [ D loss: 0.349609, acc.: 88%] [G loss: 4.279405]\n",
            "1964 [ D loss: 0.512780, acc.: 69%] [G loss: 3.027565]\n",
            "1965 [ D loss: 0.345565, acc.: 84%] [G loss: 3.206394]\n",
            "1966 [ D loss: 0.276002, acc.: 92%] [G loss: 3.529394]\n",
            "1967 [ D loss: 0.370090, acc.: 80%] [G loss: 4.411703]\n",
            "1968 [ D loss: 0.211233, acc.: 94%] [G loss: 6.327319]\n",
            "1969 [ D loss: 0.500584, acc.: 70%] [G loss: 2.297718]\n",
            "1970 [ D loss: 0.318374, acc.: 85%] [G loss: 3.498104]\n",
            "1971 [ D loss: 0.300239, acc.: 87%] [G loss: 3.283755]\n",
            "1972 [ D loss: 0.215450, acc.: 95%] [G loss: 3.183000]\n",
            "1973 [ D loss: 0.454537, acc.: 69%] [G loss: 2.129414]\n",
            "1974 [ D loss: 0.337297, acc.: 87%] [G loss: 3.543527]\n",
            "1975 [ D loss: 0.382504, acc.: 82%] [G loss: 2.611067]\n",
            "1976 [ D loss: 0.422416, acc.: 85%] [G loss: 4.774885]\n",
            "1977 [ D loss: 0.591307, acc.: 60%] [G loss: 2.781748]\n",
            "1978 [ D loss: 0.464652, acc.: 72%] [G loss: 4.660731]\n",
            "1979 [ D loss: 0.443082, acc.: 77%] [G loss: 3.810046]\n",
            "1980 [ D loss: 0.531766, acc.: 73%] [G loss: 5.443150]\n",
            "1981 [ D loss: 0.630379, acc.: 67%] [G loss: 1.651078]\n",
            "1982 [ D loss: 0.323010, acc.: 84%] [G loss: 3.044508]\n",
            "1983 [ D loss: 0.405672, acc.: 81%] [G loss: 2.988676]\n",
            "1984 [ D loss: 0.427091, acc.: 78%] [G loss: 2.497754]\n",
            "1985 [ D loss: 0.224946, acc.: 95%] [G loss: 4.271922]\n",
            "1986 [ D loss: 0.290639, acc.: 89%] [G loss: 5.332012]\n",
            "1987 [ D loss: 0.167721, acc.: 96%] [G loss: 3.149015]\n",
            "1988 [ D loss: 0.272428, acc.: 88%] [G loss: 8.717808]\n",
            "1989 [ D loss: 0.317641, acc.: 88%] [G loss: 6.648213]\n",
            "1990 [ D loss: 0.410626, acc.: 79%] [G loss: 4.231730]\n",
            "1991 [ D loss: 0.257772, acc.: 91%] [G loss: 3.630923]\n",
            "1992 [ D loss: 0.390653, acc.: 85%] [G loss: 4.109498]\n",
            "1993 [ D loss: 0.293037, acc.: 92%] [G loss: 4.477479]\n",
            "1994 [ D loss: 0.377846, acc.: 81%] [G loss: 5.736480]\n",
            "1995 [ D loss: 0.335585, acc.: 84%] [G loss: 3.320430]\n",
            "1996 [ D loss: 0.501952, acc.: 71%] [G loss: 3.040513]\n",
            "1997 [ D loss: 0.600770, acc.: 64%] [G loss: 3.191343]\n",
            "1998 [ D loss: 0.273154, acc.: 91%] [G loss: 5.783144]\n",
            "1999 [ D loss: 0.249444, acc.: 91%] [G loss: 5.002981]\n",
            "2000 [ D loss: 0.399557, acc.: 76%] [G loss: 3.085198]\n",
            "2001 [ D loss: 0.256155, acc.: 93%] [G loss: 3.296234]\n",
            "2002 [ D loss: 0.456304, acc.: 78%] [G loss: 2.841868]\n",
            "2003 [ D loss: 0.550930, acc.: 66%] [G loss: 1.651228]\n",
            "2004 [ D loss: 0.444322, acc.: 80%] [G loss: 2.877375]\n",
            "2005 [ D loss: 0.499995, acc.: 78%] [G loss: 4.390018]\n",
            "2006 [ D loss: 0.524858, acc.: 70%] [G loss: 6.427182]\n",
            "2007 [ D loss: 0.240335, acc.: 92%] [G loss: 5.063998]\n",
            "2008 [ D loss: 0.492473, acc.: 66%] [G loss: 2.487559]\n",
            "2009 [ D loss: 0.468649, acc.: 73%] [G loss: 2.271125]\n",
            "2010 [ D loss: 0.404089, acc.: 82%] [G loss: 2.627527]\n",
            "2011 [ D loss: 0.391553, acc.: 86%] [G loss: 3.261441]\n",
            "2012 [ D loss: 0.431487, acc.: 73%] [G loss: 8.399313]\n",
            "2013 [ D loss: 0.269863, acc.: 88%] [G loss: 3.780200]\n",
            "2014 [ D loss: 0.131351, acc.: 97%] [G loss: 5.739390]\n",
            "2015 [ D loss: 0.276207, acc.: 88%] [G loss: 4.012371]\n",
            "2016 [ D loss: 0.269959, acc.: 88%] [G loss: 3.885284]\n",
            "2017 [ D loss: 0.270441, acc.: 88%] [G loss: 4.739817]\n",
            "2018 [ D loss: 0.326055, acc.: 80%] [G loss: 3.282793]\n",
            "2019 [ D loss: 0.393071, acc.: 77%] [G loss: 4.096524]\n",
            "2020 [ D loss: 0.294554, acc.: 91%] [G loss: 3.735836]\n",
            "2021 [ D loss: 0.275630, acc.: 90%] [G loss: 3.857807]\n",
            "2022 [ D loss: 0.395476, acc.: 79%] [G loss: 4.837439]\n",
            "2023 [ D loss: 0.165260, acc.: 97%] [G loss: 5.170863]\n",
            "2024 [ D loss: 0.553033, acc.: 70%] [G loss: 3.093477]\n",
            "2025 [ D loss: 0.525939, acc.: 67%] [G loss: 2.258608]\n",
            "2026 [ D loss: 0.310837, acc.: 90%] [G loss: 2.796581]\n",
            "2027 [ D loss: 0.383317, acc.: 86%] [G loss: 2.231292]\n",
            "2028 [ D loss: 0.425935, acc.: 82%] [G loss: 3.301810]\n",
            "2029 [ D loss: 0.534599, acc.: 69%] [G loss: 5.004232]\n",
            "2030 [ D loss: 0.303628, acc.: 89%] [G loss: 4.054161]\n",
            "2031 [ D loss: 0.479180, acc.: 70%] [G loss: 2.524165]\n",
            "2032 [ D loss: 0.295777, acc.: 89%] [G loss: 6.385529]\n",
            "2033 [ D loss: 0.412699, acc.: 78%] [G loss: 3.523253]\n",
            "2034 [ D loss: 0.254702, acc.: 90%] [G loss: 7.859823]\n",
            "2035 [ D loss: 0.285106, acc.: 90%] [G loss: 2.879345]\n",
            "2036 [ D loss: 0.558803, acc.: 66%] [G loss: 2.069977]\n",
            "2037 [ D loss: 0.380181, acc.: 80%] [G loss: 3.860942]\n",
            "2038 [ D loss: 0.494310, acc.: 64%] [G loss: 3.004863]\n",
            "2039 [ D loss: 0.291715, acc.: 90%] [G loss: 4.412269]\n",
            "2040 [ D loss: 0.250329, acc.: 93%] [G loss: 7.937532]\n",
            "2041 [ D loss: 0.253871, acc.: 91%] [G loss: 5.928692]\n",
            "2042 [ D loss: 0.255235, acc.: 88%] [G loss: 5.735768]\n",
            "2043 [ D loss: 0.180712, acc.: 93%] [G loss: 11.573639]\n",
            "2044 [ D loss: 0.222508, acc.: 88%] [G loss: 11.363853]\n",
            "2045 [ D loss: 0.169637, acc.: 93%] [G loss: 8.188689]\n",
            "2046 [ D loss: 0.214541, acc.: 93%] [G loss: 3.248204]\n",
            "2047 [ D loss: 0.222212, acc.: 92%] [G loss: 4.735748]\n",
            "2048 [ D loss: 0.288081, acc.: 88%] [G loss: 2.578706]\n",
            "2049 [ D loss: 0.202701, acc.: 96%] [G loss: 5.102396]\n",
            "2050 [ D loss: 0.184797, acc.: 95%] [G loss: 3.363708]\n",
            "2051 [ D loss: 0.281097, acc.: 89%] [G loss: 4.301424]\n",
            "2052 [ D loss: 0.192061, acc.: 94%] [G loss: 7.265761]\n",
            "2053 [ D loss: 0.233216, acc.: 90%] [G loss: 6.930410]\n",
            "2054 [ D loss: 0.112327, acc.: 98%] [G loss: 7.828353]\n",
            "2055 [ D loss: 0.394822, acc.: 79%] [G loss: 3.269029]\n",
            "2056 [ D loss: 0.206174, acc.: 94%] [G loss: 8.844735]\n",
            "2057 [ D loss: 0.243583, acc.: 91%] [G loss: 8.719526]\n",
            "2058 [ D loss: 0.261982, acc.: 89%] [G loss: 5.697042]\n",
            "2059 [ D loss: 0.284068, acc.: 88%] [G loss: 5.161520]\n",
            "2060 [ D loss: 0.201205, acc.: 96%] [G loss: 3.967876]\n",
            "2061 [ D loss: 0.463557, acc.: 68%] [G loss: 1.856166]\n",
            "2062 [ D loss: 0.408321, acc.: 78%] [G loss: 4.066514]\n",
            "2063 [ D loss: 0.307342, acc.: 89%] [G loss: 4.285887]\n",
            "2064 [ D loss: 0.239358, acc.: 96%] [G loss: 4.287985]\n",
            "2065 [ D loss: 0.258600, acc.: 91%] [G loss: 5.977655]\n",
            "2066 [ D loss: 0.243016, acc.: 91%] [G loss: 4.852291]\n",
            "2067 [ D loss: 0.215734, acc.: 89%] [G loss: 5.361022]\n",
            "2068 [ D loss: 0.402612, acc.: 79%] [G loss: 3.638618]\n",
            "2069 [ D loss: 0.226425, acc.: 91%] [G loss: 5.646074]\n",
            "2070 [ D loss: 0.200700, acc.: 95%] [G loss: 7.684722]\n",
            "2071 [ D loss: 0.338136, acc.: 84%] [G loss: 4.475592]\n",
            "2072 [ D loss: 0.248994, acc.: 91%] [G loss: 4.362434]\n",
            "2073 [ D loss: 0.239922, acc.: 88%] [G loss: 5.994895]\n",
            "2074 [ D loss: 0.384334, acc.: 82%] [G loss: 3.607275]\n",
            "2075 [ D loss: 0.377764, acc.: 84%] [G loss: 2.909696]\n",
            "2076 [ D loss: 0.418768, acc.: 83%] [G loss: 2.657228]\n",
            "2077 [ D loss: 0.438006, acc.: 79%] [G loss: 2.676593]\n",
            "2078 [ D loss: 0.564214, acc.: 69%] [G loss: 1.992661]\n",
            "2079 [ D loss: 0.429004, acc.: 90%] [G loss: 2.572329]\n",
            "2080 [ D loss: 0.381917, acc.: 87%] [G loss: 4.927569]\n",
            "2081 [ D loss: 0.275660, acc.: 90%] [G loss: 7.259376]\n",
            "2082 [ D loss: 0.354482, acc.: 80%] [G loss: 3.017612]\n",
            "2083 [ D loss: 0.216260, acc.: 94%] [G loss: 6.778254]\n",
            "2084 [ D loss: 0.332220, acc.: 87%] [G loss: 2.711529]\n",
            "2085 [ D loss: 0.308373, acc.: 89%] [G loss: 2.280653]\n",
            "2086 [ D loss: 0.396482, acc.: 80%] [G loss: 2.794523]\n",
            "2087 [ D loss: 0.250220, acc.: 92%] [G loss: 3.531400]\n",
            "2088 [ D loss: 0.271650, acc.: 91%] [G loss: 3.466642]\n",
            "2089 [ D loss: 0.393409, acc.: 84%] [G loss: 2.357708]\n",
            "2090 [ D loss: 0.341320, acc.: 86%] [G loss: 4.955445]\n",
            "2091 [ D loss: 0.467345, acc.: 77%] [G loss: 2.708549]\n",
            "2092 [ D loss: 0.316528, acc.: 91%] [G loss: 2.318305]\n",
            "2093 [ D loss: 0.343129, acc.: 83%] [G loss: 3.753335]\n",
            "2094 [ D loss: 0.218958, acc.: 93%] [G loss: 5.540967]\n",
            "2095 [ D loss: 0.294487, acc.: 91%] [G loss: 2.938174]\n",
            "2096 [ D loss: 0.492773, acc.: 74%] [G loss: 3.223046]\n",
            "2097 [ D loss: 0.210795, acc.: 96%] [G loss: 4.156089]\n",
            "2098 [ D loss: 0.284007, acc.: 88%] [G loss: 3.949505]\n",
            "2099 [ D loss: 0.360974, acc.: 80%] [G loss: 9.781528]\n",
            "2100 [ D loss: 0.372051, acc.: 85%] [G loss: 2.987038]\n",
            "2101 [ D loss: 0.399447, acc.: 81%] [G loss: 2.771434]\n",
            "2102 [ D loss: 0.410811, acc.: 84%] [G loss: 2.467571]\n",
            "2103 [ D loss: 0.405957, acc.: 84%] [G loss: 3.606280]\n",
            "2104 [ D loss: 0.272953, acc.: 91%] [G loss: 4.983694]\n",
            "2105 [ D loss: 0.431114, acc.: 74%] [G loss: 2.147224]\n",
            "2106 [ D loss: 0.396574, acc.: 88%] [G loss: 2.287712]\n",
            "2107 [ D loss: 0.489489, acc.: 73%] [G loss: 2.797659]\n",
            "2108 [ D loss: 0.428258, acc.: 80%] [G loss: 2.515675]\n",
            "2109 [ D loss: 0.458196, acc.: 84%] [G loss: 2.526191]\n",
            "2110 [ D loss: 0.455978, acc.: 88%] [G loss: 3.452704]\n",
            "2111 [ D loss: 0.418151, acc.: 81%] [G loss: 5.410522]\n",
            "2112 [ D loss: 0.358810, acc.: 84%] [G loss: 4.827059]\n",
            "2113 [ D loss: 0.551760, acc.: 66%] [G loss: 2.014054]\n",
            "2114 [ D loss: 0.434314, acc.: 74%] [G loss: 2.358970]\n",
            "2115 [ D loss: 0.543371, acc.: 73%] [G loss: 4.242370]\n",
            "2116 [ D loss: 0.356717, acc.: 84%] [G loss: 5.346582]\n",
            "2117 [ D loss: 0.310180, acc.: 82%] [G loss: 4.739512]\n",
            "2118 [ D loss: 0.257289, acc.: 91%] [G loss: 3.720254]\n",
            "2119 [ D loss: 0.490200, acc.: 66%] [G loss: 4.546212]\n",
            "2120 [ D loss: 0.244305, acc.: 91%] [G loss: 3.890978]\n",
            "2121 [ D loss: 0.370666, acc.: 86%] [G loss: 3.112440]\n",
            "2122 [ D loss: 0.274578, acc.: 95%] [G loss: 5.674538]\n",
            "2123 [ D loss: 0.315778, acc.: 83%] [G loss: 3.211477]\n",
            "2124 [ D loss: 0.556307, acc.: 70%] [G loss: 3.742369]\n",
            "2125 [ D loss: 0.296247, acc.: 90%] [G loss: 4.083954]\n",
            "2126 [ D loss: 0.255473, acc.: 93%] [G loss: 2.947293]\n",
            "2127 [ D loss: 0.402906, acc.: 80%] [G loss: 3.418459]\n",
            "2128 [ D loss: 0.283623, acc.: 88%] [G loss: 2.854754]\n",
            "2129 [ D loss: 0.351036, acc.: 87%] [G loss: 10.561602]\n",
            "2130 [ D loss: 0.532954, acc.: 66%] [G loss: 2.899438]\n",
            "2131 [ D loss: 0.229009, acc.: 94%] [G loss: 4.597608]\n",
            "2132 [ D loss: 0.593933, acc.: 66%] [G loss: 2.554180]\n",
            "2133 [ D loss: 0.345084, acc.: 90%] [G loss: 3.697832]\n",
            "2134 [ D loss: 0.388099, acc.: 84%] [G loss: 3.897549]\n",
            "2135 [ D loss: 0.323134, acc.: 90%] [G loss: 4.190100]\n",
            "2136 [ D loss: 0.356586, acc.: 85%] [G loss: 3.980444]\n",
            "2137 [ D loss: 0.317804, acc.: 84%] [G loss: 3.051795]\n",
            "2138 [ D loss: 0.371153, acc.: 82%] [G loss: 4.294978]\n",
            "2139 [ D loss: 0.284545, acc.: 95%] [G loss: 3.276336]\n",
            "2140 [ D loss: 0.393226, acc.: 87%] [G loss: 4.299345]\n",
            "2141 [ D loss: 0.195579, acc.: 95%] [G loss: 3.517038]\n",
            "2142 [ D loss: 0.342555, acc.: 84%] [G loss: 3.301111]\n",
            "2143 [ D loss: 0.216856, acc.: 93%] [G loss: 3.892435]\n",
            "2144 [ D loss: 0.141801, acc.: 98%] [G loss: 6.170539]\n",
            "2145 [ D loss: 0.224067, acc.: 88%] [G loss: 4.749844]\n",
            "2146 [ D loss: 0.292865, acc.: 86%] [G loss: 3.105622]\n",
            "2147 [ D loss: 0.307745, acc.: 83%] [G loss: 4.050745]\n",
            "2148 [ D loss: 0.162781, acc.: 95%] [G loss: 6.582940]\n",
            "2149 [ D loss: 0.408783, acc.: 74%] [G loss: 2.839039]\n",
            "2150 [ D loss: 0.318624, acc.: 87%] [G loss: 3.066973]\n",
            "2151 [ D loss: 0.352618, acc.: 91%] [G loss: 2.793550]\n",
            "2152 [ D loss: 0.423947, acc.: 88%] [G loss: 2.745013]\n",
            "2153 [ D loss: 0.304053, acc.: 88%] [G loss: 4.074206]\n",
            "2154 [ D loss: 0.292231, acc.: 91%] [G loss: 2.386328]\n",
            "2155 [ D loss: 0.331858, acc.: 88%] [G loss: 2.815596]\n",
            "2156 [ D loss: 0.273095, acc.: 94%] [G loss: 3.834305]\n",
            "2157 [ D loss: 0.434338, acc.: 80%] [G loss: 2.749577]\n",
            "2158 [ D loss: 0.317770, acc.: 91%] [G loss: 2.016922]\n",
            "2159 [ D loss: 0.260743, acc.: 96%] [G loss: 3.723370]\n",
            "2160 [ D loss: 0.277566, acc.: 92%] [G loss: 3.894495]\n",
            "2161 [ D loss: 0.352363, acc.: 87%] [G loss: 2.903991]\n",
            "2162 [ D loss: 0.284942, acc.: 95%] [G loss: 6.642267]\n",
            "2163 [ D loss: 0.274836, acc.: 94%] [G loss: 3.754154]\n",
            "2164 [ D loss: 0.422035, acc.: 84%] [G loss: 3.518060]\n",
            "2165 [ D loss: 0.270488, acc.: 93%] [G loss: 2.901451]\n",
            "2166 [ D loss: 0.247931, acc.: 97%] [G loss: 3.117591]\n",
            "2167 [ D loss: 0.189508, acc.: 95%] [G loss: 4.146235]\n",
            "2168 [ D loss: 0.229193, acc.: 92%] [G loss: 2.984455]\n",
            "2169 [ D loss: 0.387540, acc.: 82%] [G loss: 3.598224]\n",
            "2170 [ D loss: 0.157179, acc.: 95%] [G loss: 4.917592]\n",
            "2171 [ D loss: 0.273704, acc.: 88%] [G loss: 4.066562]\n",
            "2172 [ D loss: 0.120235, acc.: 98%] [G loss: 7.096421]\n",
            "2173 [ D loss: 0.277806, acc.: 88%] [G loss: 3.971145]\n",
            "2174 [ D loss: 0.170519, acc.: 97%] [G loss: 3.255731]\n",
            "2175 [ D loss: 0.184735, acc.: 92%] [G loss: 7.601356]\n",
            "2176 [ D loss: 0.461253, acc.: 77%] [G loss: 4.489639]\n",
            "2177 [ D loss: 0.358554, acc.: 82%] [G loss: 3.215830]\n",
            "2178 [ D loss: 0.333806, acc.: 88%] [G loss: 1.731342]\n",
            "2179 [ D loss: 0.318909, acc.: 85%] [G loss: 6.431133]\n",
            "2180 [ D loss: 0.292725, acc.: 88%] [G loss: 3.463507]\n",
            "2181 [ D loss: 0.450436, acc.: 73%] [G loss: 2.199118]\n",
            "2182 [ D loss: 0.309132, acc.: 89%] [G loss: 3.008171]\n",
            "2183 [ D loss: 0.391737, acc.: 82%] [G loss: 4.629907]\n",
            "2184 [ D loss: 0.493265, acc.: 70%] [G loss: 1.668785]\n",
            "2185 [ D loss: 0.427937, acc.: 79%] [G loss: 2.695689]\n",
            "2186 [ D loss: 0.569290, acc.: 70%] [G loss: 4.007444]\n",
            "2187 [ D loss: 0.557375, acc.: 70%] [G loss: 4.890858]\n",
            "2188 [ D loss: 0.423192, acc.: 75%] [G loss: 3.563068]\n",
            "2189 [ D loss: 0.269415, acc.: 91%] [G loss: 5.214638]\n",
            "2190 [ D loss: 0.239715, acc.: 89%] [G loss: 7.049385]\n",
            "2191 [ D loss: 0.279006, acc.: 89%] [G loss: 6.326820]\n",
            "2192 [ D loss: 0.404216, acc.: 80%] [G loss: 4.346126]\n",
            "2193 [ D loss: 0.204763, acc.: 93%] [G loss: 4.687692]\n",
            "2194 [ D loss: 0.392425, acc.: 76%] [G loss: 3.194449]\n",
            "2195 [ D loss: 0.207789, acc.: 94%] [G loss: 4.504323]\n",
            "2196 [ D loss: 0.213687, acc.: 97%] [G loss: 4.762608]\n",
            "2197 [ D loss: 0.205689, acc.: 92%] [G loss: 7.260907]\n",
            "2198 [ D loss: 0.417247, acc.: 79%] [G loss: 4.760571]\n",
            "2199 [ D loss: 0.348191, acc.: 87%] [G loss: 3.125608]\n",
            "2200 [ D loss: 0.339353, acc.: 87%] [G loss: 6.018815]\n",
            "2201 [ D loss: 0.292024, acc.: 88%] [G loss: 3.937586]\n",
            "2202 [ D loss: 0.452266, acc.: 82%] [G loss: 3.073151]\n",
            "2203 [ D loss: 0.370320, acc.: 80%] [G loss: 2.894804]\n",
            "2204 [ D loss: 0.576811, acc.: 70%] [G loss: 2.778771]\n",
            "2205 [ D loss: 0.469703, acc.: 80%] [G loss: 2.686355]\n",
            "2206 [ D loss: 0.285394, acc.: 92%] [G loss: 3.062801]\n",
            "2207 [ D loss: 0.398790, acc.: 82%] [G loss: 3.198325]\n",
            "2208 [ D loss: 0.316351, acc.: 86%] [G loss: 5.616258]\n",
            "2209 [ D loss: 0.286185, acc.: 88%] [G loss: 4.096640]\n",
            "2210 [ D loss: 0.309254, acc.: 88%] [G loss: 4.798496]\n",
            "2211 [ D loss: 0.304517, acc.: 88%] [G loss: 3.980408]\n",
            "2212 [ D loss: 0.314602, acc.: 85%] [G loss: 4.816185]\n",
            "2213 [ D loss: 0.158803, acc.: 96%] [G loss: 9.381594]\n",
            "2214 [ D loss: 0.417730, acc.: 80%] [G loss: 5.361369]\n",
            "2215 [ D loss: 0.127868, acc.: 95%] [G loss: 8.436602]\n",
            "2216 [ D loss: 0.204088, acc.: 94%] [G loss: 2.819047]\n",
            "2217 [ D loss: 0.388888, acc.: 78%] [G loss: 3.428570]\n",
            "2218 [ D loss: 0.283756, acc.: 91%] [G loss: 5.865842]\n",
            "2219 [ D loss: 0.268274, acc.: 87%] [G loss: 4.599108]\n",
            "2220 [ D loss: 0.262392, acc.: 91%] [G loss: 2.553838]\n",
            "2221 [ D loss: 0.335482, acc.: 86%] [G loss: 6.061018]\n",
            "2222 [ D loss: 0.227666, acc.: 94%] [G loss: 4.697202]\n",
            "2223 [ D loss: 0.380673, acc.: 79%] [G loss: 2.726871]\n",
            "2224 [ D loss: 0.242947, acc.: 95%] [G loss: 6.072093]\n",
            "2225 [ D loss: 0.343610, acc.: 84%] [G loss: 3.319116]\n",
            "2226 [ D loss: 0.308398, acc.: 94%] [G loss: 2.694979]\n",
            "2227 [ D loss: 0.305700, acc.: 90%] [G loss: 3.095957]\n",
            "2228 [ D loss: 0.388438, acc.: 83%] [G loss: 2.839730]\n",
            "2229 [ D loss: 0.255172, acc.: 92%] [G loss: 5.076308]\n",
            "2230 [ D loss: 0.205920, acc.: 96%] [G loss: 4.759337]\n",
            "2231 [ D loss: 0.272291, acc.: 88%] [G loss: 2.993861]\n",
            "2232 [ D loss: 0.365637, acc.: 85%] [G loss: 3.046125]\n",
            "2233 [ D loss: 0.369723, acc.: 85%] [G loss: 3.769985]\n",
            "2234 [ D loss: 0.173581, acc.: 97%] [G loss: 4.167942]\n",
            "2235 [ D loss: 0.169634, acc.: 95%] [G loss: 3.510149]\n",
            "2236 [ D loss: 0.271740, acc.: 87%] [G loss: 3.620137]\n",
            "2237 [ D loss: 0.419924, acc.: 76%] [G loss: 3.075069]\n",
            "2238 [ D loss: 0.144112, acc.: 99%] [G loss: 3.166511]\n",
            "2239 [ D loss: 0.354422, acc.: 83%] [G loss: 5.752906]\n",
            "2240 [ D loss: 0.335665, acc.: 84%] [G loss: 4.713448]\n",
            "2241 [ D loss: 0.376315, acc.: 80%] [G loss: 3.167255]\n",
            "2242 [ D loss: 0.297750, acc.: 91%] [G loss: 4.851933]\n",
            "2243 [ D loss: 0.363805, acc.: 84%] [G loss: 2.425328]\n",
            "2244 [ D loss: 0.513302, acc.: 71%] [G loss: 2.060009]\n",
            "2245 [ D loss: 0.368956, acc.: 85%] [G loss: 3.152718]\n",
            "2246 [ D loss: 0.464776, acc.: 84%] [G loss: 3.344612]\n",
            "2247 [ D loss: 0.298055, acc.: 93%] [G loss: 2.410188]\n",
            "2248 [ D loss: 0.324484, acc.: 88%] [G loss: 2.466655]\n",
            "2249 [ D loss: 0.270228, acc.: 95%] [G loss: 4.549928]\n",
            "2250 [ D loss: 0.262526, acc.: 90%] [G loss: 5.533233]\n",
            "2251 [ D loss: 0.221975, acc.: 94%] [G loss: 7.422917]\n",
            "2252 [ D loss: 0.384344, acc.: 83%] [G loss: 3.382549]\n",
            "2253 [ D loss: 0.264862, acc.: 95%] [G loss: 3.839225]\n",
            "2254 [ D loss: 0.396136, acc.: 84%] [G loss: 4.012362]\n",
            "2255 [ D loss: 0.316481, acc.: 85%] [G loss: 3.513444]\n",
            "2256 [ D loss: 0.228441, acc.: 98%] [G loss: 6.019353]\n",
            "2257 [ D loss: 0.205446, acc.: 95%] [G loss: 4.725302]\n",
            "2258 [ D loss: 0.296901, acc.: 83%] [G loss: 4.708143]\n",
            "2259 [ D loss: 0.314330, acc.: 88%] [G loss: 5.083086]\n",
            "2260 [ D loss: 0.250531, acc.: 93%] [G loss: 5.328178]\n",
            "2261 [ D loss: 0.271276, acc.: 93%] [G loss: 2.927210]\n",
            "2262 [ D loss: 0.504645, acc.: 71%] [G loss: 2.078995]\n",
            "2263 [ D loss: 0.241311, acc.: 91%] [G loss: 2.940064]\n",
            "2264 [ D loss: 0.324573, acc.: 91%] [G loss: 2.871622]\n",
            "2265 [ D loss: 0.360059, acc.: 83%] [G loss: 2.754375]\n",
            "2266 [ D loss: 0.261975, acc.: 88%] [G loss: 5.010066]\n",
            "2267 [ D loss: 0.354684, acc.: 83%] [G loss: 4.867272]\n",
            "2268 [ D loss: 0.271173, acc.: 91%] [G loss: 5.072311]\n",
            "2269 [ D loss: 0.236037, acc.: 91%] [G loss: 5.335138]\n",
            "2270 [ D loss: 0.170699, acc.: 97%] [G loss: 5.986172]\n",
            "2271 [ D loss: 0.275289, acc.: 88%] [G loss: 3.534976]\n",
            "2272 [ D loss: 0.283940, acc.: 91%] [G loss: 6.733515]\n",
            "2273 [ D loss: 0.143774, acc.: 97%] [G loss: 4.264079]\n",
            "2274 [ D loss: 0.334086, acc.: 86%] [G loss: 3.766647]\n",
            "2275 [ D loss: 0.449989, acc.: 76%] [G loss: 2.989660]\n",
            "2276 [ D loss: 0.202903, acc.: 93%] [G loss: 5.352868]\n",
            "2277 [ D loss: 0.487831, acc.: 76%] [G loss: 2.986231]\n",
            "2278 [ D loss: 0.288507, acc.: 91%] [G loss: 8.445078]\n",
            "2279 [ D loss: 0.212441, acc.: 93%] [G loss: 5.173132]\n",
            "2280 [ D loss: 0.404891, acc.: 83%] [G loss: 2.868218]\n",
            "2281 [ D loss: 0.298040, acc.: 93%] [G loss: 2.728495]\n",
            "2282 [ D loss: 0.260429, acc.: 91%] [G loss: 1.883361]\n",
            "2283 [ D loss: 0.305716, acc.: 91%] [G loss: 2.696769]\n",
            "2284 [ D loss: 0.232490, acc.: 94%] [G loss: 4.399020]\n",
            "2285 [ D loss: 0.422866, acc.: 78%] [G loss: 2.333904]\n",
            "2286 [ D loss: 0.225028, acc.: 92%] [G loss: 3.848015]\n",
            "2287 [ D loss: 0.307045, acc.: 90%] [G loss: 3.201095]\n",
            "2288 [ D loss: 0.353028, acc.: 87%] [G loss: 3.108379]\n",
            "2289 [ D loss: 0.339202, acc.: 83%] [G loss: 2.072824]\n",
            "2290 [ D loss: 0.530496, acc.: 68%] [G loss: 2.776799]\n",
            "2291 [ D loss: 0.443466, acc.: 81%] [G loss: 3.451925]\n",
            "2292 [ D loss: 0.449668, acc.: 77%] [G loss: 2.787960]\n",
            "2293 [ D loss: 0.464014, acc.: 81%] [G loss: 2.913760]\n",
            "2294 [ D loss: 0.314413, acc.: 89%] [G loss: 4.450166]\n",
            "2295 [ D loss: 0.227556, acc.: 91%] [G loss: 6.714491]\n",
            "2296 [ D loss: 0.308511, acc.: 84%] [G loss: 6.359672]\n",
            "2297 [ D loss: 0.268792, acc.: 89%] [G loss: 6.736202]\n",
            "2298 [ D loss: 0.129105, acc.: 96%] [G loss: 10.014204]\n",
            "2299 [ D loss: 0.301591, acc.: 84%] [G loss: 5.424448]\n",
            "2300 [ D loss: 0.396553, acc.: 80%] [G loss: 4.868007]\n",
            "2301 [ D loss: 0.214226, acc.: 94%] [G loss: 8.830923]\n",
            "2302 [ D loss: 0.271831, acc.: 93%] [G loss: 4.346668]\n",
            "2303 [ D loss: 0.196594, acc.: 95%] [G loss: 8.034609]\n",
            "2304 [ D loss: 0.343823, acc.: 82%] [G loss: 3.662565]\n",
            "2305 [ D loss: 0.153714, acc.: 97%] [G loss: 4.973401]\n",
            "2306 [ D loss: 0.298224, acc.: 88%] [G loss: 4.110663]\n",
            "2307 [ D loss: 0.192563, acc.: 95%] [G loss: 6.626539]\n",
            "2308 [ D loss: 0.164385, acc.: 97%] [G loss: 4.610803]\n",
            "2309 [ D loss: 0.276666, acc.: 89%] [G loss: 5.127945]\n",
            "2310 [ D loss: 0.365203, acc.: 81%] [G loss: 2.428743]\n",
            "2311 [ D loss: 0.365231, acc.: 95%] [G loss: 3.039203]\n",
            "2312 [ D loss: 0.282255, acc.: 91%] [G loss: 4.592800]\n",
            "2313 [ D loss: 0.244231, acc.: 93%] [G loss: 3.378073]\n",
            "2314 [ D loss: 0.366239, acc.: 79%] [G loss: 3.061025]\n",
            "2315 [ D loss: 0.353975, acc.: 88%] [G loss: 3.823536]\n",
            "2316 [ D loss: 0.176441, acc.: 98%] [G loss: 2.601204]\n",
            "2317 [ D loss: 0.207418, acc.: 95%] [G loss: 4.656306]\n",
            "2318 [ D loss: 0.226781, acc.: 94%] [G loss: 7.792883]\n",
            "2319 [ D loss: 0.386241, acc.: 77%] [G loss: 4.003102]\n",
            "2320 [ D loss: 0.153464, acc.: 97%] [G loss: 5.518602]\n",
            "2321 [ D loss: 0.207359, acc.: 94%] [G loss: 5.190653]\n",
            "2322 [ D loss: 0.402423, acc.: 77%] [G loss: 3.476880]\n",
            "2323 [ D loss: 0.216136, acc.: 93%] [G loss: 5.313977]\n",
            "2324 [ D loss: 0.254832, acc.: 91%] [G loss: 4.434507]\n",
            "2325 [ D loss: 0.272092, acc.: 91%] [G loss: 4.330234]\n",
            "2326 [ D loss: 0.177221, acc.: 95%] [G loss: 4.209619]\n",
            "2327 [ D loss: 0.314603, acc.: 88%] [G loss: 4.157042]\n",
            "2328 [ D loss: 0.205665, acc.: 95%] [G loss: 5.261281]\n",
            "2329 [ D loss: 0.387726, acc.: 83%] [G loss: 2.726237]\n",
            "2330 [ D loss: 0.242118, acc.: 91%] [G loss: 5.898362]\n",
            "2331 [ D loss: 0.315930, acc.: 85%] [G loss: 4.069408]\n",
            "2332 [ D loss: 0.266814, acc.: 89%] [G loss: 3.517419]\n",
            "2333 [ D loss: 0.245351, acc.: 91%] [G loss: 3.018134]\n",
            "2334 [ D loss: 0.305251, acc.: 84%] [G loss: 3.580626]\n",
            "2335 [ D loss: 0.307835, acc.: 93%] [G loss: 3.436004]\n",
            "2336 [ D loss: 0.246964, acc.: 91%] [G loss: 8.147709]\n",
            "2337 [ D loss: 0.374660, acc.: 84%] [G loss: 2.700291]\n",
            "2338 [ D loss: 0.366118, acc.: 90%] [G loss: 2.922280]\n",
            "2339 [ D loss: 0.334048, acc.: 88%] [G loss: 3.835992]\n",
            "2340 [ D loss: 0.225767, acc.: 95%] [G loss: 3.935031]\n",
            "2341 [ D loss: 0.348741, acc.: 88%] [G loss: 2.993465]\n",
            "2342 [ D loss: 0.292018, acc.: 97%] [G loss: 4.167824]\n",
            "2343 [ D loss: 0.204828, acc.: 97%] [G loss: 6.429466]\n",
            "2344 [ D loss: 0.296581, acc.: 89%] [G loss: 6.484502]\n",
            "2345 [ D loss: 0.134841, acc.: 98%] [G loss: 7.714237]\n",
            "2346 [ D loss: 0.156340, acc.: 97%] [G loss: 8.213782]\n",
            "2347 [ D loss: 0.249403, acc.: 89%] [G loss: 8.732622]\n",
            "2348 [ D loss: 0.408744, acc.: 76%] [G loss: 4.352036]\n",
            "2349 [ D loss: 0.224437, acc.: 96%] [G loss: 8.849777]\n",
            "2350 [ D loss: 0.227388, acc.: 96%] [G loss: 4.164204]\n",
            "2351 [ D loss: 0.299745, acc.: 90%] [G loss: 3.982700]\n",
            "2352 [ D loss: 0.239076, acc.: 94%] [G loss: 2.955114]\n",
            "2353 [ D loss: 0.231459, acc.: 91%] [G loss: 4.392871]\n",
            "2354 [ D loss: 0.291865, acc.: 89%] [G loss: 3.985127]\n",
            "2355 [ D loss: 0.384675, acc.: 87%] [G loss: 3.231876]\n",
            "2356 [ D loss: 0.234833, acc.: 92%] [G loss: 4.456527]\n",
            "2357 [ D loss: 0.218645, acc.: 96%] [G loss: 2.930513]\n",
            "2358 [ D loss: 0.256499, acc.: 93%] [G loss: 4.780853]\n",
            "2359 [ D loss: 0.172642, acc.: 96%] [G loss: 3.591011]\n",
            "2360 [ D loss: 0.202566, acc.: 96%] [G loss: 5.761524]\n",
            "2361 [ D loss: 0.270906, acc.: 88%] [G loss: 3.183414]\n",
            "2362 [ D loss: 0.206374, acc.: 92%] [G loss: 6.568350]\n",
            "2363 [ D loss: 0.166893, acc.: 95%] [G loss: 8.532011]\n",
            "2364 [ D loss: 0.260694, acc.: 88%] [G loss: 4.792510]\n",
            "2365 [ D loss: 0.330638, acc.: 87%] [G loss: 3.377826]\n",
            "2366 [ D loss: 0.353841, acc.: 83%] [G loss: 3.545539]\n",
            "2367 [ D loss: 0.245246, acc.: 95%] [G loss: 5.014975]\n",
            "2368 [ D loss: 0.214577, acc.: 92%] [G loss: 6.211712]\n",
            "2369 [ D loss: 0.174730, acc.: 94%] [G loss: 7.848343]\n",
            "2370 [ D loss: 0.242060, acc.: 91%] [G loss: 4.064919]\n",
            "2371 [ D loss: 0.170484, acc.: 97%] [G loss: 6.383984]\n",
            "2372 [ D loss: 0.202272, acc.: 93%] [G loss: 5.533955]\n",
            "2373 [ D loss: 0.178091, acc.: 95%] [G loss: 6.099973]\n",
            "2374 [ D loss: 0.204561, acc.: 94%] [G loss: 4.020202]\n",
            "2375 [ D loss: 0.181345, acc.: 98%] [G loss: 4.049340]\n",
            "2376 [ D loss: 0.282613, acc.: 89%] [G loss: 4.117581]\n",
            "2377 [ D loss: 0.326499, acc.: 93%] [G loss: 3.625371]\n",
            "2378 [ D loss: 0.188876, acc.: 98%] [G loss: 6.092726]\n",
            "2379 [ D loss: 0.228759, acc.: 95%] [G loss: 5.137100]\n",
            "2380 [ D loss: 0.402774, acc.: 83%] [G loss: 3.202111]\n",
            "2381 [ D loss: 0.249037, acc.: 91%] [G loss: 4.116411]\n",
            "2382 [ D loss: 0.285692, acc.: 91%] [G loss: 3.794534]\n",
            "2383 [ D loss: 0.247834, acc.: 97%] [G loss: 3.356634]\n",
            "2384 [ D loss: 0.281316, acc.: 94%] [G loss: 2.993592]\n",
            "2385 [ D loss: 0.323548, acc.: 89%] [G loss: 3.757947]\n",
            "2386 [ D loss: 0.242261, acc.: 98%] [G loss: 3.348754]\n",
            "2387 [ D loss: 0.328573, acc.: 93%] [G loss: 3.201990]\n",
            "2388 [ D loss: 0.302177, acc.: 91%] [G loss: 2.958811]\n",
            "2389 [ D loss: 0.219890, acc.: 91%] [G loss: 7.102456]\n",
            "2390 [ D loss: 0.435675, acc.: 76%] [G loss: 2.889303]\n",
            "2391 [ D loss: 0.189152, acc.: 93%] [G loss: 5.941514]\n",
            "2392 [ D loss: 0.328813, acc.: 86%] [G loss: 3.288061]\n",
            "2393 [ D loss: 0.274783, acc.: 94%] [G loss: 2.537288]\n",
            "2394 [ D loss: 0.292581, acc.: 95%] [G loss: 3.664098]\n",
            "2395 [ D loss: 0.262463, acc.: 91%] [G loss: 4.360743]\n",
            "2396 [ D loss: 0.253845, acc.: 93%] [G loss: 4.876196]\n",
            "2397 [ D loss: 0.217619, acc.: 93%] [G loss: 7.713241]\n",
            "2398 [ D loss: 0.323869, acc.: 84%] [G loss: 3.183803]\n",
            "2399 [ D loss: 0.187303, acc.: 98%] [G loss: 3.824418]\n",
            "2400 [ D loss: 0.319273, acc.: 88%] [G loss: 3.913555]\n",
            "2401 [ D loss: 0.284735, acc.: 88%] [G loss: 4.288345]\n",
            "2402 [ D loss: 0.259934, acc.: 88%] [G loss: 3.366303]\n",
            "2403 [ D loss: 0.289540, acc.: 92%] [G loss: 3.450994]\n",
            "2404 [ D loss: 0.299575, acc.: 88%] [G loss: 6.469761]\n",
            "2405 [ D loss: 0.232787, acc.: 96%] [G loss: 5.607232]\n",
            "2406 [ D loss: 0.284799, acc.: 89%] [G loss: 5.121903]\n",
            "2407 [ D loss: 0.274093, acc.: 89%] [G loss: 7.794917]\n",
            "2408 [ D loss: 0.177438, acc.: 96%] [G loss: 8.250791]\n",
            "2409 [ D loss: 0.192301, acc.: 96%] [G loss: 7.247212]\n",
            "2410 [ D loss: 0.215921, acc.: 92%] [G loss: 7.382995]\n",
            "2411 [ D loss: 0.380692, acc.: 82%] [G loss: 3.324715]\n",
            "2412 [ D loss: 0.280534, acc.: 92%] [G loss: 3.864826]\n",
            "2413 [ D loss: 0.312891, acc.: 87%] [G loss: 4.397436]\n",
            "2414 [ D loss: 0.196080, acc.: 97%] [G loss: 8.602124]\n",
            "2415 [ D loss: 0.294187, acc.: 91%] [G loss: 4.154281]\n",
            "2416 [ D loss: 0.246276, acc.: 91%] [G loss: 4.173228]\n",
            "2417 [ D loss: 0.184067, acc.: 96%] [G loss: 3.752256]\n",
            "2418 [ D loss: 0.340013, acc.: 88%] [G loss: 3.631410]\n",
            "2419 [ D loss: 0.352792, acc.: 84%] [G loss: 3.867429]\n",
            "2420 [ D loss: 0.201808, acc.: 95%] [G loss: 4.968111]\n",
            "2421 [ D loss: 0.518615, acc.: 67%] [G loss: 2.726132]\n",
            "2422 [ D loss: 0.346213, acc.: 87%] [G loss: 3.541924]\n",
            "2423 [ D loss: 0.227932, acc.: 92%] [G loss: 3.554133]\n",
            "2424 [ D loss: 0.327271, acc.: 88%] [G loss: 2.851045]\n",
            "2425 [ D loss: 0.315129, acc.: 93%] [G loss: 2.785002]\n",
            "2426 [ D loss: 0.250496, acc.: 94%] [G loss: 3.776037]\n",
            "2427 [ D loss: 0.150438, acc.: 97%] [G loss: 3.422656]\n",
            "2428 [ D loss: 0.366655, acc.: 80%] [G loss: 2.912889]\n",
            "2429 [ D loss: 0.141200, acc.: 100%] [G loss: 5.389216]\n",
            "2430 [ D loss: 0.267000, acc.: 90%] [G loss: 3.906170]\n",
            "2431 [ D loss: 0.365218, acc.: 83%] [G loss: 3.579364]\n",
            "2432 [ D loss: 0.231997, acc.: 95%] [G loss: 2.168057]\n",
            "2433 [ D loss: 0.250785, acc.: 94%] [G loss: 3.255852]\n",
            "2434 [ D loss: 0.215040, acc.: 95%] [G loss: 3.079563]\n",
            "2435 [ D loss: 0.310849, acc.: 91%] [G loss: 4.548252]\n",
            "2436 [ D loss: 0.211532, acc.: 94%] [G loss: 4.357296]\n",
            "2437 [ D loss: 0.199745, acc.: 98%] [G loss: 5.338525]\n",
            "2438 [ D loss: 0.232962, acc.: 89%] [G loss: 4.922463]\n",
            "2439 [ D loss: 0.305357, acc.: 88%] [G loss: 3.168940]\n",
            "2440 [ D loss: 0.213048, acc.: 95%] [G loss: 2.899178]\n",
            "2441 [ D loss: 0.216036, acc.: 93%] [G loss: 3.847610]\n",
            "2442 [ D loss: 0.326378, acc.: 87%] [G loss: 3.561438]\n",
            "2443 [ D loss: 0.278855, acc.: 92%] [G loss: 5.570098]\n",
            "2444 [ D loss: 0.221863, acc.: 95%] [G loss: 6.677160]\n",
            "2445 [ D loss: 0.276019, acc.: 92%] [G loss: 5.037621]\n",
            "2446 [ D loss: 0.196005, acc.: 92%] [G loss: 5.066184]\n",
            "2447 [ D loss: 0.214076, acc.: 93%] [G loss: 4.487980]\n",
            "2448 [ D loss: 0.228952, acc.: 93%] [G loss: 4.877020]\n",
            "2449 [ D loss: 0.209467, acc.: 94%] [G loss: 6.370823]\n",
            "2450 [ D loss: 0.250151, acc.: 94%] [G loss: 2.592633]\n",
            "2451 [ D loss: 0.277197, acc.: 97%] [G loss: 3.157439]\n",
            "2452 [ D loss: 0.204038, acc.: 95%] [G loss: 6.571445]\n",
            "2453 [ D loss: 0.274497, acc.: 90%] [G loss: 2.306915]\n",
            "2454 [ D loss: 0.226004, acc.: 95%] [G loss: 5.357986]\n",
            "2455 [ D loss: 0.276965, acc.: 91%] [G loss: 3.211084]\n",
            "2456 [ D loss: 0.319795, acc.: 88%] [G loss: 2.326867]\n",
            "2457 [ D loss: 0.240240, acc.: 94%] [G loss: 3.380087]\n",
            "2458 [ D loss: 0.275477, acc.: 96%] [G loss: 1.942178]\n",
            "2459 [ D loss: 0.181961, acc.: 95%] [G loss: 2.927308]\n",
            "2460 [ D loss: 0.196960, acc.: 96%] [G loss: 4.247247]\n",
            "2461 [ D loss: 0.168488, acc.: 97%] [G loss: 7.234964]\n",
            "2462 [ D loss: 0.278621, acc.: 88%] [G loss: 3.570610]\n",
            "2463 [ D loss: 0.261912, acc.: 95%] [G loss: 3.710675]\n",
            "2464 [ D loss: 0.187547, acc.: 97%] [G loss: 5.049301]\n",
            "2465 [ D loss: 0.281792, acc.: 86%] [G loss: 4.776701]\n",
            "2466 [ D loss: 0.227908, acc.: 91%] [G loss: 4.228341]\n",
            "2467 [ D loss: 0.160759, acc.: 95%] [G loss: 8.477048]\n",
            "2468 [ D loss: 0.243806, acc.: 89%] [G loss: 5.401113]\n",
            "2469 [ D loss: 0.169334, acc.: 98%] [G loss: 7.780189]\n",
            "2470 [ D loss: 0.172325, acc.: 96%] [G loss: 3.885947]\n",
            "2471 [ D loss: 0.197440, acc.: 95%] [G loss: 3.634958]\n",
            "2472 [ D loss: 0.299406, acc.: 89%] [G loss: 3.462931]\n",
            "2473 [ D loss: 0.223231, acc.: 92%] [G loss: 5.506301]\n",
            "2474 [ D loss: 0.143527, acc.: 97%] [G loss: 6.990088]\n",
            "2475 [ D loss: 0.266267, acc.: 87%] [G loss: 5.428767]\n",
            "2476 [ D loss: 0.183540, acc.: 96%] [G loss: 4.320970]\n",
            "2477 [ D loss: 0.193928, acc.: 93%] [G loss: 7.166057]\n",
            "2478 [ D loss: 0.524580, acc.: 75%] [G loss: 2.434271]\n",
            "2479 [ D loss: 0.200302, acc.: 96%] [G loss: 3.883869]\n",
            "2480 [ D loss: 0.282985, acc.: 90%] [G loss: 4.476717]\n",
            "2481 [ D loss: 0.126130, acc.: 98%] [G loss: 6.297067]\n",
            "2482 [ D loss: 0.151469, acc.: 98%] [G loss: 5.116113]\n",
            "2483 [ D loss: 0.186359, acc.: 95%] [G loss: 5.629814]\n",
            "2484 [ D loss: 0.215758, acc.: 96%] [G loss: 3.623902]\n",
            "2485 [ D loss: 0.279069, acc.: 89%] [G loss: 4.909922]\n",
            "2486 [ D loss: 0.240569, acc.: 90%] [G loss: 4.249430]\n",
            "2487 [ D loss: 0.165375, acc.: 95%] [G loss: 3.781026]\n",
            "2488 [ D loss: 0.078359, acc.: 100%] [G loss: 8.853886]\n",
            "2489 [ D loss: 0.175029, acc.: 94%] [G loss: 4.353188]\n",
            "2490 [ D loss: 0.158193, acc.: 98%] [G loss: 7.460601]\n",
            "2491 [ D loss: 0.216308, acc.: 95%] [G loss: 3.745274]\n",
            "2492 [ D loss: 0.292671, acc.: 91%] [G loss: 3.398420]\n",
            "2493 [ D loss: 0.156745, acc.: 96%] [G loss: 4.764528]\n",
            "2494 [ D loss: 0.287819, acc.: 88%] [G loss: 2.772455]\n",
            "2495 [ D loss: 0.223357, acc.: 95%] [G loss: 5.589833]\n",
            "2496 [ D loss: 0.201229, acc.: 97%] [G loss: 2.755179]\n",
            "2497 [ D loss: 0.198400, acc.: 96%] [G loss: 5.004466]\n",
            "2498 [ D loss: 0.185453, acc.: 95%] [G loss: 2.563189]\n",
            "2499 [ D loss: 0.165145, acc.: 97%] [G loss: 5.142311]\n",
            "2500 [ D loss: 0.218419, acc.: 94%] [G loss: 3.419047]\n",
            "2501 [ D loss: 0.147244, acc.: 99%] [G loss: 3.814323]\n",
            "2502 [ D loss: 0.213122, acc.: 95%] [G loss: 3.783893]\n",
            "2503 [ D loss: 0.436748, acc.: 80%] [G loss: 3.248703]\n",
            "2504 [ D loss: 0.186080, acc.: 95%] [G loss: 4.521251]\n",
            "2505 [ D loss: 0.238002, acc.: 95%] [G loss: 4.502931]\n",
            "2506 [ D loss: 0.144099, acc.: 96%] [G loss: 5.745022]\n",
            "2507 [ D loss: 0.214195, acc.: 95%] [G loss: 7.078485]\n",
            "2508 [ D loss: 0.127212, acc.: 97%] [G loss: 3.764388]\n",
            "2509 [ D loss: 0.225436, acc.: 91%] [G loss: 9.221849]\n",
            "2510 [ D loss: 0.114290, acc.: 98%] [G loss: 7.898665]\n",
            "2511 [ D loss: 0.154665, acc.: 96%] [G loss: 3.117974]\n",
            "2512 [ D loss: 0.150304, acc.: 97%] [G loss: 4.672220]\n",
            "2513 [ D loss: 0.207876, acc.: 94%] [G loss: 11.122071]\n",
            "2514 [ D loss: 0.191812, acc.: 94%] [G loss: 6.083073]\n",
            "2515 [ D loss: 0.179298, acc.: 96%] [G loss: 5.070604]\n",
            "2516 [ D loss: 0.230348, acc.: 91%] [G loss: 4.756549]\n",
            "2517 [ D loss: 0.124681, acc.: 98%] [G loss: 9.295429]\n",
            "2518 [ D loss: 0.204924, acc.: 91%] [G loss: 5.971409]\n",
            "2519 [ D loss: 0.204734, acc.: 95%] [G loss: 4.232943]\n",
            "2520 [ D loss: 0.264065, acc.: 95%] [G loss: 4.318067]\n",
            "2521 [ D loss: 0.265170, acc.: 93%] [G loss: 4.789343]\n",
            "2522 [ D loss: 0.171856, acc.: 98%] [G loss: 6.719309]\n",
            "2523 [ D loss: 0.108501, acc.: 98%] [G loss: 7.812124]\n",
            "2524 [ D loss: 0.137184, acc.: 98%] [G loss: 6.187236]\n",
            "2525 [ D loss: 0.207063, acc.: 93%] [G loss: 4.658537]\n",
            "2526 [ D loss: 0.251076, acc.: 91%] [G loss: 4.558124]\n",
            "2527 [ D loss: 0.147657, acc.: 96%] [G loss: 5.590726]\n",
            "2528 [ D loss: 0.143360, acc.: 98%] [G loss: 2.666820]\n",
            "2529 [ D loss: 0.181049, acc.: 92%] [G loss: 3.856965]\n",
            "2530 [ D loss: 0.196797, acc.: 95%] [G loss: 3.641570]\n",
            "2531 [ D loss: 0.243884, acc.: 91%] [G loss: 3.279731]\n",
            "2532 [ D loss: 0.266737, acc.: 88%] [G loss: 3.928058]\n",
            "2533 [ D loss: 0.196836, acc.: 95%] [G loss: 4.813096]\n",
            "2534 [ D loss: 0.240885, acc.: 91%] [G loss: 3.122122]\n",
            "2535 [ D loss: 0.133086, acc.: 96%] [G loss: 4.787720]\n",
            "2536 [ D loss: 0.318229, acc.: 88%] [G loss: 2.503642]\n",
            "2537 [ D loss: 0.271669, acc.: 92%] [G loss: 3.984558]\n",
            "2538 [ D loss: 0.302719, acc.: 86%] [G loss: 5.623602]\n",
            "2539 [ D loss: 0.174359, acc.: 96%] [G loss: 3.798040]\n",
            "2540 [ D loss: 0.295120, acc.: 88%] [G loss: 3.654513]\n",
            "2541 [ D loss: 0.127364, acc.: 98%] [G loss: 4.275162]\n",
            "2542 [ D loss: 0.210650, acc.: 91%] [G loss: 3.643640]\n",
            "2543 [ D loss: 0.208269, acc.: 94%] [G loss: 3.441138]\n",
            "2544 [ D loss: 0.173791, acc.: 97%] [G loss: 4.601414]\n",
            "2545 [ D loss: 0.405147, acc.: 83%] [G loss: 3.314339]\n",
            "2546 [ D loss: 0.275540, acc.: 90%] [G loss: 3.111506]\n",
            "2547 [ D loss: 0.235117, acc.: 94%] [G loss: 2.787321]\n",
            "2548 [ D loss: 0.307674, acc.: 88%] [G loss: 3.731583]\n",
            "2549 [ D loss: 0.258476, acc.: 92%] [G loss: 2.416371]\n",
            "2550 [ D loss: 0.184116, acc.: 95%] [G loss: 5.228038]\n",
            "2551 [ D loss: 0.193376, acc.: 95%] [G loss: 3.927133]\n",
            "2552 [ D loss: 0.312656, acc.: 91%] [G loss: 3.014048]\n",
            "2553 [ D loss: 0.196570, acc.: 96%] [G loss: 4.224106]\n",
            "2554 [ D loss: 0.231486, acc.: 92%] [G loss: 5.857677]\n",
            "2555 [ D loss: 0.126908, acc.: 98%] [G loss: 7.112863]\n",
            "2556 [ D loss: 0.167416, acc.: 95%] [G loss: 5.623469]\n",
            "2557 [ D loss: 0.223948, acc.: 92%] [G loss: 3.936503]\n",
            "2558 [ D loss: 0.427538, acc.: 82%] [G loss: 3.632650]\n",
            "2559 [ D loss: 0.299431, acc.: 85%] [G loss: 3.601617]\n",
            "2560 [ D loss: 0.285739, acc.: 91%] [G loss: 2.521401]\n",
            "2561 [ D loss: 0.240708, acc.: 92%] [G loss: 4.491263]\n",
            "2562 [ D loss: 0.213244, acc.: 96%] [G loss: 4.553869]\n",
            "2563 [ D loss: 0.274689, acc.: 94%] [G loss: 3.078211]\n",
            "2564 [ D loss: 0.174202, acc.: 97%] [G loss: 4.124154]\n",
            "2565 [ D loss: 0.180501, acc.: 95%] [G loss: 3.237159]\n",
            "2566 [ D loss: 0.239029, acc.: 91%] [G loss: 6.280732]\n",
            "2567 [ D loss: 0.137932, acc.: 97%] [G loss: 3.148787]\n",
            "2568 [ D loss: 0.157415, acc.: 96%] [G loss: 3.541675]\n",
            "2569 [ D loss: 0.334908, acc.: 87%] [G loss: 3.911070]\n",
            "2570 [ D loss: 0.213409, acc.: 95%] [G loss: 6.283173]\n",
            "2571 [ D loss: 0.303683, acc.: 89%] [G loss: 3.461873]\n",
            "2572 [ D loss: 0.262115, acc.: 92%] [G loss: 3.240865]\n",
            "2573 [ D loss: 0.238364, acc.: 94%] [G loss: 3.607171]\n",
            "2574 [ D loss: 0.187846, acc.: 96%] [G loss: 3.020893]\n",
            "2575 [ D loss: 0.224490, acc.: 96%] [G loss: 4.283852]\n",
            "2576 [ D loss: 0.141251, acc.: 98%] [G loss: 3.431567]\n",
            "2577 [ D loss: 0.176175, acc.: 93%] [G loss: 6.696492]\n",
            "2578 [ D loss: 0.221714, acc.: 92%] [G loss: 5.852898]\n",
            "2579 [ D loss: 0.142329, acc.: 98%] [G loss: 3.697826]\n",
            "2580 [ D loss: 0.168759, acc.: 96%] [G loss: 5.243352]\n",
            "2581 [ D loss: 0.326815, acc.: 87%] [G loss: 3.074160]\n",
            "2582 [ D loss: 0.382724, acc.: 84%] [G loss: 4.478330]\n",
            "2583 [ D loss: 0.180288, acc.: 95%] [G loss: 8.026512]\n",
            "2584 [ D loss: 0.172489, acc.: 95%] [G loss: 3.181176]\n",
            "2585 [ D loss: 0.176031, acc.: 98%] [G loss: 5.279064]\n",
            "2586 [ D loss: 0.217372, acc.: 92%] [G loss: 4.128879]\n",
            "2587 [ D loss: 0.156168, acc.: 98%] [G loss: 4.951214]\n",
            "2588 [ D loss: 0.334725, acc.: 85%] [G loss: 3.831345]\n",
            "2589 [ D loss: 0.191676, acc.: 96%] [G loss: 7.054878]\n",
            "2590 [ D loss: 0.247610, acc.: 91%] [G loss: 4.783404]\n",
            "2591 [ D loss: 0.241672, acc.: 88%] [G loss: 7.314044]\n",
            "2592 [ D loss: 0.073586, acc.: 99%] [G loss: 8.079131]\n",
            "2593 [ D loss: 0.181942, acc.: 95%] [G loss: 9.263753]\n",
            "2594 [ D loss: 0.144411, acc.: 95%] [G loss: 5.520770]\n",
            "2595 [ D loss: 0.263694, acc.: 90%] [G loss: 5.344680]\n",
            "2596 [ D loss: 0.266029, acc.: 89%] [G loss: 4.300004]\n",
            "2597 [ D loss: 0.197290, acc.: 95%] [G loss: 4.870508]\n",
            "2598 [ D loss: 0.196521, acc.: 95%] [G loss: 4.228282]\n",
            "2599 [ D loss: 0.204984, acc.: 93%] [G loss: 3.436282]\n",
            "2600 [ D loss: 0.130668, acc.: 98%] [G loss: 9.306877]\n",
            "2601 [ D loss: 0.186678, acc.: 94%] [G loss: 4.660163]\n",
            "2602 [ D loss: 0.254430, acc.: 90%] [G loss: 4.148088]\n",
            "2603 [ D loss: 0.407213, acc.: 81%] [G loss: 3.973672]\n",
            "2604 [ D loss: 0.176470, acc.: 95%] [G loss: 5.957881]\n",
            "2605 [ D loss: 0.189964, acc.: 95%] [G loss: 4.710820]\n",
            "2606 [ D loss: 0.306655, acc.: 86%] [G loss: 3.534801]\n",
            "2607 [ D loss: 0.205024, acc.: 96%] [G loss: 5.198458]\n",
            "2608 [ D loss: 0.182111, acc.: 93%] [G loss: 3.090969]\n",
            "2609 [ D loss: 0.214986, acc.: 93%] [G loss: 4.132505]\n",
            "2610 [ D loss: 0.112748, acc.: 98%] [G loss: 5.399035]\n",
            "2611 [ D loss: 0.334805, acc.: 84%] [G loss: 5.385725]\n",
            "2612 [ D loss: 0.286312, acc.: 85%] [G loss: 4.070047]\n",
            "2613 [ D loss: 0.187056, acc.: 94%] [G loss: 6.371663]\n",
            "2614 [ D loss: 0.258163, acc.: 95%] [G loss: 5.567432]\n",
            "2615 [ D loss: 0.101005, acc.: 97%] [G loss: 5.627969]\n",
            "2616 [ D loss: 0.247915, acc.: 92%] [G loss: 3.553118]\n",
            "2617 [ D loss: 0.197836, acc.: 92%] [G loss: 6.274733]\n",
            "2618 [ D loss: 0.139800, acc.: 97%] [G loss: 4.378229]\n",
            "2619 [ D loss: 0.230964, acc.: 94%] [G loss: 3.115412]\n",
            "2620 [ D loss: 0.193777, acc.: 98%] [G loss: 3.345914]\n",
            "2621 [ D loss: 0.352461, acc.: 89%] [G loss: 2.779615]\n",
            "2622 [ D loss: 0.325219, acc.: 88%] [G loss: 3.638615]\n",
            "2623 [ D loss: 0.169153, acc.: 96%] [G loss: 2.638668]\n",
            "2624 [ D loss: 0.189426, acc.: 94%] [G loss: 4.887439]\n",
            "2625 [ D loss: 0.094930, acc.: 98%] [G loss: 7.555221]\n",
            "2626 [ D loss: 0.233356, acc.: 91%] [G loss: 8.311413]\n",
            "2627 [ D loss: 0.144182, acc.: 95%] [G loss: 5.312757]\n",
            "2628 [ D loss: 0.151109, acc.: 94%] [G loss: 5.150252]\n",
            "2629 [ D loss: 0.262970, acc.: 88%] [G loss: 4.012044]\n",
            "2630 [ D loss: 0.125109, acc.: 96%] [G loss: 6.151051]\n",
            "2631 [ D loss: 0.344492, acc.: 82%] [G loss: 4.274488]\n",
            "2632 [ D loss: 0.176699, acc.: 95%] [G loss: 4.193219]\n",
            "2633 [ D loss: 0.254600, acc.: 92%] [G loss: 3.221478]\n",
            "2634 [ D loss: 0.230373, acc.: 94%] [G loss: 3.236340]\n",
            "2635 [ D loss: 0.279941, acc.: 91%] [G loss: 4.178827]\n",
            "2636 [ D loss: 0.172502, acc.: 91%] [G loss: 4.045402]\n",
            "2637 [ D loss: 0.421944, acc.: 74%] [G loss: 3.848793]\n",
            "2638 [ D loss: 0.272041, acc.: 88%] [G loss: 3.777644]\n",
            "2639 [ D loss: 0.253071, acc.: 91%] [G loss: 4.589419]\n",
            "2640 [ D loss: 0.096130, acc.: 100%] [G loss: 4.670430]\n",
            "2641 [ D loss: 0.151321, acc.: 96%] [G loss: 7.118858]\n",
            "2642 [ D loss: 0.137929, acc.: 98%] [G loss: 5.635662]\n",
            "2643 [ D loss: 0.269676, acc.: 90%] [G loss: 3.946376]\n",
            "2644 [ D loss: 0.259172, acc.: 90%] [G loss: 4.423933]\n",
            "2645 [ D loss: 0.294259, acc.: 89%] [G loss: 3.723730]\n",
            "2646 [ D loss: 0.316308, acc.: 89%] [G loss: 5.403360]\n",
            "2647 [ D loss: 0.250886, acc.: 92%] [G loss: 4.226463]\n",
            "2648 [ D loss: 0.326802, acc.: 86%] [G loss: 4.683545]\n",
            "2649 [ D loss: 0.217777, acc.: 91%] [G loss: 3.852009]\n",
            "2650 [ D loss: 0.185124, acc.: 94%] [G loss: 4.335621]\n",
            "2651 [ D loss: 0.130865, acc.: 95%] [G loss: 7.885009]\n",
            "2652 [ D loss: 0.318499, acc.: 83%] [G loss: 5.057069]\n",
            "2653 [ D loss: 0.177404, acc.: 91%] [G loss: 6.137241]\n",
            "2654 [ D loss: 0.218676, acc.: 95%] [G loss: 7.574181]\n",
            "2655 [ D loss: 0.122265, acc.: 97%] [G loss: 4.472900]\n",
            "2656 [ D loss: 0.134108, acc.: 97%] [G loss: 8.040908]\n",
            "2657 [ D loss: 0.177562, acc.: 95%] [G loss: 4.201096]\n",
            "2658 [ D loss: 0.153605, acc.: 95%] [G loss: 4.528208]\n",
            "2659 [ D loss: 0.252832, acc.: 88%] [G loss: 2.905987]\n",
            "2660 [ D loss: 0.146412, acc.: 96%] [G loss: 5.423520]\n",
            "2661 [ D loss: 0.289337, acc.: 87%] [G loss: 8.248159]\n",
            "2662 [ D loss: 0.175227, acc.: 93%] [G loss: 7.483449]\n",
            "2663 [ D loss: 0.128241, acc.: 98%] [G loss: 3.762847]\n",
            "2664 [ D loss: 0.182073, acc.: 93%] [G loss: 4.247900]\n",
            "2665 [ D loss: 0.164826, acc.: 96%] [G loss: 3.340145]\n",
            "2666 [ D loss: 0.112219, acc.: 96%] [G loss: 7.017352]\n",
            "2667 [ D loss: 0.227144, acc.: 93%] [G loss: 3.496763]\n",
            "2668 [ D loss: 0.107394, acc.: 98%] [G loss: 4.672840]\n",
            "2669 [ D loss: 0.263001, acc.: 90%] [G loss: 4.998730]\n",
            "2670 [ D loss: 0.111632, acc.: 98%] [G loss: 6.626162]\n",
            "2671 [ D loss: 0.227628, acc.: 94%] [G loss: 4.098514]\n",
            "2672 [ D loss: 0.278479, acc.: 88%] [G loss: 3.383713]\n",
            "2673 [ D loss: 0.206937, acc.: 98%] [G loss: 3.472987]\n",
            "2674 [ D loss: 0.231293, acc.: 93%] [G loss: 5.752827]\n",
            "2675 [ D loss: 0.201240, acc.: 94%] [G loss: 4.100040]\n",
            "2676 [ D loss: 0.232289, acc.: 95%] [G loss: 4.005771]\n",
            "2677 [ D loss: 0.137576, acc.: 95%] [G loss: 7.304329]\n",
            "2678 [ D loss: 0.218395, acc.: 95%] [G loss: 4.770105]\n",
            "2679 [ D loss: 0.221012, acc.: 95%] [G loss: 3.522164]\n",
            "2680 [ D loss: 0.150735, acc.: 98%] [G loss: 4.242791]\n",
            "2681 [ D loss: 0.182938, acc.: 97%] [G loss: 3.026219]\n",
            "2682 [ D loss: 0.195566, acc.: 93%] [G loss: 3.048133]\n",
            "2683 [ D loss: 0.286481, acc.: 92%] [G loss: 3.986615]\n",
            "2684 [ D loss: 0.094925, acc.: 98%] [G loss: 9.037245]\n",
            "2685 [ D loss: 0.252900, acc.: 91%] [G loss: 4.291368]\n",
            "2686 [ D loss: 0.141197, acc.: 95%] [G loss: 4.262524]\n",
            "2687 [ D loss: 0.159899, acc.: 98%] [G loss: 3.413903]\n",
            "2688 [ D loss: 0.193828, acc.: 95%] [G loss: 3.788543]\n",
            "2689 [ D loss: 0.206821, acc.: 95%] [G loss: 3.539332]\n",
            "2690 [ D loss: 0.218586, acc.: 92%] [G loss: 3.875668]\n",
            "2691 [ D loss: 0.158454, acc.: 98%] [G loss: 3.173797]\n",
            "2692 [ D loss: 0.342426, acc.: 85%] [G loss: 4.787152]\n",
            "2693 [ D loss: 0.213480, acc.: 93%] [G loss: 8.652819]\n",
            "2694 [ D loss: 0.168096, acc.: 95%] [G loss: 3.412136]\n",
            "2695 [ D loss: 0.179557, acc.: 94%] [G loss: 4.031759]\n",
            "2696 [ D loss: 0.196014, acc.: 95%] [G loss: 4.503660]\n",
            "2697 [ D loss: 0.086937, acc.: 99%] [G loss: 5.222781]\n",
            "2698 [ D loss: 0.236341, acc.: 92%] [G loss: 5.288367]\n",
            "2699 [ D loss: 0.154470, acc.: 95%] [G loss: 10.587385]\n",
            "2700 [ D loss: 0.156869, acc.: 94%] [G loss: 4.057525]\n",
            "2701 [ D loss: 0.251072, acc.: 94%] [G loss: 5.029321]\n",
            "2702 [ D loss: 0.129709, acc.: 95%] [G loss: 6.177158]\n",
            "2703 [ D loss: 0.228115, acc.: 95%] [G loss: 2.816084]\n",
            "2704 [ D loss: 0.147333, acc.: 97%] [G loss: 3.840688]\n",
            "2705 [ D loss: 0.258336, acc.: 95%] [G loss: 4.615322]\n",
            "2706 [ D loss: 0.107363, acc.: 99%] [G loss: 5.892327]\n",
            "2707 [ D loss: 0.304549, acc.: 85%] [G loss: 7.364544]\n",
            "2708 [ D loss: 0.181212, acc.: 96%] [G loss: 6.322280]\n",
            "2709 [ D loss: 0.190825, acc.: 91%] [G loss: 3.723264]\n",
            "2710 [ D loss: 0.223581, acc.: 91%] [G loss: 8.071349]\n",
            "2711 [ D loss: 0.193983, acc.: 93%] [G loss: 4.725273]\n",
            "2712 [ D loss: 0.132661, acc.: 97%] [G loss: 8.774929]\n",
            "2713 [ D loss: 0.258022, acc.: 89%] [G loss: 3.792143]\n",
            "2714 [ D loss: 0.134209, acc.: 100%] [G loss: 5.234784]\n",
            "2715 [ D loss: 0.127596, acc.: 98%] [G loss: 4.206778]\n",
            "2716 [ D loss: 0.199640, acc.: 98%] [G loss: 3.027772]\n",
            "2717 [ D loss: 0.437481, acc.: 84%] [G loss: 3.277907]\n",
            "2718 [ D loss: 0.229252, acc.: 95%] [G loss: 4.722691]\n",
            "2719 [ D loss: 0.345449, acc.: 85%] [G loss: 3.420158]\n",
            "2720 [ D loss: 0.198190, acc.: 96%] [G loss: 4.127827]\n",
            "2721 [ D loss: 0.144550, acc.: 99%] [G loss: 3.812792]\n",
            "2722 [ D loss: 0.268219, acc.: 90%] [G loss: 6.028273]\n",
            "2723 [ D loss: 0.218937, acc.: 96%] [G loss: 5.634759]\n",
            "2724 [ D loss: 0.185752, acc.: 94%] [G loss: 10.157972]\n",
            "2725 [ D loss: 0.201846, acc.: 94%] [G loss: 7.842787]\n",
            "2726 [ D loss: 0.142787, acc.: 95%] [G loss: 5.757758]\n",
            "2727 [ D loss: 0.128146, acc.: 97%] [G loss: 9.180159]\n",
            "2728 [ D loss: 0.161358, acc.: 93%] [G loss: 5.341489]\n",
            "2729 [ D loss: 0.342891, acc.: 80%] [G loss: 3.840354]\n",
            "2730 [ D loss: 0.139039, acc.: 97%] [G loss: 5.696972]\n",
            "2731 [ D loss: 0.239011, acc.: 95%] [G loss: 3.315366]\n",
            "2732 [ D loss: 0.213711, acc.: 97%] [G loss: 3.608465]\n",
            "2733 [ D loss: 0.208885, acc.: 98%] [G loss: 4.663472]\n",
            "2734 [ D loss: 0.179839, acc.: 96%] [G loss: 3.273305]\n",
            "2735 [ D loss: 0.162433, acc.: 98%] [G loss: 3.728283]\n",
            "2736 [ D loss: 0.227322, acc.: 98%] [G loss: 4.269612]\n",
            "2737 [ D loss: 0.181466, acc.: 94%] [G loss: 5.564629]\n",
            "2738 [ D loss: 0.156097, acc.: 96%] [G loss: 3.771812]\n",
            "2739 [ D loss: 0.175286, acc.: 94%] [G loss: 4.895296]\n",
            "2740 [ D loss: 0.307368, acc.: 88%] [G loss: 5.451751]\n",
            "2741 [ D loss: 0.221567, acc.: 93%] [G loss: 6.983532]\n",
            "2742 [ D loss: 0.165088, acc.: 95%] [G loss: 6.702729]\n",
            "2743 [ D loss: 0.207218, acc.: 93%] [G loss: 5.177904]\n",
            "2744 [ D loss: 0.342056, acc.: 81%] [G loss: 4.704091]\n",
            "2745 [ D loss: 0.200938, acc.: 93%] [G loss: 8.104136]\n",
            "2746 [ D loss: 0.204615, acc.: 92%] [G loss: 4.201278]\n",
            "2747 [ D loss: 0.172229, acc.: 95%] [G loss: 6.869953]\n",
            "2748 [ D loss: 0.237457, acc.: 93%] [G loss: 3.225671]\n",
            "2749 [ D loss: 0.212967, acc.: 95%] [G loss: 5.230541]\n",
            "2750 [ D loss: 0.235515, acc.: 93%] [G loss: 4.207433]\n",
            "2751 [ D loss: 0.163747, acc.: 95%] [G loss: 6.462891]\n",
            "2752 [ D loss: 0.321507, acc.: 84%] [G loss: 3.759683]\n",
            "2753 [ D loss: 0.127046, acc.: 95%] [G loss: 7.306870]\n",
            "2754 [ D loss: 0.177954, acc.: 96%] [G loss: 5.128300]\n",
            "2755 [ D loss: 0.190380, acc.: 95%] [G loss: 6.777233]\n",
            "2756 [ D loss: 0.086669, acc.: 99%] [G loss: 8.643534]\n",
            "2757 [ D loss: 0.096336, acc.: 98%] [G loss: 4.697428]\n",
            "2758 [ D loss: 0.223309, acc.: 91%] [G loss: 6.092932]\n",
            "2759 [ D loss: 0.157635, acc.: 96%] [G loss: 3.793672]\n",
            "2760 [ D loss: 0.295396, acc.: 88%] [G loss: 4.205818]\n",
            "2761 [ D loss: 0.227760, acc.: 90%] [G loss: 4.905799]\n",
            "2762 [ D loss: 0.174399, acc.: 95%] [G loss: 4.074112]\n",
            "2763 [ D loss: 0.220462, acc.: 91%] [G loss: 3.412373]\n",
            "2764 [ D loss: 0.238991, acc.: 95%] [G loss: 4.581251]\n",
            "2765 [ D loss: 0.166089, acc.: 92%] [G loss: 6.040524]\n",
            "2766 [ D loss: 0.180037, acc.: 93%] [G loss: 7.806710]\n",
            "2767 [ D loss: 0.151135, acc.: 95%] [G loss: 4.880520]\n",
            "2768 [ D loss: 0.143595, acc.: 95%] [G loss: 5.489552]\n",
            "2769 [ D loss: 0.112013, acc.: 98%] [G loss: 6.842339]\n",
            "2770 [ D loss: 0.168133, acc.: 95%] [G loss: 6.171082]\n",
            "2771 [ D loss: 0.205700, acc.: 93%] [G loss: 4.152074]\n",
            "2772 [ D loss: 0.224037, acc.: 95%] [G loss: 3.107582]\n",
            "2773 [ D loss: 0.325718, acc.: 84%] [G loss: 3.270411]\n",
            "2774 [ D loss: 0.223529, acc.: 98%] [G loss: 3.738053]\n",
            "2775 [ D loss: 0.114382, acc.: 98%] [G loss: 5.966769]\n",
            "2776 [ D loss: 0.268429, acc.: 91%] [G loss: 3.819787]\n",
            "2777 [ D loss: 0.203439, acc.: 94%] [G loss: 3.228976]\n",
            "2778 [ D loss: 0.381700, acc.: 86%] [G loss: 3.243857]\n",
            "2779 [ D loss: 0.240114, acc.: 91%] [G loss: 6.184634]\n",
            "2780 [ D loss: 0.190031, acc.: 97%] [G loss: 3.961782]\n",
            "2781 [ D loss: 0.377368, acc.: 81%] [G loss: 3.825964]\n",
            "2782 [ D loss: 0.204737, acc.: 94%] [G loss: 4.307583]\n",
            "2783 [ D loss: 0.196276, acc.: 96%] [G loss: 3.956116]\n",
            "2784 [ D loss: 0.107475, acc.: 98%] [G loss: 6.736288]\n",
            "2785 [ D loss: 0.202031, acc.: 98%] [G loss: 3.964176]\n",
            "2786 [ D loss: 0.162619, acc.: 98%] [G loss: 4.045708]\n",
            "2787 [ D loss: 0.259613, acc.: 91%] [G loss: 3.736642]\n",
            "2788 [ D loss: 0.220167, acc.: 93%] [G loss: 4.402921]\n",
            "2789 [ D loss: 0.198266, acc.: 94%] [G loss: 3.586674]\n",
            "2790 [ D loss: 0.257631, acc.: 91%] [G loss: 5.291679]\n",
            "2791 [ D loss: 0.137164, acc.: 96%] [G loss: 5.608099]\n",
            "2792 [ D loss: 0.206777, acc.: 94%] [G loss: 3.897232]\n",
            "2793 [ D loss: 0.184328, acc.: 96%] [G loss: 6.230518]\n",
            "2794 [ D loss: 0.268321, acc.: 88%] [G loss: 3.501280]\n",
            "2795 [ D loss: 0.253698, acc.: 91%] [G loss: 3.378168]\n",
            "2796 [ D loss: 0.236579, acc.: 95%] [G loss: 3.750497]\n",
            "2797 [ D loss: 0.280454, acc.: 94%] [G loss: 4.531170]\n",
            "2798 [ D loss: 0.209411, acc.: 92%] [G loss: 5.996257]\n",
            "2799 [ D loss: 0.181111, acc.: 95%] [G loss: 4.383418]\n",
            "2800 [ D loss: 0.197444, acc.: 95%] [G loss: 5.216450]\n",
            "2801 [ D loss: 0.153372, acc.: 98%] [G loss: 4.745212]\n",
            "2802 [ D loss: 0.213899, acc.: 94%] [G loss: 3.780578]\n",
            "2803 [ D loss: 0.235569, acc.: 96%] [G loss: 3.731997]\n",
            "2804 [ D loss: 0.298363, acc.: 88%] [G loss: 3.629061]\n",
            "2805 [ D loss: 0.107330, acc.: 99%] [G loss: 5.277703]\n",
            "2806 [ D loss: 0.246905, acc.: 90%] [G loss: 3.986405]\n",
            "2807 [ D loss: 0.161317, acc.: 95%] [G loss: 4.458889]\n",
            "2808 [ D loss: 0.232404, acc.: 95%] [G loss: 3.527184]\n",
            "2809 [ D loss: 0.279930, acc.: 94%] [G loss: 3.395632]\n",
            "2810 [ D loss: 0.196160, acc.: 95%] [G loss: 3.864625]\n",
            "2811 [ D loss: 0.253244, acc.: 94%] [G loss: 4.426649]\n",
            "2812 [ D loss: 0.124480, acc.: 98%] [G loss: 6.285450]\n",
            "2813 [ D loss: 0.188106, acc.: 95%] [G loss: 4.090427]\n",
            "2814 [ D loss: 0.136636, acc.: 96%] [G loss: 5.198994]\n",
            "2815 [ D loss: 0.235625, acc.: 94%] [G loss: 6.401073]\n",
            "2816 [ D loss: 0.117127, acc.: 98%] [G loss: 8.128183]\n",
            "2817 [ D loss: 0.172801, acc.: 98%] [G loss: 7.037957]\n",
            "2818 [ D loss: 0.148018, acc.: 98%] [G loss: 3.509310]\n",
            "2819 [ D loss: 0.206653, acc.: 94%] [G loss: 3.338037]\n",
            "2820 [ D loss: 0.318735, acc.: 87%] [G loss: 4.695606]\n",
            "2821 [ D loss: 0.230063, acc.: 91%] [G loss: 3.856500]\n",
            "2822 [ D loss: 0.163700, acc.: 96%] [G loss: 3.973948]\n",
            "2823 [ D loss: 0.189428, acc.: 96%] [G loss: 3.131071]\n",
            "2824 [ D loss: 0.188045, acc.: 97%] [G loss: 4.169621]\n",
            "2825 [ D loss: 0.145140, acc.: 95%] [G loss: 4.500426]\n",
            "2826 [ D loss: 0.359163, acc.: 85%] [G loss: 4.575286]\n",
            "2827 [ D loss: 0.276367, acc.: 88%] [G loss: 3.001591]\n",
            "2828 [ D loss: 0.458905, acc.: 79%] [G loss: 4.052909]\n",
            "2829 [ D loss: 0.207971, acc.: 96%] [G loss: 4.321404]\n",
            "2830 [ D loss: 0.289809, acc.: 86%] [G loss: 3.940682]\n",
            "2831 [ D loss: 0.240581, acc.: 96%] [G loss: 4.655362]\n",
            "2832 [ D loss: 0.243662, acc.: 91%] [G loss: 4.557748]\n",
            "2833 [ D loss: 0.227809, acc.: 95%] [G loss: 3.273728]\n",
            "2834 [ D loss: 0.135816, acc.: 98%] [G loss: 4.298042]\n",
            "2835 [ D loss: 0.235671, acc.: 92%] [G loss: 3.225495]\n",
            "2836 [ D loss: 0.115475, acc.: 96%] [G loss: 3.994717]\n",
            "2837 [ D loss: 0.303354, acc.: 88%] [G loss: 4.397185]\n",
            "2838 [ D loss: 0.193543, acc.: 93%] [G loss: 4.184404]\n",
            "2839 [ D loss: 0.200812, acc.: 94%] [G loss: 3.935279]\n",
            "2840 [ D loss: 0.186454, acc.: 94%] [G loss: 4.395328]\n",
            "2841 [ D loss: 0.184405, acc.: 96%] [G loss: 3.865467]\n",
            "2842 [ D loss: 0.239211, acc.: 91%] [G loss: 2.861616]\n",
            "2843 [ D loss: 0.270212, acc.: 92%] [G loss: 3.267947]\n",
            "2844 [ D loss: 0.331540, acc.: 88%] [G loss: 4.069979]\n",
            "2845 [ D loss: 0.119822, acc.: 96%] [G loss: 7.463626]\n",
            "2846 [ D loss: 0.133782, acc.: 95%] [G loss: 8.361736]\n",
            "2847 [ D loss: 0.187281, acc.: 93%] [G loss: 8.397537]\n",
            "2848 [ D loss: 0.156634, acc.: 96%] [G loss: 4.222078]\n",
            "2849 [ D loss: 0.271021, acc.: 91%] [G loss: 4.107972]\n",
            "2850 [ D loss: 0.225899, acc.: 95%] [G loss: 4.161582]\n",
            "2851 [ D loss: 0.164459, acc.: 95%] [G loss: 3.656018]\n",
            "2852 [ D loss: 0.307762, acc.: 88%] [G loss: 3.768391]\n",
            "2853 [ D loss: 0.320082, acc.: 90%] [G loss: 3.574739]\n",
            "2854 [ D loss: 0.251598, acc.: 93%] [G loss: 4.526891]\n",
            "2855 [ D loss: 0.238652, acc.: 93%] [G loss: 5.888433]\n",
            "2856 [ D loss: 0.188083, acc.: 95%] [G loss: 3.238094]\n",
            "2857 [ D loss: 0.167179, acc.: 97%] [G loss: 3.548820]\n",
            "2858 [ D loss: 0.199851, acc.: 95%] [G loss: 3.679701]\n",
            "2859 [ D loss: 0.234505, acc.: 94%] [G loss: 2.802313]\n",
            "2860 [ D loss: 0.359810, acc.: 88%] [G loss: 4.100307]\n",
            "2861 [ D loss: 0.271918, acc.: 90%] [G loss: 4.566293]\n",
            "2862 [ D loss: 0.360972, acc.: 82%] [G loss: 5.097741]\n",
            "2863 [ D loss: 0.356312, acc.: 86%] [G loss: 3.650710]\n",
            "2864 [ D loss: 0.375453, acc.: 84%] [G loss: 5.849868]\n",
            "2865 [ D loss: 0.092397, acc.: 98%] [G loss: 9.224794]\n",
            "2866 [ D loss: 0.136435, acc.: 96%] [G loss: 2.851801]\n",
            "2867 [ D loss: 0.202224, acc.: 95%] [G loss: 6.132793]\n",
            "2868 [ D loss: 0.136740, acc.: 95%] [G loss: 7.820135]\n",
            "2869 [ D loss: 0.161163, acc.: 95%] [G loss: 5.935299]\n",
            "2870 [ D loss: 0.182577, acc.: 95%] [G loss: 4.789628]\n",
            "2871 [ D loss: 0.203009, acc.: 95%] [G loss: 3.711728]\n",
            "2872 [ D loss: 0.302077, acc.: 90%] [G loss: 5.502928]\n",
            "2873 [ D loss: 0.226201, acc.: 95%] [G loss: 8.231997]\n",
            "2874 [ D loss: 0.320324, acc.: 85%] [G loss: 4.837298]\n",
            "2875 [ D loss: 0.232183, acc.: 90%] [G loss: 6.970145]\n",
            "2876 [ D loss: 0.217693, acc.: 90%] [G loss: 4.391891]\n",
            "2877 [ D loss: 0.223923, acc.: 94%] [G loss: 3.619891]\n",
            "2878 [ D loss: 0.192094, acc.: 96%] [G loss: 3.559934]\n",
            "2879 [ D loss: 0.146314, acc.: 97%] [G loss: 4.420208]\n",
            "2880 [ D loss: 0.110524, acc.: 98%] [G loss: 6.662108]\n",
            "2881 [ D loss: 0.366863, acc.: 84%] [G loss: 4.513893]\n",
            "2882 [ D loss: 0.376541, acc.: 84%] [G loss: 7.038559]\n",
            "2883 [ D loss: 0.339300, acc.: 88%] [G loss: 4.151042]\n",
            "2884 [ D loss: 0.100124, acc.: 96%] [G loss: 5.357491]\n",
            "2885 [ D loss: 0.175380, acc.: 95%] [G loss: 4.469915]\n",
            "2886 [ D loss: 0.228574, acc.: 91%] [G loss: 3.944444]\n",
            "2887 [ D loss: 0.195012, acc.: 98%] [G loss: 5.190545]\n",
            "2888 [ D loss: 0.222152, acc.: 94%] [G loss: 3.201197]\n",
            "2889 [ D loss: 0.178561, acc.: 95%] [G loss: 3.892920]\n",
            "2890 [ D loss: 0.236790, acc.: 92%] [G loss: 6.587363]\n",
            "2891 [ D loss: 0.383927, acc.: 82%] [G loss: 3.592205]\n",
            "2892 [ D loss: 0.202155, acc.: 96%] [G loss: 3.536180]\n",
            "2893 [ D loss: 0.203412, acc.: 95%] [G loss: 4.573482]\n",
            "2894 [ D loss: 0.138758, acc.: 95%] [G loss: 9.651954]\n",
            "2895 [ D loss: 0.147890, acc.: 95%] [G loss: 7.812459]\n",
            "2896 [ D loss: 0.183217, acc.: 92%] [G loss: 5.771334]\n",
            "2897 [ D loss: 0.144492, acc.: 97%] [G loss: 8.437114]\n",
            "2898 [ D loss: 0.132330, acc.: 98%] [G loss: 7.208694]\n",
            "2899 [ D loss: 0.149609, acc.: 95%] [G loss: 4.926375]\n",
            "2900 [ D loss: 0.162382, acc.: 95%] [G loss: 4.392447]\n",
            "2901 [ D loss: 0.112895, acc.: 98%] [G loss: 6.242020]\n",
            "2902 [ D loss: 0.144503, acc.: 96%] [G loss: 8.850878]\n",
            "2903 [ D loss: 0.115313, acc.: 97%] [G loss: 6.283011]\n",
            "2904 [ D loss: 0.235181, acc.: 94%] [G loss: 4.766719]\n",
            "2905 [ D loss: 0.157488, acc.: 98%] [G loss: 3.540136]\n",
            "2906 [ D loss: 0.227099, acc.: 94%] [G loss: 4.386612]\n",
            "2907 [ D loss: 0.122662, acc.: 98%] [G loss: 3.770353]\n",
            "2908 [ D loss: 0.180327, acc.: 98%] [G loss: 6.453485]\n",
            "2909 [ D loss: 0.118011, acc.: 98%] [G loss: 6.964130]\n",
            "2910 [ D loss: 0.192549, acc.: 94%] [G loss: 3.511269]\n",
            "2911 [ D loss: 0.219267, acc.: 95%] [G loss: 4.727237]\n",
            "2912 [ D loss: 0.213902, acc.: 97%] [G loss: 3.700091]\n",
            "2913 [ D loss: 0.162417, acc.: 95%] [G loss: 5.306410]\n",
            "2914 [ D loss: 0.204839, acc.: 91%] [G loss: 4.882688]\n",
            "2915 [ D loss: 0.183931, acc.: 94%] [G loss: 4.665913]\n",
            "2916 [ D loss: 0.150260, acc.: 97%] [G loss: 5.823140]\n",
            "2917 [ D loss: 0.383032, acc.: 80%] [G loss: 3.956753]\n",
            "2918 [ D loss: 0.223157, acc.: 95%] [G loss: 6.131546]\n",
            "2919 [ D loss: 0.183980, acc.: 93%] [G loss: 6.626108]\n",
            "2920 [ D loss: 0.156862, acc.: 96%] [G loss: 4.993488]\n",
            "2921 [ D loss: 0.174870, acc.: 95%] [G loss: 10.066975]\n",
            "2922 [ D loss: 0.166044, acc.: 94%] [G loss: 6.029940]\n",
            "2923 [ D loss: 0.087559, acc.: 100%] [G loss: 7.076758]\n",
            "2924 [ D loss: 0.361476, acc.: 78%] [G loss: 4.183641]\n",
            "2925 [ D loss: 0.304707, acc.: 88%] [G loss: 3.280940]\n",
            "2926 [ D loss: 0.176380, acc.: 95%] [G loss: 5.082631]\n",
            "2927 [ D loss: 0.249203, acc.: 91%] [G loss: 3.308884]\n",
            "2928 [ D loss: 0.237937, acc.: 94%] [G loss: 4.285642]\n",
            "2929 [ D loss: 0.191243, acc.: 95%] [G loss: 3.925323]\n",
            "2930 [ D loss: 0.186240, acc.: 95%] [G loss: 4.945064]\n",
            "2931 [ D loss: 0.195884, acc.: 92%] [G loss: 9.260279]\n",
            "2932 [ D loss: 0.209929, acc.: 95%] [G loss: 4.413148]\n",
            "2933 [ D loss: 0.219822, acc.: 90%] [G loss: 8.189829]\n",
            "2934 [ D loss: 0.232368, acc.: 91%] [G loss: 4.401349]\n",
            "2935 [ D loss: 0.158612, acc.: 96%] [G loss: 4.056835]\n",
            "2936 [ D loss: 0.233834, acc.: 88%] [G loss: 5.523029]\n",
            "2937 [ D loss: 0.177470, acc.: 94%] [G loss: 4.952765]\n",
            "2938 [ D loss: 0.288771, acc.: 86%] [G loss: 4.132182]\n",
            "2939 [ D loss: 0.258142, acc.: 88%] [G loss: 5.146382]\n",
            "2940 [ D loss: 0.195572, acc.: 95%] [G loss: 5.145514]\n",
            "2941 [ D loss: 0.145877, acc.: 96%] [G loss: 6.162454]\n",
            "2942 [ D loss: 0.197128, acc.: 92%] [G loss: 4.424586]\n",
            "2943 [ D loss: 0.114782, acc.: 98%] [G loss: 4.915946]\n",
            "2944 [ D loss: 0.156293, acc.: 95%] [G loss: 4.965010]\n",
            "2945 [ D loss: 0.132047, acc.: 98%] [G loss: 5.769374]\n",
            "2946 [ D loss: 0.270806, acc.: 91%] [G loss: 2.854792]\n",
            "2947 [ D loss: 0.288764, acc.: 90%] [G loss: 3.291652]\n",
            "2948 [ D loss: 0.267060, acc.: 90%] [G loss: 7.935518]\n",
            "2949 [ D loss: 0.134760, acc.: 99%] [G loss: 7.495150]\n",
            "2950 [ D loss: 0.317325, acc.: 89%] [G loss: 3.394799]\n",
            "2951 [ D loss: 0.172972, acc.: 92%] [G loss: 3.892529]\n",
            "2952 [ D loss: 0.315921, acc.: 89%] [G loss: 3.426236]\n",
            "2953 [ D loss: 0.263330, acc.: 91%] [G loss: 3.546323]\n",
            "2954 [ D loss: 0.215398, acc.: 94%] [G loss: 3.623950]\n",
            "2955 [ D loss: 0.300757, acc.: 88%] [G loss: 2.848703]\n",
            "2956 [ D loss: 0.206227, acc.: 95%] [G loss: 3.427410]\n",
            "2957 [ D loss: 0.241468, acc.: 95%] [G loss: 4.169653]\n",
            "2958 [ D loss: 0.279652, acc.: 93%] [G loss: 4.978063]\n",
            "2959 [ D loss: 0.235673, acc.: 90%] [G loss: 5.290569]\n",
            "2960 [ D loss: 0.223043, acc.: 90%] [G loss: 4.042956]\n",
            "2961 [ D loss: 0.161039, acc.: 95%] [G loss: 5.998122]\n",
            "2962 [ D loss: 0.195051, acc.: 96%] [G loss: 7.452777]\n",
            "2963 [ D loss: 0.177359, acc.: 98%] [G loss: 3.988408]\n",
            "2964 [ D loss: 0.137673, acc.: 96%] [G loss: 6.413101]\n",
            "2965 [ D loss: 0.128788, acc.: 97%] [G loss: 5.127749]\n",
            "2966 [ D loss: 0.136034, acc.: 96%] [G loss: 4.509869]\n",
            "2967 [ D loss: 0.266505, acc.: 91%] [G loss: 3.308436]\n",
            "2968 [ D loss: 0.316851, acc.: 89%] [G loss: 4.148251]\n",
            "2969 [ D loss: 0.256582, acc.: 91%] [G loss: 5.793612]\n",
            "2970 [ D loss: 0.266672, acc.: 91%] [G loss: 3.583411]\n",
            "2971 [ D loss: 0.236619, acc.: 93%] [G loss: 3.722282]\n",
            "2972 [ D loss: 0.254842, acc.: 92%] [G loss: 4.015413]\n",
            "2973 [ D loss: 0.300826, acc.: 90%] [G loss: 3.258495]\n",
            "2974 [ D loss: 0.243777, acc.: 91%] [G loss: 4.549054]\n",
            "2975 [ D loss: 0.327847, acc.: 89%] [G loss: 4.481796]\n",
            "2976 [ D loss: 0.224914, acc.: 92%] [G loss: 4.128990]\n",
            "2977 [ D loss: 0.167773, acc.: 98%] [G loss: 3.463597]\n",
            "2978 [ D loss: 0.156255, acc.: 96%] [G loss: 3.743733]\n",
            "2979 [ D loss: 0.253965, acc.: 92%] [G loss: 6.201989]\n",
            "2980 [ D loss: 0.188692, acc.: 95%] [G loss: 3.893769]\n",
            "2981 [ D loss: 0.221267, acc.: 95%] [G loss: 7.338002]\n",
            "2982 [ D loss: 0.122880, acc.: 96%] [G loss: 5.721255]\n",
            "2983 [ D loss: 0.100646, acc.: 98%] [G loss: 9.488426]\n",
            "2984 [ D loss: 0.131831, acc.: 94%] [G loss: 5.624340]\n",
            "2985 [ D loss: 0.098594, acc.: 97%] [G loss: 4.009727]\n",
            "2986 [ D loss: 0.076443, acc.: 99%] [G loss: 6.411204]\n",
            "2987 [ D loss: 0.268829, acc.: 87%] [G loss: 4.880557]\n",
            "2988 [ D loss: 0.355636, acc.: 88%] [G loss: 4.284243]\n",
            "2989 [ D loss: 0.187389, acc.: 94%] [G loss: 7.861465]\n",
            "2990 [ D loss: 0.184671, acc.: 95%] [G loss: 4.165695]\n",
            "2991 [ D loss: 0.122400, acc.: 98%] [G loss: 3.969723]\n",
            "2992 [ D loss: 0.158464, acc.: 95%] [G loss: 4.872310]\n",
            "2993 [ D loss: 0.168369, acc.: 95%] [G loss: 3.823742]\n",
            "2994 [ D loss: 0.426484, acc.: 82%] [G loss: 3.328230]\n",
            "2995 [ D loss: 0.382610, acc.: 81%] [G loss: 3.748453]\n",
            "2996 [ D loss: 0.323409, acc.: 88%] [G loss: 4.153243]\n",
            "2997 [ D loss: 0.124132, acc.: 98%] [G loss: 5.577311]\n",
            "2998 [ D loss: 0.299928, acc.: 91%] [G loss: 5.093671]\n",
            "2999 [ D loss: 0.131920, acc.: 97%] [G loss: 6.450639]\n",
            "3000 [ D loss: 0.186998, acc.: 94%] [G loss: 5.857097]\n",
            "3001 [ D loss: 0.151032, acc.: 95%] [G loss: 9.794128]\n",
            "3002 [ D loss: 0.175897, acc.: 97%] [G loss: 4.216519]\n",
            "3003 [ D loss: 0.148257, acc.: 96%] [G loss: 5.475817]\n",
            "3004 [ D loss: 0.362087, acc.: 83%] [G loss: 3.483115]\n",
            "3005 [ D loss: 0.175595, acc.: 98%] [G loss: 3.665346]\n",
            "3006 [ D loss: 0.237310, acc.: 95%] [G loss: 3.232555]\n",
            "3007 [ D loss: 0.173933, acc.: 96%] [G loss: 2.908024]\n",
            "3008 [ D loss: 0.346067, acc.: 83%] [G loss: 3.948878]\n",
            "3009 [ D loss: 0.508910, acc.: 79%] [G loss: 3.708301]\n",
            "3010 [ D loss: 1.339190, acc.: 41%] [G loss: 3.008758]\n",
            "3011 [ D loss: 0.101411, acc.: 98%] [G loss: 3.335607]\n",
            "3012 [ D loss: 0.361362, acc.: 84%] [G loss: 4.320130]\n",
            "3013 [ D loss: 0.320400, acc.: 89%] [G loss: 4.465329]\n",
            "3014 [ D loss: 0.496654, acc.: 77%] [G loss: 3.723007]\n",
            "3015 [ D loss: 0.197307, acc.: 93%] [G loss: 4.019882]\n",
            "3016 [ D loss: 0.195428, acc.: 95%] [G loss: 3.517834]\n",
            "3017 [ D loss: 0.259382, acc.: 90%] [G loss: 4.209896]\n",
            "3018 [ D loss: 0.184305, acc.: 95%] [G loss: 5.008479]\n",
            "3019 [ D loss: 0.155902, acc.: 97%] [G loss: 3.695306]\n",
            "3020 [ D loss: 0.220284, acc.: 95%] [G loss: 3.999189]\n",
            "3021 [ D loss: 0.241159, acc.: 94%] [G loss: 3.981910]\n",
            "3022 [ D loss: 0.247270, acc.: 93%] [G loss: 3.493360]\n",
            "3023 [ D loss: 0.223781, acc.: 95%] [G loss: 6.575485]\n",
            "3024 [ D loss: 0.217226, acc.: 91%] [G loss: 3.815179]\n",
            "3025 [ D loss: 0.208902, acc.: 95%] [G loss: 3.433903]\n",
            "3026 [ D loss: 0.222174, acc.: 91%] [G loss: 3.828658]\n",
            "3027 [ D loss: 0.154470, acc.: 95%] [G loss: 5.443050]\n",
            "3028 [ D loss: 0.470837, acc.: 77%] [G loss: 3.817635]\n",
            "3029 [ D loss: 0.308831, acc.: 86%] [G loss: 5.487359]\n",
            "3030 [ D loss: 0.239806, acc.: 91%] [G loss: 4.403272]\n",
            "3031 [ D loss: 0.264084, acc.: 91%] [G loss: 4.880291]\n",
            "3032 [ D loss: 0.161068, acc.: 95%] [G loss: 8.977994]\n",
            "3033 [ D loss: 0.122685, acc.: 98%] [G loss: 4.976726]\n",
            "3034 [ D loss: 0.313858, acc.: 90%] [G loss: 4.760798]\n",
            "3035 [ D loss: 0.173611, acc.: 95%] [G loss: 6.611765]\n",
            "3036 [ D loss: 0.292820, acc.: 89%] [G loss: 4.421333]\n",
            "3037 [ D loss: 0.186414, acc.: 93%] [G loss: 4.999993]\n",
            "3038 [ D loss: 0.174022, acc.: 95%] [G loss: 10.857029]\n",
            "3039 [ D loss: 0.120205, acc.: 97%] [G loss: 7.725808]\n",
            "3040 [ D loss: 0.255050, acc.: 91%] [G loss: 4.660563]\n",
            "3041 [ D loss: 0.139161, acc.: 94%] [G loss: 6.065707]\n",
            "3042 [ D loss: 0.194244, acc.: 94%] [G loss: 4.129344]\n",
            "3043 [ D loss: 0.242567, acc.: 94%] [G loss: 3.174240]\n",
            "3044 [ D loss: 0.170073, acc.: 95%] [G loss: 3.216863]\n",
            "3045 [ D loss: 0.346048, acc.: 91%] [G loss: 6.017143]\n",
            "3046 [ D loss: 0.107963, acc.: 99%] [G loss: 6.636097]\n",
            "3047 [ D loss: 0.228127, acc.: 94%] [G loss: 3.725161]\n",
            "3048 [ D loss: 0.176867, acc.: 94%] [G loss: 6.955882]\n",
            "3049 [ D loss: 0.334396, acc.: 91%] [G loss: 3.422381]\n",
            "3050 [ D loss: 0.346088, acc.: 87%] [G loss: 3.195106]\n",
            "3051 [ D loss: 0.370304, acc.: 90%] [G loss: 4.275106]\n",
            "3052 [ D loss: 0.225643, acc.: 93%] [G loss: 5.988346]\n",
            "3053 [ D loss: 0.212947, acc.: 92%] [G loss: 7.592577]\n",
            "3054 [ D loss: 0.176755, acc.: 95%] [G loss: 4.861587]\n",
            "3055 [ D loss: 0.110406, acc.: 98%] [G loss: 5.310638]\n",
            "3056 [ D loss: 0.249645, acc.: 88%] [G loss: 4.037783]\n",
            "3057 [ D loss: 0.227303, acc.: 95%] [G loss: 3.168288]\n",
            "3058 [ D loss: 0.155318, acc.: 98%] [G loss: 5.308094]\n",
            "3059 [ D loss: 0.153727, acc.: 96%] [G loss: 3.508391]\n",
            "3060 [ D loss: 0.267524, acc.: 88%] [G loss: 5.636798]\n",
            "3061 [ D loss: 0.263546, acc.: 89%] [G loss: 4.662614]\n",
            "3062 [ D loss: 0.261956, acc.: 92%] [G loss: 4.600216]\n",
            "3063 [ D loss: 0.240700, acc.: 93%] [G loss: 3.355981]\n",
            "3064 [ D loss: 0.177235, acc.: 97%] [G loss: 4.064959]\n",
            "3065 [ D loss: 0.283718, acc.: 91%] [G loss: 4.013780]\n",
            "3066 [ D loss: 0.267448, acc.: 90%] [G loss: 3.593713]\n",
            "3067 [ D loss: 0.245339, acc.: 91%] [G loss: 3.540345]\n",
            "3068 [ D loss: 0.218790, acc.: 93%] [G loss: 3.397628]\n",
            "3069 [ D loss: 0.191870, acc.: 95%] [G loss: 2.963861]\n",
            "3070 [ D loss: 0.135398, acc.: 97%] [G loss: 6.324641]\n",
            "3071 [ D loss: 0.322310, acc.: 88%] [G loss: 3.105987]\n",
            "3072 [ D loss: 0.139780, acc.: 98%] [G loss: 3.733938]\n",
            "3073 [ D loss: 0.273484, acc.: 93%] [G loss: 3.681598]\n",
            "3074 [ D loss: 0.201858, acc.: 95%] [G loss: 4.670258]\n",
            "3075 [ D loss: 0.244094, acc.: 91%] [G loss: 3.716176]\n",
            "3076 [ D loss: 0.175318, acc.: 94%] [G loss: 4.441924]\n",
            "3077 [ D loss: 0.185500, acc.: 95%] [G loss: 3.635701]\n",
            "3078 [ D loss: 0.212005, acc.: 94%] [G loss: 3.511306]\n",
            "3079 [ D loss: 0.329043, acc.: 89%] [G loss: 4.227088]\n",
            "3080 [ D loss: 0.208182, acc.: 94%] [G loss: 3.445514]\n",
            "3081 [ D loss: 0.293228, acc.: 88%] [G loss: 3.939897]\n",
            "3082 [ D loss: 0.173458, acc.: 96%] [G loss: 5.130767]\n",
            "3083 [ D loss: 0.210918, acc.: 95%] [G loss: 4.856782]\n",
            "3084 [ D loss: 0.091528, acc.: 98%] [G loss: 4.966622]\n",
            "3085 [ D loss: 0.249938, acc.: 90%] [G loss: 3.923912]\n",
            "3086 [ D loss: 0.180934, acc.: 97%] [G loss: 3.861441]\n",
            "3087 [ D loss: 0.201295, acc.: 95%] [G loss: 5.293156]\n",
            "3088 [ D loss: 0.312736, acc.: 88%] [G loss: 3.431329]\n",
            "3089 [ D loss: 0.327422, acc.: 87%] [G loss: 4.084318]\n",
            "3090 [ D loss: 0.271395, acc.: 89%] [G loss: 4.264608]\n",
            "3091 [ D loss: 0.142343, acc.: 98%] [G loss: 4.550078]\n",
            "3092 [ D loss: 0.156552, acc.: 95%] [G loss: 5.076644]\n",
            "3093 [ D loss: 0.141593, acc.: 98%] [G loss: 4.983520]\n",
            "3094 [ D loss: 0.202070, acc.: 93%] [G loss: 3.217787]\n",
            "3095 [ D loss: 0.182805, acc.: 96%] [G loss: 6.482163]\n",
            "3096 [ D loss: 0.126111, acc.: 97%] [G loss: 6.950114]\n",
            "3097 [ D loss: 0.276580, acc.: 91%] [G loss: 5.927756]\n",
            "3098 [ D loss: 0.149062, acc.: 96%] [G loss: 8.249025]\n",
            "3099 [ D loss: 0.212970, acc.: 92%] [G loss: 4.279189]\n",
            "3100 [ D loss: 0.162566, acc.: 95%] [G loss: 4.170123]\n",
            "3101 [ D loss: 0.134990, acc.: 98%] [G loss: 4.686455]\n",
            "3102 [ D loss: 0.231380, acc.: 88%] [G loss: 4.918454]\n",
            "3103 [ D loss: 0.099657, acc.: 96%] [G loss: 9.966033]\n",
            "3104 [ D loss: 0.121766, acc.: 95%] [G loss: 8.157526]\n",
            "3105 [ D loss: 0.534877, acc.: 76%] [G loss: 4.718497]\n",
            "3106 [ D loss: 0.172105, acc.: 95%] [G loss: 3.852832]\n",
            "3107 [ D loss: 0.192255, acc.: 94%] [G loss: 4.212132]\n",
            "3108 [ D loss: 0.253103, acc.: 91%] [G loss: 3.998644]\n",
            "3109 [ D loss: 0.257137, acc.: 90%] [G loss: 3.619562]\n",
            "3110 [ D loss: 0.270939, acc.: 93%] [G loss: 3.073511]\n",
            "3111 [ D loss: 0.249379, acc.: 93%] [G loss: 4.082790]\n",
            "3112 [ D loss: 0.145012, acc.: 98%] [G loss: 5.175969]\n",
            "3113 [ D loss: 0.181821, acc.: 94%] [G loss: 4.053188]\n",
            "3114 [ D loss: 0.161839, acc.: 95%] [G loss: 4.019777]\n",
            "3115 [ D loss: 0.257799, acc.: 91%] [G loss: 3.433332]\n",
            "3116 [ D loss: 0.227053, acc.: 91%] [G loss: 4.158901]\n",
            "3117 [ D loss: 0.202096, acc.: 95%] [G loss: 8.516731]\n",
            "3118 [ D loss: 0.205017, acc.: 92%] [G loss: 4.786733]\n",
            "3119 [ D loss: 0.179891, acc.: 95%] [G loss: 5.452001]\n",
            "3120 [ D loss: 0.165169, acc.: 95%] [G loss: 4.037347]\n",
            "3121 [ D loss: 0.121837, acc.: 98%] [G loss: 5.154670]\n",
            "3122 [ D loss: 0.186738, acc.: 95%] [G loss: 4.480895]\n",
            "3123 [ D loss: 0.132805, acc.: 96%] [G loss: 4.556263]\n",
            "3124 [ D loss: 0.175898, acc.: 95%] [G loss: 6.256596]\n",
            "3125 [ D loss: 0.110123, acc.: 98%] [G loss: 5.780613]\n",
            "3126 [ D loss: 0.297431, acc.: 88%] [G loss: 3.466377]\n",
            "3127 [ D loss: 0.288874, acc.: 89%] [G loss: 4.058412]\n",
            "3128 [ D loss: 0.273388, acc.: 87%] [G loss: 3.724284]\n",
            "3129 [ D loss: 0.159252, acc.: 95%] [G loss: 4.819088]\n",
            "3130 [ D loss: 0.223235, acc.: 94%] [G loss: 3.608542]\n",
            "3131 [ D loss: 0.183336, acc.: 96%] [G loss: 3.819599]\n",
            "3132 [ D loss: 0.255879, acc.: 88%] [G loss: 3.906859]\n",
            "3133 [ D loss: 0.227325, acc.: 92%] [G loss: 4.318523]\n",
            "3134 [ D loss: 0.220189, acc.: 95%] [G loss: 3.169974]\n",
            "3135 [ D loss: 0.288064, acc.: 90%] [G loss: 4.271414]\n",
            "3136 [ D loss: 0.240816, acc.: 93%] [G loss: 5.308057]\n",
            "3137 [ D loss: 0.213654, acc.: 92%] [G loss: 4.236369]\n",
            "3138 [ D loss: 0.180716, acc.: 95%] [G loss: 4.617961]\n",
            "3139 [ D loss: 0.226685, acc.: 91%] [G loss: 5.320323]\n",
            "3140 [ D loss: 0.190013, acc.: 91%] [G loss: 5.224407]\n",
            "3141 [ D loss: 0.228211, acc.: 89%] [G loss: 6.238585]\n",
            "3142 [ D loss: 0.261178, acc.: 89%] [G loss: 5.714239]\n",
            "3143 [ D loss: 0.312394, acc.: 88%] [G loss: 5.366026]\n",
            "3144 [ D loss: 0.267705, acc.: 91%] [G loss: 3.743871]\n",
            "3145 [ D loss: 0.269386, acc.: 93%] [G loss: 3.609432]\n",
            "3146 [ D loss: 0.237869, acc.: 91%] [G loss: 3.255315]\n",
            "3147 [ D loss: 0.244956, acc.: 90%] [G loss: 3.356061]\n",
            "3148 [ D loss: 0.283994, acc.: 91%] [G loss: 3.476675]\n",
            "3149 [ D loss: 0.253094, acc.: 91%] [G loss: 4.147333]\n",
            "3150 [ D loss: 0.188699, acc.: 95%] [G loss: 3.745858]\n",
            "3151 [ D loss: 0.192825, acc.: 96%] [G loss: 4.373463]\n",
            "3152 [ D loss: 0.212289, acc.: 92%] [G loss: 6.896998]\n",
            "3153 [ D loss: 0.214438, acc.: 94%] [G loss: 4.184591]\n",
            "3154 [ D loss: 0.145118, acc.: 95%] [G loss: 4.495852]\n",
            "3155 [ D loss: 0.233953, acc.: 91%] [G loss: 10.533976]\n",
            "3156 [ D loss: 0.319312, acc.: 88%] [G loss: 5.688265]\n",
            "3157 [ D loss: 0.168203, acc.: 95%] [G loss: 4.047142]\n",
            "3158 [ D loss: 0.173572, acc.: 95%] [G loss: 3.781348]\n",
            "3159 [ D loss: 0.204627, acc.: 91%] [G loss: 5.316235]\n",
            "3160 [ D loss: 0.075781, acc.: 99%] [G loss: 8.250372]\n",
            "3161 [ D loss: 0.162967, acc.: 97%] [G loss: 5.059252]\n",
            "3162 [ D loss: 0.164998, acc.: 93%] [G loss: 7.826434]\n",
            "3163 [ D loss: 0.168811, acc.: 95%] [G loss: 5.975949]\n",
            "3164 [ D loss: 0.169244, acc.: 97%] [G loss: 6.115892]\n",
            "3165 [ D loss: 0.270716, acc.: 89%] [G loss: 5.921101]\n",
            "3166 [ D loss: 0.075332, acc.: 99%] [G loss: 6.818727]\n",
            "3167 [ D loss: 0.223981, acc.: 92%] [G loss: 5.864577]\n",
            "3168 [ D loss: 0.139305, acc.: 97%] [G loss: 5.773178]\n",
            "3169 [ D loss: 0.235010, acc.: 89%] [G loss: 3.367776]\n",
            "3170 [ D loss: 0.241884, acc.: 92%] [G loss: 3.813518]\n",
            "3171 [ D loss: 0.241616, acc.: 93%] [G loss: 3.523526]\n",
            "3172 [ D loss: 0.277325, acc.: 91%] [G loss: 3.568999]\n",
            "3173 [ D loss: 0.333248, acc.: 84%] [G loss: 3.701897]\n",
            "3174 [ D loss: 0.331377, acc.: 91%] [G loss: 3.305955]\n",
            "3175 [ D loss: 0.167646, acc.: 95%] [G loss: 3.209177]\n",
            "3176 [ D loss: 0.159143, acc.: 95%] [G loss: 4.615782]\n",
            "3177 [ D loss: 0.202072, acc.: 91%] [G loss: 4.575781]\n",
            "3178 [ D loss: 0.241521, acc.: 95%] [G loss: 3.410832]\n",
            "3179 [ D loss: 0.250686, acc.: 91%] [G loss: 4.116561]\n",
            "3180 [ D loss: 0.191488, acc.: 92%] [G loss: 5.672451]\n",
            "3181 [ D loss: 0.209628, acc.: 95%] [G loss: 3.575273]\n",
            "3182 [ D loss: 0.254376, acc.: 94%] [G loss: 3.659895]\n",
            "3183 [ D loss: 0.243633, acc.: 90%] [G loss: 4.831959]\n",
            "3184 [ D loss: 0.213693, acc.: 92%] [G loss: 3.998652]\n",
            "3185 [ D loss: 0.177692, acc.: 96%] [G loss: 5.011442]\n",
            "3186 [ D loss: 0.121379, acc.: 95%] [G loss: 5.520274]\n",
            "3187 [ D loss: 0.266598, acc.: 92%] [G loss: 4.757809]\n",
            "3188 [ D loss: 0.178888, acc.: 94%] [G loss: 8.949631]\n",
            "3189 [ D loss: 0.121912, acc.: 96%] [G loss: 10.221611]\n",
            "3190 [ D loss: 0.057561, acc.: 100%] [G loss: 7.773140]\n",
            "3191 [ D loss: 0.159742, acc.: 96%] [G loss: 5.154948]\n",
            "3192 [ D loss: 0.160523, acc.: 95%] [G loss: 4.669743]\n",
            "3193 [ D loss: 0.190277, acc.: 93%] [G loss: 5.082371]\n",
            "3194 [ D loss: 0.247333, acc.: 94%] [G loss: 3.352227]\n",
            "3195 [ D loss: 0.214204, acc.: 95%] [G loss: 4.469769]\n",
            "3196 [ D loss: 0.203665, acc.: 94%] [G loss: 5.166776]\n",
            "3197 [ D loss: 0.125092, acc.: 98%] [G loss: 8.896489]\n",
            "3198 [ D loss: 0.169033, acc.: 95%] [G loss: 5.830459]\n",
            "3199 [ D loss: 0.103604, acc.: 98%] [G loss: 5.847779]\n",
            "3200 [ D loss: 0.239625, acc.: 91%] [G loss: 3.990627]\n",
            "3201 [ D loss: 0.160412, acc.: 95%] [G loss: 5.389318]\n",
            "3202 [ D loss: 0.186102, acc.: 92%] [G loss: 5.059411]\n",
            "3203 [ D loss: 0.178670, acc.: 96%] [G loss: 4.326814]\n",
            "3204 [ D loss: 0.280511, acc.: 89%] [G loss: 4.655290]\n",
            "3205 [ D loss: 0.185279, acc.: 94%] [G loss: 4.196311]\n",
            "3206 [ D loss: 0.197510, acc.: 95%] [G loss: 4.965171]\n",
            "3207 [ D loss: 0.123059, acc.: 98%] [G loss: 9.537189]\n",
            "3208 [ D loss: 0.155109, acc.: 95%] [G loss: 6.063163]\n",
            "3209 [ D loss: 0.102580, acc.: 97%] [G loss: 9.638411]\n",
            "3210 [ D loss: 0.157510, acc.: 96%] [G loss: 6.970764]\n",
            "3211 [ D loss: 0.144676, acc.: 96%] [G loss: 6.483637]\n",
            "3212 [ D loss: 0.200945, acc.: 92%] [G loss: 6.264319]\n",
            "3213 [ D loss: 0.206297, acc.: 93%] [G loss: 3.609126]\n",
            "3214 [ D loss: 0.157875, acc.: 95%] [G loss: 5.601738]\n",
            "3215 [ D loss: 0.223923, acc.: 95%] [G loss: 5.454683]\n",
            "3216 [ D loss: 0.077070, acc.: 98%] [G loss: 6.377656]\n",
            "3217 [ D loss: 0.126752, acc.: 96%] [G loss: 3.838179]\n",
            "3218 [ D loss: 0.278382, acc.: 89%] [G loss: 4.442060]\n",
            "3219 [ D loss: 0.189595, acc.: 91%] [G loss: 5.014342]\n",
            "3220 [ D loss: 0.150759, acc.: 98%] [G loss: 3.565415]\n",
            "3221 [ D loss: 0.160312, acc.: 96%] [G loss: 6.512749]\n",
            "3222 [ D loss: 0.154492, acc.: 95%] [G loss: 7.627116]\n",
            "3223 [ D loss: 0.265145, acc.: 93%] [G loss: 6.183491]\n",
            "3224 [ D loss: 0.101293, acc.: 98%] [G loss: 8.771676]\n",
            "3225 [ D loss: 0.269505, acc.: 91%] [G loss: 5.169742]\n",
            "3226 [ D loss: 0.177220, acc.: 94%] [G loss: 5.258553]\n",
            "3227 [ D loss: 0.185547, acc.: 95%] [G loss: 4.111932]\n",
            "3228 [ D loss: 0.146911, acc.: 98%] [G loss: 4.593681]\n",
            "3229 [ D loss: 0.217361, acc.: 95%] [G loss: 9.222813]\n",
            "3230 [ D loss: 0.256239, acc.: 89%] [G loss: 5.551445]\n",
            "3231 [ D loss: 0.180457, acc.: 95%] [G loss: 4.416377]\n",
            "3232 [ D loss: 0.272261, acc.: 90%] [G loss: 5.580881]\n",
            "3233 [ D loss: 0.134359, acc.: 95%] [G loss: 6.778580]\n",
            "3234 [ D loss: 0.208380, acc.: 95%] [G loss: 8.293902]\n",
            "3235 [ D loss: 0.092152, acc.: 98%] [G loss: 4.347702]\n",
            "3236 [ D loss: 0.224654, acc.: 91%] [G loss: 5.871547]\n",
            "3237 [ D loss: 0.193924, acc.: 94%] [G loss: 4.780472]\n",
            "3238 [ D loss: 0.370404, acc.: 84%] [G loss: 5.870225]\n",
            "3239 [ D loss: 0.162223, acc.: 94%] [G loss: 9.009360]\n",
            "3240 [ D loss: 0.206727, acc.: 95%] [G loss: 5.435627]\n",
            "3241 [ D loss: 0.123513, acc.: 98%] [G loss: 5.711154]\n",
            "3242 [ D loss: 0.154667, acc.: 97%] [G loss: 3.860938]\n",
            "3243 [ D loss: 0.129932, acc.: 98%] [G loss: 4.688074]\n",
            "3244 [ D loss: 0.226726, acc.: 93%] [G loss: 3.714535]\n",
            "3245 [ D loss: 0.272838, acc.: 92%] [G loss: 3.541562]\n",
            "3246 [ D loss: 0.230232, acc.: 91%] [G loss: 6.064625]\n",
            "3247 [ D loss: 0.177765, acc.: 92%] [G loss: 3.612316]\n",
            "3248 [ D loss: 0.250870, acc.: 89%] [G loss: 3.523333]\n",
            "3249 [ D loss: 0.151317, acc.: 98%] [G loss: 4.678253]\n",
            "3250 [ D loss: 0.216658, acc.: 90%] [G loss: 4.653536]\n",
            "3251 [ D loss: 0.187438, acc.: 94%] [G loss: 5.418590]\n",
            "3252 [ D loss: 0.338235, acc.: 84%] [G loss: 4.237552]\n",
            "3253 [ D loss: 0.198749, acc.: 95%] [G loss: 4.441164]\n",
            "3254 [ D loss: 0.382481, acc.: 81%] [G loss: 4.491002]\n",
            "3255 [ D loss: 0.328089, acc.: 80%] [G loss: 4.910293]\n",
            "3256 [ D loss: 0.287853, acc.: 87%] [G loss: 4.521000]\n",
            "3257 [ D loss: 0.237832, acc.: 94%] [G loss: 5.144515]\n",
            "3258 [ D loss: 0.202633, acc.: 94%] [G loss: 7.530779]\n",
            "3259 [ D loss: 0.117806, acc.: 95%] [G loss: 9.782667]\n",
            "3260 [ D loss: 0.182895, acc.: 95%] [G loss: 4.347655]\n",
            "3261 [ D loss: 0.054915, acc.: 99%] [G loss: 8.962160]\n",
            "3262 [ D loss: 0.202634, acc.: 91%] [G loss: 4.768167]\n",
            "3263 [ D loss: 0.134748, acc.: 97%] [G loss: 3.706848]\n",
            "3264 [ D loss: 0.280897, acc.: 89%] [G loss: 4.320511]\n",
            "3265 [ D loss: 0.146325, acc.: 98%] [G loss: 5.719326]\n",
            "3266 [ D loss: 0.299987, acc.: 88%] [G loss: 4.587862]\n",
            "3267 [ D loss: 0.220231, acc.: 92%] [G loss: 4.431842]\n",
            "3268 [ D loss: 0.233728, acc.: 94%] [G loss: 5.127142]\n",
            "3269 [ D loss: 0.283086, acc.: 88%] [G loss: 4.273335]\n",
            "3270 [ D loss: 0.369224, acc.: 86%] [G loss: 5.259225]\n",
            "3271 [ D loss: 0.273239, acc.: 90%] [G loss: 4.359291]\n",
            "3272 [ D loss: 0.190840, acc.: 96%] [G loss: 4.066084]\n",
            "3273 [ D loss: 0.149088, acc.: 95%] [G loss: 5.548286]\n",
            "3274 [ D loss: 0.242460, acc.: 95%] [G loss: 4.448471]\n",
            "3275 [ D loss: 0.234329, acc.: 93%] [G loss: 4.837755]\n",
            "3276 [ D loss: 0.183021, acc.: 93%] [G loss: 5.301802]\n",
            "3277 [ D loss: 0.254146, acc.: 88%] [G loss: 4.024980]\n",
            "3278 [ D loss: 0.162810, acc.: 98%] [G loss: 4.662506]\n",
            "3279 [ D loss: 0.228059, acc.: 93%] [G loss: 5.178170]\n",
            "3280 [ D loss: 0.238115, acc.: 96%] [G loss: 4.156713]\n",
            "3281 [ D loss: 0.208707, acc.: 94%] [G loss: 4.043079]\n",
            "3282 [ D loss: 0.316659, acc.: 87%] [G loss: 4.685578]\n",
            "3283 [ D loss: 0.169468, acc.: 94%] [G loss: 3.875004]\n",
            "3284 [ D loss: 0.158140, acc.: 95%] [G loss: 3.537986]\n",
            "3285 [ D loss: 0.319305, acc.: 84%] [G loss: 5.108319]\n",
            "3286 [ D loss: 0.323659, acc.: 85%] [G loss: 3.832921]\n",
            "3287 [ D loss: 0.422773, acc.: 83%] [G loss: 3.720980]\n",
            "3288 [ D loss: 0.207264, acc.: 96%] [G loss: 4.558441]\n",
            "3289 [ D loss: 0.144956, acc.: 97%] [G loss: 4.214106]\n",
            "3290 [ D loss: 0.292035, acc.: 88%] [G loss: 4.355453]\n",
            "3291 [ D loss: 0.216606, acc.: 89%] [G loss: 5.026675]\n",
            "3292 [ D loss: 0.162907, acc.: 95%] [G loss: 5.103472]\n",
            "3293 [ D loss: 0.158866, acc.: 96%] [G loss: 3.471025]\n",
            "3294 [ D loss: 0.247837, acc.: 91%] [G loss: 4.500129]\n",
            "3295 [ D loss: 0.223375, acc.: 93%] [G loss: 3.660618]\n",
            "3296 [ D loss: 0.392424, acc.: 84%] [G loss: 3.874174]\n",
            "3297 [ D loss: 0.342186, acc.: 89%] [G loss: 4.127363]\n",
            "3298 [ D loss: 0.170131, acc.: 95%] [G loss: 3.742139]\n",
            "3299 [ D loss: 0.204941, acc.: 95%] [G loss: 4.089877]\n",
            "3300 [ D loss: 0.122684, acc.: 97%] [G loss: 4.999813]\n",
            "3301 [ D loss: 0.181313, acc.: 95%] [G loss: 4.622050]\n",
            "3302 [ D loss: 0.179721, acc.: 97%] [G loss: 3.891762]\n",
            "3303 [ D loss: 0.239692, acc.: 91%] [G loss: 4.930682]\n",
            "3304 [ D loss: 0.119595, acc.: 99%] [G loss: 4.382797]\n",
            "3305 [ D loss: 0.199860, acc.: 93%] [G loss: 4.681199]\n",
            "3306 [ D loss: 0.125281, acc.: 99%] [G loss: 4.038976]\n",
            "3307 [ D loss: 0.265842, acc.: 88%] [G loss: 4.875489]\n",
            "3308 [ D loss: 0.189349, acc.: 95%] [G loss: 4.382111]\n",
            "3309 [ D loss: 0.258596, acc.: 92%] [G loss: 3.822580]\n",
            "3310 [ D loss: 0.216485, acc.: 93%] [G loss: 4.027310]\n",
            "3311 [ D loss: 0.248768, acc.: 92%] [G loss: 3.134905]\n",
            "3312 [ D loss: 0.324700, acc.: 89%] [G loss: 3.295676]\n",
            "3313 [ D loss: 0.296525, acc.: 91%] [G loss: 5.104589]\n",
            "3314 [ D loss: 0.150475, acc.: 95%] [G loss: 4.785137]\n",
            "3315 [ D loss: 0.204025, acc.: 93%] [G loss: 4.695095]\n",
            "3316 [ D loss: 0.133703, acc.: 98%] [G loss: 5.401206]\n",
            "3317 [ D loss: 0.164114, acc.: 96%] [G loss: 4.084984]\n",
            "3318 [ D loss: 0.249559, acc.: 92%] [G loss: 3.352319]\n",
            "3319 [ D loss: 0.347630, acc.: 89%] [G loss: 5.034730]\n",
            "3320 [ D loss: 0.201226, acc.: 94%] [G loss: 2.995952]\n",
            "3321 [ D loss: 0.190841, acc.: 95%] [G loss: 4.387363]\n",
            "3322 [ D loss: 0.140640, acc.: 97%] [G loss: 2.971711]\n",
            "3323 [ D loss: 0.171328, acc.: 95%] [G loss: 5.090405]\n",
            "3324 [ D loss: 0.129213, acc.: 95%] [G loss: 6.899922]\n",
            "3325 [ D loss: 0.197752, acc.: 96%] [G loss: 3.734885]\n",
            "3326 [ D loss: 0.162978, acc.: 96%] [G loss: 3.239741]\n",
            "3327 [ D loss: 0.251609, acc.: 89%] [G loss: 3.321397]\n",
            "3328 [ D loss: 0.196656, acc.: 93%] [G loss: 4.284631]\n",
            "3329 [ D loss: 0.175395, acc.: 97%] [G loss: 3.006186]\n",
            "3330 [ D loss: 0.141006, acc.: 97%] [G loss: 4.377361]\n",
            "3331 [ D loss: 0.186142, acc.: 92%] [G loss: 5.726777]\n",
            "3332 [ D loss: 0.164911, acc.: 96%] [G loss: 4.278718]\n",
            "3333 [ D loss: 0.171960, acc.: 95%] [G loss: 4.299251]\n",
            "3334 [ D loss: 0.132477, acc.: 96%] [G loss: 5.165967]\n",
            "3335 [ D loss: 0.175675, acc.: 94%] [G loss: 3.575905]\n",
            "3336 [ D loss: 0.249039, acc.: 92%] [G loss: 4.915369]\n",
            "3337 [ D loss: 0.231895, acc.: 92%] [G loss: 6.697814]\n",
            "3338 [ D loss: 0.162070, acc.: 97%] [G loss: 5.392786]\n",
            "3339 [ D loss: 0.198005, acc.: 93%] [G loss: 6.006633]\n",
            "3340 [ D loss: 0.162652, acc.: 94%] [G loss: 4.009682]\n",
            "3341 [ D loss: 0.211021, acc.: 91%] [G loss: 3.628574]\n",
            "3342 [ D loss: 0.105847, acc.: 99%] [G loss: 5.223846]\n",
            "3343 [ D loss: 0.173700, acc.: 96%] [G loss: 5.411278]\n",
            "3344 [ D loss: 0.126382, acc.: 96%] [G loss: 4.643476]\n",
            "3345 [ D loss: 0.318576, acc.: 86%] [G loss: 3.468234]\n",
            "3346 [ D loss: 0.276530, acc.: 87%] [G loss: 5.853128]\n",
            "3347 [ D loss: 0.131410, acc.: 98%] [G loss: 4.877432]\n",
            "3348 [ D loss: 0.101869, acc.: 98%] [G loss: 5.417128]\n",
            "3349 [ D loss: 0.207894, acc.: 93%] [G loss: 4.505007]\n",
            "3350 [ D loss: 0.085567, acc.: 97%] [G loss: 9.217966]\n",
            "3351 [ D loss: 0.101930, acc.: 98%] [G loss: 5.986534]\n",
            "3352 [ D loss: 0.102249, acc.: 97%] [G loss: 3.247391]\n",
            "3353 [ D loss: 0.097463, acc.: 98%] [G loss: 5.524378]\n",
            "3354 [ D loss: 0.117722, acc.: 98%] [G loss: 3.945719]\n",
            "3355 [ D loss: 0.198693, acc.: 91%] [G loss: 3.162932]\n",
            "3356 [ D loss: 0.145755, acc.: 97%] [G loss: 7.062408]\n",
            "3357 [ D loss: 0.184010, acc.: 97%] [G loss: 4.970181]\n",
            "3358 [ D loss: 0.112944, acc.: 98%] [G loss: 4.024497]\n",
            "3359 [ D loss: 0.230513, acc.: 95%] [G loss: 4.466266]\n",
            "3360 [ D loss: 0.187608, acc.: 92%] [G loss: 4.076056]\n",
            "3361 [ D loss: 0.225722, acc.: 94%] [G loss: 3.615297]\n",
            "3362 [ D loss: 0.177843, acc.: 97%] [G loss: 3.232248]\n",
            "3363 [ D loss: 0.167076, acc.: 95%] [G loss: 4.113040]\n",
            "3364 [ D loss: 0.196890, acc.: 94%] [G loss: 4.259086]\n",
            "3365 [ D loss: 0.239602, acc.: 91%] [G loss: 3.664769]\n",
            "3366 [ D loss: 0.230282, acc.: 95%] [G loss: 4.577719]\n",
            "3367 [ D loss: 0.324198, acc.: 87%] [G loss: 3.108636]\n",
            "3368 [ D loss: 0.210989, acc.: 95%] [G loss: 3.705379]\n",
            "3369 [ D loss: 0.144909, acc.: 95%] [G loss: 4.240951]\n",
            "3370 [ D loss: 0.126094, acc.: 98%] [G loss: 3.529196]\n",
            "3371 [ D loss: 0.154214, acc.: 95%] [G loss: 5.737054]\n",
            "3372 [ D loss: 0.091592, acc.: 98%] [G loss: 5.118406]\n",
            "3373 [ D loss: 0.202868, acc.: 92%] [G loss: 4.673785]\n",
            "3374 [ D loss: 0.197284, acc.: 95%] [G loss: 4.635582]\n",
            "3375 [ D loss: 0.221662, acc.: 95%] [G loss: 4.573201]\n",
            "3376 [ D loss: 0.106636, acc.: 98%] [G loss: 6.317918]\n",
            "3377 [ D loss: 0.092459, acc.: 99%] [G loss: 4.911512]\n",
            "3378 [ D loss: 0.349153, acc.: 82%] [G loss: 4.167595]\n",
            "3379 [ D loss: 0.306804, acc.: 88%] [G loss: 5.717842]\n",
            "3380 [ D loss: 0.112328, acc.: 95%] [G loss: 7.791794]\n",
            "3381 [ D loss: 0.098530, acc.: 98%] [G loss: 8.646970]\n",
            "3382 [ D loss: 0.082128, acc.: 98%] [G loss: 5.412696]\n",
            "3383 [ D loss: 0.108141, acc.: 95%] [G loss: 5.507278]\n",
            "3384 [ D loss: 0.138068, acc.: 97%] [G loss: 8.467263]\n",
            "3385 [ D loss: 0.190528, acc.: 91%] [G loss: 4.553287]\n",
            "3386 [ D loss: 0.221866, acc.: 92%] [G loss: 4.881047]\n",
            "3387 [ D loss: 0.291098, acc.: 88%] [G loss: 5.160882]\n",
            "3388 [ D loss: 0.204725, acc.: 92%] [G loss: 6.145123]\n",
            "3389 [ D loss: 0.162084, acc.: 94%] [G loss: 6.224666]\n",
            "3390 [ D loss: 0.282996, acc.: 92%] [G loss: 3.985722]\n",
            "3391 [ D loss: 0.085633, acc.: 98%] [G loss: 5.431545]\n",
            "3392 [ D loss: 0.211723, acc.: 94%] [G loss: 5.647067]\n",
            "3393 [ D loss: 0.095236, acc.: 98%] [G loss: 9.074865]\n",
            "3394 [ D loss: 0.131725, acc.: 96%] [G loss: 6.015654]\n",
            "3395 [ D loss: 0.080928, acc.: 98%] [G loss: 6.812895]\n",
            "3396 [ D loss: 0.232547, acc.: 93%] [G loss: 4.201130]\n",
            "3397 [ D loss: 0.211024, acc.: 91%] [G loss: 8.911598]\n",
            "3398 [ D loss: 0.166718, acc.: 92%] [G loss: 6.553285]\n",
            "3399 [ D loss: 0.184082, acc.: 95%] [G loss: 6.806701]\n",
            "3400 [ D loss: 0.115412, acc.: 97%] [G loss: 5.554473]\n",
            "3401 [ D loss: 0.254512, acc.: 91%] [G loss: 4.057339]\n",
            "3402 [ D loss: 0.320883, acc.: 88%] [G loss: 3.852402]\n",
            "3403 [ D loss: 0.232720, acc.: 94%] [G loss: 5.065394]\n",
            "3404 [ D loss: 0.227816, acc.: 91%] [G loss: 6.065044]\n",
            "3405 [ D loss: 0.165036, acc.: 93%] [G loss: 4.334250]\n",
            "3406 [ D loss: 0.235666, acc.: 91%] [G loss: 4.296624]\n",
            "3407 [ D loss: 0.167794, acc.: 97%] [G loss: 4.313985]\n",
            "3408 [ D loss: 0.376848, acc.: 88%] [G loss: 3.951833]\n",
            "3409 [ D loss: 0.194995, acc.: 94%] [G loss: 3.738744]\n",
            "3410 [ D loss: 0.167416, acc.: 95%] [G loss: 3.617999]\n",
            "3411 [ D loss: 0.251006, acc.: 91%] [G loss: 3.982664]\n",
            "3412 [ D loss: 0.152856, acc.: 95%] [G loss: 5.667904]\n",
            "3413 [ D loss: 0.162137, acc.: 98%] [G loss: 4.058755]\n",
            "3414 [ D loss: 0.167248, acc.: 95%] [G loss: 3.325910]\n",
            "3415 [ D loss: 0.110710, acc.: 97%] [G loss: 4.782165]\n",
            "3416 [ D loss: 0.119361, acc.: 98%] [G loss: 5.194528]\n",
            "3417 [ D loss: 0.138760, acc.: 98%] [G loss: 6.651340]\n",
            "3418 [ D loss: 0.125083, acc.: 96%] [G loss: 4.313886]\n",
            "3419 [ D loss: 0.330406, acc.: 84%] [G loss: 5.279460]\n",
            "3420 [ D loss: 0.403531, acc.: 82%] [G loss: 5.405779]\n",
            "3421 [ D loss: 0.217825, acc.: 93%] [G loss: 4.960989]\n",
            "3422 [ D loss: 0.168029, acc.: 95%] [G loss: 6.728098]\n",
            "3423 [ D loss: 0.109520, acc.: 99%] [G loss: 5.519063]\n",
            "3424 [ D loss: 0.110692, acc.: 98%] [G loss: 6.653815]\n",
            "3425 [ D loss: 0.151271, acc.: 95%] [G loss: 4.176156]\n",
            "3426 [ D loss: 0.147608, acc.: 97%] [G loss: 4.009499]\n",
            "3427 [ D loss: 0.185180, acc.: 95%] [G loss: 3.802562]\n",
            "3428 [ D loss: 0.141059, acc.: 97%] [G loss: 4.552616]\n",
            "3429 [ D loss: 0.204599, acc.: 95%] [G loss: 6.065598]\n",
            "3430 [ D loss: 0.172451, acc.: 94%] [G loss: 4.457334]\n",
            "3431 [ D loss: 0.254676, acc.: 92%] [G loss: 4.190156]\n",
            "3432 [ D loss: 0.175389, acc.: 93%] [G loss: 4.206478]\n",
            "3433 [ D loss: 0.106212, acc.: 95%] [G loss: 8.376895]\n",
            "3434 [ D loss: 0.126460, acc.: 98%] [G loss: 4.588161]\n",
            "3435 [ D loss: 0.095355, acc.: 98%] [G loss: 5.105470]\n",
            "3436 [ D loss: 0.142557, acc.: 98%] [G loss: 5.704292]\n",
            "3437 [ D loss: 0.137904, acc.: 94%] [G loss: 5.858048]\n",
            "3438 [ D loss: 0.184796, acc.: 94%] [G loss: 7.807853]\n",
            "3439 [ D loss: 0.142439, acc.: 97%] [G loss: 6.063568]\n",
            "3440 [ D loss: 0.178191, acc.: 96%] [G loss: 5.579988]\n",
            "3441 [ D loss: 0.200266, acc.: 95%] [G loss: 3.290376]\n",
            "3442 [ D loss: 0.168780, acc.: 95%] [G loss: 4.265808]\n",
            "3443 [ D loss: 0.146155, acc.: 96%] [G loss: 3.426335]\n",
            "3444 [ D loss: 0.159995, acc.: 95%] [G loss: 3.653215]\n",
            "3445 [ D loss: 0.193747, acc.: 94%] [G loss: 5.825722]\n",
            "3446 [ D loss: 0.157858, acc.: 97%] [G loss: 3.651599]\n",
            "3447 [ D loss: 0.067097, acc.: 98%] [G loss: 6.316206]\n",
            "3448 [ D loss: 0.114622, acc.: 96%] [G loss: 4.850757]\n",
            "3449 [ D loss: 0.154234, acc.: 97%] [G loss: 3.770717]\n",
            "3450 [ D loss: 0.161467, acc.: 93%] [G loss: 6.683885]\n",
            "3451 [ D loss: 0.126763, acc.: 96%] [G loss: 5.697446]\n",
            "3452 [ D loss: 0.162690, acc.: 93%] [G loss: 4.655457]\n",
            "3453 [ D loss: 0.200327, acc.: 93%] [G loss: 11.406197]\n",
            "3454 [ D loss: 0.102706, acc.: 95%] [G loss: 7.261919]\n",
            "3455 [ D loss: 0.262050, acc.: 90%] [G loss: 7.287244]\n",
            "3456 [ D loss: 0.125747, acc.: 95%] [G loss: 7.250306]\n",
            "3457 [ D loss: 0.148445, acc.: 97%] [G loss: 4.775899]\n",
            "3458 [ D loss: 0.307863, acc.: 89%] [G loss: 4.450623]\n",
            "3459 [ D loss: 0.137722, acc.: 97%] [G loss: 4.485900]\n",
            "3460 [ D loss: 0.094905, acc.: 98%] [G loss: 4.673169]\n",
            "3461 [ D loss: 0.190727, acc.: 92%] [G loss: 4.883423]\n",
            "3462 [ D loss: 0.196313, acc.: 93%] [G loss: 6.883422]\n",
            "3463 [ D loss: 0.240193, acc.: 91%] [G loss: 4.533854]\n",
            "3464 [ D loss: 0.265227, acc.: 89%] [G loss: 4.284350]\n",
            "3465 [ D loss: 0.184241, acc.: 94%] [G loss: 4.245943]\n",
            "3466 [ D loss: 0.212512, acc.: 95%] [G loss: 4.053507]\n",
            "3467 [ D loss: 0.195784, acc.: 94%] [G loss: 4.232901]\n",
            "3468 [ D loss: 0.205519, acc.: 93%] [G loss: 3.585588]\n",
            "3469 [ D loss: 0.138337, acc.: 95%] [G loss: 4.653582]\n",
            "3470 [ D loss: 0.241567, acc.: 90%] [G loss: 4.670566]\n",
            "3471 [ D loss: 0.131871, acc.: 96%] [G loss: 6.416659]\n",
            "3472 [ D loss: 0.254362, acc.: 86%] [G loss: 5.417603]\n",
            "3473 [ D loss: 0.177289, acc.: 94%] [G loss: 7.799363]\n",
            "3474 [ D loss: 0.106566, acc.: 98%] [G loss: 8.598268]\n",
            "3475 [ D loss: 0.162717, acc.: 96%] [G loss: 5.880086]\n",
            "3476 [ D loss: 0.171414, acc.: 97%] [G loss: 6.793959]\n",
            "3477 [ D loss: 0.159830, acc.: 95%] [G loss: 8.362473]\n",
            "3478 [ D loss: 0.157841, acc.: 95%] [G loss: 5.376577]\n",
            "3479 [ D loss: 0.175925, acc.: 92%] [G loss: 5.906403]\n",
            "3480 [ D loss: 0.108282, acc.: 96%] [G loss: 7.438664]\n",
            "3481 [ D loss: 0.157159, acc.: 95%] [G loss: 6.341398]\n",
            "3482 [ D loss: 0.114984, acc.: 98%] [G loss: 3.830363]\n",
            "3483 [ D loss: 0.122955, acc.: 95%] [G loss: 4.704112]\n",
            "3484 [ D loss: 0.221355, acc.: 91%] [G loss: 4.623400]\n",
            "3485 [ D loss: 0.127682, acc.: 97%] [G loss: 5.047721]\n",
            "3486 [ D loss: 0.175053, acc.: 95%] [G loss: 3.887488]\n",
            "3487 [ D loss: 0.142215, acc.: 97%] [G loss: 5.274579]\n",
            "3488 [ D loss: 0.229159, acc.: 93%] [G loss: 5.868755]\n",
            "3489 [ D loss: 0.171642, acc.: 92%] [G loss: 6.777569]\n",
            "3490 [ D loss: 0.341073, acc.: 83%] [G loss: 5.725995]\n",
            "3491 [ D loss: 0.123823, acc.: 96%] [G loss: 8.863226]\n",
            "3492 [ D loss: 0.091290, acc.: 97%] [G loss: 6.134300]\n",
            "3493 [ D loss: 0.105538, acc.: 96%] [G loss: 6.483768]\n",
            "3494 [ D loss: 0.247059, acc.: 91%] [G loss: 4.660306]\n",
            "3495 [ D loss: 0.118950, acc.: 95%] [G loss: 5.375492]\n",
            "3496 [ D loss: 0.128400, acc.: 98%] [G loss: 6.654044]\n",
            "3497 [ D loss: 0.187132, acc.: 94%] [G loss: 5.034102]\n",
            "3498 [ D loss: 0.100479, acc.: 98%] [G loss: 4.593679]\n",
            "3499 [ D loss: 0.282197, acc.: 88%] [G loss: 8.555899]\n",
            "3500 [ D loss: 0.316874, acc.: 86%] [G loss: 5.697129]\n",
            "3501 [ D loss: 0.223875, acc.: 95%] [G loss: 3.815336]\n",
            "3502 [ D loss: 0.193566, acc.: 94%] [G loss: 3.924166]\n",
            "3503 [ D loss: 0.174366, acc.: 96%] [G loss: 6.440004]\n",
            "3504 [ D loss: 0.187776, acc.: 95%] [G loss: 4.186439]\n",
            "3505 [ D loss: 0.208311, acc.: 93%] [G loss: 3.984028]\n",
            "3506 [ D loss: 0.214766, acc.: 93%] [G loss: 4.648930]\n",
            "3507 [ D loss: 0.197575, acc.: 95%] [G loss: 3.727936]\n",
            "3508 [ D loss: 0.277503, acc.: 90%] [G loss: 4.577329]\n",
            "3509 [ D loss: 0.178770, acc.: 93%] [G loss: 5.376675]\n",
            "3510 [ D loss: 0.236811, acc.: 94%] [G loss: 4.679373]\n",
            "3511 [ D loss: 0.115557, acc.: 98%] [G loss: 6.882472]\n",
            "3512 [ D loss: 0.188237, acc.: 95%] [G loss: 5.627693]\n",
            "3513 [ D loss: 0.288631, acc.: 88%] [G loss: 4.957437]\n",
            "3514 [ D loss: 0.103463, acc.: 95%] [G loss: 6.768037]\n",
            "3515 [ D loss: 0.172118, acc.: 93%] [G loss: 3.493998]\n",
            "3516 [ D loss: 0.125570, acc.: 98%] [G loss: 5.309800]\n",
            "3517 [ D loss: 0.099924, acc.: 98%] [G loss: 5.064221]\n",
            "3518 [ D loss: 0.148332, acc.: 97%] [G loss: 8.617484]\n",
            "3519 [ D loss: 0.203583, acc.: 92%] [G loss: 4.453295]\n",
            "3520 [ D loss: 0.255597, acc.: 88%] [G loss: 4.232836]\n",
            "3521 [ D loss: 0.209811, acc.: 93%] [G loss: 8.337944]\n",
            "3522 [ D loss: 0.238810, acc.: 92%] [G loss: 6.818379]\n",
            "3523 [ D loss: 0.231916, acc.: 91%] [G loss: 6.056435]\n",
            "3524 [ D loss: 0.127543, acc.: 96%] [G loss: 5.103365]\n",
            "3525 [ D loss: 0.215956, acc.: 95%] [G loss: 3.966990]\n",
            "3526 [ D loss: 0.179945, acc.: 95%] [G loss: 5.904254]\n",
            "3527 [ D loss: 0.203074, acc.: 94%] [G loss: 5.181964]\n",
            "3528 [ D loss: 0.185707, acc.: 92%] [G loss: 4.203326]\n",
            "3529 [ D loss: 0.145465, acc.: 97%] [G loss: 5.564308]\n",
            "3530 [ D loss: 0.221406, acc.: 93%] [G loss: 4.803101]\n",
            "3531 [ D loss: 0.159523, acc.: 95%] [G loss: 4.935231]\n",
            "3532 [ D loss: 0.313607, acc.: 87%] [G loss: 4.142516]\n",
            "3533 [ D loss: 0.107714, acc.: 98%] [G loss: 6.001619]\n",
            "3534 [ D loss: 0.172317, acc.: 96%] [G loss: 5.087856]\n",
            "3535 [ D loss: 0.144100, acc.: 97%] [G loss: 6.350409]\n",
            "3536 [ D loss: 0.145547, acc.: 96%] [G loss: 7.943163]\n",
            "3537 [ D loss: 0.287357, acc.: 85%] [G loss: 4.656410]\n",
            "3538 [ D loss: 0.175016, acc.: 94%] [G loss: 6.478066]\n",
            "3539 [ D loss: 0.178567, acc.: 95%] [G loss: 4.698658]\n",
            "3540 [ D loss: 0.218852, acc.: 92%] [G loss: 4.106027]\n",
            "3541 [ D loss: 0.235952, acc.: 94%] [G loss: 5.069312]\n",
            "3542 [ D loss: 0.139983, acc.: 95%] [G loss: 6.219678]\n",
            "3543 [ D loss: 0.237360, acc.: 88%] [G loss: 4.561778]\n",
            "3544 [ D loss: 0.195641, acc.: 95%] [G loss: 6.987773]\n",
            "3545 [ D loss: 0.215610, acc.: 93%] [G loss: 5.318031]\n",
            "3546 [ D loss: 0.190651, acc.: 95%] [G loss: 4.040372]\n",
            "3547 [ D loss: 0.291527, acc.: 86%] [G loss: 4.131096]\n",
            "3548 [ D loss: 0.177222, acc.: 92%] [G loss: 6.500848]\n",
            "3549 [ D loss: 0.307670, acc.: 90%] [G loss: 7.644147]\n",
            "3550 [ D loss: 0.141356, acc.: 96%] [G loss: 6.417741]\n",
            "3551 [ D loss: 0.118886, acc.: 99%] [G loss: 7.540209]\n",
            "3552 [ D loss: 0.148716, acc.: 94%] [G loss: 5.791189]\n",
            "3553 [ D loss: 0.175768, acc.: 92%] [G loss: 4.320292]\n",
            "3554 [ D loss: 0.171791, acc.: 96%] [G loss: 6.489995]\n",
            "3555 [ D loss: 0.121194, acc.: 96%] [G loss: 5.821187]\n",
            "3556 [ D loss: 0.318984, acc.: 85%] [G loss: 4.013497]\n",
            "3557 [ D loss: 0.242980, acc.: 92%] [G loss: 4.714902]\n",
            "3558 [ D loss: 0.248944, acc.: 90%] [G loss: 3.775654]\n",
            "3559 [ D loss: 0.193968, acc.: 95%] [G loss: 4.152891]\n",
            "3560 [ D loss: 0.117726, acc.: 98%] [G loss: 4.196301]\n",
            "3561 [ D loss: 0.183092, acc.: 98%] [G loss: 4.347143]\n",
            "3562 [ D loss: 0.143924, acc.: 97%] [G loss: 5.118754]\n",
            "3563 [ D loss: 0.117125, acc.: 99%] [G loss: 5.114558]\n",
            "3564 [ D loss: 0.184314, acc.: 93%] [G loss: 6.273153]\n",
            "3565 [ D loss: 0.207235, acc.: 90%] [G loss: 4.465596]\n",
            "3566 [ D loss: 0.111806, acc.: 97%] [G loss: 5.792072]\n",
            "3567 [ D loss: 0.150652, acc.: 93%] [G loss: 10.273113]\n",
            "3568 [ D loss: 0.071989, acc.: 100%] [G loss: 6.632786]\n",
            "3569 [ D loss: 0.215382, acc.: 91%] [G loss: 4.941122]\n",
            "3570 [ D loss: 0.108158, acc.: 97%] [G loss: 7.050746]\n",
            "3571 [ D loss: 0.149827, acc.: 95%] [G loss: 4.967701]\n",
            "3572 [ D loss: 0.210259, acc.: 95%] [G loss: 3.876826]\n",
            "3573 [ D loss: 0.228494, acc.: 95%] [G loss: 5.106764]\n",
            "3574 [ D loss: 0.275511, acc.: 90%] [G loss: 3.988407]\n",
            "3575 [ D loss: 0.236593, acc.: 91%] [G loss: 5.653236]\n",
            "3576 [ D loss: 0.149351, acc.: 95%] [G loss: 4.637171]\n",
            "3577 [ D loss: 0.132824, acc.: 97%] [G loss: 7.946168]\n",
            "3578 [ D loss: 0.180368, acc.: 91%] [G loss: 6.136709]\n",
            "3579 [ D loss: 0.156806, acc.: 97%] [G loss: 6.278803]\n",
            "3580 [ D loss: 0.126049, acc.: 96%] [G loss: 5.696648]\n",
            "3581 [ D loss: 0.154500, acc.: 98%] [G loss: 4.824103]\n",
            "3582 [ D loss: 0.144975, acc.: 95%] [G loss: 4.034587]\n",
            "3583 [ D loss: 0.148895, acc.: 97%] [G loss: 2.762068]\n",
            "3584 [ D loss: 0.258905, acc.: 90%] [G loss: 4.528213]\n",
            "3585 [ D loss: 0.133491, acc.: 97%] [G loss: 3.779029]\n",
            "3586 [ D loss: 0.238122, acc.: 93%] [G loss: 3.960009]\n",
            "3587 [ D loss: 0.222768, acc.: 93%] [G loss: 4.104805]\n",
            "3588 [ D loss: 0.309741, acc.: 86%] [G loss: 3.687870]\n",
            "3589 [ D loss: 0.223449, acc.: 90%] [G loss: 4.060615]\n",
            "3590 [ D loss: 0.147387, acc.: 95%] [G loss: 7.520404]\n",
            "3591 [ D loss: 0.201194, acc.: 96%] [G loss: 5.220688]\n",
            "3592 [ D loss: 0.215816, acc.: 95%] [G loss: 4.409701]\n",
            "3593 [ D loss: 0.169298, acc.: 91%] [G loss: 5.435720]\n",
            "3594 [ D loss: 0.233552, acc.: 90%] [G loss: 5.028242]\n",
            "3595 [ D loss: 0.098082, acc.: 98%] [G loss: 4.619691]\n",
            "3596 [ D loss: 0.183372, acc.: 95%] [G loss: 3.831543]\n",
            "3597 [ D loss: 0.182567, acc.: 97%] [G loss: 4.329535]\n",
            "3598 [ D loss: 0.155235, acc.: 95%] [G loss: 5.983659]\n",
            "3599 [ D loss: 0.295500, acc.: 89%] [G loss: 4.067941]\n",
            "3600 [ D loss: 0.164938, acc.: 97%] [G loss: 4.692299]\n",
            "3601 [ D loss: 0.241047, acc.: 91%] [G loss: 3.915581]\n",
            "3602 [ D loss: 0.269374, acc.: 92%] [G loss: 3.455507]\n",
            "3603 [ D loss: 0.210422, acc.: 94%] [G loss: 4.291064]\n",
            "3604 [ D loss: 0.149327, acc.: 96%] [G loss: 5.945267]\n",
            "3605 [ D loss: 0.124878, acc.: 97%] [G loss: 3.813883]\n",
            "3606 [ D loss: 0.283841, acc.: 90%] [G loss: 3.638352]\n",
            "3607 [ D loss: 0.189636, acc.: 93%] [G loss: 5.091289]\n",
            "3608 [ D loss: 0.206402, acc.: 93%] [G loss: 3.635330]\n",
            "3609 [ D loss: 0.239012, acc.: 95%] [G loss: 5.108975]\n",
            "3610 [ D loss: 0.156588, acc.: 96%] [G loss: 4.294623]\n",
            "3611 [ D loss: 0.183858, acc.: 95%] [G loss: 3.803609]\n",
            "3612 [ D loss: 0.283376, acc.: 91%] [G loss: 3.546616]\n",
            "3613 [ D loss: 0.183105, acc.: 96%] [G loss: 4.031470]\n",
            "3614 [ D loss: 0.219623, acc.: 95%] [G loss: 3.007425]\n",
            "3615 [ D loss: 0.172015, acc.: 96%] [G loss: 3.650649]\n",
            "3616 [ D loss: 0.193081, acc.: 94%] [G loss: 3.299149]\n",
            "3617 [ D loss: 0.136507, acc.: 96%] [G loss: 3.931299]\n",
            "3618 [ D loss: 0.187544, acc.: 96%] [G loss: 3.958033]\n",
            "3619 [ D loss: 0.181463, acc.: 95%] [G loss: 4.183465]\n",
            "3620 [ D loss: 0.092813, acc.: 98%] [G loss: 3.573933]\n",
            "3621 [ D loss: 0.273579, acc.: 90%] [G loss: 3.868006]\n",
            "3622 [ D loss: 0.289246, acc.: 88%] [G loss: 3.601262]\n",
            "3623 [ D loss: 0.263993, acc.: 90%] [G loss: 3.538123]\n",
            "3624 [ D loss: 0.192578, acc.: 94%] [G loss: 4.504408]\n",
            "3625 [ D loss: 0.226713, acc.: 95%] [G loss: 4.275533]\n",
            "3626 [ D loss: 0.162257, acc.: 95%] [G loss: 4.224461]\n",
            "3627 [ D loss: 0.124761, acc.: 99%] [G loss: 4.872151]\n",
            "3628 [ D loss: 0.066249, acc.: 100%] [G loss: 9.486182]\n",
            "3629 [ D loss: 0.192689, acc.: 91%] [G loss: 7.025462]\n",
            "3630 [ D loss: 0.180112, acc.: 95%] [G loss: 5.685382]\n",
            "3631 [ D loss: 0.066129, acc.: 99%] [G loss: 8.394890]\n",
            "3632 [ D loss: 0.168924, acc.: 95%] [G loss: 5.167864]\n",
            "3633 [ D loss: 0.158048, acc.: 95%] [G loss: 4.509990]\n",
            "3634 [ D loss: 0.129319, acc.: 96%] [G loss: 5.721593]\n",
            "3635 [ D loss: 0.109068, acc.: 98%] [G loss: 4.608391]\n",
            "3636 [ D loss: 0.195982, acc.: 94%] [G loss: 4.762905]\n",
            "3637 [ D loss: 0.155830, acc.: 96%] [G loss: 5.916859]\n",
            "3638 [ D loss: 0.209500, acc.: 91%] [G loss: 4.016460]\n",
            "3639 [ D loss: 0.153011, acc.: 97%] [G loss: 4.362403]\n",
            "3640 [ D loss: 0.191933, acc.: 91%] [G loss: 5.880098]\n",
            "3641 [ D loss: 0.219064, acc.: 90%] [G loss: 5.842964]\n",
            "3642 [ D loss: 0.176201, acc.: 91%] [G loss: 5.766125]\n",
            "3643 [ D loss: 0.131168, acc.: 97%] [G loss: 8.855095]\n",
            "3644 [ D loss: 0.120409, acc.: 97%] [G loss: 4.325948]\n",
            "3645 [ D loss: 0.174404, acc.: 95%] [G loss: 7.516175]\n",
            "3646 [ D loss: 0.116236, acc.: 97%] [G loss: 6.093103]\n",
            "3647 [ D loss: 0.125984, acc.: 98%] [G loss: 6.647765]\n",
            "3648 [ D loss: 0.094683, acc.: 96%] [G loss: 9.003320]\n",
            "3649 [ D loss: 0.132110, acc.: 96%] [G loss: 6.040605]\n",
            "3650 [ D loss: 0.103532, acc.: 98%] [G loss: 7.621524]\n",
            "3651 [ D loss: 0.176245, acc.: 93%] [G loss: 3.702317]\n",
            "3652 [ D loss: 0.179865, acc.: 94%] [G loss: 4.928150]\n",
            "3653 [ D loss: 0.150129, acc.: 95%] [G loss: 7.912190]\n",
            "3654 [ D loss: 0.191639, acc.: 95%] [G loss: 4.353570]\n",
            "3655 [ D loss: 0.132115, acc.: 99%] [G loss: 5.703742]\n",
            "3656 [ D loss: 0.214498, acc.: 91%] [G loss: 4.176459]\n",
            "3657 [ D loss: 0.167234, acc.: 95%] [G loss: 4.428007]\n",
            "3658 [ D loss: 0.207441, acc.: 93%] [G loss: 3.884664]\n",
            "3659 [ D loss: 0.210212, acc.: 94%] [G loss: 4.540160]\n",
            "3660 [ D loss: 0.297623, acc.: 88%] [G loss: 4.114972]\n",
            "3661 [ D loss: 0.237174, acc.: 93%] [G loss: 4.854445]\n",
            "3662 [ D loss: 0.089409, acc.: 99%] [G loss: 5.364912]\n",
            "3663 [ D loss: 0.130482, acc.: 99%] [G loss: 4.578590]\n",
            "3664 [ D loss: 0.090322, acc.: 98%] [G loss: 6.276061]\n",
            "3665 [ D loss: 0.240273, acc.: 92%] [G loss: 4.394614]\n",
            "3666 [ D loss: 0.200754, acc.: 94%] [G loss: 6.262595]\n",
            "3667 [ D loss: 0.301563, acc.: 88%] [G loss: 4.367496]\n",
            "3668 [ D loss: 0.259172, acc.: 89%] [G loss: 3.902052]\n",
            "3669 [ D loss: 0.101341, acc.: 98%] [G loss: 4.694566]\n",
            "3670 [ D loss: 0.180607, acc.: 95%] [G loss: 6.972160]\n",
            "3671 [ D loss: 0.277665, acc.: 87%] [G loss: 4.523688]\n",
            "3672 [ D loss: 0.227776, acc.: 88%] [G loss: 8.860772]\n",
            "3673 [ D loss: 0.211454, acc.: 92%] [G loss: 7.966905]\n",
            "3674 [ D loss: 0.176907, acc.: 93%] [G loss: 4.348848]\n",
            "3675 [ D loss: 0.216541, acc.: 91%] [G loss: 4.757875]\n",
            "3676 [ D loss: 0.163231, acc.: 96%] [G loss: 3.983426]\n",
            "3677 [ D loss: 0.145363, acc.: 96%] [G loss: 6.317782]\n",
            "3678 [ D loss: 0.221915, acc.: 92%] [G loss: 5.233269]\n",
            "3679 [ D loss: 0.085842, acc.: 97%] [G loss: 4.460351]\n",
            "3680 [ D loss: 0.275391, acc.: 91%] [G loss: 5.574354]\n",
            "3681 [ D loss: 0.063801, acc.: 98%] [G loss: 6.998599]\n",
            "3682 [ D loss: 0.132903, acc.: 95%] [G loss: 4.680592]\n",
            "3683 [ D loss: 0.118101, acc.: 98%] [G loss: 4.894243]\n",
            "3684 [ D loss: 0.175710, acc.: 95%] [G loss: 4.635780]\n",
            "3685 [ D loss: 0.282890, acc.: 95%] [G loss: 4.135199]\n",
            "3686 [ D loss: 0.179332, acc.: 96%] [G loss: 4.007728]\n",
            "3687 [ D loss: 0.197631, acc.: 95%] [G loss: 4.025169]\n",
            "3688 [ D loss: 0.121349, acc.: 97%] [G loss: 4.167045]\n",
            "3689 [ D loss: 0.228209, acc.: 93%] [G loss: 6.734567]\n",
            "3690 [ D loss: 0.160378, acc.: 95%] [G loss: 7.294064]\n",
            "3691 [ D loss: 0.183853, acc.: 92%] [G loss: 7.308849]\n",
            "3692 [ D loss: 0.166545, acc.: 93%] [G loss: 6.779023]\n",
            "3693 [ D loss: 0.088196, acc.: 98%] [G loss: 5.853583]\n",
            "3694 [ D loss: 0.080576, acc.: 99%] [G loss: 8.183884]\n",
            "3695 [ D loss: 0.148050, acc.: 95%] [G loss: 7.508426]\n",
            "3696 [ D loss: 0.133213, acc.: 98%] [G loss: 5.895613]\n",
            "3697 [ D loss: 0.190042, acc.: 94%] [G loss: 6.539674]\n",
            "3698 [ D loss: 0.205230, acc.: 92%] [G loss: 5.654324]\n",
            "3699 [ D loss: 0.225915, acc.: 92%] [G loss: 6.605424]\n",
            "3700 [ D loss: 0.164787, acc.: 95%] [G loss: 4.409174]\n",
            "3701 [ D loss: 0.147832, acc.: 95%] [G loss: 5.821272]\n",
            "3702 [ D loss: 0.151117, acc.: 96%] [G loss: 5.258839]\n",
            "3703 [ D loss: 0.115483, acc.: 99%] [G loss: 5.925165]\n",
            "3704 [ D loss: 0.196230, acc.: 95%] [G loss: 4.167216]\n",
            "3705 [ D loss: 0.122501, acc.: 98%] [G loss: 4.294219]\n",
            "3706 [ D loss: 0.214964, acc.: 92%] [G loss: 3.152988]\n",
            "3707 [ D loss: 0.154571, acc.: 97%] [G loss: 5.011606]\n",
            "3708 [ D loss: 0.103560, acc.: 97%] [G loss: 4.528680]\n",
            "3709 [ D loss: 0.155717, acc.: 95%] [G loss: 4.163301]\n",
            "3710 [ D loss: 0.212605, acc.: 92%] [G loss: 11.276242]\n",
            "3711 [ D loss: 0.188231, acc.: 93%] [G loss: 5.990727]\n",
            "3712 [ D loss: 0.371464, acc.: 83%] [G loss: 3.920588]\n",
            "3713 [ D loss: 0.117356, acc.: 99%] [G loss: 4.191748]\n",
            "3714 [ D loss: 0.217703, acc.: 93%] [G loss: 4.256909]\n",
            "3715 [ D loss: 0.293940, acc.: 88%] [G loss: 3.462369]\n",
            "3716 [ D loss: 0.147096, acc.: 98%] [G loss: 9.837152]\n",
            "3717 [ D loss: 0.187553, acc.: 92%] [G loss: 5.102648]\n",
            "3718 [ D loss: 0.172182, acc.: 95%] [G loss: 5.177357]\n",
            "3719 [ D loss: 0.133427, acc.: 96%] [G loss: 8.286884]\n",
            "3720 [ D loss: 0.166004, acc.: 95%] [G loss: 6.494644]\n",
            "3721 [ D loss: 0.127852, acc.: 96%] [G loss: 4.043215]\n",
            "3722 [ D loss: 0.117397, acc.: 97%] [G loss: 5.608243]\n",
            "3723 [ D loss: 0.087927, acc.: 98%] [G loss: 8.842396]\n",
            "3724 [ D loss: 0.128763, acc.: 96%] [G loss: 4.741899]\n",
            "3725 [ D loss: 0.121987, acc.: 98%] [G loss: 4.752627]\n",
            "3726 [ D loss: 0.238841, acc.: 91%] [G loss: 4.241248]\n",
            "3727 [ D loss: 0.239856, acc.: 89%] [G loss: 5.008871]\n",
            "3728 [ D loss: 0.230763, acc.: 91%] [G loss: 4.446851]\n",
            "3729 [ D loss: 0.252225, acc.: 91%] [G loss: 5.986196]\n",
            "3730 [ D loss: 0.203059, acc.: 91%] [G loss: 5.838891]\n",
            "3731 [ D loss: 0.095367, acc.: 98%] [G loss: 4.234091]\n",
            "3732 [ D loss: 0.123190, acc.: 96%] [G loss: 5.885237]\n",
            "3733 [ D loss: 0.197988, acc.: 94%] [G loss: 3.891753]\n",
            "3734 [ D loss: 0.182346, acc.: 95%] [G loss: 6.371555]\n",
            "3735 [ D loss: 0.136713, acc.: 96%] [G loss: 4.033658]\n",
            "3736 [ D loss: 0.140226, acc.: 95%] [G loss: 8.011119]\n",
            "3737 [ D loss: 0.133188, acc.: 96%] [G loss: 4.442641]\n",
            "3738 [ D loss: 0.115444, acc.: 98%] [G loss: 7.555691]\n",
            "3739 [ D loss: 0.070296, acc.: 99%] [G loss: 9.894892]\n",
            "3740 [ D loss: 0.168955, acc.: 95%] [G loss: 4.172612]\n",
            "3741 [ D loss: 0.223465, acc.: 93%] [G loss: 5.143097]\n",
            "3742 [ D loss: 0.221899, acc.: 92%] [G loss: 4.325521]\n",
            "3743 [ D loss: 0.175635, acc.: 95%] [G loss: 4.080845]\n",
            "3744 [ D loss: 0.120977, acc.: 96%] [G loss: 4.156094]\n",
            "3745 [ D loss: 0.138287, acc.: 95%] [G loss: 5.217664]\n",
            "3746 [ D loss: 0.203646, acc.: 94%] [G loss: 4.379338]\n",
            "3747 [ D loss: 0.287918, acc.: 88%] [G loss: 4.267492]\n",
            "3748 [ D loss: 0.209746, acc.: 92%] [G loss: 4.726199]\n",
            "3749 [ D loss: 0.154504, acc.: 98%] [G loss: 4.587507]\n",
            "3750 [ D loss: 0.248353, acc.: 88%] [G loss: 3.523009]\n",
            "3751 [ D loss: 0.166774, acc.: 95%] [G loss: 5.249855]\n",
            "3752 [ D loss: 0.079634, acc.: 99%] [G loss: 6.351770]\n",
            "3753 [ D loss: 0.147986, acc.: 97%] [G loss: 6.773672]\n",
            "3754 [ D loss: 0.129254, acc.: 97%] [G loss: 4.596623]\n",
            "3755 [ D loss: 0.209215, acc.: 96%] [G loss: 4.441718]\n",
            "3756 [ D loss: 0.269022, acc.: 90%] [G loss: 3.528210]\n",
            "3757 [ D loss: 0.238981, acc.: 88%] [G loss: 4.994582]\n",
            "3758 [ D loss: 0.258946, acc.: 90%] [G loss: 4.070858]\n",
            "3759 [ D loss: 0.163622, acc.: 96%] [G loss: 4.154723]\n",
            "3760 [ D loss: 0.236362, acc.: 93%] [G loss: 4.341550]\n",
            "3761 [ D loss: 0.179698, acc.: 95%] [G loss: 4.514801]\n",
            "3762 [ D loss: 0.160755, acc.: 98%] [G loss: 3.952228]\n",
            "3763 [ D loss: 0.205439, acc.: 94%] [G loss: 4.983160]\n",
            "3764 [ D loss: 0.165210, acc.: 95%] [G loss: 5.423446]\n",
            "3765 [ D loss: 0.283161, acc.: 90%] [G loss: 3.799847]\n",
            "3766 [ D loss: 0.231210, acc.: 92%] [G loss: 3.807296]\n",
            "3767 [ D loss: 0.141485, acc.: 96%] [G loss: 3.997098]\n",
            "3768 [ D loss: 0.238527, acc.: 91%] [G loss: 4.981527]\n",
            "3769 [ D loss: 0.142795, acc.: 97%] [G loss: 5.539949]\n",
            "3770 [ D loss: 0.159935, acc.: 95%] [G loss: 7.885232]\n",
            "3771 [ D loss: 0.206096, acc.: 93%] [G loss: 7.419266]\n",
            "3772 [ D loss: 0.205141, acc.: 94%] [G loss: 5.583616]\n",
            "3773 [ D loss: 0.099392, acc.: 97%] [G loss: 5.523379]\n",
            "3774 [ D loss: 0.263409, acc.: 88%] [G loss: 4.523445]\n",
            "3775 [ D loss: 0.203980, acc.: 93%] [G loss: 4.592902]\n",
            "3776 [ D loss: 0.260014, acc.: 89%] [G loss: 5.085428]\n",
            "3777 [ D loss: 0.092748, acc.: 98%] [G loss: 8.770381]\n",
            "3778 [ D loss: 0.198129, acc.: 96%] [G loss: 4.957769]\n",
            "3779 [ D loss: 0.153827, acc.: 96%] [G loss: 3.819242]\n",
            "3780 [ D loss: 0.470877, acc.: 78%] [G loss: 5.922601]\n",
            "3781 [ D loss: 0.232386, acc.: 91%] [G loss: 5.000147]\n",
            "3782 [ D loss: 0.241953, acc.: 91%] [G loss: 4.182805]\n",
            "3783 [ D loss: 0.276042, acc.: 88%] [G loss: 4.030475]\n",
            "3784 [ D loss: 0.168497, acc.: 93%] [G loss: 4.639922]\n",
            "3785 [ D loss: 0.086017, acc.: 99%] [G loss: 5.793224]\n",
            "3786 [ D loss: 0.229881, acc.: 93%] [G loss: 5.115012]\n",
            "3787 [ D loss: 0.189929, acc.: 95%] [G loss: 4.350578]\n",
            "3788 [ D loss: 0.185786, acc.: 94%] [G loss: 4.737396]\n",
            "3789 [ D loss: 0.135058, acc.: 97%] [G loss: 4.527238]\n",
            "3790 [ D loss: 0.152107, acc.: 95%] [G loss: 7.693116]\n",
            "3791 [ D loss: 0.104922, acc.: 98%] [G loss: 5.134063]\n",
            "3792 [ D loss: 0.157208, acc.: 95%] [G loss: 6.700337]\n",
            "3793 [ D loss: 0.133729, acc.: 98%] [G loss: 5.038244]\n",
            "3794 [ D loss: 0.321973, acc.: 86%] [G loss: 5.658198]\n",
            "3795 [ D loss: 0.304141, acc.: 84%] [G loss: 5.445700]\n",
            "3796 [ D loss: 0.269635, acc.: 89%] [G loss: 4.323568]\n",
            "3797 [ D loss: 0.207358, acc.: 92%] [G loss: 4.528214]\n",
            "3798 [ D loss: 0.252333, acc.: 91%] [G loss: 5.323290]\n",
            "3799 [ D loss: 0.160481, acc.: 95%] [G loss: 6.886216]\n",
            "3800 [ D loss: 0.140244, acc.: 98%] [G loss: 5.586636]\n",
            "3801 [ D loss: 0.157637, acc.: 96%] [G loss: 4.500961]\n",
            "3802 [ D loss: 0.150697, acc.: 97%] [G loss: 3.929376]\n",
            "3803 [ D loss: 0.135794, acc.: 97%] [G loss: 4.857213]\n",
            "3804 [ D loss: 0.176210, acc.: 96%] [G loss: 4.489340]\n",
            "3805 [ D loss: 0.150573, acc.: 98%] [G loss: 4.503221]\n",
            "3806 [ D loss: 0.228025, acc.: 93%] [G loss: 4.888876]\n",
            "3807 [ D loss: 0.225227, acc.: 92%] [G loss: 4.641775]\n",
            "3808 [ D loss: 0.210622, acc.: 91%] [G loss: 3.887370]\n",
            "3809 [ D loss: 0.120517, acc.: 96%] [G loss: 5.723642]\n",
            "3810 [ D loss: 0.053928, acc.: 99%] [G loss: 5.718608]\n",
            "3811 [ D loss: 0.104748, acc.: 99%] [G loss: 4.328626]\n",
            "3812 [ D loss: 0.255109, acc.: 92%] [G loss: 6.629121]\n",
            "3813 [ D loss: 0.105076, acc.: 98%] [G loss: 4.920450]\n",
            "3814 [ D loss: 0.364155, acc.: 84%] [G loss: 6.552674]\n",
            "3815 [ D loss: 0.139053, acc.: 96%] [G loss: 8.014851]\n",
            "3816 [ D loss: 0.294038, acc.: 89%] [G loss: 4.812188]\n",
            "3817 [ D loss: 0.160811, acc.: 94%] [G loss: 7.206871]\n",
            "3818 [ D loss: 0.195161, acc.: 94%] [G loss: 4.377737]\n",
            "3819 [ D loss: 0.152007, acc.: 96%] [G loss: 4.541954]\n",
            "3820 [ D loss: 0.158683, acc.: 95%] [G loss: 4.047857]\n",
            "3821 [ D loss: 0.211117, acc.: 91%] [G loss: 4.904026]\n",
            "3822 [ D loss: 0.344569, acc.: 82%] [G loss: 4.604567]\n",
            "3823 [ D loss: 0.175327, acc.: 93%] [G loss: 4.171659]\n",
            "3824 [ D loss: 0.217889, acc.: 88%] [G loss: 4.397444]\n",
            "3825 [ D loss: 0.198615, acc.: 94%] [G loss: 4.396041]\n",
            "3826 [ D loss: 0.246192, acc.: 91%] [G loss: 4.196906]\n",
            "3827 [ D loss: 0.187052, acc.: 94%] [G loss: 4.866920]\n",
            "3828 [ D loss: 0.149930, acc.: 95%] [G loss: 4.412468]\n",
            "3829 [ D loss: 0.178899, acc.: 95%] [G loss: 4.821738]\n",
            "3830 [ D loss: 0.171936, acc.: 94%] [G loss: 5.525252]\n",
            "3831 [ D loss: 0.155871, acc.: 95%] [G loss: 4.298681]\n",
            "3832 [ D loss: 0.277484, acc.: 87%] [G loss: 5.366698]\n",
            "3833 [ D loss: 0.209062, acc.: 93%] [G loss: 5.400479]\n",
            "3834 [ D loss: 0.155453, acc.: 97%] [G loss: 4.989192]\n",
            "3835 [ D loss: 0.146025, acc.: 97%] [G loss: 4.195382]\n",
            "3836 [ D loss: 0.177510, acc.: 95%] [G loss: 5.011854]\n",
            "3837 [ D loss: 0.131706, acc.: 98%] [G loss: 4.913369]\n",
            "3838 [ D loss: 0.199801, acc.: 94%] [G loss: 4.186134]\n",
            "3839 [ D loss: 0.210423, acc.: 92%] [G loss: 5.686748]\n",
            "3840 [ D loss: 0.243176, acc.: 91%] [G loss: 5.056819]\n",
            "3841 [ D loss: 0.247822, acc.: 89%] [G loss: 4.335129]\n",
            "3842 [ D loss: 0.252892, acc.: 91%] [G loss: 3.893507]\n",
            "3843 [ D loss: 0.116609, acc.: 100%] [G loss: 5.941792]\n",
            "3844 [ D loss: 0.292188, acc.: 92%] [G loss: 4.314558]\n",
            "3845 [ D loss: 0.245407, acc.: 91%] [G loss: 5.668797]\n",
            "3846 [ D loss: 0.094306, acc.: 98%] [G loss: 8.372319]\n",
            "3847 [ D loss: 0.153866, acc.: 95%] [G loss: 4.684886]\n",
            "3848 [ D loss: 0.110474, acc.: 98%] [G loss: 8.557887]\n",
            "3849 [ D loss: 0.218632, acc.: 91%] [G loss: 5.488788]\n",
            "3850 [ D loss: 0.107949, acc.: 98%] [G loss: 4.128682]\n",
            "3851 [ D loss: 0.159827, acc.: 95%] [G loss: 6.285017]\n",
            "3852 [ D loss: 0.191489, acc.: 92%] [G loss: 4.794447]\n",
            "3853 [ D loss: 0.158758, acc.: 95%] [G loss: 5.188293]\n",
            "3854 [ D loss: 0.273075, acc.: 91%] [G loss: 4.451641]\n",
            "3855 [ D loss: 0.256400, acc.: 91%] [G loss: 5.246747]\n",
            "3856 [ D loss: 0.239308, acc.: 88%] [G loss: 4.121317]\n",
            "3857 [ D loss: 0.164087, acc.: 96%] [G loss: 4.457265]\n",
            "3858 [ D loss: 0.177881, acc.: 91%] [G loss: 5.382216]\n",
            "3859 [ D loss: 0.144484, acc.: 94%] [G loss: 5.830770]\n",
            "3860 [ D loss: 0.200804, acc.: 93%] [G loss: 3.504893]\n",
            "3861 [ D loss: 0.129720, acc.: 96%] [G loss: 5.443445]\n",
            "3862 [ D loss: 0.158745, acc.: 97%] [G loss: 4.410870]\n",
            "3863 [ D loss: 0.275513, acc.: 84%] [G loss: 5.470418]\n",
            "3864 [ D loss: 0.212873, acc.: 93%] [G loss: 5.345094]\n",
            "3865 [ D loss: 0.113524, acc.: 97%] [G loss: 8.426091]\n",
            "3866 [ D loss: 0.233251, acc.: 90%] [G loss: 4.369203]\n",
            "3867 [ D loss: 0.163722, acc.: 94%] [G loss: 4.202078]\n",
            "3868 [ D loss: 0.284222, acc.: 84%] [G loss: 4.471359]\n",
            "3869 [ D loss: 0.311026, acc.: 88%] [G loss: 4.269463]\n",
            "3870 [ D loss: 0.336793, acc.: 88%] [G loss: 3.975285]\n",
            "3871 [ D loss: 0.124890, acc.: 96%] [G loss: 5.149951]\n",
            "3872 [ D loss: 0.232787, acc.: 91%] [G loss: 3.978750]\n",
            "3873 [ D loss: 0.196957, acc.: 92%] [G loss: 4.708208]\n",
            "3874 [ D loss: 0.164723, acc.: 95%] [G loss: 6.116900]\n",
            "3875 [ D loss: 0.160653, acc.: 97%] [G loss: 3.667609]\n",
            "3876 [ D loss: 0.132377, acc.: 96%] [G loss: 9.260878]\n",
            "3877 [ D loss: 0.166470, acc.: 93%] [G loss: 5.869032]\n",
            "3878 [ D loss: 0.168701, acc.: 95%] [G loss: 3.495793]\n",
            "3879 [ D loss: 0.126014, acc.: 95%] [G loss: 5.082072]\n",
            "3880 [ D loss: 0.135965, acc.: 98%] [G loss: 5.143561]\n",
            "3881 [ D loss: 0.331671, acc.: 84%] [G loss: 4.327153]\n",
            "3882 [ D loss: 0.210017, acc.: 94%] [G loss: 4.144602]\n",
            "3883 [ D loss: 0.325662, acc.: 88%] [G loss: 4.189085]\n",
            "3884 [ D loss: 0.165288, acc.: 95%] [G loss: 5.010474]\n",
            "3885 [ D loss: 0.168657, acc.: 95%] [G loss: 4.150933]\n",
            "3886 [ D loss: 0.174607, acc.: 95%] [G loss: 4.453497]\n",
            "3887 [ D loss: 0.153607, acc.: 95%] [G loss: 4.227277]\n",
            "3888 [ D loss: 0.106836, acc.: 97%] [G loss: 5.743654]\n",
            "3889 [ D loss: 0.134163, acc.: 97%] [G loss: 5.269996]\n",
            "3890 [ D loss: 0.107215, acc.: 96%] [G loss: 5.029874]\n",
            "3891 [ D loss: 0.114135, acc.: 97%] [G loss: 4.269074]\n",
            "3892 [ D loss: 0.155709, acc.: 93%] [G loss: 8.015512]\n",
            "3893 [ D loss: 0.147296, acc.: 94%] [G loss: 6.517868]\n",
            "3894 [ D loss: 0.142216, acc.: 97%] [G loss: 5.934479]\n",
            "3895 [ D loss: 0.198140, acc.: 94%] [G loss: 7.846529]\n",
            "3896 [ D loss: 0.114826, acc.: 98%] [G loss: 5.402157]\n",
            "3897 [ D loss: 0.099344, acc.: 98%] [G loss: 3.771673]\n",
            "3898 [ D loss: 0.277126, acc.: 89%] [G loss: 4.671193]\n",
            "3899 [ D loss: 0.104567, acc.: 98%] [G loss: 8.656858]\n",
            "3900 [ D loss: 0.252207, acc.: 90%] [G loss: 4.321504]\n",
            "3901 [ D loss: 0.135900, acc.: 98%] [G loss: 5.625460]\n",
            "3902 [ D loss: 0.169325, acc.: 95%] [G loss: 5.541951]\n",
            "3903 [ D loss: 0.157456, acc.: 93%] [G loss: 9.047968]\n",
            "3904 [ D loss: 0.153980, acc.: 94%] [G loss: 4.788792]\n",
            "3905 [ D loss: 0.142961, acc.: 97%] [G loss: 6.149831]\n",
            "3906 [ D loss: 0.164789, acc.: 94%] [G loss: 4.663574]\n",
            "3907 [ D loss: 0.131351, acc.: 98%] [G loss: 4.447496]\n",
            "3908 [ D loss: 0.150780, acc.: 97%] [G loss: 3.701281]\n",
            "3909 [ D loss: 0.114540, acc.: 96%] [G loss: 5.387500]\n",
            "3910 [ D loss: 0.254392, acc.: 88%] [G loss: 4.910760]\n",
            "3911 [ D loss: 0.250457, acc.: 91%] [G loss: 3.582696]\n",
            "3912 [ D loss: 0.164569, acc.: 98%] [G loss: 3.708385]\n",
            "3913 [ D loss: 0.260780, acc.: 95%] [G loss: 3.478932]\n",
            "3914 [ D loss: 0.146676, acc.: 95%] [G loss: 3.500147]\n",
            "3915 [ D loss: 0.189368, acc.: 91%] [G loss: 5.097903]\n",
            "3916 [ D loss: 0.194625, acc.: 94%] [G loss: 3.735020]\n",
            "3917 [ D loss: 0.176647, acc.: 95%] [G loss: 3.569520]\n",
            "3918 [ D loss: 0.103589, acc.: 99%] [G loss: 4.375360]\n",
            "3919 [ D loss: 0.236747, acc.: 93%] [G loss: 4.013284]\n",
            "3920 [ D loss: 0.112528, acc.: 97%] [G loss: 3.854914]\n",
            "3921 [ D loss: 0.183432, acc.: 93%] [G loss: 6.226572]\n",
            "3922 [ D loss: 0.144910, acc.: 96%] [G loss: 6.589668]\n",
            "3923 [ D loss: 0.103725, acc.: 98%] [G loss: 5.143638]\n",
            "3924 [ D loss: 0.154770, acc.: 97%] [G loss: 4.145070]\n",
            "3925 [ D loss: 0.177267, acc.: 95%] [G loss: 4.317939]\n",
            "3926 [ D loss: 0.215397, acc.: 94%] [G loss: 5.009659]\n",
            "3927 [ D loss: 0.163163, acc.: 95%] [G loss: 4.551596]\n",
            "3928 [ D loss: 0.165023, acc.: 95%] [G loss: 3.756512]\n",
            "3929 [ D loss: 0.141085, acc.: 99%] [G loss: 3.954236]\n",
            "3930 [ D loss: 0.195310, acc.: 92%] [G loss: 3.752902]\n",
            "3931 [ D loss: 0.102387, acc.: 98%] [G loss: 4.108202]\n",
            "3932 [ D loss: 0.149275, acc.: 98%] [G loss: 3.489873]\n",
            "3933 [ D loss: 0.156656, acc.: 95%] [G loss: 3.997601]\n",
            "3934 [ D loss: 0.164370, acc.: 95%] [G loss: 4.836026]\n",
            "3935 [ D loss: 0.133364, acc.: 96%] [G loss: 4.356589]\n",
            "3936 [ D loss: 0.247103, acc.: 91%] [G loss: 4.151733]\n",
            "3937 [ D loss: 0.113896, acc.: 98%] [G loss: 4.966630]\n",
            "3938 [ D loss: 0.177290, acc.: 95%] [G loss: 4.832076]\n",
            "3939 [ D loss: 0.149747, acc.: 98%] [G loss: 4.714136]\n",
            "3940 [ D loss: 0.153593, acc.: 95%] [G loss: 4.989159]\n",
            "3941 [ D loss: 0.159902, acc.: 92%] [G loss: 4.966918]\n",
            "3942 [ D loss: 0.137096, acc.: 94%] [G loss: 4.605248]\n",
            "3943 [ D loss: 0.166072, acc.: 93%] [G loss: 6.974384]\n",
            "3944 [ D loss: 0.179578, acc.: 95%] [G loss: 5.284957]\n",
            "3945 [ D loss: 0.149209, acc.: 95%] [G loss: 5.989269]\n",
            "3946 [ D loss: 0.227385, acc.: 88%] [G loss: 5.016833]\n",
            "3947 [ D loss: 0.212979, acc.: 93%] [G loss: 4.841828]\n",
            "3948 [ D loss: 0.185880, acc.: 95%] [G loss: 3.952245]\n",
            "3949 [ D loss: 0.252707, acc.: 91%] [G loss: 5.424887]\n",
            "3950 [ D loss: 0.132225, acc.: 95%] [G loss: 6.331935]\n",
            "3951 [ D loss: 0.243909, acc.: 92%] [G loss: 3.984588]\n",
            "3952 [ D loss: 0.131268, acc.: 97%] [G loss: 6.275319]\n",
            "3953 [ D loss: 0.136970, acc.: 95%] [G loss: 5.164339]\n",
            "3954 [ D loss: 0.140235, acc.: 98%] [G loss: 4.054731]\n",
            "3955 [ D loss: 0.106534, acc.: 98%] [G loss: 3.901571]\n",
            "3956 [ D loss: 0.167734, acc.: 96%] [G loss: 5.783780]\n",
            "3957 [ D loss: 0.258570, acc.: 90%] [G loss: 4.504698]\n",
            "3958 [ D loss: 0.269772, acc.: 87%] [G loss: 8.645802]\n",
            "3959 [ D loss: 0.229451, acc.: 87%] [G loss: 9.425797]\n",
            "3960 [ D loss: 0.074567, acc.: 98%] [G loss: 8.509146]\n",
            "3961 [ D loss: 0.150634, acc.: 98%] [G loss: 4.688671]\n",
            "3962 [ D loss: 0.108980, acc.: 98%] [G loss: 4.574336]\n",
            "3963 [ D loss: 0.120555, acc.: 96%] [G loss: 5.103045]\n",
            "3964 [ D loss: 0.142875, acc.: 97%] [G loss: 5.094833]\n",
            "3965 [ D loss: 0.293824, acc.: 92%] [G loss: 4.429837]\n",
            "3966 [ D loss: 0.256242, acc.: 87%] [G loss: 3.855592]\n",
            "3967 [ D loss: 0.183240, acc.: 93%] [G loss: 4.292000]\n",
            "3968 [ D loss: 0.164198, acc.: 95%] [G loss: 5.252991]\n",
            "3969 [ D loss: 0.212915, acc.: 93%] [G loss: 4.982142]\n",
            "3970 [ D loss: 0.091912, acc.: 97%] [G loss: 7.766191]\n",
            "3971 [ D loss: 0.166106, acc.: 95%] [G loss: 5.208519]\n",
            "3972 [ D loss: 0.196243, acc.: 95%] [G loss: 5.832593]\n",
            "3973 [ D loss: 0.180664, acc.: 95%] [G loss: 8.016817]\n",
            "3974 [ D loss: 0.218079, acc.: 92%] [G loss: 7.492907]\n",
            "3975 [ D loss: 0.097444, acc.: 96%] [G loss: 7.265669]\n",
            "3976 [ D loss: 0.171717, acc.: 95%] [G loss: 4.778186]\n",
            "3977 [ D loss: 0.067554, acc.: 98%] [G loss: 7.406995]\n",
            "3978 [ D loss: 0.095475, acc.: 98%] [G loss: 4.286296]\n",
            "3979 [ D loss: 0.147798, acc.: 97%] [G loss: 4.729813]\n",
            "3980 [ D loss: 0.259175, acc.: 91%] [G loss: 4.296712]\n",
            "3981 [ D loss: 0.153650, acc.: 93%] [G loss: 4.168401]\n",
            "3982 [ D loss: 0.205000, acc.: 96%] [G loss: 4.900194]\n",
            "3983 [ D loss: 0.169756, acc.: 94%] [G loss: 5.185387]\n",
            "3984 [ D loss: 0.194645, acc.: 93%] [G loss: 5.531630]\n",
            "3985 [ D loss: 0.087061, acc.: 97%] [G loss: 6.600932]\n",
            "3986 [ D loss: 0.149901, acc.: 95%] [G loss: 5.569142]\n",
            "3987 [ D loss: 0.074388, acc.: 98%] [G loss: 6.297435]\n",
            "3988 [ D loss: 0.122913, acc.: 97%] [G loss: 6.412235]\n",
            "3989 [ D loss: 0.164985, acc.: 95%] [G loss: 4.025148]\n",
            "3990 [ D loss: 0.176362, acc.: 95%] [G loss: 3.868088]\n",
            "3991 [ D loss: 0.169956, acc.: 96%] [G loss: 4.573415]\n",
            "3992 [ D loss: 0.139223, acc.: 98%] [G loss: 3.964291]\n",
            "3993 [ D loss: 0.194126, acc.: 92%] [G loss: 3.962075]\n",
            "3994 [ D loss: 0.205538, acc.: 94%] [G loss: 3.717996]\n",
            "3995 [ D loss: 0.136512, acc.: 98%] [G loss: 4.576230]\n",
            "3996 [ D loss: 0.150677, acc.: 95%] [G loss: 3.499359]\n",
            "3997 [ D loss: 0.184157, acc.: 93%] [G loss: 4.055971]\n",
            "3998 [ D loss: 0.190046, acc.: 95%] [G loss: 3.839809]\n",
            "3999 [ D loss: 0.203919, acc.: 94%] [G loss: 4.108426]\n",
            "4000 [ D loss: 0.176354, acc.: 93%] [G loss: 4.758260]\n",
            "4001 [ D loss: 0.125033, acc.: 95%] [G loss: 4.298036]\n",
            "4002 [ D loss: 0.266782, acc.: 89%] [G loss: 4.508226]\n",
            "4003 [ D loss: 0.160626, acc.: 92%] [G loss: 7.903419]\n",
            "4004 [ D loss: 0.168899, acc.: 94%] [G loss: 6.089979]\n",
            "4005 [ D loss: 0.144398, acc.: 97%] [G loss: 4.954394]\n",
            "4006 [ D loss: 0.144168, acc.: 97%] [G loss: 5.037961]\n",
            "4007 [ D loss: 0.215443, acc.: 95%] [G loss: 4.455938]\n",
            "4008 [ D loss: 0.096679, acc.: 98%] [G loss: 6.132085]\n",
            "4009 [ D loss: 0.112627, acc.: 99%] [G loss: 5.515040]\n",
            "4010 [ D loss: 0.104128, acc.: 97%] [G loss: 4.991729]\n",
            "4011 [ D loss: 0.140035, acc.: 98%] [G loss: 5.795845]\n",
            "4012 [ D loss: 0.197177, acc.: 91%] [G loss: 6.451364]\n",
            "4013 [ D loss: 0.125973, acc.: 94%] [G loss: 6.047835]\n",
            "4014 [ D loss: 0.195493, acc.: 94%] [G loss: 7.073472]\n",
            "4015 [ D loss: 0.048723, acc.: 100%] [G loss: 5.860714]\n",
            "4016 [ D loss: 0.156265, acc.: 95%] [G loss: 6.422534]\n",
            "4017 [ D loss: 0.170739, acc.: 93%] [G loss: 5.721841]\n",
            "4018 [ D loss: 0.076653, acc.: 99%] [G loss: 6.896276]\n",
            "4019 [ D loss: 0.134929, acc.: 95%] [G loss: 7.868914]\n",
            "4020 [ D loss: 0.155702, acc.: 97%] [G loss: 5.363235]\n",
            "4021 [ D loss: 0.117464, acc.: 98%] [G loss: 5.282207]\n",
            "4022 [ D loss: 0.133217, acc.: 98%] [G loss: 4.561199]\n",
            "4023 [ D loss: 0.170196, acc.: 97%] [G loss: 4.654642]\n",
            "4024 [ D loss: 0.125391, acc.: 98%] [G loss: 5.022758]\n",
            "4025 [ D loss: 0.173889, acc.: 95%] [G loss: 6.678032]\n",
            "4026 [ D loss: 0.144744, acc.: 95%] [G loss: 5.763468]\n",
            "4027 [ D loss: 0.145338, acc.: 93%] [G loss: 8.249325]\n",
            "4028 [ D loss: 0.089111, acc.: 98%] [G loss: 5.888474]\n",
            "4029 [ D loss: 0.121167, acc.: 97%] [G loss: 5.785394]\n",
            "4030 [ D loss: 0.117926, acc.: 97%] [G loss: 4.704099]\n",
            "4031 [ D loss: 0.290568, acc.: 89%] [G loss: 6.242938]\n",
            "4032 [ D loss: 0.206695, acc.: 89%] [G loss: 5.772014]\n",
            "4033 [ D loss: 0.180180, acc.: 93%] [G loss: 7.365883]\n",
            "4034 [ D loss: 0.131738, acc.: 95%] [G loss: 6.719434]\n",
            "4035 [ D loss: 0.147947, acc.: 93%] [G loss: 6.937887]\n",
            "4036 [ D loss: 0.121817, acc.: 97%] [G loss: 6.758575]\n",
            "4037 [ D loss: 0.100156, acc.: 98%] [G loss: 8.091064]\n",
            "4038 [ D loss: 0.177105, acc.: 93%] [G loss: 6.163347]\n",
            "4039 [ D loss: 0.185616, acc.: 95%] [G loss: 6.107059]\n",
            "4040 [ D loss: 0.197762, acc.: 92%] [G loss: 4.706249]\n",
            "4041 [ D loss: 0.207434, acc.: 92%] [G loss: 5.055900]\n",
            "4042 [ D loss: 0.084239, acc.: 99%] [G loss: 4.758385]\n",
            "4043 [ D loss: 0.202662, acc.: 91%] [G loss: 9.790506]\n",
            "4044 [ D loss: 0.186141, acc.: 91%] [G loss: 5.577997]\n",
            "4045 [ D loss: 0.124702, acc.: 98%] [G loss: 4.763060]\n",
            "4046 [ D loss: 0.100345, acc.: 96%] [G loss: 6.346394]\n",
            "4047 [ D loss: 0.143477, acc.: 95%] [G loss: 4.552826]\n",
            "4048 [ D loss: 0.124163, acc.: 95%] [G loss: 4.207242]\n",
            "4049 [ D loss: 0.139137, acc.: 95%] [G loss: 4.793288]\n",
            "4050 [ D loss: 0.209992, acc.: 91%] [G loss: 5.508148]\n",
            "4051 [ D loss: 0.186066, acc.: 91%] [G loss: 4.732391]\n",
            "4052 [ D loss: 0.134048, acc.: 98%] [G loss: 4.336587]\n",
            "4053 [ D loss: 0.143115, acc.: 94%] [G loss: 4.571997]\n",
            "4054 [ D loss: 0.280551, acc.: 88%] [G loss: 4.957144]\n",
            "4055 [ D loss: 0.254388, acc.: 89%] [G loss: 5.233315]\n",
            "4056 [ D loss: 0.207895, acc.: 94%] [G loss: 5.223771]\n",
            "4057 [ D loss: 0.181841, acc.: 92%] [G loss: 5.920604]\n",
            "4058 [ D loss: 0.166340, acc.: 95%] [G loss: 4.671507]\n",
            "4059 [ D loss: 0.113887, acc.: 98%] [G loss: 4.229453]\n",
            "4060 [ D loss: 0.146871, acc.: 96%] [G loss: 6.268978]\n",
            "4061 [ D loss: 0.147285, acc.: 94%] [G loss: 5.379423]\n",
            "4062 [ D loss: 0.171956, acc.: 94%] [G loss: 4.165017]\n",
            "4063 [ D loss: 0.260988, acc.: 87%] [G loss: 4.570642]\n",
            "4064 [ D loss: 0.196547, acc.: 91%] [G loss: 4.914578]\n",
            "4065 [ D loss: 0.121743, acc.: 98%] [G loss: 5.612400]\n",
            "4066 [ D loss: 0.115344, acc.: 98%] [G loss: 6.095877]\n",
            "4067 [ D loss: 0.163031, acc.: 98%] [G loss: 4.995195]\n",
            "4068 [ D loss: 0.095131, acc.: 98%] [G loss: 5.053612]\n",
            "4069 [ D loss: 0.160060, acc.: 95%] [G loss: 4.128518]\n",
            "4070 [ D loss: 0.111995, acc.: 98%] [G loss: 4.589592]\n",
            "4071 [ D loss: 0.194004, acc.: 94%] [G loss: 5.512071]\n",
            "4072 [ D loss: 0.108440, acc.: 98%] [G loss: 6.819100]\n",
            "4073 [ D loss: 0.141462, acc.: 97%] [G loss: 5.549949]\n",
            "4074 [ D loss: 0.101851, acc.: 98%] [G loss: 5.778649]\n",
            "4075 [ D loss: 0.160447, acc.: 94%] [G loss: 5.434074]\n",
            "4076 [ D loss: 0.204989, acc.: 92%] [G loss: 5.551408]\n",
            "4077 [ D loss: 0.166518, acc.: 95%] [G loss: 5.683214]\n",
            "4078 [ D loss: 0.168099, acc.: 91%] [G loss: 5.470140]\n",
            "4079 [ D loss: 0.125643, acc.: 97%] [G loss: 11.875122]\n",
            "4080 [ D loss: 0.197811, acc.: 94%] [G loss: 3.643292]\n",
            "4081 [ D loss: 0.121511, acc.: 95%] [G loss: 4.957113]\n",
            "4082 [ D loss: 0.185823, acc.: 91%] [G loss: 5.372931]\n",
            "4083 [ D loss: 0.099292, acc.: 98%] [G loss: 5.420556]\n",
            "4084 [ D loss: 0.226594, acc.: 93%] [G loss: 5.239547]\n",
            "4085 [ D loss: 0.187105, acc.: 93%] [G loss: 4.739103]\n",
            "4086 [ D loss: 0.129587, acc.: 97%] [G loss: 5.956565]\n",
            "4087 [ D loss: 0.168484, acc.: 95%] [G loss: 4.680102]\n",
            "4088 [ D loss: 0.188025, acc.: 95%] [G loss: 5.034904]\n",
            "4089 [ D loss: 0.115654, acc.: 95%] [G loss: 4.403297]\n",
            "4090 [ D loss: 0.090207, acc.: 98%] [G loss: 4.947680]\n",
            "4091 [ D loss: 0.105762, acc.: 96%] [G loss: 5.344920]\n",
            "4092 [ D loss: 0.072568, acc.: 99%] [G loss: 4.869244]\n",
            "4093 [ D loss: 0.213833, acc.: 93%] [G loss: 4.744000]\n",
            "4094 [ D loss: 0.140054, acc.: 98%] [G loss: 4.055196]\n",
            "4095 [ D loss: 0.202175, acc.: 95%] [G loss: 4.709244]\n",
            "4096 [ D loss: 0.198715, acc.: 95%] [G loss: 5.661475]\n",
            "4097 [ D loss: 0.106419, acc.: 98%] [G loss: 5.005136]\n",
            "4098 [ D loss: 0.141500, acc.: 98%] [G loss: 5.688921]\n",
            "4099 [ D loss: 0.190922, acc.: 93%] [G loss: 4.457244]\n",
            "4100 [ D loss: 0.113057, acc.: 97%] [G loss: 5.517227]\n",
            "4101 [ D loss: 0.256366, acc.: 89%] [G loss: 4.251114]\n",
            "4102 [ D loss: 0.111503, acc.: 95%] [G loss: 4.015265]\n",
            "4103 [ D loss: 0.341797, acc.: 89%] [G loss: 5.124474]\n",
            "4104 [ D loss: 0.194404, acc.: 95%] [G loss: 5.295095]\n",
            "4105 [ D loss: 0.116912, acc.: 96%] [G loss: 4.584641]\n",
            "4106 [ D loss: 0.219882, acc.: 95%] [G loss: 4.529593]\n",
            "4107 [ D loss: 0.147167, acc.: 95%] [G loss: 4.353158]\n",
            "4108 [ D loss: 0.152400, acc.: 98%] [G loss: 4.989238]\n",
            "4109 [ D loss: 0.172438, acc.: 95%] [G loss: 6.208960]\n",
            "4110 [ D loss: 0.175103, acc.: 95%] [G loss: 7.646921]\n",
            "4111 [ D loss: 0.186376, acc.: 94%] [G loss: 7.559840]\n",
            "4112 [ D loss: 0.173343, acc.: 93%] [G loss: 5.458639]\n",
            "4113 [ D loss: 0.182993, acc.: 91%] [G loss: 5.256660]\n",
            "4114 [ D loss: 0.173264, acc.: 94%] [G loss: 9.652197]\n",
            "4115 [ D loss: 0.163452, acc.: 95%] [G loss: 3.724787]\n",
            "4116 [ D loss: 0.184544, acc.: 93%] [G loss: 4.451555]\n",
            "4117 [ D loss: 0.212711, acc.: 93%] [G loss: 6.239284]\n",
            "4118 [ D loss: 0.078619, acc.: 98%] [G loss: 6.255231]\n",
            "4119 [ D loss: 0.075760, acc.: 100%] [G loss: 9.494885]\n",
            "4120 [ D loss: 0.057445, acc.: 100%] [G loss: 7.764414]\n",
            "4121 [ D loss: 0.066240, acc.: 98%] [G loss: 5.604635]\n",
            "4122 [ D loss: 0.111597, acc.: 97%] [G loss: 3.288927]\n",
            "4123 [ D loss: 0.114316, acc.: 98%] [G loss: 6.228167]\n",
            "4124 [ D loss: 0.082341, acc.: 98%] [G loss: 9.736490]\n",
            "4125 [ D loss: 0.208721, acc.: 92%] [G loss: 7.192788]\n",
            "4126 [ D loss: 0.132494, acc.: 95%] [G loss: 5.451177]\n",
            "4127 [ D loss: 0.114221, acc.: 97%] [G loss: 6.820275]\n",
            "4128 [ D loss: 0.172107, acc.: 91%] [G loss: 6.125466]\n",
            "4129 [ D loss: 0.159431, acc.: 95%] [G loss: 5.973662]\n",
            "4130 [ D loss: 0.294920, acc.: 90%] [G loss: 5.984650]\n",
            "4131 [ D loss: 0.104309, acc.: 97%] [G loss: 6.458241]\n",
            "4132 [ D loss: 0.154992, acc.: 95%] [G loss: 5.084509]\n",
            "4133 [ D loss: 0.118736, acc.: 97%] [G loss: 5.262669]\n",
            "4134 [ D loss: 0.122305, acc.: 97%] [G loss: 7.766898]\n",
            "4135 [ D loss: 0.130059, acc.: 96%] [G loss: 6.186743]\n",
            "4136 [ D loss: 0.175221, acc.: 95%] [G loss: 4.051717]\n",
            "4137 [ D loss: 0.207563, acc.: 93%] [G loss: 4.932588]\n",
            "4138 [ D loss: 0.167560, acc.: 95%] [G loss: 4.595613]\n",
            "4139 [ D loss: 0.137153, acc.: 97%] [G loss: 3.671825]\n",
            "4140 [ D loss: 0.197873, acc.: 95%] [G loss: 6.878808]\n",
            "4141 [ D loss: 0.158402, acc.: 92%] [G loss: 6.203397]\n",
            "4142 [ D loss: 0.232247, acc.: 90%] [G loss: 7.633568]\n",
            "4143 [ D loss: 0.137399, acc.: 95%] [G loss: 6.693460]\n",
            "4144 [ D loss: 0.218034, acc.: 90%] [G loss: 6.095690]\n",
            "4145 [ D loss: 0.064569, acc.: 99%] [G loss: 7.372874]\n",
            "4146 [ D loss: 0.158588, acc.: 95%] [G loss: 5.055294]\n",
            "4147 [ D loss: 0.197458, acc.: 93%] [G loss: 4.799488]\n",
            "4148 [ D loss: 0.215990, acc.: 91%] [G loss: 4.259286]\n",
            "4149 [ D loss: 0.162315, acc.: 95%] [G loss: 5.142093]\n",
            "4150 [ D loss: 0.098187, acc.: 98%] [G loss: 5.034514]\n",
            "4151 [ D loss: 0.171826, acc.: 95%] [G loss: 5.198300]\n",
            "4152 [ D loss: 0.084415, acc.: 98%] [G loss: 6.260451]\n",
            "4153 [ D loss: 0.177352, acc.: 95%] [G loss: 4.413404]\n",
            "4154 [ D loss: 0.138962, acc.: 95%] [G loss: 5.114227]\n",
            "4155 [ D loss: 0.189049, acc.: 91%] [G loss: 7.572741]\n",
            "4156 [ D loss: 0.131698, acc.: 95%] [G loss: 4.968606]\n",
            "4157 [ D loss: 0.115849, acc.: 98%] [G loss: 5.251279]\n",
            "4158 [ D loss: 0.208549, acc.: 91%] [G loss: 5.589194]\n",
            "4159 [ D loss: 0.182935, acc.: 95%] [G loss: 5.177516]\n",
            "4160 [ D loss: 0.157033, acc.: 95%] [G loss: 4.575756]\n",
            "4161 [ D loss: 0.109652, acc.: 97%] [G loss: 5.430468]\n",
            "4162 [ D loss: 0.182073, acc.: 95%] [G loss: 6.327456]\n",
            "4163 [ D loss: 0.131453, acc.: 95%] [G loss: 6.424493]\n",
            "4164 [ D loss: 0.197470, acc.: 91%] [G loss: 9.427437]\n",
            "4165 [ D loss: 0.108971, acc.: 98%] [G loss: 8.008503]\n",
            "4166 [ D loss: 0.115130, acc.: 97%] [G loss: 10.149414]\n",
            "4167 [ D loss: 0.150558, acc.: 94%] [G loss: 5.518961]\n",
            "4168 [ D loss: 0.177024, acc.: 94%] [G loss: 6.254181]\n",
            "4169 [ D loss: 0.145937, acc.: 97%] [G loss: 5.539554]\n",
            "4170 [ D loss: 0.218741, acc.: 91%] [G loss: 5.134827]\n",
            "4171 [ D loss: 0.111671, acc.: 98%] [G loss: 7.721619]\n",
            "4172 [ D loss: 0.293013, acc.: 86%] [G loss: 5.017391]\n",
            "4173 [ D loss: 0.085422, acc.: 98%] [G loss: 7.164698]\n",
            "4174 [ D loss: 0.127992, acc.: 95%] [G loss: 5.960209]\n",
            "4175 [ D loss: 0.203975, acc.: 90%] [G loss: 5.360381]\n",
            "4176 [ D loss: 0.207899, acc.: 91%] [G loss: 5.373006]\n",
            "4177 [ D loss: 0.228779, acc.: 90%] [G loss: 4.684411]\n",
            "4178 [ D loss: 0.096045, acc.: 97%] [G loss: 5.008476]\n",
            "4179 [ D loss: 0.104678, acc.: 97%] [G loss: 4.811042]\n",
            "4180 [ D loss: 0.196630, acc.: 94%] [G loss: 5.643778]\n",
            "4181 [ D loss: 0.174726, acc.: 95%] [G loss: 7.414647]\n",
            "4182 [ D loss: 0.086773, acc.: 98%] [G loss: 4.273082]\n",
            "4183 [ D loss: 0.277590, acc.: 89%] [G loss: 4.242900]\n",
            "4184 [ D loss: 0.111884, acc.: 98%] [G loss: 8.382876]\n",
            "4185 [ D loss: 0.159840, acc.: 95%] [G loss: 4.917279]\n",
            "4186 [ D loss: 0.134248, acc.: 95%] [G loss: 5.606367]\n",
            "4187 [ D loss: 0.174061, acc.: 96%] [G loss: 4.870806]\n",
            "4188 [ D loss: 0.096208, acc.: 95%] [G loss: 10.053480]\n",
            "4189 [ D loss: 0.121200, acc.: 98%] [G loss: 6.441452]\n",
            "4190 [ D loss: 0.074289, acc.: 97%] [G loss: 11.068970]\n",
            "4191 [ D loss: 0.087680, acc.: 96%] [G loss: 5.249525]\n",
            "4192 [ D loss: 0.234773, acc.: 88%] [G loss: 10.688148]\n",
            "4193 [ D loss: 0.082476, acc.: 97%] [G loss: 10.953427]\n",
            "4194 [ D loss: 0.107237, acc.: 95%] [G loss: 8.405630]\n",
            "4195 [ D loss: 0.125443, acc.: 95%] [G loss: 12.224412]\n",
            "4196 [ D loss: 0.097039, acc.: 97%] [G loss: 7.360669]\n",
            "4197 [ D loss: 0.079850, acc.: 98%] [G loss: 6.007703]\n",
            "4198 [ D loss: 0.143036, acc.: 97%] [G loss: 6.418559]\n",
            "4199 [ D loss: 0.089267, acc.: 98%] [G loss: 6.308931]\n",
            "4200 [ D loss: 0.108883, acc.: 97%] [G loss: 4.764227]\n",
            "4201 [ D loss: 0.136173, acc.: 94%] [G loss: 6.023571]\n",
            "4202 [ D loss: 0.131015, acc.: 97%] [G loss: 4.617002]\n",
            "4203 [ D loss: 0.117788, acc.: 97%] [G loss: 5.019472]\n",
            "4204 [ D loss: 0.261617, acc.: 91%] [G loss: 3.661370]\n",
            "4205 [ D loss: 0.297972, acc.: 87%] [G loss: 4.447547]\n",
            "4206 [ D loss: 0.134605, acc.: 98%] [G loss: 4.435415]\n",
            "4207 [ D loss: 0.209541, acc.: 92%] [G loss: 5.114210]\n",
            "4208 [ D loss: 0.163466, acc.: 96%] [G loss: 6.724315]\n",
            "4209 [ D loss: 0.181361, acc.: 93%] [G loss: 4.312882]\n",
            "4210 [ D loss: 0.056993, acc.: 99%] [G loss: 5.628862]\n",
            "4211 [ D loss: 0.101450, acc.: 98%] [G loss: 5.937090]\n",
            "4212 [ D loss: 0.136876, acc.: 95%] [G loss: 11.177020]\n",
            "4213 [ D loss: 0.091002, acc.: 98%] [G loss: 9.233947]\n",
            "4214 [ D loss: 0.135269, acc.: 94%] [G loss: 5.829295]\n",
            "4215 [ D loss: 0.128185, acc.: 97%] [G loss: 4.868107]\n",
            "4216 [ D loss: 0.110936, acc.: 97%] [G loss: 5.359520]\n",
            "4217 [ D loss: 0.084257, acc.: 98%] [G loss: 7.602736]\n",
            "4218 [ D loss: 0.124841, acc.: 98%] [G loss: 4.404443]\n",
            "4219 [ D loss: 0.192234, acc.: 95%] [G loss: 4.389383]\n",
            "4220 [ D loss: 0.172759, acc.: 95%] [G loss: 4.423950]\n",
            "4221 [ D loss: 0.286839, acc.: 86%] [G loss: 4.724440]\n",
            "4222 [ D loss: 0.154187, acc.: 95%] [G loss: 4.396745]\n",
            "4223 [ D loss: 0.185247, acc.: 95%] [G loss: 4.848185]\n",
            "4224 [ D loss: 0.173431, acc.: 95%] [G loss: 4.296308]\n",
            "4225 [ D loss: 0.155267, acc.: 94%] [G loss: 4.971109]\n",
            "4226 [ D loss: 0.127468, acc.: 95%] [G loss: 4.661602]\n",
            "4227 [ D loss: 0.330926, acc.: 84%] [G loss: 4.044201]\n",
            "4228 [ D loss: 0.204472, acc.: 93%] [G loss: 5.943871]\n",
            "4229 [ D loss: 0.291665, acc.: 86%] [G loss: 6.172181]\n",
            "4230 [ D loss: 0.128736, acc.: 96%] [G loss: 5.596702]\n",
            "4231 [ D loss: 0.152941, acc.: 94%] [G loss: 4.904006]\n",
            "4232 [ D loss: 0.109728, acc.: 96%] [G loss: 4.539400]\n",
            "4233 [ D loss: 0.172172, acc.: 96%] [G loss: 3.627730]\n",
            "4234 [ D loss: 0.162646, acc.: 95%] [G loss: 4.466020]\n",
            "4235 [ D loss: 0.161768, acc.: 93%] [G loss: 4.896506]\n",
            "4236 [ D loss: 0.171513, acc.: 93%] [G loss: 4.517249]\n",
            "4237 [ D loss: 0.128844, acc.: 96%] [G loss: 4.987222]\n",
            "4238 [ D loss: 0.136837, acc.: 95%] [G loss: 5.417867]\n",
            "4239 [ D loss: 0.126074, acc.: 98%] [G loss: 5.456479]\n",
            "4240 [ D loss: 0.222830, acc.: 93%] [G loss: 4.999568]\n",
            "4241 [ D loss: 0.230814, acc.: 90%] [G loss: 4.905702]\n",
            "4242 [ D loss: 0.123052, acc.: 97%] [G loss: 4.144258]\n",
            "4243 [ D loss: 0.113306, acc.: 97%] [G loss: 6.379311]\n",
            "4244 [ D loss: 0.082827, acc.: 98%] [G loss: 6.905083]\n",
            "4245 [ D loss: 0.106455, acc.: 95%] [G loss: 7.292741]\n",
            "4246 [ D loss: 0.205294, acc.: 91%] [G loss: 4.433795]\n",
            "4247 [ D loss: 0.102714, acc.: 96%] [G loss: 6.948254]\n",
            "4248 [ D loss: 0.084550, acc.: 97%] [G loss: 10.873994]\n",
            "4249 [ D loss: 0.064815, acc.: 100%] [G loss: 9.320843]\n",
            "4250 [ D loss: 0.175459, acc.: 95%] [G loss: 5.226988]\n",
            "4251 [ D loss: 0.114128, acc.: 95%] [G loss: 5.308715]\n",
            "4252 [ D loss: 0.214273, acc.: 92%] [G loss: 6.301339]\n",
            "4253 [ D loss: 0.122941, acc.: 96%] [G loss: 6.505605]\n",
            "4254 [ D loss: 0.200599, acc.: 92%] [G loss: 6.481656]\n",
            "4255 [ D loss: 0.263404, acc.: 90%] [G loss: 4.883117]\n",
            "4256 [ D loss: 0.197841, acc.: 95%] [G loss: 4.802666]\n",
            "4257 [ D loss: 0.172162, acc.: 91%] [G loss: 4.770876]\n",
            "4258 [ D loss: 0.095255, acc.: 97%] [G loss: 6.852055]\n",
            "4259 [ D loss: 0.093861, acc.: 97%] [G loss: 5.877535]\n",
            "4260 [ D loss: 0.133745, acc.: 96%] [G loss: 5.822297]\n",
            "4261 [ D loss: 0.101884, acc.: 97%] [G loss: 7.956999]\n",
            "4262 [ D loss: 0.186271, acc.: 93%] [G loss: 3.870773]\n",
            "4263 [ D loss: 0.180351, acc.: 92%] [G loss: 5.301790]\n",
            "4264 [ D loss: 0.156064, acc.: 95%] [G loss: 4.883326]\n",
            "4265 [ D loss: 0.176506, acc.: 94%] [G loss: 8.386778]\n",
            "4266 [ D loss: 0.110057, acc.: 97%] [G loss: 5.350671]\n",
            "4267 [ D loss: 0.244952, acc.: 93%] [G loss: 4.636270]\n",
            "4268 [ D loss: 0.167419, acc.: 93%] [G loss: 4.638165]\n",
            "4269 [ D loss: 0.205192, acc.: 90%] [G loss: 6.558539]\n",
            "4270 [ D loss: 0.158252, acc.: 96%] [G loss: 4.741589]\n",
            "4271 [ D loss: 0.162665, acc.: 93%] [G loss: 6.400464]\n",
            "4272 [ D loss: 0.112457, acc.: 98%] [G loss: 4.935836]\n",
            "4273 [ D loss: 0.153992, acc.: 95%] [G loss: 5.004046]\n",
            "4274 [ D loss: 0.115137, acc.: 95%] [G loss: 6.580444]\n",
            "4275 [ D loss: 0.139864, acc.: 96%] [G loss: 5.723830]\n",
            "4276 [ D loss: 0.124735, acc.: 95%] [G loss: 4.574286]\n",
            "4277 [ D loss: 0.185884, acc.: 93%] [G loss: 4.661816]\n",
            "4278 [ D loss: 0.141840, acc.: 95%] [G loss: 4.607548]\n",
            "4279 [ D loss: 0.110891, acc.: 96%] [G loss: 6.241828]\n",
            "4280 [ D loss: 0.084199, acc.: 98%] [G loss: 8.618925]\n",
            "4281 [ D loss: 0.187791, acc.: 91%] [G loss: 7.033875]\n",
            "4282 [ D loss: 0.214296, acc.: 92%] [G loss: 9.417828]\n",
            "4283 [ D loss: 0.181166, acc.: 91%] [G loss: 6.369240]\n",
            "4284 [ D loss: 0.173738, acc.: 93%] [G loss: 6.114081]\n",
            "4285 [ D loss: 0.102414, acc.: 95%] [G loss: 5.389823]\n",
            "4286 [ D loss: 0.140076, acc.: 95%] [G loss: 4.604455]\n",
            "4287 [ D loss: 0.152764, acc.: 96%] [G loss: 4.621520]\n",
            "4288 [ D loss: 0.251062, acc.: 90%] [G loss: 5.552579]\n",
            "4289 [ D loss: 0.221390, acc.: 89%] [G loss: 5.072851]\n",
            "4290 [ D loss: 0.199127, acc.: 95%] [G loss: 6.518381]\n",
            "4291 [ D loss: 0.121186, acc.: 96%] [G loss: 5.516847]\n",
            "4292 [ D loss: 0.131459, acc.: 95%] [G loss: 6.760464]\n",
            "4293 [ D loss: 0.130255, acc.: 97%] [G loss: 4.658505]\n",
            "4294 [ D loss: 0.152168, acc.: 97%] [G loss: 5.552401]\n",
            "4295 [ D loss: 0.191600, acc.: 94%] [G loss: 4.895626]\n",
            "4296 [ D loss: 0.194372, acc.: 90%] [G loss: 4.299253]\n",
            "4297 [ D loss: 0.142112, acc.: 94%] [G loss: 4.863869]\n",
            "4298 [ D loss: 0.153277, acc.: 95%] [G loss: 3.820279]\n",
            "4299 [ D loss: 0.119441, acc.: 95%] [G loss: 4.087724]\n",
            "4300 [ D loss: 0.245487, acc.: 90%] [G loss: 5.578376]\n",
            "4301 [ D loss: 0.313256, acc.: 85%] [G loss: 4.918325]\n",
            "4302 [ D loss: 0.296900, acc.: 86%] [G loss: 5.949074]\n",
            "4303 [ D loss: 0.217357, acc.: 90%] [G loss: 3.837347]\n",
            "4304 [ D loss: 0.136491, acc.: 95%] [G loss: 9.603132]\n",
            "4305 [ D loss: 0.199355, acc.: 94%] [G loss: 6.717699]\n",
            "4306 [ D loss: 0.083233, acc.: 97%] [G loss: 6.164097]\n",
            "4307 [ D loss: 0.160383, acc.: 95%] [G loss: 6.237876]\n",
            "4308 [ D loss: 0.107391, acc.: 98%] [G loss: 7.740101]\n",
            "4309 [ D loss: 0.098053, acc.: 96%] [G loss: 9.054135]\n",
            "4310 [ D loss: 0.113648, acc.: 96%] [G loss: 4.291913]\n",
            "4311 [ D loss: 0.084276, acc.: 98%] [G loss: 6.422344]\n",
            "4312 [ D loss: 0.077378, acc.: 99%] [G loss: 4.442623]\n",
            "4313 [ D loss: 0.193370, acc.: 90%] [G loss: 7.032452]\n",
            "4314 [ D loss: 0.177954, acc.: 94%] [G loss: 4.710114]\n",
            "4315 [ D loss: 0.163636, acc.: 95%] [G loss: 5.766263]\n",
            "4316 [ D loss: 0.182598, acc.: 92%] [G loss: 5.834539]\n",
            "4317 [ D loss: 0.220609, acc.: 91%] [G loss: 5.300253]\n",
            "4318 [ D loss: 0.191999, acc.: 93%] [G loss: 5.393893]\n",
            "4319 [ D loss: 0.162168, acc.: 95%] [G loss: 4.436285]\n",
            "4320 [ D loss: 0.169235, acc.: 95%] [G loss: 5.180281]\n",
            "4321 [ D loss: 0.107331, acc.: 98%] [G loss: 3.069295]\n",
            "4322 [ D loss: 0.138090, acc.: 95%] [G loss: 5.345220]\n",
            "4323 [ D loss: 0.194524, acc.: 95%] [G loss: 4.240480]\n",
            "4324 [ D loss: 0.200733, acc.: 95%] [G loss: 6.740507]\n",
            "4325 [ D loss: 0.141623, acc.: 92%] [G loss: 6.556999]\n",
            "4326 [ D loss: 0.203962, acc.: 92%] [G loss: 6.204910]\n",
            "4327 [ D loss: 0.067566, acc.: 99%] [G loss: 6.546148]\n",
            "4328 [ D loss: 0.095027, acc.: 97%] [G loss: 7.386318]\n",
            "4329 [ D loss: 0.083792, acc.: 98%] [G loss: 5.006893]\n",
            "4330 [ D loss: 0.106044, acc.: 97%] [G loss: 6.592012]\n",
            "4331 [ D loss: 0.123380, acc.: 96%] [G loss: 5.972319]\n",
            "4332 [ D loss: 0.292283, acc.: 84%] [G loss: 5.656870]\n",
            "4333 [ D loss: 0.121160, acc.: 95%] [G loss: 8.516712]\n",
            "4334 [ D loss: 0.155741, acc.: 95%] [G loss: 5.526108]\n",
            "4335 [ D loss: 0.131364, acc.: 96%] [G loss: 4.416736]\n",
            "4336 [ D loss: 0.118076, acc.: 95%] [G loss: 5.700887]\n",
            "4337 [ D loss: 0.150269, acc.: 96%] [G loss: 6.667752]\n",
            "4338 [ D loss: 0.171075, acc.: 91%] [G loss: 7.577060]\n",
            "4339 [ D loss: 0.121521, acc.: 97%] [G loss: 4.618983]\n",
            "4340 [ D loss: 0.084007, acc.: 98%] [G loss: 5.550317]\n",
            "4341 [ D loss: 0.144669, acc.: 95%] [G loss: 5.671959]\n",
            "4342 [ D loss: 0.109278, acc.: 98%] [G loss: 7.348807]\n",
            "4343 [ D loss: 0.178355, acc.: 93%] [G loss: 7.761476]\n",
            "4344 [ D loss: 0.232272, acc.: 92%] [G loss: 5.726957]\n",
            "4345 [ D loss: 0.103520, acc.: 96%] [G loss: 8.304796]\n",
            "4346 [ D loss: 0.165912, acc.: 93%] [G loss: 10.554813]\n",
            "4347 [ D loss: 0.056026, acc.: 98%] [G loss: 9.685391]\n",
            "4348 [ D loss: 0.096682, acc.: 95%] [G loss: 7.423388]\n",
            "4349 [ D loss: 0.125686, acc.: 95%] [G loss: 5.534970]\n",
            "4350 [ D loss: 0.088986, acc.: 97%] [G loss: 10.310186]\n",
            "4351 [ D loss: 0.135198, acc.: 96%] [G loss: 6.202380]\n",
            "4352 [ D loss: 0.176189, acc.: 94%] [G loss: 5.097901]\n",
            "4353 [ D loss: 0.133449, acc.: 95%] [G loss: 7.061926]\n",
            "4354 [ D loss: 0.158342, acc.: 92%] [G loss: 8.480003]\n",
            "4355 [ D loss: 0.174700, acc.: 95%] [G loss: 5.235865]\n",
            "4356 [ D loss: 0.077336, acc.: 99%] [G loss: 7.919575]\n",
            "4357 [ D loss: 0.101584, acc.: 96%] [G loss: 6.949458]\n",
            "4358 [ D loss: 0.141599, acc.: 95%] [G loss: 8.127022]\n",
            "4359 [ D loss: 0.187236, acc.: 91%] [G loss: 5.952083]\n",
            "4360 [ D loss: 0.251517, acc.: 93%] [G loss: 5.013617]\n",
            "4361 [ D loss: 0.190786, acc.: 92%] [G loss: 3.813139]\n",
            "4362 [ D loss: 0.176768, acc.: 95%] [G loss: 3.611942]\n",
            "4363 [ D loss: 0.092986, acc.: 96%] [G loss: 6.012545]\n",
            "4364 [ D loss: 0.213015, acc.: 93%] [G loss: 6.451043]\n",
            "4365 [ D loss: 0.127230, acc.: 95%] [G loss: 7.478453]\n",
            "4366 [ D loss: 0.123666, acc.: 98%] [G loss: 5.987223]\n",
            "4367 [ D loss: 0.136756, acc.: 96%] [G loss: 5.639090]\n",
            "4368 [ D loss: 0.170071, acc.: 95%] [G loss: 8.849915]\n",
            "4369 [ D loss: 0.146709, acc.: 95%] [G loss: 6.115344]\n",
            "4370 [ D loss: 0.083584, acc.: 98%] [G loss: 4.093687]\n",
            "4371 [ D loss: 0.162610, acc.: 92%] [G loss: 9.841857]\n",
            "4372 [ D loss: 0.110674, acc.: 97%] [G loss: 8.045379]\n",
            "4373 [ D loss: 0.059773, acc.: 99%] [G loss: 5.917888]\n",
            "4374 [ D loss: 0.244469, acc.: 87%] [G loss: 5.319091]\n",
            "4375 [ D loss: 0.113766, acc.: 95%] [G loss: 6.216085]\n",
            "4376 [ D loss: 0.171626, acc.: 95%] [G loss: 6.269902]\n",
            "4377 [ D loss: 0.089632, acc.: 98%] [G loss: 5.079996]\n",
            "4378 [ D loss: 0.144138, acc.: 98%] [G loss: 5.495970]\n",
            "4379 [ D loss: 0.163853, acc.: 95%] [G loss: 4.858348]\n",
            "4380 [ D loss: 0.157676, acc.: 96%] [G loss: 6.019147]\n",
            "4381 [ D loss: 0.098154, acc.: 98%] [G loss: 8.301836]\n",
            "4382 [ D loss: 0.126398, acc.: 98%] [G loss: 4.854577]\n",
            "4383 [ D loss: 0.170672, acc.: 93%] [G loss: 5.830761]\n",
            "4384 [ D loss: 0.192867, acc.: 91%] [G loss: 6.502466]\n",
            "4385 [ D loss: 0.252860, acc.: 90%] [G loss: 6.441054]\n",
            "4386 [ D loss: 0.149027, acc.: 95%] [G loss: 4.906528]\n",
            "4387 [ D loss: 0.180845, acc.: 92%] [G loss: 3.957117]\n",
            "4388 [ D loss: 0.299974, acc.: 88%] [G loss: 4.728529]\n",
            "4389 [ D loss: 0.182028, acc.: 95%] [G loss: 6.892471]\n",
            "4390 [ D loss: 0.080813, acc.: 98%] [G loss: 5.915133]\n",
            "4391 [ D loss: 0.163535, acc.: 95%] [G loss: 5.619443]\n",
            "4392 [ D loss: 0.088048, acc.: 98%] [G loss: 6.384325]\n",
            "4393 [ D loss: 0.087506, acc.: 97%] [G loss: 9.213226]\n",
            "4394 [ D loss: 0.085229, acc.: 97%] [G loss: 5.773190]\n",
            "4395 [ D loss: 0.197591, acc.: 92%] [G loss: 6.380031]\n",
            "4396 [ D loss: 0.207858, acc.: 94%] [G loss: 4.778537]\n",
            "4397 [ D loss: 0.258229, acc.: 91%] [G loss: 5.144278]\n",
            "4398 [ D loss: 0.145869, acc.: 95%] [G loss: 5.550025]\n",
            "4399 [ D loss: 0.121728, acc.: 96%] [G loss: 6.586674]\n",
            "4400 [ D loss: 0.151052, acc.: 95%] [G loss: 7.499278]\n",
            "4401 [ D loss: 0.147361, acc.: 94%] [G loss: 5.711185]\n",
            "4402 [ D loss: 0.120329, acc.: 98%] [G loss: 5.465973]\n",
            "4403 [ D loss: 0.194644, acc.: 92%] [G loss: 5.120842]\n",
            "4404 [ D loss: 0.173267, acc.: 94%] [G loss: 6.953328]\n",
            "4405 [ D loss: 0.089046, acc.: 98%] [G loss: 5.964903]\n",
            "4406 [ D loss: 0.190048, acc.: 94%] [G loss: 5.277345]\n",
            "4407 [ D loss: 0.215207, acc.: 91%] [G loss: 4.283718]\n",
            "4408 [ D loss: 0.203455, acc.: 92%] [G loss: 4.634043]\n",
            "4409 [ D loss: 0.442489, acc.: 77%] [G loss: 4.981194]\n",
            "4410 [ D loss: 0.129712, acc.: 95%] [G loss: 5.579059]\n",
            "4411 [ D loss: 0.119444, acc.: 95%] [G loss: 5.831310]\n",
            "4412 [ D loss: 0.188490, acc.: 95%] [G loss: 4.778109]\n",
            "4413 [ D loss: 0.139635, acc.: 95%] [G loss: 5.545909]\n",
            "4414 [ D loss: 0.147880, acc.: 97%] [G loss: 5.140399]\n",
            "4415 [ D loss: 0.081196, acc.: 99%] [G loss: 7.986082]\n",
            "4416 [ D loss: 0.135840, acc.: 95%] [G loss: 6.139911]\n",
            "4417 [ D loss: 0.090563, acc.: 98%] [G loss: 7.624573]\n",
            "4418 [ D loss: 0.115400, acc.: 98%] [G loss: 5.267694]\n",
            "4419 [ D loss: 0.130270, acc.: 98%] [G loss: 8.167592]\n",
            "4420 [ D loss: 0.097760, acc.: 97%] [G loss: 8.342060]\n",
            "4421 [ D loss: 0.126081, acc.: 96%] [G loss: 6.051873]\n",
            "4422 [ D loss: 0.131447, acc.: 97%] [G loss: 3.572835]\n",
            "4423 [ D loss: 0.170621, acc.: 95%] [G loss: 6.367728]\n",
            "4424 [ D loss: 0.340930, acc.: 84%] [G loss: 5.803384]\n",
            "4425 [ D loss: 0.172677, acc.: 95%] [G loss: 5.449029]\n",
            "4426 [ D loss: 0.131085, acc.: 96%] [G loss: 5.627125]\n",
            "4427 [ D loss: 0.109120, acc.: 98%] [G loss: 4.725086]\n",
            "4428 [ D loss: 0.143890, acc.: 97%] [G loss: 4.522215]\n",
            "4429 [ D loss: 0.112646, acc.: 95%] [G loss: 5.521787]\n",
            "4430 [ D loss: 0.140304, acc.: 97%] [G loss: 3.669129]\n",
            "4431 [ D loss: 0.124331, acc.: 97%] [G loss: 6.450737]\n",
            "4432 [ D loss: 0.165297, acc.: 95%] [G loss: 3.837229]\n",
            "4433 [ D loss: 0.075860, acc.: 98%] [G loss: 2.788197]\n",
            "4434 [ D loss: 0.133468, acc.: 97%] [G loss: 4.407267]\n",
            "4435 [ D loss: 0.214299, acc.: 91%] [G loss: 4.546015]\n",
            "4436 [ D loss: 0.191002, acc.: 92%] [G loss: 10.019917]\n",
            "4437 [ D loss: 0.264511, acc.: 86%] [G loss: 5.319230]\n",
            "4438 [ D loss: 0.150341, acc.: 95%] [G loss: 7.155023]\n",
            "4439 [ D loss: 0.160283, acc.: 94%] [G loss: 6.113100]\n",
            "4440 [ D loss: 0.204729, acc.: 91%] [G loss: 6.956328]\n",
            "4441 [ D loss: 0.211478, acc.: 93%] [G loss: 7.269692]\n",
            "4442 [ D loss: 0.116649, acc.: 95%] [G loss: 5.076565]\n",
            "4443 [ D loss: 0.137601, acc.: 97%] [G loss: 4.309132]\n",
            "4444 [ D loss: 0.172032, acc.: 97%] [G loss: 5.157207]\n",
            "4445 [ D loss: 0.096334, acc.: 96%] [G loss: 4.365949]\n",
            "4446 [ D loss: 0.215570, acc.: 92%] [G loss: 7.811243]\n",
            "4447 [ D loss: 0.108647, acc.: 97%] [G loss: 9.733910]\n",
            "4448 [ D loss: 0.122508, acc.: 98%] [G loss: 8.525198]\n",
            "4449 [ D loss: 0.102328, acc.: 95%] [G loss: 9.928308]\n",
            "4450 [ D loss: 0.174371, acc.: 91%] [G loss: 10.301135]\n",
            "4451 [ D loss: 0.108678, acc.: 95%] [G loss: 5.155527]\n",
            "4452 [ D loss: 0.080454, acc.: 97%] [G loss: 3.859459]\n",
            "4453 [ D loss: 0.133987, acc.: 96%] [G loss: 7.973566]\n",
            "4454 [ D loss: 0.103133, acc.: 98%] [G loss: 5.664877]\n",
            "4455 [ D loss: 0.141227, acc.: 98%] [G loss: 3.851330]\n",
            "4456 [ D loss: 0.167108, acc.: 95%] [G loss: 5.240758]\n",
            "4457 [ D loss: 0.145543, acc.: 95%] [G loss: 3.396958]\n",
            "4458 [ D loss: 0.137163, acc.: 97%] [G loss: 4.533274]\n",
            "4459 [ D loss: 0.093637, acc.: 98%] [G loss: 4.534920]\n",
            "4460 [ D loss: 0.150138, acc.: 95%] [G loss: 4.814473]\n",
            "4461 [ D loss: 0.110364, acc.: 99%] [G loss: 4.806106]\n",
            "4462 [ D loss: 0.159225, acc.: 95%] [G loss: 4.640300]\n",
            "4463 [ D loss: 0.161089, acc.: 92%] [G loss: 6.544209]\n",
            "4464 [ D loss: 0.236329, acc.: 91%] [G loss: 6.013987]\n",
            "4465 [ D loss: 0.085995, acc.: 98%] [G loss: 5.207665]\n",
            "4466 [ D loss: 0.235526, acc.: 91%] [G loss: 3.614143]\n",
            "4467 [ D loss: 0.272791, acc.: 88%] [G loss: 5.644867]\n",
            "4468 [ D loss: 0.185269, acc.: 91%] [G loss: 6.656651]\n",
            "4469 [ D loss: 0.343199, acc.: 84%] [G loss: 4.849712]\n",
            "4470 [ D loss: 0.193468, acc.: 95%] [G loss: 5.230717]\n",
            "4471 [ D loss: 0.358814, acc.: 84%] [G loss: 6.414078]\n",
            "4472 [ D loss: 0.118867, acc.: 96%] [G loss: 7.996243]\n",
            "4473 [ D loss: 0.615900, acc.: 72%] [G loss: 4.856497]\n",
            "4474 [ D loss: 0.098795, acc.: 97%] [G loss: 10.944738]\n",
            "4475 [ D loss: 0.258186, acc.: 88%] [G loss: 6.406554]\n",
            "4476 [ D loss: 0.091399, acc.: 97%] [G loss: 4.587289]\n",
            "4477 [ D loss: 0.061155, acc.: 99%] [G loss: 9.923307]\n",
            "4478 [ D loss: 0.100616, acc.: 98%] [G loss: 6.440738]\n",
            "4479 [ D loss: 0.067142, acc.: 99%] [G loss: 6.275077]\n",
            "4480 [ D loss: 0.147902, acc.: 95%] [G loss: 4.604273]\n",
            "4481 [ D loss: 0.119737, acc.: 95%] [G loss: 4.606274]\n",
            "4482 [ D loss: 0.077077, acc.: 98%] [G loss: 5.233317]\n",
            "4483 [ D loss: 0.142613, acc.: 97%] [G loss: 4.223247]\n",
            "4484 [ D loss: 0.153505, acc.: 95%] [G loss: 4.909755]\n",
            "4485 [ D loss: 0.123301, acc.: 98%] [G loss: 5.642547]\n",
            "4486 [ D loss: 0.109575, acc.: 98%] [G loss: 4.377028]\n",
            "4487 [ D loss: 0.103785, acc.: 98%] [G loss: 4.829079]\n",
            "4488 [ D loss: 0.130523, acc.: 94%] [G loss: 4.286921]\n",
            "4489 [ D loss: 0.132424, acc.: 96%] [G loss: 4.110475]\n",
            "4490 [ D loss: 0.160297, acc.: 95%] [G loss: 5.178947]\n",
            "4491 [ D loss: 0.118696, acc.: 98%] [G loss: 4.441996]\n",
            "4492 [ D loss: 0.079933, acc.: 98%] [G loss: 3.902504]\n",
            "4493 [ D loss: 0.172274, acc.: 94%] [G loss: 2.621296]\n",
            "4494 [ D loss: 0.254410, acc.: 90%] [G loss: 4.400091]\n",
            "4495 [ D loss: 0.420783, acc.: 80%] [G loss: 4.100044]\n",
            "4496 [ D loss: 0.160113, acc.: 95%] [G loss: 5.297100]\n",
            "4497 [ D loss: 0.064536, acc.: 100%] [G loss: 7.241370]\n",
            "4498 [ D loss: 0.181130, acc.: 95%] [G loss: 4.640185]\n",
            "4499 [ D loss: 0.243271, acc.: 89%] [G loss: 6.392276]\n",
            "4500 [ D loss: 0.084880, acc.: 98%] [G loss: 5.008854]\n",
            "4501 [ D loss: 0.300637, acc.: 91%] [G loss: 4.635642]\n",
            "4502 [ D loss: 0.137341, acc.: 97%] [G loss: 4.927447]\n",
            "4503 [ D loss: 0.151610, acc.: 94%] [G loss: 5.278736]\n",
            "4504 [ D loss: 0.180933, acc.: 95%] [G loss: 3.784949]\n",
            "4505 [ D loss: 0.090678, acc.: 97%] [G loss: 5.772063]\n",
            "4506 [ D loss: 0.193563, acc.: 93%] [G loss: 5.203197]\n",
            "4507 [ D loss: 0.043362, acc.: 100%] [G loss: 6.833787]\n",
            "4508 [ D loss: 0.112454, acc.: 95%] [G loss: 5.311399]\n",
            "4509 [ D loss: 0.064686, acc.: 99%] [G loss: 6.857814]\n",
            "4510 [ D loss: 0.091298, acc.: 97%] [G loss: 5.785241]\n",
            "4511 [ D loss: 0.162727, acc.: 95%] [G loss: 5.147418]\n",
            "4512 [ D loss: 0.134658, acc.: 97%] [G loss: 4.505586]\n",
            "4513 [ D loss: 0.161219, acc.: 98%] [G loss: 4.186275]\n",
            "4514 [ D loss: 0.224643, acc.: 92%] [G loss: 6.138298]\n",
            "4515 [ D loss: 0.161653, acc.: 94%] [G loss: 5.938701]\n",
            "4516 [ D loss: 0.270086, acc.: 88%] [G loss: 6.036864]\n",
            "4517 [ D loss: 0.164165, acc.: 94%] [G loss: 7.088503]\n",
            "4518 [ D loss: 0.275306, acc.: 89%] [G loss: 5.365468]\n",
            "4519 [ D loss: 0.142484, acc.: 93%] [G loss: 5.276228]\n",
            "4520 [ D loss: 0.128874, acc.: 95%] [G loss: 6.818946]\n",
            "4521 [ D loss: 0.084711, acc.: 99%] [G loss: 5.963867]\n",
            "4522 [ D loss: 0.087947, acc.: 98%] [G loss: 4.849133]\n",
            "4523 [ D loss: 0.115043, acc.: 98%] [G loss: 4.193005]\n",
            "4524 [ D loss: 0.094515, acc.: 98%] [G loss: 6.458033]\n",
            "4525 [ D loss: 0.160807, acc.: 93%] [G loss: 4.281102]\n",
            "4526 [ D loss: 0.107329, acc.: 97%] [G loss: 5.553389]\n",
            "4527 [ D loss: 0.198144, acc.: 94%] [G loss: 5.047318]\n",
            "4528 [ D loss: 0.148388, acc.: 97%] [G loss: 4.713237]\n",
            "4529 [ D loss: 0.075939, acc.: 98%] [G loss: 6.500590]\n",
            "4530 [ D loss: 0.177192, acc.: 93%] [G loss: 5.279235]\n",
            "4531 [ D loss: 0.135747, acc.: 92%] [G loss: 4.756916]\n",
            "4532 [ D loss: 0.158306, acc.: 95%] [G loss: 4.231638]\n",
            "4533 [ D loss: 0.207728, acc.: 92%] [G loss: 5.229572]\n",
            "4534 [ D loss: 0.180246, acc.: 95%] [G loss: 4.853366]\n",
            "4535 [ D loss: 0.127985, acc.: 96%] [G loss: 4.601494]\n",
            "4536 [ D loss: 0.183809, acc.: 92%] [G loss: 5.075760]\n",
            "4537 [ D loss: 0.213572, acc.: 91%] [G loss: 4.770387]\n",
            "4538 [ D loss: 0.163489, acc.: 94%] [G loss: 4.061852]\n",
            "4539 [ D loss: 0.097472, acc.: 97%] [G loss: 3.736684]\n",
            "4540 [ D loss: 0.121575, acc.: 96%] [G loss: 3.757489]\n",
            "4541 [ D loss: 0.058882, acc.: 99%] [G loss: 5.222235]\n",
            "4542 [ D loss: 0.102247, acc.: 97%] [G loss: 5.025640]\n",
            "4543 [ D loss: 0.123461, acc.: 95%] [G loss: 4.582579]\n",
            "4544 [ D loss: 0.184047, acc.: 95%] [G loss: 4.463946]\n",
            "4545 [ D loss: 0.073772, acc.: 98%] [G loss: 6.218297]\n",
            "4546 [ D loss: 0.131415, acc.: 99%] [G loss: 4.647988]\n",
            "4547 [ D loss: 0.071974, acc.: 99%] [G loss: 5.900444]\n",
            "4548 [ D loss: 0.202733, acc.: 91%] [G loss: 4.617592]\n",
            "4549 [ D loss: 0.105849, acc.: 97%] [G loss: 5.701358]\n",
            "4550 [ D loss: 0.175402, acc.: 92%] [G loss: 4.521240]\n",
            "4551 [ D loss: 0.118561, acc.: 97%] [G loss: 5.082952]\n",
            "4552 [ D loss: 0.220757, acc.: 91%] [G loss: 5.214892]\n",
            "4553 [ D loss: 0.225875, acc.: 86%] [G loss: 6.227287]\n",
            "4554 [ D loss: 0.221226, acc.: 95%] [G loss: 6.265184]\n",
            "4555 [ D loss: 0.115316, acc.: 96%] [G loss: 6.554538]\n",
            "4556 [ D loss: 0.207380, acc.: 91%] [G loss: 4.393420]\n",
            "4557 [ D loss: 0.103285, acc.: 98%] [G loss: 6.215396]\n",
            "4558 [ D loss: 0.156849, acc.: 97%] [G loss: 4.636908]\n",
            "4559 [ D loss: 0.148908, acc.: 94%] [G loss: 5.985675]\n",
            "4560 [ D loss: 0.108135, acc.: 99%] [G loss: 5.427087]\n",
            "4561 [ D loss: 0.123237, acc.: 96%] [G loss: 5.542427]\n",
            "4562 [ D loss: 0.139207, acc.: 95%] [G loss: 8.394552]\n",
            "4563 [ D loss: 0.095934, acc.: 96%] [G loss: 6.085286]\n",
            "4564 [ D loss: 0.157311, acc.: 97%] [G loss: 6.951849]\n",
            "4565 [ D loss: 0.085357, acc.: 97%] [G loss: 6.849978]\n",
            "4566 [ D loss: 0.129562, acc.: 97%] [G loss: 6.991096]\n",
            "4567 [ D loss: 0.144657, acc.: 97%] [G loss: 4.647838]\n",
            "4568 [ D loss: 0.148763, acc.: 96%] [G loss: 4.416906]\n",
            "4569 [ D loss: 0.095828, acc.: 98%] [G loss: 4.598121]\n",
            "4570 [ D loss: 0.164001, acc.: 96%] [G loss: 3.915972]\n",
            "4571 [ D loss: 0.127986, acc.: 96%] [G loss: 5.143129]\n",
            "4572 [ D loss: 0.173604, acc.: 91%] [G loss: 6.200409]\n",
            "4573 [ D loss: 0.152930, acc.: 95%] [G loss: 8.095158]\n",
            "4574 [ D loss: 0.159148, acc.: 95%] [G loss: 4.641011]\n",
            "4575 [ D loss: 0.136682, acc.: 95%] [G loss: 5.428552]\n",
            "4576 [ D loss: 0.060764, acc.: 98%] [G loss: 6.933324]\n",
            "4577 [ D loss: 0.152701, acc.: 96%] [G loss: 4.686296]\n",
            "4578 [ D loss: 0.121095, acc.: 95%] [G loss: 5.150033]\n",
            "4579 [ D loss: 0.132903, acc.: 95%] [G loss: 5.149840]\n",
            "4580 [ D loss: 0.278683, acc.: 87%] [G loss: 5.299840]\n",
            "4581 [ D loss: 0.180236, acc.: 95%] [G loss: 5.015704]\n",
            "4582 [ D loss: 0.199528, acc.: 94%] [G loss: 3.585266]\n",
            "4583 [ D loss: 0.154492, acc.: 95%] [G loss: 5.464456]\n",
            "4584 [ D loss: 0.153996, acc.: 91%] [G loss: 4.427686]\n",
            "4585 [ D loss: 0.084722, acc.: 98%] [G loss: 8.361439]\n",
            "4586 [ D loss: 0.105054, acc.: 99%] [G loss: 4.095719]\n",
            "4587 [ D loss: 0.161512, acc.: 96%] [G loss: 4.214660]\n",
            "4588 [ D loss: 0.151062, acc.: 95%] [G loss: 9.249138]\n",
            "4589 [ D loss: 0.092436, acc.: 98%] [G loss: 7.451771]\n",
            "4590 [ D loss: 0.190094, acc.: 95%] [G loss: 4.579804]\n",
            "4591 [ D loss: 0.117412, acc.: 95%] [G loss: 8.330672]\n",
            "4592 [ D loss: 0.291322, acc.: 86%] [G loss: 7.047941]\n",
            "4593 [ D loss: 0.277880, acc.: 90%] [G loss: 6.369871]\n",
            "4594 [ D loss: 0.152099, acc.: 96%] [G loss: 6.659303]\n",
            "4595 [ D loss: 0.108447, acc.: 99%] [G loss: 4.827464]\n",
            "4596 [ D loss: 0.148378, acc.: 98%] [G loss: 8.651275]\n",
            "4597 [ D loss: 0.043550, acc.: 99%] [G loss: 5.894215]\n",
            "4598 [ D loss: 0.100171, acc.: 97%] [G loss: 11.656321]\n",
            "4599 [ D loss: 0.124485, acc.: 98%] [G loss: 6.200404]\n",
            "4600 [ D loss: 0.056654, acc.: 98%] [G loss: 9.135141]\n",
            "4601 [ D loss: 0.131162, acc.: 95%] [G loss: 6.494716]\n",
            "4602 [ D loss: 0.132294, acc.: 96%] [G loss: 5.607032]\n",
            "4603 [ D loss: 0.111512, acc.: 97%] [G loss: 4.572800]\n",
            "4604 [ D loss: 0.107828, acc.: 98%] [G loss: 5.710006]\n",
            "4605 [ D loss: 0.177868, acc.: 95%] [G loss: 5.582629]\n",
            "4606 [ D loss: 0.154142, acc.: 94%] [G loss: 4.824155]\n",
            "4607 [ D loss: 0.178444, acc.: 96%] [G loss: 4.575043]\n",
            "4608 [ D loss: 0.211838, acc.: 91%] [G loss: 5.332693]\n",
            "4609 [ D loss: 0.125349, acc.: 98%] [G loss: 4.225958]\n",
            "4610 [ D loss: 0.163532, acc.: 95%] [G loss: 3.783770]\n",
            "4611 [ D loss: 0.106292, acc.: 99%] [G loss: 4.508724]\n",
            "4612 [ D loss: 0.130643, acc.: 95%] [G loss: 5.572498]\n",
            "4613 [ D loss: 0.229609, acc.: 91%] [G loss: 4.914903]\n",
            "4614 [ D loss: 0.138251, acc.: 95%] [G loss: 4.599647]\n",
            "4615 [ D loss: 0.221619, acc.: 90%] [G loss: 4.908064]\n",
            "4616 [ D loss: 0.160604, acc.: 95%] [G loss: 5.867321]\n",
            "4617 [ D loss: 0.214327, acc.: 90%] [G loss: 3.883021]\n",
            "4618 [ D loss: 0.243144, acc.: 85%] [G loss: 7.144923]\n",
            "4619 [ D loss: 0.169595, acc.: 94%] [G loss: 6.493009]\n",
            "4620 [ D loss: 0.123940, acc.: 95%] [G loss: 6.915452]\n",
            "4621 [ D loss: 0.147041, acc.: 95%] [G loss: 8.061306]\n",
            "4622 [ D loss: 0.205912, acc.: 92%] [G loss: 5.955267]\n",
            "4623 [ D loss: 0.108838, acc.: 96%] [G loss: 5.896928]\n",
            "4624 [ D loss: 0.091332, acc.: 96%] [G loss: 5.692322]\n",
            "4625 [ D loss: 0.129917, acc.: 95%] [G loss: 7.445163]\n",
            "4626 [ D loss: 0.174592, acc.: 93%] [G loss: 6.006300]\n",
            "4627 [ D loss: 0.174126, acc.: 95%] [G loss: 6.051229]\n",
            "4628 [ D loss: 0.117329, acc.: 95%] [G loss: 6.248954]\n",
            "4629 [ D loss: 0.115482, acc.: 98%] [G loss: 5.142978]\n",
            "4630 [ D loss: 0.173122, acc.: 92%] [G loss: 5.264012]\n",
            "4631 [ D loss: 0.140918, acc.: 97%] [G loss: 9.439014]\n",
            "4632 [ D loss: 0.098889, acc.: 95%] [G loss: 4.661346]\n",
            "4633 [ D loss: 0.153215, acc.: 95%] [G loss: 5.646779]\n",
            "4634 [ D loss: 0.130851, acc.: 96%] [G loss: 6.732140]\n",
            "4635 [ D loss: 0.092967, acc.: 98%] [G loss: 9.720856]\n",
            "4636 [ D loss: 0.079605, acc.: 99%] [G loss: 5.890118]\n",
            "4637 [ D loss: 0.153250, acc.: 95%] [G loss: 3.424319]\n",
            "4638 [ D loss: 0.106142, acc.: 98%] [G loss: 6.413743]\n",
            "4639 [ D loss: 0.108562, acc.: 98%] [G loss: 5.330986]\n",
            "4640 [ D loss: 0.112893, acc.: 97%] [G loss: 3.959880]\n",
            "4641 [ D loss: 0.213895, acc.: 93%] [G loss: 4.924347]\n",
            "4642 [ D loss: 0.139619, acc.: 95%] [G loss: 6.578366]\n",
            "4643 [ D loss: 0.108126, acc.: 95%] [G loss: 5.002994]\n",
            "4644 [ D loss: 0.159252, acc.: 96%] [G loss: 3.955946]\n",
            "4645 [ D loss: 0.106020, acc.: 98%] [G loss: 6.070260]\n",
            "4646 [ D loss: 0.215628, acc.: 92%] [G loss: 4.777557]\n",
            "4647 [ D loss: 0.109239, acc.: 97%] [G loss: 4.999702]\n",
            "4648 [ D loss: 0.082576, acc.: 98%] [G loss: 4.555834]\n",
            "4649 [ D loss: 0.211644, acc.: 94%] [G loss: 3.933885]\n",
            "4650 [ D loss: 0.237486, acc.: 91%] [G loss: 3.956077]\n",
            "4651 [ D loss: 0.082059, acc.: 98%] [G loss: 4.638498]\n",
            "4652 [ D loss: 0.172810, acc.: 95%] [G loss: 5.481264]\n",
            "4653 [ D loss: 0.114996, acc.: 98%] [G loss: 4.558482]\n",
            "4654 [ D loss: 0.084406, acc.: 95%] [G loss: 4.709634]\n",
            "4655 [ D loss: 0.229943, acc.: 90%] [G loss: 5.632464]\n",
            "4656 [ D loss: 0.105880, acc.: 95%] [G loss: 5.955428]\n",
            "4657 [ D loss: 0.143049, acc.: 93%] [G loss: 9.080559]\n",
            "4658 [ D loss: 0.163643, acc.: 92%] [G loss: 5.850893]\n",
            "4659 [ D loss: 0.121577, acc.: 96%] [G loss: 5.335219]\n",
            "4660 [ D loss: 0.066381, acc.: 98%] [G loss: 7.754303]\n",
            "4661 [ D loss: 0.155847, acc.: 95%] [G loss: 5.032066]\n",
            "4662 [ D loss: 0.162282, acc.: 95%] [G loss: 4.948531]\n",
            "4663 [ D loss: 0.100293, acc.: 97%] [G loss: 5.556487]\n",
            "4664 [ D loss: 0.127329, acc.: 99%] [G loss: 4.033597]\n",
            "4665 [ D loss: 0.052776, acc.: 100%] [G loss: 4.780419]\n",
            "4666 [ D loss: 0.104842, acc.: 98%] [G loss: 4.381445]\n",
            "4667 [ D loss: 0.202581, acc.: 91%] [G loss: 4.235085]\n",
            "4668 [ D loss: 0.196648, acc.: 91%] [G loss: 4.593571]\n",
            "4669 [ D loss: 0.122178, acc.: 98%] [G loss: 5.243429]\n",
            "4670 [ D loss: 0.071870, acc.: 98%] [G loss: 5.164220]\n",
            "4671 [ D loss: 0.106886, acc.: 98%] [G loss: 4.678169]\n",
            "4672 [ D loss: 0.118224, acc.: 95%] [G loss: 6.834981]\n",
            "4673 [ D loss: 0.202100, acc.: 93%] [G loss: 4.752122]\n",
            "4674 [ D loss: 0.231258, acc.: 91%] [G loss: 5.162567]\n",
            "4675 [ D loss: 0.139209, acc.: 95%] [G loss: 5.331208]\n",
            "4676 [ D loss: 0.231709, acc.: 91%] [G loss: 6.558713]\n",
            "4677 [ D loss: 0.144194, acc.: 93%] [G loss: 7.071601]\n",
            "4678 [ D loss: 0.230000, acc.: 91%] [G loss: 4.551353]\n",
            "4679 [ D loss: 0.114035, acc.: 95%] [G loss: 5.919654]\n",
            "4680 [ D loss: 0.157093, acc.: 96%] [G loss: 6.363343]\n",
            "4681 [ D loss: 0.135952, acc.: 95%] [G loss: 4.135391]\n",
            "4682 [ D loss: 0.097179, acc.: 98%] [G loss: 4.463186]\n",
            "4683 [ D loss: 0.113451, acc.: 99%] [G loss: 5.545727]\n",
            "4684 [ D loss: 0.159927, acc.: 96%] [G loss: 4.851548]\n",
            "4685 [ D loss: 0.157726, acc.: 96%] [G loss: 6.558713]\n",
            "4686 [ D loss: 0.098639, acc.: 97%] [G loss: 7.118388]\n",
            "4687 [ D loss: 0.103143, acc.: 98%] [G loss: 6.817806]\n",
            "4688 [ D loss: 0.082390, acc.: 98%] [G loss: 5.241556]\n",
            "4689 [ D loss: 0.164442, acc.: 96%] [G loss: 4.392772]\n",
            "4690 [ D loss: 0.078782, acc.: 98%] [G loss: 7.070189]\n",
            "4691 [ D loss: 0.169039, acc.: 95%] [G loss: 6.159051]\n",
            "4692 [ D loss: 0.101993, acc.: 98%] [G loss: 6.017801]\n",
            "4693 [ D loss: 0.163823, acc.: 95%] [G loss: 7.221388]\n",
            "4694 [ D loss: 0.173366, acc.: 92%] [G loss: 4.850421]\n",
            "4695 [ D loss: 0.144897, acc.: 96%] [G loss: 11.181720]\n",
            "4696 [ D loss: 0.109274, acc.: 95%] [G loss: 7.503840]\n",
            "4697 [ D loss: 0.114330, acc.: 94%] [G loss: 9.655691]\n",
            "4698 [ D loss: 0.127340, acc.: 95%] [G loss: 5.288203]\n",
            "4699 [ D loss: 0.147767, acc.: 95%] [G loss: 5.016300]\n",
            "4700 [ D loss: 0.133411, acc.: 96%] [G loss: 4.668895]\n",
            "4701 [ D loss: 0.117819, acc.: 95%] [G loss: 3.806983]\n",
            "4702 [ D loss: 0.178316, acc.: 94%] [G loss: 4.095948]\n",
            "4703 [ D loss: 0.196461, acc.: 94%] [G loss: 9.301692]\n",
            "4704 [ D loss: 0.103624, acc.: 98%] [G loss: 5.160194]\n",
            "4705 [ D loss: 0.155105, acc.: 95%] [G loss: 4.452374]\n",
            "4706 [ D loss: 0.285933, acc.: 87%] [G loss: 5.516184]\n",
            "4707 [ D loss: 0.135458, acc.: 95%] [G loss: 7.245849]\n",
            "4708 [ D loss: 0.242130, acc.: 88%] [G loss: 3.707656]\n",
            "4709 [ D loss: 0.184196, acc.: 95%] [G loss: 8.174217]\n",
            "4710 [ D loss: 0.064055, acc.: 98%] [G loss: 5.404534]\n",
            "4711 [ D loss: 0.200121, acc.: 94%] [G loss: 4.355535]\n",
            "4712 [ D loss: 0.182589, acc.: 92%] [G loss: 4.671549]\n",
            "4713 [ D loss: 0.078903, acc.: 99%] [G loss: 6.533546]\n",
            "4714 [ D loss: 0.122819, acc.: 96%] [G loss: 7.547118]\n",
            "4715 [ D loss: 0.168171, acc.: 95%] [G loss: 5.915255]\n",
            "4716 [ D loss: 0.122505, acc.: 95%] [G loss: 4.922531]\n",
            "4717 [ D loss: 0.168925, acc.: 95%] [G loss: 5.289099]\n",
            "4718 [ D loss: 0.117204, acc.: 97%] [G loss: 5.979299]\n",
            "4719 [ D loss: 0.142327, acc.: 93%] [G loss: 6.750228]\n",
            "4720 [ D loss: 0.166518, acc.: 96%] [G loss: 6.952628]\n",
            "4721 [ D loss: 0.109271, acc.: 97%] [G loss: 7.926374]\n",
            "4722 [ D loss: 0.097782, acc.: 96%] [G loss: 10.584208]\n",
            "4723 [ D loss: 0.069185, acc.: 98%] [G loss: 5.387459]\n",
            "4724 [ D loss: 0.195812, acc.: 91%] [G loss: 5.454125]\n",
            "4725 [ D loss: 0.135059, acc.: 95%] [G loss: 8.095095]\n",
            "4726 [ D loss: 0.265155, acc.: 90%] [G loss: 5.422510]\n",
            "4727 [ D loss: 0.094277, acc.: 98%] [G loss: 5.356652]\n",
            "4728 [ D loss: 0.228369, acc.: 90%] [G loss: 4.284332]\n",
            "4729 [ D loss: 0.110320, acc.: 97%] [G loss: 5.197477]\n",
            "4730 [ D loss: 0.171444, acc.: 96%] [G loss: 5.072501]\n",
            "4731 [ D loss: 0.134228, acc.: 94%] [G loss: 5.389530]\n",
            "4732 [ D loss: 0.186445, acc.: 94%] [G loss: 4.076602]\n",
            "4733 [ D loss: 0.093188, acc.: 98%] [G loss: 4.251592]\n",
            "4734 [ D loss: 0.133495, acc.: 97%] [G loss: 7.268308]\n",
            "4735 [ D loss: 0.083123, acc.: 98%] [G loss: 7.462585]\n",
            "4736 [ D loss: 0.129613, acc.: 98%] [G loss: 3.845720]\n",
            "4737 [ D loss: 0.119330, acc.: 96%] [G loss: 4.206683]\n",
            "4738 [ D loss: 0.168143, acc.: 95%] [G loss: 7.409035]\n",
            "4739 [ D loss: 0.147510, acc.: 95%] [G loss: 5.058712]\n",
            "4740 [ D loss: 0.111754, acc.: 98%] [G loss: 4.900573]\n",
            "4741 [ D loss: 0.159127, acc.: 95%] [G loss: 5.816446]\n",
            "4742 [ D loss: 0.159605, acc.: 95%] [G loss: 6.252273]\n",
            "4743 [ D loss: 0.100787, acc.: 95%] [G loss: 5.311872]\n",
            "4744 [ D loss: 0.139829, acc.: 96%] [G loss: 5.013954]\n",
            "4745 [ D loss: 0.185339, acc.: 91%] [G loss: 5.709949]\n",
            "4746 [ D loss: 0.182800, acc.: 94%] [G loss: 5.441744]\n",
            "4747 [ D loss: 0.188544, acc.: 89%] [G loss: 6.109976]\n",
            "4748 [ D loss: 0.228597, acc.: 91%] [G loss: 5.515285]\n",
            "4749 [ D loss: 0.122915, acc.: 95%] [G loss: 5.831654]\n",
            "4750 [ D loss: 0.189276, acc.: 93%] [G loss: 7.204727]\n",
            "4751 [ D loss: 0.077663, acc.: 98%] [G loss: 5.558630]\n",
            "4752 [ D loss: 0.116978, acc.: 97%] [G loss: 4.886013]\n",
            "4753 [ D loss: 0.104294, acc.: 98%] [G loss: 5.419618]\n",
            "4754 [ D loss: 0.236533, acc.: 88%] [G loss: 7.470964]\n",
            "4755 [ D loss: 0.095260, acc.: 98%] [G loss: 9.939043]\n",
            "4756 [ D loss: 0.111147, acc.: 95%] [G loss: 10.095938]\n",
            "4757 [ D loss: 0.069235, acc.: 98%] [G loss: 11.649258]\n",
            "4758 [ D loss: 0.083526, acc.: 99%] [G loss: 5.921220]\n",
            "4759 [ D loss: 0.211622, acc.: 91%] [G loss: 9.727354]\n",
            "4760 [ D loss: 0.141266, acc.: 97%] [G loss: 8.819903]\n",
            "4761 [ D loss: 0.319341, acc.: 88%] [G loss: 5.656389]\n",
            "4762 [ D loss: 0.147587, acc.: 95%] [G loss: 7.246552]\n",
            "4763 [ D loss: 0.140455, acc.: 98%] [G loss: 6.493866]\n",
            "4764 [ D loss: 0.141223, acc.: 96%] [G loss: 6.503882]\n",
            "4765 [ D loss: 0.179399, acc.: 91%] [G loss: 5.560964]\n",
            "4766 [ D loss: 0.133014, acc.: 96%] [G loss: 5.746229]\n",
            "4767 [ D loss: 0.121417, acc.: 96%] [G loss: 12.123193]\n",
            "4768 [ D loss: 0.164833, acc.: 96%] [G loss: 6.676089]\n",
            "4769 [ D loss: 0.156927, acc.: 96%] [G loss: 8.594278]\n",
            "4770 [ D loss: 0.073635, acc.: 99%] [G loss: 5.792890]\n",
            "4771 [ D loss: 0.100114, acc.: 98%] [G loss: 4.870399]\n",
            "4772 [ D loss: 0.131642, acc.: 95%] [G loss: 5.175900]\n",
            "4773 [ D loss: 0.159087, acc.: 95%] [G loss: 5.674026]\n",
            "4774 [ D loss: 0.083364, acc.: 98%] [G loss: 6.424800]\n",
            "4775 [ D loss: 0.151774, acc.: 95%] [G loss: 4.434536]\n",
            "4776 [ D loss: 0.129431, acc.: 95%] [G loss: 6.662831]\n",
            "4777 [ D loss: 0.173848, acc.: 93%] [G loss: 6.463524]\n",
            "4778 [ D loss: 0.102603, acc.: 97%] [G loss: 4.742992]\n",
            "4779 [ D loss: 0.180352, acc.: 91%] [G loss: 5.823971]\n",
            "4780 [ D loss: 0.119509, acc.: 98%] [G loss: 4.705914]\n",
            "4781 [ D loss: 0.113938, acc.: 97%] [G loss: 6.950290]\n",
            "4782 [ D loss: 0.124441, acc.: 97%] [G loss: 5.317225]\n",
            "4783 [ D loss: 0.212866, acc.: 92%] [G loss: 6.897438]\n",
            "4784 [ D loss: 0.118461, acc.: 97%] [G loss: 6.075725]\n",
            "4785 [ D loss: 0.181035, acc.: 91%] [G loss: 4.839153]\n",
            "4786 [ D loss: 0.247317, acc.: 90%] [G loss: 5.407591]\n",
            "4787 [ D loss: 0.135760, acc.: 95%] [G loss: 5.210691]\n",
            "4788 [ D loss: 0.161413, acc.: 92%] [G loss: 6.447162]\n",
            "4789 [ D loss: 0.245200, acc.: 89%] [G loss: 6.035280]\n",
            "4790 [ D loss: 0.241734, acc.: 94%] [G loss: 6.599442]\n",
            "4791 [ D loss: 0.144908, acc.: 95%] [G loss: 4.699996]\n",
            "4792 [ D loss: 0.176663, acc.: 95%] [G loss: 5.022713]\n",
            "4793 [ D loss: 0.170404, acc.: 95%] [G loss: 7.135770]\n",
            "4794 [ D loss: 0.164290, acc.: 93%] [G loss: 6.701700]\n",
            "4795 [ D loss: 0.078660, acc.: 99%] [G loss: 4.818197]\n",
            "4796 [ D loss: 0.196768, acc.: 93%] [G loss: 4.183987]\n",
            "4797 [ D loss: 0.138765, acc.: 95%] [G loss: 6.825436]\n",
            "4798 [ D loss: 0.261091, acc.: 91%] [G loss: 6.415070]\n",
            "4799 [ D loss: 0.124771, acc.: 96%] [G loss: 5.061506]\n",
            "4800 [ D loss: 0.239601, acc.: 91%] [G loss: 6.585944]\n",
            "4801 [ D loss: 0.190427, acc.: 89%] [G loss: 5.862081]\n",
            "4802 [ D loss: 0.073304, acc.: 98%] [G loss: 6.786244]\n",
            "4803 [ D loss: 0.109023, acc.: 96%] [G loss: 6.540110]\n",
            "4804 [ D loss: 0.209206, acc.: 92%] [G loss: 4.860914]\n",
            "4805 [ D loss: 0.128207, acc.: 95%] [G loss: 4.994060]\n",
            "4806 [ D loss: 0.124344, acc.: 95%] [G loss: 6.419874]\n",
            "4807 [ D loss: 0.089876, acc.: 98%] [G loss: 9.337811]\n",
            "4808 [ D loss: 0.200771, acc.: 91%] [G loss: 5.069262]\n",
            "4809 [ D loss: 0.075273, acc.: 98%] [G loss: 6.079434]\n",
            "4810 [ D loss: 0.259607, acc.: 89%] [G loss: 9.709386]\n",
            "4811 [ D loss: 0.116427, acc.: 95%] [G loss: 10.236948]\n",
            "4812 [ D loss: 0.138739, acc.: 95%] [G loss: 7.455066]\n",
            "4813 [ D loss: 0.118479, acc.: 96%] [G loss: 5.169628]\n",
            "4814 [ D loss: 0.110071, acc.: 98%] [G loss: 3.982673]\n",
            "4815 [ D loss: 0.134719, acc.: 95%] [G loss: 3.778629]\n",
            "4816 [ D loss: 0.125237, acc.: 95%] [G loss: 5.344183]\n",
            "4817 [ D loss: 0.217102, acc.: 92%] [G loss: 4.899449]\n",
            "4818 [ D loss: 0.130134, acc.: 94%] [G loss: 5.143156]\n",
            "4819 [ D loss: 0.194407, acc.: 94%] [G loss: 3.932312]\n",
            "4820 [ D loss: 0.129150, acc.: 95%] [G loss: 5.225829]\n",
            "4821 [ D loss: 0.114189, acc.: 96%] [G loss: 5.343595]\n",
            "4822 [ D loss: 0.158742, acc.: 95%] [G loss: 4.776844]\n",
            "4823 [ D loss: 0.185692, acc.: 94%] [G loss: 5.219520]\n",
            "4824 [ D loss: 0.134559, acc.: 95%] [G loss: 4.191454]\n",
            "4825 [ D loss: 0.132720, acc.: 96%] [G loss: 4.321914]\n",
            "4826 [ D loss: 0.183007, acc.: 93%] [G loss: 4.531734]\n",
            "4827 [ D loss: 0.145023, acc.: 94%] [G loss: 4.851538]\n",
            "4828 [ D loss: 0.119218, acc.: 97%] [G loss: 4.981930]\n",
            "4829 [ D loss: 0.163760, acc.: 95%] [G loss: 4.603354]\n",
            "4830 [ D loss: 0.111747, acc.: 98%] [G loss: 5.337789]\n",
            "4831 [ D loss: 0.137073, acc.: 95%] [G loss: 4.953869]\n",
            "4832 [ D loss: 0.109733, acc.: 97%] [G loss: 5.383626]\n",
            "4833 [ D loss: 0.042783, acc.: 100%] [G loss: 5.707720]\n",
            "4834 [ D loss: 0.074079, acc.: 98%] [G loss: 4.851830]\n",
            "4835 [ D loss: 0.128744, acc.: 95%] [G loss: 5.360145]\n",
            "4836 [ D loss: 0.080665, acc.: 97%] [G loss: 6.420419]\n",
            "4837 [ D loss: 0.038476, acc.: 100%] [G loss: 5.622028]\n",
            "4838 [ D loss: 0.121911, acc.: 98%] [G loss: 6.311765]\n",
            "4839 [ D loss: 0.067657, acc.: 98%] [G loss: 5.220345]\n",
            "4840 [ D loss: 0.073453, acc.: 98%] [G loss: 3.942178]\n",
            "4841 [ D loss: 0.119766, acc.: 95%] [G loss: 6.572030]\n",
            "4842 [ D loss: 0.130760, acc.: 98%] [G loss: 7.813114]\n",
            "4843 [ D loss: 0.152849, acc.: 95%] [G loss: 4.562691]\n",
            "4844 [ D loss: 0.127776, acc.: 95%] [G loss: 4.716219]\n",
            "4845 [ D loss: 0.192184, acc.: 94%] [G loss: 5.622372]\n",
            "4846 [ D loss: 0.280773, acc.: 88%] [G loss: 4.597796]\n",
            "4847 [ D loss: 0.122591, acc.: 95%] [G loss: 5.331378]\n",
            "4848 [ D loss: 0.180791, acc.: 93%] [G loss: 6.108557]\n",
            "4849 [ D loss: 0.075425, acc.: 99%] [G loss: 4.576488]\n",
            "4850 [ D loss: 0.188725, acc.: 93%] [G loss: 4.072136]\n",
            "4851 [ D loss: 0.114686, acc.: 97%] [G loss: 7.404422]\n",
            "4852 [ D loss: 0.179369, acc.: 91%] [G loss: 5.447803]\n",
            "4853 [ D loss: 0.191878, acc.: 95%] [G loss: 4.313604]\n",
            "4854 [ D loss: 0.220949, acc.: 92%] [G loss: 3.620636]\n",
            "4855 [ D loss: 0.172700, acc.: 95%] [G loss: 3.301351]\n",
            "4856 [ D loss: 0.147733, acc.: 96%] [G loss: 4.732232]\n",
            "4857 [ D loss: 0.160370, acc.: 95%] [G loss: 3.894582]\n",
            "4858 [ D loss: 0.087468, acc.: 98%] [G loss: 5.684854]\n",
            "4859 [ D loss: 0.192171, acc.: 93%] [G loss: 4.866192]\n",
            "4860 [ D loss: 0.186936, acc.: 94%] [G loss: 4.348445]\n",
            "4861 [ D loss: 0.099450, acc.: 98%] [G loss: 6.245634]\n",
            "4862 [ D loss: 0.143362, acc.: 96%] [G loss: 5.836306]\n",
            "4863 [ D loss: 0.171374, acc.: 94%] [G loss: 7.534083]\n",
            "4864 [ D loss: 0.161933, acc.: 95%] [G loss: 6.549409]\n",
            "4865 [ D loss: 0.096158, acc.: 98%] [G loss: 5.027328]\n",
            "4866 [ D loss: 0.116802, acc.: 97%] [G loss: 6.154030]\n",
            "4867 [ D loss: 0.129728, acc.: 97%] [G loss: 5.923807]\n",
            "4868 [ D loss: 0.132025, acc.: 95%] [G loss: 5.948271]\n",
            "4869 [ D loss: 0.177139, acc.: 94%] [G loss: 5.211787]\n",
            "4870 [ D loss: 0.090034, acc.: 98%] [G loss: 4.761897]\n",
            "4871 [ D loss: 0.215469, acc.: 91%] [G loss: 5.885920]\n",
            "4872 [ D loss: 0.195163, acc.: 93%] [G loss: 5.260992]\n",
            "4873 [ D loss: 0.137503, acc.: 97%] [G loss: 4.565186]\n",
            "4874 [ D loss: 0.118282, acc.: 98%] [G loss: 5.175790]\n",
            "4875 [ D loss: 0.112698, acc.: 96%] [G loss: 9.886703]\n",
            "4876 [ D loss: 0.207237, acc.: 92%] [G loss: 5.189321]\n",
            "4877 [ D loss: 0.192701, acc.: 92%] [G loss: 5.666838]\n",
            "4878 [ D loss: 0.229796, acc.: 91%] [G loss: 4.374097]\n",
            "4879 [ D loss: 0.135785, acc.: 95%] [G loss: 5.918045]\n",
            "4880 [ D loss: 0.096953, acc.: 98%] [G loss: 4.245324]\n",
            "4881 [ D loss: 0.209823, acc.: 92%] [G loss: 4.849481]\n",
            "4882 [ D loss: 0.124053, acc.: 96%] [G loss: 4.978677]\n",
            "4883 [ D loss: 0.191226, acc.: 95%] [G loss: 5.889137]\n",
            "4884 [ D loss: 0.107643, acc.: 97%] [G loss: 4.610609]\n",
            "4885 [ D loss: 0.123534, acc.: 98%] [G loss: 3.386394]\n",
            "4886 [ D loss: 0.110046, acc.: 98%] [G loss: 8.203187]\n",
            "4887 [ D loss: 0.148492, acc.: 95%] [G loss: 6.033747]\n",
            "4888 [ D loss: 0.130830, acc.: 96%] [G loss: 5.670843]\n",
            "4889 [ D loss: 0.114872, acc.: 98%] [G loss: 5.646852]\n",
            "4890 [ D loss: 0.166930, acc.: 95%] [G loss: 5.344152]\n",
            "4891 [ D loss: 0.116341, acc.: 98%] [G loss: 6.371486]\n",
            "4892 [ D loss: 0.078278, acc.: 98%] [G loss: 8.485039]\n",
            "4893 [ D loss: 0.121398, acc.: 96%] [G loss: 8.355680]\n",
            "4894 [ D loss: 0.109500, acc.: 96%] [G loss: 6.605468]\n",
            "4895 [ D loss: 0.090785, acc.: 96%] [G loss: 9.824489]\n",
            "4896 [ D loss: 0.221459, acc.: 89%] [G loss: 6.399064]\n",
            "4897 [ D loss: 0.139427, acc.: 95%] [G loss: 4.810143]\n",
            "4898 [ D loss: 0.281021, acc.: 90%] [G loss: 4.667055]\n",
            "4899 [ D loss: 0.160789, acc.: 95%] [G loss: 5.912824]\n",
            "4900 [ D loss: 0.139950, acc.: 95%] [G loss: 3.650863]\n",
            "4901 [ D loss: 0.158948, acc.: 92%] [G loss: 4.251721]\n",
            "4902 [ D loss: 0.143979, acc.: 93%] [G loss: 5.373700]\n",
            "4903 [ D loss: 0.170055, acc.: 95%] [G loss: 4.346625]\n",
            "4904 [ D loss: 0.192688, acc.: 92%] [G loss: 3.760754]\n",
            "4905 [ D loss: 0.281320, acc.: 89%] [G loss: 4.457670]\n",
            "4906 [ D loss: 0.109968, acc.: 97%] [G loss: 5.520707]\n",
            "4907 [ D loss: 0.166687, acc.: 94%] [G loss: 4.158659]\n",
            "4908 [ D loss: 0.108063, acc.: 96%] [G loss: 5.338745]\n",
            "4909 [ D loss: 0.266405, acc.: 89%] [G loss: 4.978442]\n",
            "4910 [ D loss: 0.090045, acc.: 98%] [G loss: 4.606653]\n",
            "4911 [ D loss: 0.216924, acc.: 95%] [G loss: 5.036837]\n",
            "4912 [ D loss: 0.091162, acc.: 97%] [G loss: 4.862473]\n",
            "4913 [ D loss: 0.155356, acc.: 96%] [G loss: 4.735517]\n",
            "4914 [ D loss: 0.228334, acc.: 90%] [G loss: 4.828701]\n",
            "4915 [ D loss: 0.120982, acc.: 97%] [G loss: 4.603237]\n",
            "4916 [ D loss: 0.136147, acc.: 95%] [G loss: 5.994562]\n",
            "4917 [ D loss: 0.145906, acc.: 94%] [G loss: 4.644074]\n",
            "4918 [ D loss: 0.228954, acc.: 92%] [G loss: 6.366168]\n",
            "4919 [ D loss: 0.209721, acc.: 93%] [G loss: 7.665583]\n",
            "4920 [ D loss: 0.187299, acc.: 92%] [G loss: 5.278879]\n",
            "4921 [ D loss: 0.065288, acc.: 99%] [G loss: 7.242974]\n",
            "4922 [ D loss: 0.221463, acc.: 90%] [G loss: 4.680047]\n",
            "4923 [ D loss: 0.124010, acc.: 95%] [G loss: 5.475040]\n",
            "4924 [ D loss: 0.166559, acc.: 94%] [G loss: 4.124147]\n",
            "4925 [ D loss: 0.145498, acc.: 95%] [G loss: 5.251213]\n",
            "4926 [ D loss: 0.181593, acc.: 95%] [G loss: 6.031234]\n",
            "4927 [ D loss: 0.148523, acc.: 95%] [G loss: 5.640558]\n",
            "4928 [ D loss: 0.079296, acc.: 98%] [G loss: 5.480121]\n",
            "4929 [ D loss: 0.148635, acc.: 95%] [G loss: 11.305094]\n",
            "4930 [ D loss: 0.063887, acc.: 99%] [G loss: 6.910106]\n",
            "4931 [ D loss: 0.123999, acc.: 96%] [G loss: 4.582538]\n",
            "4932 [ D loss: 0.118866, acc.: 98%] [G loss: 5.960828]\n",
            "4933 [ D loss: 0.098114, acc.: 97%] [G loss: 5.112103]\n",
            "4934 [ D loss: 0.281441, acc.: 89%] [G loss: 4.889197]\n",
            "4935 [ D loss: 0.139472, acc.: 92%] [G loss: 6.157403]\n",
            "4936 [ D loss: 0.058312, acc.: 99%] [G loss: 8.680708]\n",
            "4937 [ D loss: 0.116340, acc.: 94%] [G loss: 5.425990]\n",
            "4938 [ D loss: 0.036512, acc.: 100%] [G loss: 5.654706]\n",
            "4939 [ D loss: 0.112517, acc.: 97%] [G loss: 5.281855]\n",
            "4940 [ D loss: 0.110732, acc.: 95%] [G loss: 8.037185]\n",
            "4941 [ D loss: 0.120429, acc.: 95%] [G loss: 5.812552]\n",
            "4942 [ D loss: 0.050939, acc.: 98%] [G loss: 4.369689]\n",
            "4943 [ D loss: 0.083081, acc.: 97%] [G loss: 8.860884]\n",
            "4944 [ D loss: 0.079231, acc.: 98%] [G loss: 9.444896]\n",
            "4945 [ D loss: 0.093124, acc.: 97%] [G loss: 7.692463]\n",
            "4946 [ D loss: 0.132099, acc.: 95%] [G loss: 5.972260]\n",
            "4947 [ D loss: 0.086716, acc.: 98%] [G loss: 8.332439]\n",
            "4948 [ D loss: 0.133772, acc.: 98%] [G loss: 6.623898]\n",
            "4949 [ D loss: 0.136951, acc.: 95%] [G loss: 4.604882]\n",
            "4950 [ D loss: 0.144481, acc.: 95%] [G loss: 5.816615]\n",
            "4951 [ D loss: 0.160578, acc.: 96%] [G loss: 8.075998]\n",
            "4952 [ D loss: 0.130046, acc.: 96%] [G loss: 8.895932]\n",
            "4953 [ D loss: 0.120462, acc.: 95%] [G loss: 5.432392]\n",
            "4954 [ D loss: 0.094739, acc.: 98%] [G loss: 11.360587]\n",
            "4955 [ D loss: 0.076544, acc.: 98%] [G loss: 5.988308]\n",
            "4956 [ D loss: 0.168637, acc.: 92%] [G loss: 6.059848]\n",
            "4957 [ D loss: 0.099441, acc.: 95%] [G loss: 5.489041]\n",
            "4958 [ D loss: 0.223394, acc.: 92%] [G loss: 5.634189]\n",
            "4959 [ D loss: 0.059755, acc.: 98%] [G loss: 6.561226]\n",
            "4960 [ D loss: 0.217715, acc.: 93%] [G loss: 5.466397]\n",
            "4961 [ D loss: 0.132728, acc.: 96%] [G loss: 4.862277]\n",
            "4962 [ D loss: 0.069308, acc.: 100%] [G loss: 5.026737]\n",
            "4963 [ D loss: 0.171373, acc.: 95%] [G loss: 5.446270]\n",
            "4964 [ D loss: 0.182120, acc.: 91%] [G loss: 6.119989]\n",
            "4965 [ D loss: 0.113287, acc.: 96%] [G loss: 5.983673]\n",
            "4966 [ D loss: 0.190836, acc.: 92%] [G loss: 5.358938]\n",
            "4967 [ D loss: 0.180730, acc.: 94%] [G loss: 6.814118]\n",
            "4968 [ D loss: 0.109436, acc.: 95%] [G loss: 5.199918]\n",
            "4969 [ D loss: 0.074086, acc.: 98%] [G loss: 5.072730]\n",
            "4970 [ D loss: 0.195425, acc.: 91%] [G loss: 3.735352]\n",
            "4971 [ D loss: 0.161689, acc.: 95%] [G loss: 6.784214]\n",
            "4972 [ D loss: 0.144460, acc.: 95%] [G loss: 5.655578]\n",
            "4973 [ D loss: 0.120971, acc.: 97%] [G loss: 6.366813]\n",
            "4974 [ D loss: 0.105862, acc.: 96%] [G loss: 6.997760]\n",
            "4975 [ D loss: 0.150676, acc.: 95%] [G loss: 6.613606]\n",
            "4976 [ D loss: 0.081174, acc.: 98%] [G loss: 6.978720]\n",
            "4977 [ D loss: 0.137528, acc.: 95%] [G loss: 6.139482]\n",
            "4978 [ D loss: 0.180272, acc.: 93%] [G loss: 5.341234]\n",
            "4979 [ D loss: 0.138252, acc.: 94%] [G loss: 4.678983]\n",
            "4980 [ D loss: 0.082622, acc.: 100%] [G loss: 7.780291]\n",
            "4981 [ D loss: 0.084982, acc.: 98%] [G loss: 6.405591]\n",
            "4982 [ D loss: 0.146580, acc.: 96%] [G loss: 6.275933]\n",
            "4983 [ D loss: 0.086416, acc.: 98%] [G loss: 5.196455]\n",
            "4984 [ D loss: 0.206965, acc.: 90%] [G loss: 5.884304]\n",
            "4985 [ D loss: 0.122754, acc.: 96%] [G loss: 5.591037]\n",
            "4986 [ D loss: 0.145976, acc.: 97%] [G loss: 4.636932]\n",
            "4987 [ D loss: 0.193231, acc.: 92%] [G loss: 3.365529]\n",
            "4988 [ D loss: 0.100712, acc.: 97%] [G loss: 8.084772]\n",
            "4989 [ D loss: 0.148450, acc.: 95%] [G loss: 4.344630]\n",
            "4990 [ D loss: 0.162139, acc.: 95%] [G loss: 6.895196]\n",
            "4991 [ D loss: 0.109593, acc.: 95%] [G loss: 8.612052]\n",
            "4992 [ D loss: 0.096713, acc.: 96%] [G loss: 6.152752]\n",
            "4993 [ D loss: 0.174584, acc.: 92%] [G loss: 4.913705]\n",
            "4994 [ D loss: 0.091206, acc.: 98%] [G loss: 6.164111]\n",
            "4995 [ D loss: 0.159206, acc.: 95%] [G loss: 4.278293]\n",
            "4996 [ D loss: 0.198225, acc.: 92%] [G loss: 5.221500]\n",
            "4997 [ D loss: 0.140133, acc.: 95%] [G loss: 4.520188]\n",
            "4998 [ D loss: 0.137221, acc.: 93%] [G loss: 5.515214]\n",
            "4999 [ D loss: 0.151545, acc.: 94%] [G loss: 6.449630]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vJCnTHdc-GNA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "528ece96-7fc4-46ca-c3f3-72cf17c60072"
      },
      "cell_type": "code",
      "source": [
        "# 5000 iteration\n",
        "generated_img = model.generator.predict(np.random.normal(0, 1, (10, 100)))\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 2))\n",
        "n =10\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(1, n, i + 1)\n",
        "    plt.imshow(np.squeeze(generated_img[i]))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAABsCAYAAAAyoVQIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP2DzROY9tGwrAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f186da6fda0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "xwHZI3gv-HUD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170887
        },
        "outputId": "2764cddf-5281-47c2-d26d-4e0a90812f4c"
      },
      "cell_type": "code",
      "source": [
        "model = GAN()\n",
        "model.train(epochs=10000)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_17 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_111 (Dense)            (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_81 (LeakyReLU)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_112 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_82 (LeakyReLU)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_113 (Dense)            (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 533,505\n",
            "Trainable params: 533,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_114 (Dense)            (None, 256)               25856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_83 (LeakyReLU)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_49 (Batc (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_115 (Dense)            (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_84 (LeakyReLU)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_50 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_116 (Dense)            (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_85 (LeakyReLU)   (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_51 (Batc (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense_117 (Dense)            (None, 784)               803600    \n",
            "_________________________________________________________________\n",
            "reshape_15 (Reshape)         (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 1,493,520\n",
            "Trainable params: 1,489,936\n",
            "Non-trainable params: 3,584\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 [ D loss: 0.724122, acc.: 51%] [G loss: 1.102927]\n",
            "1 [ D loss: 0.534052, acc.: 84%] [G loss: 1.091428]\n",
            "2 [ D loss: 0.467874, acc.: 92%] [G loss: 1.239087]\n",
            "3 [ D loss: 0.348120, acc.: 98%] [G loss: 1.360638]\n",
            "4 [ D loss: 0.329557, acc.: 98%] [G loss: 1.502756]\n",
            "5 [ D loss: 0.264326, acc.: 100%] [G loss: 1.548258]\n",
            "6 [ D loss: 0.245714, acc.: 100%] [G loss: 1.651626]\n",
            "7 [ D loss: 0.204730, acc.: 99%] [G loss: 1.721277]\n",
            "8 [ D loss: 0.204395, acc.: 100%] [G loss: 1.836136]\n",
            "9 [ D loss: 0.212280, acc.: 99%] [G loss: 1.910343]\n",
            "10 [ D loss: 0.176994, acc.: 100%] [G loss: 1.998255]\n",
            "11 [ D loss: 0.153092, acc.: 99%] [G loss: 2.024286]\n",
            "12 [ D loss: 0.136732, acc.: 100%] [G loss: 2.185439]\n",
            "13 [ D loss: 0.145404, acc.: 100%] [G loss: 2.190495]\n",
            "14 [ D loss: 0.121057, acc.: 100%] [G loss: 2.329449]\n",
            "15 [ D loss: 0.126744, acc.: 100%] [G loss: 2.340208]\n",
            "16 [ D loss: 0.116193, acc.: 100%] [G loss: 2.413522]\n",
            "17 [ D loss: 0.102254, acc.: 100%] [G loss: 2.518327]\n",
            "18 [ D loss: 0.091707, acc.: 100%] [G loss: 2.569403]\n",
            "19 [ D loss: 0.091710, acc.: 100%] [G loss: 2.563927]\n",
            "20 [ D loss: 0.086635, acc.: 100%] [G loss: 2.707297]\n",
            "21 [ D loss: 0.093727, acc.: 100%] [G loss: 2.682388]\n",
            "22 [ D loss: 0.081821, acc.: 100%] [G loss: 2.785307]\n",
            "23 [ D loss: 0.071834, acc.: 100%] [G loss: 2.837929]\n",
            "24 [ D loss: 0.062960, acc.: 100%] [G loss: 2.890856]\n",
            "25 [ D loss: 0.073579, acc.: 100%] [G loss: 2.985252]\n",
            "26 [ D loss: 0.068808, acc.: 100%] [G loss: 2.966624]\n",
            "27 [ D loss: 0.063855, acc.: 100%] [G loss: 3.033792]\n",
            "28 [ D loss: 0.063199, acc.: 99%] [G loss: 3.118269]\n",
            "29 [ D loss: 0.060828, acc.: 100%] [G loss: 3.139297]\n",
            "30 [ D loss: 0.058871, acc.: 100%] [G loss: 3.322291]\n",
            "31 [ D loss: 0.057296, acc.: 100%] [G loss: 3.265273]\n",
            "32 [ D loss: 0.065102, acc.: 100%] [G loss: 3.297040]\n",
            "33 [ D loss: 0.055776, acc.: 100%] [G loss: 3.452156]\n",
            "34 [ D loss: 0.061691, acc.: 100%] [G loss: 3.429158]\n",
            "35 [ D loss: 0.047924, acc.: 100%] [G loss: 3.405041]\n",
            "36 [ D loss: 0.064419, acc.: 100%] [G loss: 3.484043]\n",
            "37 [ D loss: 0.063594, acc.: 100%] [G loss: 3.489223]\n",
            "38 [ D loss: 0.060591, acc.: 100%] [G loss: 3.609767]\n",
            "39 [ D loss: 0.067160, acc.: 100%] [G loss: 3.585792]\n",
            "40 [ D loss: 0.071144, acc.: 99%] [G loss: 3.656573]\n",
            "41 [ D loss: 0.059228, acc.: 100%] [G loss: 3.803236]\n",
            "42 [ D loss: 0.084698, acc.: 99%] [G loss: 3.787303]\n",
            "43 [ D loss: 0.093487, acc.: 98%] [G loss: 3.879202]\n",
            "44 [ D loss: 0.069798, acc.: 99%] [G loss: 3.910552]\n",
            "45 [ D loss: 0.080741, acc.: 99%] [G loss: 3.918726]\n",
            "46 [ D loss: 0.064284, acc.: 100%] [G loss: 3.884366]\n",
            "47 [ D loss: 0.072239, acc.: 100%] [G loss: 3.893927]\n",
            "48 [ D loss: 0.101063, acc.: 98%] [G loss: 3.911943]\n",
            "49 [ D loss: 0.092837, acc.: 99%] [G loss: 4.087725]\n",
            "50 [ D loss: 0.103175, acc.: 98%] [G loss: 4.022490]\n",
            "51 [ D loss: 0.122011, acc.: 98%] [G loss: 4.050795]\n",
            "52 [ D loss: 0.103445, acc.: 99%] [G loss: 4.086173]\n",
            "53 [ D loss: 0.123668, acc.: 97%] [G loss: 4.149819]\n",
            "54 [ D loss: 0.164222, acc.: 95%] [G loss: 3.991385]\n",
            "55 [ D loss: 0.161156, acc.: 95%] [G loss: 3.960554]\n",
            "56 [ D loss: 0.151817, acc.: 98%] [G loss: 4.006330]\n",
            "57 [ D loss: 0.158466, acc.: 95%] [G loss: 3.867178]\n",
            "58 [ D loss: 0.182676, acc.: 93%] [G loss: 3.929201]\n",
            "59 [ D loss: 0.139844, acc.: 97%] [G loss: 3.730651]\n",
            "60 [ D loss: 0.169110, acc.: 96%] [G loss: 3.777309]\n",
            "61 [ D loss: 0.183944, acc.: 95%] [G loss: 3.964590]\n",
            "62 [ D loss: 0.260158, acc.: 88%] [G loss: 3.968967]\n",
            "63 [ D loss: 0.207740, acc.: 94%] [G loss: 3.770447]\n",
            "64 [ D loss: 0.220796, acc.: 91%] [G loss: 3.560944]\n",
            "65 [ D loss: 0.177936, acc.: 96%] [G loss: 3.264241]\n",
            "66 [ D loss: 0.219806, acc.: 92%] [G loss: 3.471977]\n",
            "67 [ D loss: 0.213307, acc.: 90%] [G loss: 3.767037]\n",
            "68 [ D loss: 0.281539, acc.: 90%] [G loss: 3.962744]\n",
            "69 [ D loss: 0.367498, acc.: 84%] [G loss: 3.805253]\n",
            "70 [ D loss: 0.325037, acc.: 87%] [G loss: 3.495780]\n",
            "71 [ D loss: 0.293460, acc.: 87%] [G loss: 3.516702]\n",
            "72 [ D loss: 0.347324, acc.: 84%] [G loss: 3.484414]\n",
            "73 [ D loss: 0.225483, acc.: 93%] [G loss: 3.282263]\n",
            "74 [ D loss: 0.244689, acc.: 90%] [G loss: 3.124930]\n",
            "75 [ D loss: 0.235611, acc.: 95%] [G loss: 3.070014]\n",
            "76 [ D loss: 0.306899, acc.: 88%] [G loss: 3.074257]\n",
            "77 [ D loss: 0.315597, acc.: 83%] [G loss: 3.325502]\n",
            "78 [ D loss: 0.322682, acc.: 88%] [G loss: 3.373603]\n",
            "79 [ D loss: 0.353630, acc.: 84%] [G loss: 3.280491]\n",
            "80 [ D loss: 0.340945, acc.: 87%] [G loss: 3.325706]\n",
            "81 [ D loss: 0.319608, acc.: 88%] [G loss: 3.441162]\n",
            "82 [ D loss: 0.373459, acc.: 85%] [G loss: 3.257827]\n",
            "83 [ D loss: 0.462222, acc.: 81%] [G loss: 3.183753]\n",
            "84 [ D loss: 0.330959, acc.: 84%] [G loss: 3.030499]\n",
            "85 [ D loss: 0.251699, acc.: 93%] [G loss: 2.779039]\n",
            "86 [ D loss: 0.423646, acc.: 80%] [G loss: 3.186054]\n",
            "87 [ D loss: 0.305876, acc.: 91%] [G loss: 3.156719]\n",
            "88 [ D loss: 0.411137, acc.: 77%] [G loss: 3.282320]\n",
            "89 [ D loss: 0.395812, acc.: 81%] [G loss: 2.957065]\n",
            "90 [ D loss: 0.323092, acc.: 83%] [G loss: 2.707861]\n",
            "91 [ D loss: 0.429215, acc.: 81%] [G loss: 3.154802]\n",
            "92 [ D loss: 0.340730, acc.: 87%] [G loss: 3.322570]\n",
            "93 [ D loss: 0.443271, acc.: 78%] [G loss: 2.930787]\n",
            "94 [ D loss: 0.434724, acc.: 83%] [G loss: 2.883878]\n",
            "95 [ D loss: 0.397075, acc.: 84%] [G loss: 2.910202]\n",
            "96 [ D loss: 0.415903, acc.: 80%] [G loss: 2.941482]\n",
            "97 [ D loss: 0.388528, acc.: 83%] [G loss: 2.974048]\n",
            "98 [ D loss: 0.334326, acc.: 84%] [G loss: 2.806152]\n",
            "99 [ D loss: 0.360134, acc.: 83%] [G loss: 2.557645]\n",
            "100 [ D loss: 0.333281, acc.: 88%] [G loss: 2.616922]\n",
            "101 [ D loss: 0.427325, acc.: 77%] [G loss: 3.207335]\n",
            "102 [ D loss: 0.374275, acc.: 84%] [G loss: 3.063654]\n",
            "103 [ D loss: 0.397714, acc.: 83%] [G loss: 2.629257]\n",
            "104 [ D loss: 0.343450, acc.: 87%] [G loss: 2.776289]\n",
            "105 [ D loss: 0.336607, acc.: 84%] [G loss: 2.644743]\n",
            "106 [ D loss: 0.481263, acc.: 78%] [G loss: 2.774964]\n",
            "107 [ D loss: 0.378804, acc.: 84%] [G loss: 2.704304]\n",
            "108 [ D loss: 0.460537, acc.: 80%] [G loss: 2.559750]\n",
            "109 [ D loss: 0.356111, acc.: 90%] [G loss: 2.706120]\n",
            "110 [ D loss: 0.384128, acc.: 84%] [G loss: 2.994847]\n",
            "111 [ D loss: 0.488852, acc.: 76%] [G loss: 3.085924]\n",
            "112 [ D loss: 0.452223, acc.: 78%] [G loss: 2.954123]\n",
            "113 [ D loss: 0.398113, acc.: 84%] [G loss: 2.974280]\n",
            "114 [ D loss: 0.387878, acc.: 83%] [G loss: 2.827920]\n",
            "115 [ D loss: 0.438587, acc.: 80%] [G loss: 2.847000]\n",
            "116 [ D loss: 0.472390, acc.: 75%] [G loss: 2.832884]\n",
            "117 [ D loss: 0.456996, acc.: 82%] [G loss: 2.970697]\n",
            "118 [ D loss: 0.365262, acc.: 84%] [G loss: 3.107195]\n",
            "119 [ D loss: 0.420477, acc.: 82%] [G loss: 2.879856]\n",
            "120 [ D loss: 0.341724, acc.: 89%] [G loss: 2.858684]\n",
            "121 [ D loss: 0.353904, acc.: 86%] [G loss: 3.063094]\n",
            "122 [ D loss: 0.471847, acc.: 80%] [G loss: 3.149291]\n",
            "123 [ D loss: 0.375852, acc.: 83%] [G loss: 3.045436]\n",
            "124 [ D loss: 0.380378, acc.: 81%] [G loss: 2.678697]\n",
            "125 [ D loss: 0.426777, acc.: 80%] [G loss: 2.781484]\n",
            "126 [ D loss: 0.384879, acc.: 85%] [G loss: 2.918506]\n",
            "127 [ D loss: 0.452503, acc.: 78%] [G loss: 2.830273]\n",
            "128 [ D loss: 0.381572, acc.: 81%] [G loss: 3.197850]\n",
            "129 [ D loss: 0.365240, acc.: 84%] [G loss: 3.149160]\n",
            "130 [ D loss: 0.374027, acc.: 84%] [G loss: 2.971212]\n",
            "131 [ D loss: 0.353935, acc.: 88%] [G loss: 2.879768]\n",
            "132 [ D loss: 0.375961, acc.: 83%] [G loss: 2.935776]\n",
            "133 [ D loss: 0.422279, acc.: 84%] [G loss: 2.994246]\n",
            "134 [ D loss: 0.451390, acc.: 78%] [G loss: 3.134853]\n",
            "135 [ D loss: 0.405981, acc.: 84%] [G loss: 3.246806]\n",
            "136 [ D loss: 0.403181, acc.: 82%] [G loss: 2.985839]\n",
            "137 [ D loss: 0.423182, acc.: 84%] [G loss: 2.793672]\n",
            "138 [ D loss: 0.464077, acc.: 81%] [G loss: 3.208809]\n",
            "139 [ D loss: 0.439625, acc.: 78%] [G loss: 3.241043]\n",
            "140 [ D loss: 0.436427, acc.: 84%] [G loss: 2.784926]\n",
            "141 [ D loss: 0.572524, acc.: 66%] [G loss: 3.122393]\n",
            "142 [ D loss: 0.455156, acc.: 75%] [G loss: 3.280309]\n",
            "143 [ D loss: 0.426986, acc.: 80%] [G loss: 2.937059]\n",
            "144 [ D loss: 0.383416, acc.: 84%] [G loss: 3.067009]\n",
            "145 [ D loss: 0.473604, acc.: 74%] [G loss: 3.124506]\n",
            "146 [ D loss: 0.385331, acc.: 80%] [G loss: 3.207110]\n",
            "147 [ D loss: 0.362670, acc.: 88%] [G loss: 2.740702]\n",
            "148 [ D loss: 0.393058, acc.: 87%] [G loss: 2.692058]\n",
            "149 [ D loss: 0.499169, acc.: 73%] [G loss: 3.002142]\n",
            "150 [ D loss: 0.443268, acc.: 82%] [G loss: 3.329337]\n",
            "151 [ D loss: 0.346850, acc.: 88%] [G loss: 3.310993]\n",
            "152 [ D loss: 0.418048, acc.: 80%] [G loss: 3.160994]\n",
            "153 [ D loss: 0.416047, acc.: 81%] [G loss: 3.322351]\n",
            "154 [ D loss: 0.389514, acc.: 83%] [G loss: 2.944497]\n",
            "155 [ D loss: 0.362908, acc.: 83%] [G loss: 2.850291]\n",
            "156 [ D loss: 0.363153, acc.: 84%] [G loss: 2.844258]\n",
            "157 [ D loss: 0.449111, acc.: 77%] [G loss: 2.874073]\n",
            "158 [ D loss: 0.380416, acc.: 88%] [G loss: 3.162270]\n",
            "159 [ D loss: 0.407519, acc.: 81%] [G loss: 3.203928]\n",
            "160 [ D loss: 0.369870, acc.: 86%] [G loss: 3.264113]\n",
            "161 [ D loss: 0.429638, acc.: 81%] [G loss: 2.714569]\n",
            "162 [ D loss: 0.466158, acc.: 80%] [G loss: 2.948172]\n",
            "163 [ D loss: 0.426238, acc.: 77%] [G loss: 3.138582]\n",
            "164 [ D loss: 0.447245, acc.: 83%] [G loss: 3.003427]\n",
            "165 [ D loss: 0.432645, acc.: 81%] [G loss: 3.053189]\n",
            "166 [ D loss: 0.517559, acc.: 77%] [G loss: 3.488442]\n",
            "167 [ D loss: 0.467149, acc.: 75%] [G loss: 3.431185]\n",
            "168 [ D loss: 0.428722, acc.: 82%] [G loss: 2.995402]\n",
            "169 [ D loss: 0.475265, acc.: 80%] [G loss: 2.912212]\n",
            "170 [ D loss: 0.419971, acc.: 81%] [G loss: 3.006391]\n",
            "171 [ D loss: 0.453990, acc.: 80%] [G loss: 3.394070]\n",
            "172 [ D loss: 0.520174, acc.: 70%] [G loss: 2.912371]\n",
            "173 [ D loss: 0.525895, acc.: 73%] [G loss: 3.094770]\n",
            "174 [ D loss: 0.563050, acc.: 69%] [G loss: 3.059712]\n",
            "175 [ D loss: 0.612277, acc.: 68%] [G loss: 3.072096]\n",
            "176 [ D loss: 0.522158, acc.: 72%] [G loss: 3.403110]\n",
            "177 [ D loss: 0.571278, acc.: 68%] [G loss: 3.151669]\n",
            "178 [ D loss: 0.495965, acc.: 75%] [G loss: 2.866846]\n",
            "179 [ D loss: 0.531438, acc.: 67%] [G loss: 2.969618]\n",
            "180 [ D loss: 0.552875, acc.: 72%] [G loss: 3.188342]\n",
            "181 [ D loss: 0.442552, acc.: 80%] [G loss: 2.977457]\n",
            "182 [ D loss: 0.466207, acc.: 80%] [G loss: 2.646995]\n",
            "183 [ D loss: 0.511205, acc.: 73%] [G loss: 2.848183]\n",
            "184 [ D loss: 0.474287, acc.: 74%] [G loss: 2.970791]\n",
            "185 [ D loss: 0.510960, acc.: 74%] [G loss: 2.619811]\n",
            "186 [ D loss: 0.602818, acc.: 67%] [G loss: 2.617571]\n",
            "187 [ D loss: 0.556027, acc.: 71%] [G loss: 3.209924]\n",
            "188 [ D loss: 0.481400, acc.: 75%] [G loss: 2.904274]\n",
            "189 [ D loss: 0.627518, acc.: 62%] [G loss: 2.924697]\n",
            "190 [ D loss: 0.523492, acc.: 70%] [G loss: 3.423656]\n",
            "191 [ D loss: 0.542940, acc.: 66%] [G loss: 3.196562]\n",
            "192 [ D loss: 0.501104, acc.: 74%] [G loss: 2.673719]\n",
            "193 [ D loss: 0.615282, acc.: 66%] [G loss: 3.023115]\n",
            "194 [ D loss: 0.466569, acc.: 79%] [G loss: 2.869227]\n",
            "195 [ D loss: 0.631515, acc.: 62%] [G loss: 2.799631]\n",
            "196 [ D loss: 0.610437, acc.: 65%] [G loss: 2.667950]\n",
            "197 [ D loss: 0.550488, acc.: 70%] [G loss: 3.065516]\n",
            "198 [ D loss: 0.520155, acc.: 74%] [G loss: 2.910831]\n",
            "199 [ D loss: 0.566392, acc.: 66%] [G loss: 2.397762]\n",
            "200 [ D loss: 0.553411, acc.: 71%] [G loss: 3.096776]\n",
            "201 [ D loss: 0.571266, acc.: 66%] [G loss: 2.692450]\n",
            "202 [ D loss: 0.625529, acc.: 65%] [G loss: 2.884808]\n",
            "203 [ D loss: 0.540451, acc.: 72%] [G loss: 2.775920]\n",
            "204 [ D loss: 0.631840, acc.: 59%] [G loss: 3.003674]\n",
            "205 [ D loss: 0.550471, acc.: 70%] [G loss: 2.724912]\n",
            "206 [ D loss: 0.550158, acc.: 69%] [G loss: 2.611402]\n",
            "207 [ D loss: 0.483737, acc.: 78%] [G loss: 2.527834]\n",
            "208 [ D loss: 0.576992, acc.: 70%] [G loss: 2.765572]\n",
            "209 [ D loss: 0.540933, acc.: 71%] [G loss: 2.905808]\n",
            "210 [ D loss: 0.596121, acc.: 64%] [G loss: 2.526842]\n",
            "211 [ D loss: 0.581539, acc.: 67%] [G loss: 2.636361]\n",
            "212 [ D loss: 0.557853, acc.: 69%] [G loss: 2.725305]\n",
            "213 [ D loss: 0.611964, acc.: 65%] [G loss: 2.875312]\n",
            "214 [ D loss: 0.598754, acc.: 66%] [G loss: 2.656027]\n",
            "215 [ D loss: 0.593986, acc.: 60%] [G loss: 2.402412]\n",
            "216 [ D loss: 0.586244, acc.: 70%] [G loss: 2.451477]\n",
            "217 [ D loss: 0.519388, acc.: 74%] [G loss: 2.507111]\n",
            "218 [ D loss: 0.579406, acc.: 66%] [G loss: 2.479424]\n",
            "219 [ D loss: 0.603800, acc.: 63%] [G loss: 2.459609]\n",
            "220 [ D loss: 0.558748, acc.: 70%] [G loss: 2.587547]\n",
            "221 [ D loss: 0.622074, acc.: 62%] [G loss: 2.500069]\n",
            "222 [ D loss: 0.622379, acc.: 66%] [G loss: 2.609157]\n",
            "223 [ D loss: 0.596029, acc.: 68%] [G loss: 2.599031]\n",
            "224 [ D loss: 0.536660, acc.: 69%] [G loss: 2.544236]\n",
            "225 [ D loss: 0.603181, acc.: 68%] [G loss: 2.518505]\n",
            "226 [ D loss: 0.564164, acc.: 65%] [G loss: 2.576226]\n",
            "227 [ D loss: 0.562145, acc.: 71%] [G loss: 2.535711]\n",
            "228 [ D loss: 0.641353, acc.: 59%] [G loss: 2.317986]\n",
            "229 [ D loss: 0.627740, acc.: 67%] [G loss: 2.330009]\n",
            "230 [ D loss: 0.636311, acc.: 64%] [G loss: 2.170208]\n",
            "231 [ D loss: 0.594722, acc.: 67%] [G loss: 2.484951]\n",
            "232 [ D loss: 0.614232, acc.: 62%] [G loss: 2.679268]\n",
            "233 [ D loss: 0.568708, acc.: 68%] [G loss: 2.529233]\n",
            "234 [ D loss: 0.580706, acc.: 68%] [G loss: 2.316422]\n",
            "235 [ D loss: 0.548265, acc.: 72%] [G loss: 2.429987]\n",
            "236 [ D loss: 0.586202, acc.: 66%] [G loss: 2.470424]\n",
            "237 [ D loss: 0.574267, acc.: 70%] [G loss: 2.405953]\n",
            "238 [ D loss: 0.580718, acc.: 67%] [G loss: 2.369531]\n",
            "239 [ D loss: 0.553862, acc.: 70%] [G loss: 2.489883]\n",
            "240 [ D loss: 0.600192, acc.: 68%] [G loss: 2.460622]\n",
            "241 [ D loss: 0.585837, acc.: 64%] [G loss: 2.243806]\n",
            "242 [ D loss: 0.651758, acc.: 59%] [G loss: 2.204663]\n",
            "243 [ D loss: 0.628450, acc.: 65%] [G loss: 2.250594]\n",
            "244 [ D loss: 0.597172, acc.: 64%] [G loss: 2.363930]\n",
            "245 [ D loss: 0.657290, acc.: 61%] [G loss: 2.227782]\n",
            "246 [ D loss: 0.556369, acc.: 72%] [G loss: 2.217740]\n",
            "247 [ D loss: 0.583935, acc.: 63%] [G loss: 2.231117]\n",
            "248 [ D loss: 0.586970, acc.: 66%] [G loss: 2.202318]\n",
            "249 [ D loss: 0.586624, acc.: 66%] [G loss: 2.210463]\n",
            "250 [ D loss: 0.585251, acc.: 62%] [G loss: 2.270248]\n",
            "251 [ D loss: 0.636580, acc.: 62%] [G loss: 2.188877]\n",
            "252 [ D loss: 0.607084, acc.: 66%] [G loss: 2.194345]\n",
            "253 [ D loss: 0.593823, acc.: 63%] [G loss: 2.292479]\n",
            "254 [ D loss: 0.558753, acc.: 73%] [G loss: 2.119070]\n",
            "255 [ D loss: 0.645412, acc.: 66%] [G loss: 2.028257]\n",
            "256 [ D loss: 0.584792, acc.: 66%] [G loss: 2.080919]\n",
            "257 [ D loss: 0.607221, acc.: 60%] [G loss: 2.057618]\n",
            "258 [ D loss: 0.637951, acc.: 59%] [G loss: 2.093845]\n",
            "259 [ D loss: 0.555531, acc.: 70%] [G loss: 2.127148]\n",
            "260 [ D loss: 0.593423, acc.: 63%] [G loss: 2.042617]\n",
            "261 [ D loss: 0.559529, acc.: 70%] [G loss: 2.278691]\n",
            "262 [ D loss: 0.651412, acc.: 62%] [G loss: 2.072919]\n",
            "263 [ D loss: 0.610174, acc.: 61%] [G loss: 1.990402]\n",
            "264 [ D loss: 0.620589, acc.: 62%] [G loss: 2.050933]\n",
            "265 [ D loss: 0.597166, acc.: 65%] [G loss: 2.104441]\n",
            "266 [ D loss: 0.596040, acc.: 69%] [G loss: 2.069002]\n",
            "267 [ D loss: 0.626331, acc.: 62%] [G loss: 2.065372]\n",
            "268 [ D loss: 0.629841, acc.: 61%] [G loss: 1.980683]\n",
            "269 [ D loss: 0.591602, acc.: 67%] [G loss: 2.055961]\n",
            "270 [ D loss: 0.617820, acc.: 66%] [G loss: 2.045103]\n",
            "271 [ D loss: 0.636091, acc.: 62%] [G loss: 1.873409]\n",
            "272 [ D loss: 0.599376, acc.: 66%] [G loss: 1.916209]\n",
            "273 [ D loss: 0.604395, acc.: 68%] [G loss: 2.021339]\n",
            "274 [ D loss: 0.644259, acc.: 63%] [G loss: 1.974805]\n",
            "275 [ D loss: 0.594643, acc.: 69%] [G loss: 1.890250]\n",
            "276 [ D loss: 0.611102, acc.: 65%] [G loss: 1.808390]\n",
            "277 [ D loss: 0.594868, acc.: 68%] [G loss: 2.011488]\n",
            "278 [ D loss: 0.629930, acc.: 61%] [G loss: 2.001975]\n",
            "279 [ D loss: 0.612712, acc.: 64%] [G loss: 1.964313]\n",
            "280 [ D loss: 0.559509, acc.: 64%] [G loss: 1.979476]\n",
            "281 [ D loss: 0.601724, acc.: 63%] [G loss: 1.935421]\n",
            "282 [ D loss: 0.603394, acc.: 66%] [G loss: 1.983367]\n",
            "283 [ D loss: 0.641338, acc.: 57%] [G loss: 1.879591]\n",
            "284 [ D loss: 0.580158, acc.: 72%] [G loss: 1.949218]\n",
            "285 [ D loss: 0.640937, acc.: 55%] [G loss: 1.913141]\n",
            "286 [ D loss: 0.597077, acc.: 70%] [G loss: 1.882355]\n",
            "287 [ D loss: 0.633570, acc.: 65%] [G loss: 1.954933]\n",
            "288 [ D loss: 0.590985, acc.: 64%] [G loss: 1.972968]\n",
            "289 [ D loss: 0.637351, acc.: 62%] [G loss: 1.859777]\n",
            "290 [ D loss: 0.598577, acc.: 64%] [G loss: 1.875149]\n",
            "291 [ D loss: 0.582648, acc.: 66%] [G loss: 1.855621]\n",
            "292 [ D loss: 0.637765, acc.: 58%] [G loss: 1.759766]\n",
            "293 [ D loss: 0.612805, acc.: 62%] [G loss: 1.831501]\n",
            "294 [ D loss: 0.554510, acc.: 71%] [G loss: 1.976198]\n",
            "295 [ D loss: 0.529665, acc.: 72%] [G loss: 1.816875]\n",
            "296 [ D loss: 0.583640, acc.: 70%] [G loss: 1.836130]\n",
            "297 [ D loss: 0.629732, acc.: 62%] [G loss: 1.912983]\n",
            "298 [ D loss: 0.633489, acc.: 61%] [G loss: 1.900636]\n",
            "299 [ D loss: 0.574428, acc.: 68%] [G loss: 1.914286]\n",
            "300 [ D loss: 0.634535, acc.: 57%] [G loss: 1.780810]\n",
            "301 [ D loss: 0.604421, acc.: 63%] [G loss: 1.735508]\n",
            "302 [ D loss: 0.590527, acc.: 68%] [G loss: 1.785568]\n",
            "303 [ D loss: 0.677599, acc.: 59%] [G loss: 1.828055]\n",
            "304 [ D loss: 0.638390, acc.: 61%] [G loss: 1.794664]\n",
            "305 [ D loss: 0.625197, acc.: 61%] [G loss: 1.780631]\n",
            "306 [ D loss: 0.678465, acc.: 55%] [G loss: 1.731435]\n",
            "307 [ D loss: 0.577101, acc.: 70%] [G loss: 1.806617]\n",
            "308 [ D loss: 0.619184, acc.: 65%] [G loss: 1.796910]\n",
            "309 [ D loss: 0.609425, acc.: 63%] [G loss: 1.737144]\n",
            "310 [ D loss: 0.611673, acc.: 65%] [G loss: 1.730535]\n",
            "311 [ D loss: 0.617389, acc.: 64%] [G loss: 1.741668]\n",
            "312 [ D loss: 0.608503, acc.: 66%] [G loss: 1.705835]\n",
            "313 [ D loss: 0.587378, acc.: 66%] [G loss: 1.724401]\n",
            "314 [ D loss: 0.602995, acc.: 64%] [G loss: 1.759210]\n",
            "315 [ D loss: 0.588571, acc.: 63%] [G loss: 1.800836]\n",
            "316 [ D loss: 0.605937, acc.: 66%] [G loss: 1.834434]\n",
            "317 [ D loss: 0.594190, acc.: 64%] [G loss: 1.669295]\n",
            "318 [ D loss: 0.629100, acc.: 66%] [G loss: 1.642435]\n",
            "319 [ D loss: 0.622218, acc.: 60%] [G loss: 1.696998]\n",
            "320 [ D loss: 0.610662, acc.: 64%] [G loss: 1.724582]\n",
            "321 [ D loss: 0.579589, acc.: 66%] [G loss: 1.778193]\n",
            "322 [ D loss: 0.608669, acc.: 60%] [G loss: 1.680909]\n",
            "323 [ D loss: 0.610500, acc.: 68%] [G loss: 1.733690]\n",
            "324 [ D loss: 0.630028, acc.: 62%] [G loss: 1.633196]\n",
            "325 [ D loss: 0.629668, acc.: 67%] [G loss: 1.556896]\n",
            "326 [ D loss: 0.648776, acc.: 59%] [G loss: 1.529625]\n",
            "327 [ D loss: 0.626011, acc.: 60%] [G loss: 1.603659]\n",
            "328 [ D loss: 0.628356, acc.: 65%] [G loss: 1.685868]\n",
            "329 [ D loss: 0.617796, acc.: 59%] [G loss: 1.620724]\n",
            "330 [ D loss: 0.642811, acc.: 59%] [G loss: 1.628693]\n",
            "331 [ D loss: 0.656492, acc.: 59%] [G loss: 1.590702]\n",
            "332 [ D loss: 0.638581, acc.: 62%] [G loss: 1.554565]\n",
            "333 [ D loss: 0.621976, acc.: 62%] [G loss: 1.569293]\n",
            "334 [ D loss: 0.623540, acc.: 62%] [G loss: 1.578738]\n",
            "335 [ D loss: 0.599348, acc.: 62%] [G loss: 1.676307]\n",
            "336 [ D loss: 0.644163, acc.: 54%] [G loss: 1.561192]\n",
            "337 [ D loss: 0.664260, acc.: 57%] [G loss: 1.549562]\n",
            "338 [ D loss: 0.600291, acc.: 66%] [G loss: 1.612380]\n",
            "339 [ D loss: 0.597198, acc.: 60%] [G loss: 1.710200]\n",
            "340 [ D loss: 0.590629, acc.: 62%] [G loss: 1.665481]\n",
            "341 [ D loss: 0.588960, acc.: 66%] [G loss: 1.605847]\n",
            "342 [ D loss: 0.602175, acc.: 61%] [G loss: 1.651644]\n",
            "343 [ D loss: 0.638451, acc.: 59%] [G loss: 1.514672]\n",
            "344 [ D loss: 0.611247, acc.: 59%] [G loss: 1.541788]\n",
            "345 [ D loss: 0.579433, acc.: 69%] [G loss: 1.660892]\n",
            "346 [ D loss: 0.593279, acc.: 66%] [G loss: 1.718247]\n",
            "347 [ D loss: 0.610097, acc.: 62%] [G loss: 1.597914]\n",
            "348 [ D loss: 0.607664, acc.: 66%] [G loss: 1.602935]\n",
            "349 [ D loss: 0.594788, acc.: 65%] [G loss: 1.581306]\n",
            "350 [ D loss: 0.606990, acc.: 62%] [G loss: 1.569357]\n",
            "351 [ D loss: 0.573195, acc.: 69%] [G loss: 1.587776]\n",
            "352 [ D loss: 0.575168, acc.: 66%] [G loss: 1.617717]\n",
            "353 [ D loss: 0.557379, acc.: 70%] [G loss: 1.654279]\n",
            "354 [ D loss: 0.597184, acc.: 58%] [G loss: 1.628276]\n",
            "355 [ D loss: 0.575959, acc.: 64%] [G loss: 1.531159]\n",
            "356 [ D loss: 0.572291, acc.: 66%] [G loss: 1.601371]\n",
            "357 [ D loss: 0.613343, acc.: 59%] [G loss: 1.525526]\n",
            "358 [ D loss: 0.575399, acc.: 66%] [G loss: 1.637058]\n",
            "359 [ D loss: 0.583809, acc.: 65%] [G loss: 1.655318]\n",
            "360 [ D loss: 0.606027, acc.: 65%] [G loss: 1.600870]\n",
            "361 [ D loss: 0.601695, acc.: 62%] [G loss: 1.582245]\n",
            "362 [ D loss: 0.575516, acc.: 68%] [G loss: 1.557860]\n",
            "363 [ D loss: 0.581488, acc.: 70%] [G loss: 1.616628]\n",
            "364 [ D loss: 0.598110, acc.: 67%] [G loss: 1.556884]\n",
            "365 [ D loss: 0.598966, acc.: 63%] [G loss: 1.504884]\n",
            "366 [ D loss: 0.617586, acc.: 60%] [G loss: 1.542467]\n",
            "367 [ D loss: 0.582109, acc.: 66%] [G loss: 1.512632]\n",
            "368 [ D loss: 0.628244, acc.: 53%] [G loss: 1.541391]\n",
            "369 [ D loss: 0.589188, acc.: 66%] [G loss: 1.575871]\n",
            "370 [ D loss: 0.611727, acc.: 63%] [G loss: 1.512673]\n",
            "371 [ D loss: 0.627101, acc.: 62%] [G loss: 1.500219]\n",
            "372 [ D loss: 0.615717, acc.: 60%] [G loss: 1.490133]\n",
            "373 [ D loss: 0.631456, acc.: 60%] [G loss: 1.531743]\n",
            "374 [ D loss: 0.591404, acc.: 62%] [G loss: 1.497307]\n",
            "375 [ D loss: 0.568615, acc.: 66%] [G loss: 1.582664]\n",
            "376 [ D loss: 0.582593, acc.: 61%] [G loss: 1.563341]\n",
            "377 [ D loss: 0.654868, acc.: 52%] [G loss: 1.450807]\n",
            "378 [ D loss: 0.591331, acc.: 67%] [G loss: 1.541219]\n",
            "379 [ D loss: 0.600042, acc.: 59%] [G loss: 1.480655]\n",
            "380 [ D loss: 0.607424, acc.: 64%] [G loss: 1.483955]\n",
            "381 [ D loss: 0.599760, acc.: 64%] [G loss: 1.453344]\n",
            "382 [ D loss: 0.646284, acc.: 56%] [G loss: 1.463976]\n",
            "383 [ D loss: 0.601865, acc.: 62%] [G loss: 1.498067]\n",
            "384 [ D loss: 0.615978, acc.: 62%] [G loss: 1.452167]\n",
            "385 [ D loss: 0.624497, acc.: 60%] [G loss: 1.468452]\n",
            "386 [ D loss: 0.615876, acc.: 62%] [G loss: 1.446975]\n",
            "387 [ D loss: 0.621729, acc.: 66%] [G loss: 1.430818]\n",
            "388 [ D loss: 0.597659, acc.: 62%] [G loss: 1.508195]\n",
            "389 [ D loss: 0.590168, acc.: 65%] [G loss: 1.548321]\n",
            "390 [ D loss: 0.604838, acc.: 62%] [G loss: 1.510970]\n",
            "391 [ D loss: 0.610486, acc.: 66%] [G loss: 1.424041]\n",
            "392 [ D loss: 0.569393, acc.: 73%] [G loss: 1.407032]\n",
            "393 [ D loss: 0.637040, acc.: 64%] [G loss: 1.425087]\n",
            "394 [ D loss: 0.601026, acc.: 65%] [G loss: 1.503141]\n",
            "395 [ D loss: 0.592209, acc.: 60%] [G loss: 1.488417]\n",
            "396 [ D loss: 0.625338, acc.: 60%] [G loss: 1.467845]\n",
            "397 [ D loss: 0.588761, acc.: 71%] [G loss: 1.518273]\n",
            "398 [ D loss: 0.608743, acc.: 63%] [G loss: 1.488135]\n",
            "399 [ D loss: 0.605049, acc.: 65%] [G loss: 1.504064]\n",
            "400 [ D loss: 0.600228, acc.: 60%] [G loss: 1.456037]\n",
            "401 [ D loss: 0.589622, acc.: 64%] [G loss: 1.513384]\n",
            "402 [ D loss: 0.613521, acc.: 64%] [G loss: 1.524572]\n",
            "403 [ D loss: 0.603510, acc.: 63%] [G loss: 1.580289]\n",
            "404 [ D loss: 0.572545, acc.: 67%] [G loss: 1.593232]\n",
            "405 [ D loss: 0.586020, acc.: 63%] [G loss: 1.535572]\n",
            "406 [ D loss: 0.624548, acc.: 68%] [G loss: 1.459528]\n",
            "407 [ D loss: 0.562263, acc.: 71%] [G loss: 1.452291]\n",
            "408 [ D loss: 0.628761, acc.: 64%] [G loss: 1.442953]\n",
            "409 [ D loss: 0.586158, acc.: 70%] [G loss: 1.521868]\n",
            "410 [ D loss: 0.605789, acc.: 62%] [G loss: 1.494533]\n",
            "411 [ D loss: 0.598081, acc.: 65%] [G loss: 1.502634]\n",
            "412 [ D loss: 0.619523, acc.: 62%] [G loss: 1.459281]\n",
            "413 [ D loss: 0.601325, acc.: 62%] [G loss: 1.430490]\n",
            "414 [ D loss: 0.585004, acc.: 70%] [G loss: 1.519481]\n",
            "415 [ D loss: 0.549570, acc.: 77%] [G loss: 1.523535]\n",
            "416 [ D loss: 0.564673, acc.: 76%] [G loss: 1.463947]\n",
            "417 [ D loss: 0.587194, acc.: 71%] [G loss: 1.481993]\n",
            "418 [ D loss: 0.594977, acc.: 67%] [G loss: 1.506648]\n",
            "419 [ D loss: 0.590183, acc.: 67%] [G loss: 1.518433]\n",
            "420 [ D loss: 0.591750, acc.: 72%] [G loss: 1.390408]\n",
            "421 [ D loss: 0.596485, acc.: 65%] [G loss: 1.413377]\n",
            "422 [ D loss: 0.586466, acc.: 66%] [G loss: 1.571605]\n",
            "423 [ D loss: 0.599778, acc.: 64%] [G loss: 1.665168]\n",
            "424 [ D loss: 0.572244, acc.: 69%] [G loss: 1.467182]\n",
            "425 [ D loss: 0.559019, acc.: 74%] [G loss: 1.381521]\n",
            "426 [ D loss: 0.595375, acc.: 72%] [G loss: 1.378193]\n",
            "427 [ D loss: 0.605519, acc.: 65%] [G loss: 1.441401]\n",
            "428 [ D loss: 0.584304, acc.: 65%] [G loss: 1.535624]\n",
            "429 [ D loss: 0.584930, acc.: 66%] [G loss: 1.446395]\n",
            "430 [ D loss: 0.596410, acc.: 62%] [G loss: 1.499599]\n",
            "431 [ D loss: 0.588287, acc.: 63%] [G loss: 1.535557]\n",
            "432 [ D loss: 0.566448, acc.: 75%] [G loss: 1.466386]\n",
            "433 [ D loss: 0.562404, acc.: 76%] [G loss: 1.432886]\n",
            "434 [ D loss: 0.611009, acc.: 66%] [G loss: 1.386997]\n",
            "435 [ D loss: 0.590366, acc.: 71%] [G loss: 1.420071]\n",
            "436 [ D loss: 0.565426, acc.: 70%] [G loss: 1.499101]\n",
            "437 [ D loss: 0.589321, acc.: 65%] [G loss: 1.551655]\n",
            "438 [ D loss: 0.575793, acc.: 70%] [G loss: 1.514721]\n",
            "439 [ D loss: 0.568026, acc.: 73%] [G loss: 1.381095]\n",
            "440 [ D loss: 0.617526, acc.: 66%] [G loss: 1.325709]\n",
            "441 [ D loss: 0.610952, acc.: 70%] [G loss: 1.383596]\n",
            "442 [ D loss: 0.582569, acc.: 68%] [G loss: 1.428050]\n",
            "443 [ D loss: 0.586552, acc.: 70%] [G loss: 1.576082]\n",
            "444 [ D loss: 0.547591, acc.: 74%] [G loss: 1.606624]\n",
            "445 [ D loss: 0.552027, acc.: 71%] [G loss: 1.442971]\n",
            "446 [ D loss: 0.566796, acc.: 73%] [G loss: 1.461312]\n",
            "447 [ D loss: 0.564628, acc.: 78%] [G loss: 1.468068]\n",
            "448 [ D loss: 0.568202, acc.: 74%] [G loss: 1.482289]\n",
            "449 [ D loss: 0.583643, acc.: 69%] [G loss: 1.538645]\n",
            "450 [ D loss: 0.541782, acc.: 73%] [G loss: 1.558162]\n",
            "451 [ D loss: 0.536119, acc.: 75%] [G loss: 1.482930]\n",
            "452 [ D loss: 0.592611, acc.: 70%] [G loss: 1.398326]\n",
            "453 [ D loss: 0.596892, acc.: 75%] [G loss: 1.373176]\n",
            "454 [ D loss: 0.536071, acc.: 80%] [G loss: 1.445818]\n",
            "455 [ D loss: 0.538005, acc.: 79%] [G loss: 1.416767]\n",
            "456 [ D loss: 0.573497, acc.: 70%] [G loss: 1.422419]\n",
            "457 [ D loss: 0.571556, acc.: 66%] [G loss: 1.514642]\n",
            "458 [ D loss: 0.556897, acc.: 66%] [G loss: 1.448231]\n",
            "459 [ D loss: 0.586804, acc.: 73%] [G loss: 1.324920]\n",
            "460 [ D loss: 0.570468, acc.: 80%] [G loss: 1.312576]\n",
            "461 [ D loss: 0.587366, acc.: 66%] [G loss: 1.360213]\n",
            "462 [ D loss: 0.576239, acc.: 73%] [G loss: 1.403751]\n",
            "463 [ D loss: 0.550867, acc.: 68%] [G loss: 1.729838]\n",
            "464 [ D loss: 0.485291, acc.: 76%] [G loss: 1.915109]\n",
            "465 [ D loss: 0.569553, acc.: 78%] [G loss: 1.322518]\n",
            "466 [ D loss: 0.574412, acc.: 81%] [G loss: 1.283653]\n",
            "467 [ D loss: 0.554472, acc.: 87%] [G loss: 1.338914]\n",
            "468 [ D loss: 0.562360, acc.: 77%] [G loss: 1.441024]\n",
            "469 [ D loss: 0.562901, acc.: 70%] [G loss: 1.537336]\n",
            "470 [ D loss: 0.524380, acc.: 73%] [G loss: 1.651070]\n",
            "471 [ D loss: 0.494830, acc.: 77%] [G loss: 1.682090]\n",
            "472 [ D loss: 0.577135, acc.: 73%] [G loss: 1.228827]\n",
            "473 [ D loss: 0.579923, acc.: 78%] [G loss: 1.270398]\n",
            "474 [ D loss: 0.566450, acc.: 78%] [G loss: 1.430387]\n",
            "475 [ D loss: 0.592504, acc.: 67%] [G loss: 1.569791]\n",
            "476 [ D loss: 0.544042, acc.: 66%] [G loss: 1.810812]\n",
            "477 [ D loss: 0.531019, acc.: 80%] [G loss: 1.520929]\n",
            "478 [ D loss: 0.557070, acc.: 78%] [G loss: 1.498329]\n",
            "479 [ D loss: 0.531279, acc.: 84%] [G loss: 1.501326]\n",
            "480 [ D loss: 0.533172, acc.: 82%] [G loss: 1.586278]\n",
            "481 [ D loss: 0.553992, acc.: 74%] [G loss: 1.516202]\n",
            "482 [ D loss: 0.526322, acc.: 81%] [G loss: 1.526296]\n",
            "483 [ D loss: 0.553900, acc.: 79%] [G loss: 1.474866]\n",
            "484 [ D loss: 0.540002, acc.: 80%] [G loss: 1.551433]\n",
            "485 [ D loss: 0.516110, acc.: 80%] [G loss: 1.523074]\n",
            "486 [ D loss: 0.575344, acc.: 68%] [G loss: 1.550630]\n",
            "487 [ D loss: 0.521972, acc.: 75%] [G loss: 1.682356]\n",
            "488 [ D loss: 0.487178, acc.: 81%] [G loss: 1.907170]\n",
            "489 [ D loss: 0.522039, acc.: 77%] [G loss: 1.648424]\n",
            "490 [ D loss: 0.523871, acc.: 81%] [G loss: 1.607351]\n",
            "491 [ D loss: 0.515097, acc.: 80%] [G loss: 1.455810]\n",
            "492 [ D loss: 0.572019, acc.: 77%] [G loss: 1.328101]\n",
            "493 [ D loss: 0.533184, acc.: 88%] [G loss: 1.481590]\n",
            "494 [ D loss: 0.511298, acc.: 80%] [G loss: 1.669521]\n",
            "495 [ D loss: 0.510906, acc.: 74%] [G loss: 1.853571]\n",
            "496 [ D loss: 0.523422, acc.: 76%] [G loss: 1.685589]\n",
            "497 [ D loss: 0.502047, acc.: 83%] [G loss: 1.557202]\n",
            "498 [ D loss: 0.521247, acc.: 80%] [G loss: 1.514506]\n",
            "499 [ D loss: 0.476204, acc.: 84%] [G loss: 1.749833]\n",
            "500 [ D loss: 0.476738, acc.: 84%] [G loss: 1.717606]\n",
            "501 [ D loss: 0.488636, acc.: 91%] [G loss: 1.569402]\n",
            "502 [ D loss: 0.491339, acc.: 85%] [G loss: 1.679776]\n",
            "503 [ D loss: 0.453961, acc.: 84%] [G loss: 1.903919]\n",
            "504 [ D loss: 0.429643, acc.: 89%] [G loss: 1.987934]\n",
            "505 [ D loss: 0.486353, acc.: 86%] [G loss: 1.664088]\n",
            "506 [ D loss: 0.521349, acc.: 84%] [G loss: 1.609049]\n",
            "507 [ D loss: 0.480695, acc.: 88%] [G loss: 1.760331]\n",
            "508 [ D loss: 0.462850, acc.: 86%] [G loss: 1.862388]\n",
            "509 [ D loss: 0.498758, acc.: 78%] [G loss: 1.590286]\n",
            "510 [ D loss: 0.505213, acc.: 82%] [G loss: 1.548625]\n",
            "511 [ D loss: 0.473487, acc.: 82%] [G loss: 1.635638]\n",
            "512 [ D loss: 0.499049, acc.: 81%] [G loss: 1.703605]\n",
            "513 [ D loss: 0.446950, acc.: 82%] [G loss: 1.981154]\n",
            "514 [ D loss: 0.428713, acc.: 85%] [G loss: 2.056458]\n",
            "515 [ D loss: 0.456386, acc.: 85%] [G loss: 1.798523]\n",
            "516 [ D loss: 0.490268, acc.: 88%] [G loss: 1.617167]\n",
            "517 [ D loss: 0.451849, acc.: 85%] [G loss: 1.851639]\n",
            "518 [ D loss: 0.473058, acc.: 87%] [G loss: 1.835609]\n",
            "519 [ D loss: 0.483968, acc.: 88%] [G loss: 1.664389]\n",
            "520 [ D loss: 0.452829, acc.: 92%] [G loss: 1.752517]\n",
            "521 [ D loss: 0.445110, acc.: 88%] [G loss: 2.109924]\n",
            "522 [ D loss: 0.436714, acc.: 95%] [G loss: 1.802299]\n",
            "523 [ D loss: 0.511209, acc.: 89%] [G loss: 1.484444]\n",
            "524 [ D loss: 0.539758, acc.: 82%] [G loss: 1.574242]\n",
            "525 [ D loss: 0.475333, acc.: 75%] [G loss: 1.974540]\n",
            "526 [ D loss: 0.437300, acc.: 82%] [G loss: 2.256520]\n",
            "527 [ D loss: 0.447605, acc.: 87%] [G loss: 1.786908]\n",
            "528 [ D loss: 0.445825, acc.: 88%] [G loss: 1.653813]\n",
            "529 [ D loss: 0.447452, acc.: 89%] [G loss: 1.895465]\n",
            "530 [ D loss: 0.407448, acc.: 94%] [G loss: 2.192878]\n",
            "531 [ D loss: 0.448258, acc.: 87%] [G loss: 2.114857]\n",
            "532 [ D loss: 0.426252, acc.: 91%] [G loss: 1.904591]\n",
            "533 [ D loss: 0.425273, acc.: 94%] [G loss: 1.808278]\n",
            "534 [ D loss: 0.437222, acc.: 88%] [G loss: 1.853800]\n",
            "535 [ D loss: 0.454743, acc.: 88%] [G loss: 1.877054]\n",
            "536 [ D loss: 0.437680, acc.: 86%] [G loss: 1.995620]\n",
            "537 [ D loss: 0.430520, acc.: 90%] [G loss: 1.722987]\n",
            "538 [ D loss: 0.514102, acc.: 84%] [G loss: 1.763465]\n",
            "539 [ D loss: 0.460469, acc.: 84%] [G loss: 1.876940]\n",
            "540 [ D loss: 0.435225, acc.: 88%] [G loss: 2.099304]\n",
            "541 [ D loss: 0.434675, acc.: 88%] [G loss: 2.136308]\n",
            "542 [ D loss: 0.418452, acc.: 88%] [G loss: 2.607452]\n",
            "543 [ D loss: 0.401249, acc.: 93%] [G loss: 1.871334]\n",
            "544 [ D loss: 0.507985, acc.: 88%] [G loss: 1.467182]\n",
            "545 [ D loss: 0.454693, acc.: 88%] [G loss: 1.823001]\n",
            "546 [ D loss: 0.443617, acc.: 86%] [G loss: 2.198736]\n",
            "547 [ D loss: 0.420345, acc.: 85%] [G loss: 3.228388]\n",
            "548 [ D loss: 0.398182, acc.: 91%] [G loss: 2.224919]\n",
            "549 [ D loss: 0.490000, acc.: 89%] [G loss: 1.583498]\n",
            "550 [ D loss: 0.462972, acc.: 91%] [G loss: 1.776360]\n",
            "551 [ D loss: 0.415542, acc.: 90%] [G loss: 2.137177]\n",
            "552 [ D loss: 0.387646, acc.: 91%] [G loss: 2.872663]\n",
            "553 [ D loss: 0.399129, acc.: 95%] [G loss: 2.347234]\n",
            "554 [ D loss: 0.491706, acc.: 86%] [G loss: 1.736659]\n",
            "555 [ D loss: 0.439985, acc.: 93%] [G loss: 1.951475]\n",
            "556 [ D loss: 0.443608, acc.: 84%] [G loss: 2.206441]\n",
            "557 [ D loss: 0.392140, acc.: 91%] [G loss: 2.225363]\n",
            "558 [ D loss: 0.422832, acc.: 89%] [G loss: 2.010222]\n",
            "559 [ D loss: 0.424780, acc.: 86%] [G loss: 1.898970]\n",
            "560 [ D loss: 0.427589, acc.: 88%] [G loss: 1.937806]\n",
            "561 [ D loss: 0.408604, acc.: 92%] [G loss: 2.402430]\n",
            "562 [ D loss: 0.377299, acc.: 94%] [G loss: 2.494826]\n",
            "563 [ D loss: 0.415783, acc.: 88%] [G loss: 2.105586]\n",
            "564 [ D loss: 0.410421, acc.: 90%] [G loss: 2.182793]\n",
            "565 [ D loss: 0.377621, acc.: 95%] [G loss: 2.386278]\n",
            "566 [ D loss: 0.422828, acc.: 88%] [G loss: 2.250491]\n",
            "567 [ D loss: 0.429522, acc.: 87%] [G loss: 2.342613]\n",
            "568 [ D loss: 0.337874, acc.: 95%] [G loss: 3.143322]\n",
            "569 [ D loss: 0.419832, acc.: 97%] [G loss: 2.040138]\n",
            "570 [ D loss: 0.400364, acc.: 91%] [G loss: 2.290496]\n",
            "571 [ D loss: 0.408502, acc.: 93%] [G loss: 2.209373]\n",
            "572 [ D loss: 0.421501, acc.: 88%] [G loss: 2.026987]\n",
            "573 [ D loss: 0.390349, acc.: 92%] [G loss: 2.327113]\n",
            "574 [ D loss: 0.339449, acc.: 95%] [G loss: 3.129524]\n",
            "575 [ D loss: 0.358529, acc.: 92%] [G loss: 2.404661]\n",
            "576 [ D loss: 0.526237, acc.: 78%] [G loss: 1.676283]\n",
            "577 [ D loss: 0.413179, acc.: 98%] [G loss: 1.908525]\n",
            "578 [ D loss: 0.425085, acc.: 91%] [G loss: 2.212292]\n",
            "579 [ D loss: 0.418985, acc.: 84%] [G loss: 2.524178]\n",
            "580 [ D loss: 0.355267, acc.: 95%] [G loss: 2.299604]\n",
            "581 [ D loss: 0.411367, acc.: 90%] [G loss: 2.319720]\n",
            "582 [ D loss: 0.329975, acc.: 94%] [G loss: 3.283632]\n",
            "583 [ D loss: 0.337113, acc.: 97%] [G loss: 2.168796]\n",
            "584 [ D loss: 0.430148, acc.: 87%] [G loss: 1.792595]\n",
            "585 [ D loss: 0.389737, acc.: 92%] [G loss: 2.790026]\n",
            "586 [ D loss: 0.407574, acc.: 88%] [G loss: 2.546678]\n",
            "587 [ D loss: 0.382474, acc.: 93%] [G loss: 2.522980]\n",
            "588 [ D loss: 0.351532, acc.: 94%] [G loss: 2.552934]\n",
            "589 [ D loss: 0.393745, acc.: 91%] [G loss: 2.700798]\n",
            "590 [ D loss: 0.389391, acc.: 90%] [G loss: 3.160610]\n",
            "591 [ D loss: 0.324973, acc.: 95%] [G loss: 3.144368]\n",
            "592 [ D loss: 0.431495, acc.: 88%] [G loss: 2.019455]\n",
            "593 [ D loss: 0.406665, acc.: 91%] [G loss: 2.094730]\n",
            "594 [ D loss: 0.391980, acc.: 95%] [G loss: 2.217195]\n",
            "595 [ D loss: 0.407064, acc.: 90%] [G loss: 2.363674]\n",
            "596 [ D loss: 0.399368, acc.: 91%] [G loss: 2.457321]\n",
            "597 [ D loss: 0.370826, acc.: 91%] [G loss: 2.536967]\n",
            "598 [ D loss: 0.402449, acc.: 88%] [G loss: 2.148486]\n",
            "599 [ D loss: 0.378731, acc.: 92%] [G loss: 2.228846]\n",
            "600 [ D loss: 0.359342, acc.: 95%] [G loss: 3.040156]\n",
            "601 [ D loss: 0.345436, acc.: 94%] [G loss: 2.612766]\n",
            "602 [ D loss: 0.394589, acc.: 93%] [G loss: 2.240024]\n",
            "603 [ D loss: 0.405924, acc.: 90%] [G loss: 2.128373]\n",
            "604 [ D loss: 0.418638, acc.: 88%] [G loss: 2.469395]\n",
            "605 [ D loss: 0.401487, acc.: 86%] [G loss: 2.984698]\n",
            "606 [ D loss: 0.389476, acc.: 90%] [G loss: 2.888834]\n",
            "607 [ D loss: 0.397087, acc.: 91%] [G loss: 2.049606]\n",
            "608 [ D loss: 0.419138, acc.: 92%] [G loss: 2.157941]\n",
            "609 [ D loss: 0.343700, acc.: 95%] [G loss: 2.849162]\n",
            "610 [ D loss: 0.352067, acc.: 91%] [G loss: 2.550119]\n",
            "611 [ D loss: 0.397914, acc.: 89%] [G loss: 2.696083]\n",
            "612 [ D loss: 0.390132, acc.: 88%] [G loss: 2.435647]\n",
            "613 [ D loss: 0.383431, acc.: 90%] [G loss: 2.242548]\n",
            "614 [ D loss: 0.362981, acc.: 92%] [G loss: 2.513771]\n",
            "615 [ D loss: 0.386432, acc.: 88%] [G loss: 2.830639]\n",
            "616 [ D loss: 0.320021, acc.: 95%] [G loss: 2.754009]\n",
            "617 [ D loss: 0.429134, acc.: 88%] [G loss: 2.230513]\n",
            "618 [ D loss: 0.347927, acc.: 96%] [G loss: 2.653697]\n",
            "619 [ D loss: 0.398282, acc.: 91%] [G loss: 2.535411]\n",
            "620 [ D loss: 0.341844, acc.: 95%] [G loss: 2.711119]\n",
            "621 [ D loss: 0.415867, acc.: 87%] [G loss: 2.293230]\n",
            "622 [ D loss: 0.416071, acc.: 91%] [G loss: 2.482963]\n",
            "623 [ D loss: 0.377264, acc.: 93%] [G loss: 2.517537]\n",
            "624 [ D loss: 0.361931, acc.: 93%] [G loss: 2.782741]\n",
            "625 [ D loss: 0.402341, acc.: 90%] [G loss: 2.240497]\n",
            "626 [ D loss: 0.353717, acc.: 93%] [G loss: 2.915089]\n",
            "627 [ D loss: 0.341506, acc.: 91%] [G loss: 2.839196]\n",
            "628 [ D loss: 0.412543, acc.: 91%] [G loss: 2.283445]\n",
            "629 [ D loss: 0.328664, acc.: 95%] [G loss: 2.906000]\n",
            "630 [ D loss: 0.344051, acc.: 93%] [G loss: 3.303576]\n",
            "631 [ D loss: 0.317306, acc.: 91%] [G loss: 3.095422]\n",
            "632 [ D loss: 0.428293, acc.: 86%] [G loss: 2.302513]\n",
            "633 [ D loss: 0.347429, acc.: 94%] [G loss: 2.876455]\n",
            "634 [ D loss: 0.316218, acc.: 96%] [G loss: 2.833596]\n",
            "635 [ D loss: 0.396695, acc.: 88%] [G loss: 2.388482]\n",
            "636 [ D loss: 0.428009, acc.: 86%] [G loss: 2.341517]\n",
            "637 [ D loss: 0.364424, acc.: 95%] [G loss: 2.978563]\n",
            "638 [ D loss: 0.354608, acc.: 89%] [G loss: 3.339303]\n",
            "639 [ D loss: 0.361733, acc.: 94%] [G loss: 2.528199]\n",
            "640 [ D loss: 0.470326, acc.: 83%] [G loss: 1.913168]\n",
            "641 [ D loss: 0.358427, acc.: 91%] [G loss: 2.952944]\n",
            "642 [ D loss: 0.391237, acc.: 88%] [G loss: 3.333617]\n",
            "643 [ D loss: 0.440019, acc.: 81%] [G loss: 2.629271]\n",
            "644 [ D loss: 0.359758, acc.: 94%] [G loss: 3.123446]\n",
            "645 [ D loss: 0.338371, acc.: 94%] [G loss: 2.934403]\n",
            "646 [ D loss: 0.352761, acc.: 95%] [G loss: 2.673465]\n",
            "647 [ D loss: 0.348678, acc.: 91%] [G loss: 3.535129]\n",
            "648 [ D loss: 0.401675, acc.: 92%] [G loss: 2.337432]\n",
            "649 [ D loss: 0.369845, acc.: 94%] [G loss: 2.589635]\n",
            "650 [ D loss: 0.283666, acc.: 98%] [G loss: 4.164768]\n",
            "651 [ D loss: 0.302904, acc.: 97%] [G loss: 2.648798]\n",
            "652 [ D loss: 0.430277, acc.: 84%] [G loss: 2.159305]\n",
            "653 [ D loss: 0.374381, acc.: 93%] [G loss: 2.617589]\n",
            "654 [ D loss: 0.332482, acc.: 94%] [G loss: 3.154247]\n",
            "655 [ D loss: 0.338609, acc.: 91%] [G loss: 3.433404]\n",
            "656 [ D loss: 0.297505, acc.: 95%] [G loss: 3.268037]\n",
            "657 [ D loss: 0.403001, acc.: 88%] [G loss: 2.160373]\n",
            "658 [ D loss: 0.366875, acc.: 92%] [G loss: 2.458328]\n",
            "659 [ D loss: 0.323877, acc.: 95%] [G loss: 2.783506]\n",
            "660 [ D loss: 0.306673, acc.: 96%] [G loss: 2.994364]\n",
            "661 [ D loss: 0.394856, acc.: 90%] [G loss: 2.654738]\n",
            "662 [ D loss: 0.274225, acc.: 96%] [G loss: 3.554260]\n",
            "663 [ D loss: 0.325566, acc.: 92%] [G loss: 3.173559]\n",
            "664 [ D loss: 0.310657, acc.: 93%] [G loss: 3.634969]\n",
            "665 [ D loss: 0.268944, acc.: 97%] [G loss: 3.016848]\n",
            "666 [ D loss: 0.404257, acc.: 83%] [G loss: 2.335350]\n",
            "667 [ D loss: 0.298221, acc.: 99%] [G loss: 3.125767]\n",
            "668 [ D loss: 0.300496, acc.: 97%] [G loss: 3.126744]\n",
            "669 [ D loss: 0.324280, acc.: 93%] [G loss: 3.293582]\n",
            "670 [ D loss: 0.323322, acc.: 97%] [G loss: 2.300957]\n",
            "671 [ D loss: 0.291243, acc.: 98%] [G loss: 2.976715]\n",
            "672 [ D loss: 0.292903, acc.: 96%] [G loss: 3.593991]\n",
            "673 [ D loss: 0.383174, acc.: 89%] [G loss: 3.827631]\n",
            "674 [ D loss: 0.354666, acc.: 91%] [G loss: 2.499625]\n",
            "675 [ D loss: 0.376252, acc.: 93%] [G loss: 2.589189]\n",
            "676 [ D loss: 0.319346, acc.: 95%] [G loss: 3.643306]\n",
            "677 [ D loss: 0.291985, acc.: 97%] [G loss: 4.143276]\n",
            "678 [ D loss: 0.367686, acc.: 88%] [G loss: 2.674443]\n",
            "679 [ D loss: 0.346519, acc.: 91%] [G loss: 2.786967]\n",
            "680 [ D loss: 0.365614, acc.: 89%] [G loss: 2.775156]\n",
            "681 [ D loss: 0.338030, acc.: 96%] [G loss: 3.086017]\n",
            "682 [ D loss: 0.253310, acc.: 98%] [G loss: 3.734893]\n",
            "683 [ D loss: 0.318185, acc.: 94%] [G loss: 2.952693]\n",
            "684 [ D loss: 0.396178, acc.: 83%] [G loss: 3.568480]\n",
            "685 [ D loss: 0.282887, acc.: 98%] [G loss: 3.098480]\n",
            "686 [ D loss: 0.323294, acc.: 95%] [G loss: 2.760828]\n",
            "687 [ D loss: 0.260299, acc.: 99%] [G loss: 2.832777]\n",
            "688 [ D loss: 0.287692, acc.: 95%] [G loss: 3.075655]\n",
            "689 [ D loss: 0.434028, acc.: 80%] [G loss: 2.840801]\n",
            "690 [ D loss: 0.289057, acc.: 97%] [G loss: 3.255523]\n",
            "691 [ D loss: 0.313319, acc.: 95%] [G loss: 3.495097]\n",
            "692 [ D loss: 0.260874, acc.: 97%] [G loss: 2.699209]\n",
            "693 [ D loss: 0.402475, acc.: 87%] [G loss: 2.218390]\n",
            "694 [ D loss: 0.294134, acc.: 97%] [G loss: 2.859767]\n",
            "695 [ D loss: 0.231847, acc.: 96%] [G loss: 4.735173]\n",
            "696 [ D loss: 0.355029, acc.: 91%] [G loss: 3.588053]\n",
            "697 [ D loss: 0.316989, acc.: 92%] [G loss: 3.233684]\n",
            "698 [ D loss: 0.298308, acc.: 95%] [G loss: 3.227722]\n",
            "699 [ D loss: 0.265094, acc.: 98%] [G loss: 3.485883]\n",
            "700 [ D loss: 0.302200, acc.: 92%] [G loss: 3.299074]\n",
            "701 [ D loss: 0.303314, acc.: 93%] [G loss: 2.920925]\n",
            "702 [ D loss: 0.339409, acc.: 91%] [G loss: 2.966013]\n",
            "703 [ D loss: 0.266752, acc.: 96%] [G loss: 3.404812]\n",
            "704 [ D loss: 0.333033, acc.: 92%] [G loss: 3.328524]\n",
            "705 [ D loss: 0.289620, acc.: 97%] [G loss: 3.209337]\n",
            "706 [ D loss: 0.297887, acc.: 96%] [G loss: 2.706261]\n",
            "707 [ D loss: 0.263528, acc.: 98%] [G loss: 2.918876]\n",
            "708 [ D loss: 0.312438, acc.: 92%] [G loss: 2.920201]\n",
            "709 [ D loss: 0.287698, acc.: 92%] [G loss: 3.991677]\n",
            "710 [ D loss: 0.413827, acc.: 82%] [G loss: 2.949436]\n",
            "711 [ D loss: 0.267254, acc.: 97%] [G loss: 4.276827]\n",
            "712 [ D loss: 0.297887, acc.: 92%] [G loss: 3.548125]\n",
            "713 [ D loss: 0.318663, acc.: 92%] [G loss: 3.040487]\n",
            "714 [ D loss: 0.341852, acc.: 91%] [G loss: 3.256824]\n",
            "715 [ D loss: 0.287948, acc.: 97%] [G loss: 3.462700]\n",
            "716 [ D loss: 0.235660, acc.: 99%] [G loss: 3.825201]\n",
            "717 [ D loss: 0.244706, acc.: 97%] [G loss: 3.005218]\n",
            "718 [ D loss: 0.274193, acc.: 93%] [G loss: 2.995669]\n",
            "719 [ D loss: 0.367692, acc.: 88%] [G loss: 3.069658]\n",
            "720 [ D loss: 0.297825, acc.: 93%] [G loss: 4.067795]\n",
            "721 [ D loss: 0.263883, acc.: 96%] [G loss: 4.230477]\n",
            "722 [ D loss: 0.366989, acc.: 91%] [G loss: 2.823759]\n",
            "723 [ D loss: 0.238755, acc.: 98%] [G loss: 3.999435]\n",
            "724 [ D loss: 0.282402, acc.: 97%] [G loss: 2.954174]\n",
            "725 [ D loss: 0.313623, acc.: 93%] [G loss: 2.902330]\n",
            "726 [ D loss: 0.254689, acc.: 96%] [G loss: 3.832218]\n",
            "727 [ D loss: 0.298108, acc.: 95%] [G loss: 2.708007]\n",
            "728 [ D loss: 0.340002, acc.: 91%] [G loss: 2.851858]\n",
            "729 [ D loss: 0.260431, acc.: 97%] [G loss: 3.738440]\n",
            "730 [ D loss: 0.271138, acc.: 95%] [G loss: 3.946239]\n",
            "731 [ D loss: 0.408214, acc.: 82%] [G loss: 2.930216]\n",
            "732 [ D loss: 0.349325, acc.: 94%] [G loss: 2.939692]\n",
            "733 [ D loss: 0.307154, acc.: 95%] [G loss: 3.514284]\n",
            "734 [ D loss: 0.326966, acc.: 91%] [G loss: 3.501567]\n",
            "735 [ D loss: 0.279114, acc.: 95%] [G loss: 3.894650]\n",
            "736 [ D loss: 0.263252, acc.: 96%] [G loss: 3.308973]\n",
            "737 [ D loss: 0.283339, acc.: 92%] [G loss: 2.913271]\n",
            "738 [ D loss: 0.275842, acc.: 95%] [G loss: 3.875238]\n",
            "739 [ D loss: 0.308799, acc.: 90%] [G loss: 3.223237]\n",
            "740 [ D loss: 0.449855, acc.: 79%] [G loss: 2.782600]\n",
            "741 [ D loss: 0.417092, acc.: 87%] [G loss: 3.724066]\n",
            "742 [ D loss: 0.322495, acc.: 90%] [G loss: 4.013564]\n",
            "743 [ D loss: 0.335596, acc.: 95%] [G loss: 2.739476]\n",
            "744 [ D loss: 0.281457, acc.: 96%] [G loss: 2.634669]\n",
            "745 [ D loss: 0.335683, acc.: 89%] [G loss: 3.094316]\n",
            "746 [ D loss: 0.302566, acc.: 95%] [G loss: 3.698890]\n",
            "747 [ D loss: 0.303091, acc.: 97%] [G loss: 3.308142]\n",
            "748 [ D loss: 0.261245, acc.: 95%] [G loss: 3.535060]\n",
            "749 [ D loss: 0.298313, acc.: 96%] [G loss: 2.919059]\n",
            "750 [ D loss: 0.248307, acc.: 98%] [G loss: 3.137298]\n",
            "751 [ D loss: 0.439574, acc.: 78%] [G loss: 3.040296]\n",
            "752 [ D loss: 0.341885, acc.: 90%] [G loss: 3.273136]\n",
            "753 [ D loss: 0.288693, acc.: 97%] [G loss: 3.995012]\n",
            "754 [ D loss: 0.275899, acc.: 96%] [G loss: 3.940321]\n",
            "755 [ D loss: 0.255958, acc.: 95%] [G loss: 4.504264]\n",
            "756 [ D loss: 0.305757, acc.: 92%] [G loss: 3.567121]\n",
            "757 [ D loss: 0.293261, acc.: 92%] [G loss: 3.207932]\n",
            "758 [ D loss: 0.324076, acc.: 92%] [G loss: 3.148898]\n",
            "759 [ D loss: 0.344672, acc.: 92%] [G loss: 2.823025]\n",
            "760 [ D loss: 0.315830, acc.: 93%] [G loss: 3.471350]\n",
            "761 [ D loss: 0.297671, acc.: 95%] [G loss: 3.288989]\n",
            "762 [ D loss: 0.298035, acc.: 91%] [G loss: 3.439728]\n",
            "763 [ D loss: 0.242772, acc.: 95%] [G loss: 3.224955]\n",
            "764 [ D loss: 0.348619, acc.: 88%] [G loss: 3.756154]\n",
            "765 [ D loss: 0.298434, acc.: 92%] [G loss: 4.109838]\n",
            "766 [ D loss: 0.277846, acc.: 94%] [G loss: 4.059632]\n",
            "767 [ D loss: 0.518690, acc.: 75%] [G loss: 2.847793]\n",
            "768 [ D loss: 0.285155, acc.: 95%] [G loss: 3.643698]\n",
            "769 [ D loss: 0.246544, acc.: 98%] [G loss: 4.839849]\n",
            "770 [ D loss: 0.243694, acc.: 98%] [G loss: 2.979342]\n",
            "771 [ D loss: 0.517172, acc.: 74%] [G loss: 2.575228]\n",
            "772 [ D loss: 0.303430, acc.: 93%] [G loss: 3.619151]\n",
            "773 [ D loss: 0.391949, acc.: 83%] [G loss: 3.646110]\n",
            "774 [ D loss: 0.282905, acc.: 98%] [G loss: 3.216716]\n",
            "775 [ D loss: 0.258661, acc.: 98%] [G loss: 2.647528]\n",
            "776 [ D loss: 0.304308, acc.: 92%] [G loss: 3.324780]\n",
            "777 [ D loss: 0.227050, acc.: 98%] [G loss: 4.974289]\n",
            "778 [ D loss: 0.432362, acc.: 78%] [G loss: 3.080443]\n",
            "779 [ D loss: 0.405291, acc.: 82%] [G loss: 3.732282]\n",
            "780 [ D loss: 0.361803, acc.: 84%] [G loss: 4.849389]\n",
            "781 [ D loss: 0.265703, acc.: 94%] [G loss: 3.923386]\n",
            "782 [ D loss: 0.230187, acc.: 95%] [G loss: 4.184618]\n",
            "783 [ D loss: 0.413286, acc.: 83%] [G loss: 2.871634]\n",
            "784 [ D loss: 0.250006, acc.: 95%] [G loss: 6.069620]\n",
            "785 [ D loss: 0.501748, acc.: 74%] [G loss: 2.858518]\n",
            "786 [ D loss: 0.443290, acc.: 80%] [G loss: 3.380903]\n",
            "787 [ D loss: 0.417790, acc.: 80%] [G loss: 3.682747]\n",
            "788 [ D loss: 0.390164, acc.: 87%] [G loss: 2.388422]\n",
            "789 [ D loss: 0.211438, acc.: 98%] [G loss: 4.433785]\n",
            "790 [ D loss: 0.216918, acc.: 98%] [G loss: 5.094187]\n",
            "791 [ D loss: 0.228950, acc.: 100%] [G loss: 3.543580]\n",
            "792 [ D loss: 0.255417, acc.: 95%] [G loss: 4.183166]\n",
            "793 [ D loss: 0.307938, acc.: 89%] [G loss: 2.993049]\n",
            "794 [ D loss: 0.304813, acc.: 95%] [G loss: 3.753540]\n",
            "795 [ D loss: 0.202104, acc.: 98%] [G loss: 5.107811]\n",
            "796 [ D loss: 0.340472, acc.: 89%] [G loss: 3.255656]\n",
            "797 [ D loss: 0.405904, acc.: 80%] [G loss: 3.659157]\n",
            "798 [ D loss: 0.272144, acc.: 92%] [G loss: 3.660710]\n",
            "799 [ D loss: 0.239773, acc.: 97%] [G loss: 3.094132]\n",
            "800 [ D loss: 0.219796, acc.: 97%] [G loss: 3.379042]\n",
            "801 [ D loss: 0.264602, acc.: 97%] [G loss: 2.649143]\n",
            "802 [ D loss: 0.210763, acc.: 99%] [G loss: 3.897084]\n",
            "803 [ D loss: 0.228588, acc.: 98%] [G loss: 3.685124]\n",
            "804 [ D loss: 0.192641, acc.: 99%] [G loss: 3.643287]\n",
            "805 [ D loss: 0.350409, acc.: 82%] [G loss: 3.089495]\n",
            "806 [ D loss: 0.285582, acc.: 94%] [G loss: 3.197305]\n",
            "807 [ D loss: 0.303350, acc.: 94%] [G loss: 3.652732]\n",
            "808 [ D loss: 0.207681, acc.: 100%] [G loss: 3.764488]\n",
            "809 [ D loss: 0.267862, acc.: 94%] [G loss: 3.244676]\n",
            "810 [ D loss: 0.194186, acc.: 97%] [G loss: 3.851675]\n",
            "811 [ D loss: 0.329011, acc.: 86%] [G loss: 3.181241]\n",
            "812 [ D loss: 0.325107, acc.: 95%] [G loss: 3.212811]\n",
            "813 [ D loss: 0.256709, acc.: 98%] [G loss: 4.106647]\n",
            "814 [ D loss: 0.220458, acc.: 98%] [G loss: 3.428195]\n",
            "815 [ D loss: 0.269290, acc.: 93%] [G loss: 4.146257]\n",
            "816 [ D loss: 0.185811, acc.: 96%] [G loss: 5.792927]\n",
            "817 [ D loss: 0.581411, acc.: 73%] [G loss: 2.715340]\n",
            "818 [ D loss: 0.235527, acc.: 98%] [G loss: 3.964021]\n",
            "819 [ D loss: 0.201973, acc.: 100%] [G loss: 4.792873]\n",
            "820 [ D loss: 0.265670, acc.: 97%] [G loss: 3.676339]\n",
            "821 [ D loss: 0.316706, acc.: 85%] [G loss: 3.911996]\n",
            "822 [ D loss: 0.248331, acc.: 98%] [G loss: 3.856532]\n",
            "823 [ D loss: 0.188601, acc.: 100%] [G loss: 5.333253]\n",
            "824 [ D loss: 0.224623, acc.: 99%] [G loss: 3.017566]\n",
            "825 [ D loss: 0.353571, acc.: 87%] [G loss: 3.130963]\n",
            "826 [ D loss: 0.242630, acc.: 98%] [G loss: 4.606536]\n",
            "827 [ D loss: 0.204102, acc.: 98%] [G loss: 5.204264]\n",
            "828 [ D loss: 0.481555, acc.: 80%] [G loss: 3.096728]\n",
            "829 [ D loss: 0.232779, acc.: 97%] [G loss: 6.403480]\n",
            "830 [ D loss: 0.304331, acc.: 93%] [G loss: 3.585250]\n",
            "831 [ D loss: 0.256665, acc.: 95%] [G loss: 5.600754]\n",
            "832 [ D loss: 0.383658, acc.: 80%] [G loss: 3.760594]\n",
            "833 [ D loss: 0.190013, acc.: 97%] [G loss: 8.275985]\n",
            "834 [ D loss: 0.253384, acc.: 97%] [G loss: 3.997436]\n",
            "835 [ D loss: 0.226136, acc.: 93%] [G loss: 6.487491]\n",
            "836 [ D loss: 0.301705, acc.: 88%] [G loss: 4.500066]\n",
            "837 [ D loss: 0.216802, acc.: 96%] [G loss: 4.648520]\n",
            "838 [ D loss: 0.330347, acc.: 88%] [G loss: 4.737847]\n",
            "839 [ D loss: 0.296630, acc.: 91%] [G loss: 5.082560]\n",
            "840 [ D loss: 0.339292, acc.: 84%] [G loss: 3.713889]\n",
            "841 [ D loss: 0.262292, acc.: 93%] [G loss: 4.480789]\n",
            "842 [ D loss: 0.374947, acc.: 85%] [G loss: 4.179560]\n",
            "843 [ D loss: 0.240530, acc.: 95%] [G loss: 4.532137]\n",
            "844 [ D loss: 0.224475, acc.: 97%] [G loss: 3.915464]\n",
            "845 [ D loss: 0.180023, acc.: 97%] [G loss: 4.294464]\n",
            "846 [ D loss: 0.247471, acc.: 91%] [G loss: 3.821846]\n",
            "847 [ D loss: 0.194522, acc.: 96%] [G loss: 4.710527]\n",
            "848 [ D loss: 0.242665, acc.: 92%] [G loss: 4.999480]\n",
            "849 [ D loss: 0.495243, acc.: 75%] [G loss: 3.046730]\n",
            "850 [ D loss: 0.237391, acc.: 96%] [G loss: 5.669755]\n",
            "851 [ D loss: 0.220203, acc.: 96%] [G loss: 5.086291]\n",
            "852 [ D loss: 0.271448, acc.: 93%] [G loss: 3.471403]\n",
            "853 [ D loss: 0.226932, acc.: 97%] [G loss: 4.386648]\n",
            "854 [ D loss: 0.224726, acc.: 95%] [G loss: 4.875892]\n",
            "855 [ D loss: 0.356229, acc.: 84%] [G loss: 3.004321]\n",
            "856 [ D loss: 0.379131, acc.: 83%] [G loss: 3.575654]\n",
            "857 [ D loss: 0.272939, acc.: 91%] [G loss: 4.883634]\n",
            "858 [ D loss: 0.171204, acc.: 99%] [G loss: 5.597440]\n",
            "859 [ D loss: 0.344889, acc.: 82%] [G loss: 4.366091]\n",
            "860 [ D loss: 0.133696, acc.: 100%] [G loss: 7.957285]\n",
            "861 [ D loss: 0.198369, acc.: 96%] [G loss: 6.014938]\n",
            "862 [ D loss: 0.281332, acc.: 91%] [G loss: 3.974381]\n",
            "863 [ D loss: 0.256773, acc.: 94%] [G loss: 6.850366]\n",
            "864 [ D loss: 0.341834, acc.: 85%] [G loss: 4.787449]\n",
            "865 [ D loss: 0.171814, acc.: 98%] [G loss: 7.901885]\n",
            "866 [ D loss: 0.288759, acc.: 93%] [G loss: 4.148057]\n",
            "867 [ D loss: 0.170492, acc.: 99%] [G loss: 5.833196]\n",
            "868 [ D loss: 0.519398, acc.: 75%] [G loss: 3.150156]\n",
            "869 [ D loss: 0.179755, acc.: 100%] [G loss: 4.789157]\n",
            "870 [ D loss: 0.370407, acc.: 85%] [G loss: 5.150640]\n",
            "871 [ D loss: 0.217904, acc.: 98%] [G loss: 4.974760]\n",
            "872 [ D loss: 0.188347, acc.: 98%] [G loss: 3.634816]\n",
            "873 [ D loss: 0.303630, acc.: 88%] [G loss: 4.091233]\n",
            "874 [ D loss: 0.329691, acc.: 85%] [G loss: 4.208961]\n",
            "875 [ D loss: 0.200087, acc.: 97%] [G loss: 5.287852]\n",
            "876 [ D loss: 0.249512, acc.: 95%] [G loss: 3.506946]\n",
            "877 [ D loss: 0.177515, acc.: 98%] [G loss: 4.958181]\n",
            "878 [ D loss: 0.212980, acc.: 94%] [G loss: 3.828425]\n",
            "879 [ D loss: 0.394356, acc.: 81%] [G loss: 3.561554]\n",
            "880 [ D loss: 0.191855, acc.: 98%] [G loss: 4.962390]\n",
            "881 [ D loss: 0.202166, acc.: 99%] [G loss: 4.235747]\n",
            "882 [ D loss: 0.259016, acc.: 92%] [G loss: 3.724558]\n",
            "883 [ D loss: 0.177109, acc.: 98%] [G loss: 5.450663]\n",
            "884 [ D loss: 0.271227, acc.: 90%] [G loss: 5.167511]\n",
            "885 [ D loss: 0.271395, acc.: 91%] [G loss: 4.367895]\n",
            "886 [ D loss: 0.254876, acc.: 96%] [G loss: 3.610828]\n",
            "887 [ D loss: 0.189558, acc.: 97%] [G loss: 5.239360]\n",
            "888 [ D loss: 0.179300, acc.: 97%] [G loss: 5.127224]\n",
            "889 [ D loss: 0.355315, acc.: 86%] [G loss: 3.200637]\n",
            "890 [ D loss: 0.266777, acc.: 91%] [G loss: 4.431202]\n",
            "891 [ D loss: 0.246492, acc.: 94%] [G loss: 4.194578]\n",
            "892 [ D loss: 0.167401, acc.: 98%] [G loss: 4.980796]\n",
            "893 [ D loss: 0.391609, acc.: 78%] [G loss: 3.248008]\n",
            "894 [ D loss: 0.233286, acc.: 96%] [G loss: 4.189214]\n",
            "895 [ D loss: 0.210413, acc.: 97%] [G loss: 5.032441]\n",
            "896 [ D loss: 0.338571, acc.: 86%] [G loss: 4.702645]\n",
            "897 [ D loss: 0.333161, acc.: 88%] [G loss: 3.466648]\n",
            "898 [ D loss: 0.289295, acc.: 93%] [G loss: 4.949778]\n",
            "899 [ D loss: 0.245265, acc.: 97%] [G loss: 3.634244]\n",
            "900 [ D loss: 0.302084, acc.: 91%] [G loss: 4.099396]\n",
            "901 [ D loss: 0.202316, acc.: 98%] [G loss: 4.558479]\n",
            "902 [ D loss: 0.173192, acc.: 99%] [G loss: 6.373473]\n",
            "903 [ D loss: 0.749031, acc.: 62%] [G loss: 2.802659]\n",
            "904 [ D loss: 0.254050, acc.: 93%] [G loss: 5.727458]\n",
            "905 [ D loss: 0.220821, acc.: 98%] [G loss: 5.340765]\n",
            "906 [ D loss: 0.288404, acc.: 90%] [G loss: 3.423485]\n",
            "907 [ D loss: 0.369335, acc.: 83%] [G loss: 4.889710]\n",
            "908 [ D loss: 0.286287, acc.: 91%] [G loss: 5.232839]\n",
            "909 [ D loss: 0.211197, acc.: 97%] [G loss: 6.634254]\n",
            "910 [ D loss: 0.415850, acc.: 81%] [G loss: 4.476979]\n",
            "911 [ D loss: 0.277021, acc.: 91%] [G loss: 4.238775]\n",
            "912 [ D loss: 0.332450, acc.: 88%] [G loss: 3.617771]\n",
            "913 [ D loss: 0.223639, acc.: 97%] [G loss: 5.450073]\n",
            "914 [ D loss: 0.235553, acc.: 95%] [G loss: 4.035625]\n",
            "915 [ D loss: 0.235665, acc.: 91%] [G loss: 4.944815]\n",
            "916 [ D loss: 0.398669, acc.: 82%] [G loss: 3.269833]\n",
            "917 [ D loss: 0.289553, acc.: 90%] [G loss: 4.278743]\n",
            "918 [ D loss: 0.451664, acc.: 80%] [G loss: 3.916635]\n",
            "919 [ D loss: 0.188082, acc.: 99%] [G loss: 6.108735]\n",
            "920 [ D loss: 0.288584, acc.: 91%] [G loss: 4.055940]\n",
            "921 [ D loss: 0.248930, acc.: 91%] [G loss: 4.668046]\n",
            "922 [ D loss: 0.290865, acc.: 93%] [G loss: 3.197124]\n",
            "923 [ D loss: 0.157100, acc.: 98%] [G loss: 6.161607]\n",
            "924 [ D loss: 0.462780, acc.: 74%] [G loss: 4.330844]\n",
            "925 [ D loss: 0.304743, acc.: 86%] [G loss: 3.900333]\n",
            "926 [ D loss: 0.435696, acc.: 83%] [G loss: 3.512376]\n",
            "927 [ D loss: 0.193144, acc.: 98%] [G loss: 6.054609]\n",
            "928 [ D loss: 0.219163, acc.: 98%] [G loss: 3.779241]\n",
            "929 [ D loss: 0.228601, acc.: 93%] [G loss: 5.090139]\n",
            "930 [ D loss: 0.222713, acc.: 95%] [G loss: 3.578802]\n",
            "931 [ D loss: 0.366033, acc.: 84%] [G loss: 4.061270]\n",
            "932 [ D loss: 0.299426, acc.: 96%] [G loss: 3.204619]\n",
            "933 [ D loss: 0.182929, acc.: 98%] [G loss: 7.269192]\n",
            "934 [ D loss: 0.421765, acc.: 80%] [G loss: 4.856399]\n",
            "935 [ D loss: 0.190424, acc.: 98%] [G loss: 4.106491]\n",
            "936 [ D loss: 0.285887, acc.: 89%] [G loss: 5.792180]\n",
            "937 [ D loss: 0.348594, acc.: 84%] [G loss: 4.530758]\n",
            "938 [ D loss: 0.209764, acc.: 96%] [G loss: 5.098793]\n",
            "939 [ D loss: 0.188898, acc.: 96%] [G loss: 6.388099]\n",
            "940 [ D loss: 0.302508, acc.: 89%] [G loss: 4.047270]\n",
            "941 [ D loss: 0.308758, acc.: 87%] [G loss: 6.695782]\n",
            "942 [ D loss: 0.220598, acc.: 94%] [G loss: 6.221781]\n",
            "943 [ D loss: 0.440147, acc.: 81%] [G loss: 2.910954]\n",
            "944 [ D loss: 0.287044, acc.: 97%] [G loss: 3.824412]\n",
            "945 [ D loss: 0.217154, acc.: 95%] [G loss: 7.726996]\n",
            "946 [ D loss: 0.577517, acc.: 72%] [G loss: 2.766448]\n",
            "947 [ D loss: 0.186877, acc.: 98%] [G loss: 5.149230]\n",
            "948 [ D loss: 0.238868, acc.: 95%] [G loss: 4.667375]\n",
            "949 [ D loss: 0.628184, acc.: 66%] [G loss: 3.092719]\n",
            "950 [ D loss: 0.255062, acc.: 98%] [G loss: 4.453191]\n",
            "951 [ D loss: 0.139004, acc.: 99%] [G loss: 5.857394]\n",
            "952 [ D loss: 0.465262, acc.: 74%] [G loss: 3.518458]\n",
            "953 [ D loss: 0.310527, acc.: 91%] [G loss: 6.240928]\n",
            "954 [ D loss: 0.419436, acc.: 78%] [G loss: 4.286520]\n",
            "955 [ D loss: 0.209184, acc.: 95%] [G loss: 8.222047]\n",
            "956 [ D loss: 0.426166, acc.: 77%] [G loss: 5.819029]\n",
            "957 [ D loss: 0.293066, acc.: 87%] [G loss: 4.875694]\n",
            "958 [ D loss: 0.339003, acc.: 88%] [G loss: 4.465813]\n",
            "959 [ D loss: 0.168887, acc.: 100%] [G loss: 4.792197]\n",
            "960 [ D loss: 0.278267, acc.: 90%] [G loss: 5.289815]\n",
            "961 [ D loss: 0.321743, acc.: 89%] [G loss: 5.343855]\n",
            "962 [ D loss: 0.524456, acc.: 78%] [G loss: 4.376150]\n",
            "963 [ D loss: 0.384070, acc.: 84%] [G loss: 5.123464]\n",
            "964 [ D loss: 0.367667, acc.: 85%] [G loss: 3.691096]\n",
            "965 [ D loss: 0.377984, acc.: 88%] [G loss: 5.307189]\n",
            "966 [ D loss: 0.308904, acc.: 92%] [G loss: 4.450427]\n",
            "967 [ D loss: 0.300666, acc.: 89%] [G loss: 3.921235]\n",
            "968 [ D loss: 0.319736, acc.: 90%] [G loss: 4.037263]\n",
            "969 [ D loss: 0.200656, acc.: 98%] [G loss: 5.000735]\n",
            "970 [ D loss: 0.259987, acc.: 92%] [G loss: 6.883063]\n",
            "971 [ D loss: 0.271882, acc.: 91%] [G loss: 3.481444]\n",
            "972 [ D loss: 0.305810, acc.: 87%] [G loss: 4.720150]\n",
            "973 [ D loss: 0.447000, acc.: 80%] [G loss: 4.040190]\n",
            "974 [ D loss: 0.330374, acc.: 89%] [G loss: 4.579262]\n",
            "975 [ D loss: 0.641597, acc.: 69%] [G loss: 3.148642]\n",
            "976 [ D loss: 0.367443, acc.: 89%] [G loss: 3.456211]\n",
            "977 [ D loss: 0.199064, acc.: 99%] [G loss: 5.648340]\n",
            "978 [ D loss: 0.186399, acc.: 97%] [G loss: 4.995274]\n",
            "979 [ D loss: 0.334342, acc.: 85%] [G loss: 3.383589]\n",
            "980 [ D loss: 0.397830, acc.: 81%] [G loss: 4.205485]\n",
            "981 [ D loss: 0.280784, acc.: 93%] [G loss: 4.756427]\n",
            "982 [ D loss: 0.155161, acc.: 100%] [G loss: 6.118323]\n",
            "983 [ D loss: 0.443387, acc.: 82%] [G loss: 3.016816]\n",
            "984 [ D loss: 0.230248, acc.: 93%] [G loss: 5.882311]\n",
            "985 [ D loss: 0.226787, acc.: 95%] [G loss: 6.184243]\n",
            "986 [ D loss: 0.369715, acc.: 84%] [G loss: 3.262906]\n",
            "987 [ D loss: 0.409280, acc.: 80%] [G loss: 3.957445]\n",
            "988 [ D loss: 0.363221, acc.: 82%] [G loss: 5.185649]\n",
            "989 [ D loss: 0.264881, acc.: 94%] [G loss: 3.758026]\n",
            "990 [ D loss: 0.240729, acc.: 92%] [G loss: 5.025766]\n",
            "991 [ D loss: 0.169967, acc.: 98%] [G loss: 5.780920]\n",
            "992 [ D loss: 0.307802, acc.: 88%] [G loss: 3.674547]\n",
            "993 [ D loss: 0.231622, acc.: 95%] [G loss: 6.177644]\n",
            "994 [ D loss: 0.653315, acc.: 70%] [G loss: 3.286540]\n",
            "995 [ D loss: 0.326097, acc.: 88%] [G loss: 4.861733]\n",
            "996 [ D loss: 0.320881, acc.: 91%] [G loss: 4.898298]\n",
            "997 [ D loss: 0.202175, acc.: 97%] [G loss: 7.218486]\n",
            "998 [ D loss: 0.547021, acc.: 67%] [G loss: 2.906575]\n",
            "999 [ D loss: 0.157001, acc.: 99%] [G loss: 5.048798]\n",
            "1000 [ D loss: 0.451074, acc.: 79%] [G loss: 2.824606]\n",
            "1001 [ D loss: 0.312307, acc.: 86%] [G loss: 3.930206]\n",
            "1002 [ D loss: 0.213549, acc.: 100%] [G loss: 4.308908]\n",
            "1003 [ D loss: 0.142945, acc.: 99%] [G loss: 9.794624]\n",
            "1004 [ D loss: 0.358280, acc.: 85%] [G loss: 3.897436]\n",
            "1005 [ D loss: 0.130827, acc.: 99%] [G loss: 7.480769]\n",
            "1006 [ D loss: 0.213268, acc.: 93%] [G loss: 7.421566]\n",
            "1007 [ D loss: 0.573620, acc.: 72%] [G loss: 4.102407]\n",
            "1008 [ D loss: 0.198556, acc.: 94%] [G loss: 5.086891]\n",
            "1009 [ D loss: 0.250808, acc.: 92%] [G loss: 4.299902]\n",
            "1010 [ D loss: 0.255479, acc.: 89%] [G loss: 5.133621]\n",
            "1011 [ D loss: 0.362073, acc.: 82%] [G loss: 4.048127]\n",
            "1012 [ D loss: 0.378539, acc.: 80%] [G loss: 3.407147]\n",
            "1013 [ D loss: 0.461900, acc.: 77%] [G loss: 5.389050]\n",
            "1014 [ D loss: 0.189131, acc.: 100%] [G loss: 5.601062]\n",
            "1015 [ D loss: 0.186951, acc.: 98%] [G loss: 7.068774]\n",
            "1016 [ D loss: 0.522204, acc.: 74%] [G loss: 2.922773]\n",
            "1017 [ D loss: 0.219779, acc.: 95%] [G loss: 4.152846]\n",
            "1018 [ D loss: 0.197736, acc.: 96%] [G loss: 4.824760]\n",
            "1019 [ D loss: 0.327518, acc.: 84%] [G loss: 5.058211]\n",
            "1020 [ D loss: 0.356147, acc.: 86%] [G loss: 3.349051]\n",
            "1021 [ D loss: 0.530201, acc.: 73%] [G loss: 2.638256]\n",
            "1022 [ D loss: 0.277491, acc.: 91%] [G loss: 6.236141]\n",
            "1023 [ D loss: 0.208248, acc.: 95%] [G loss: 6.000103]\n",
            "1024 [ D loss: 0.166946, acc.: 97%] [G loss: 6.138110]\n",
            "1025 [ D loss: 0.521766, acc.: 73%] [G loss: 2.992362]\n",
            "1026 [ D loss: 0.258975, acc.: 96%] [G loss: 3.769384]\n",
            "1027 [ D loss: 0.196043, acc.: 98%] [G loss: 5.153607]\n",
            "1028 [ D loss: 0.214360, acc.: 95%] [G loss: 4.205968]\n",
            "1029 [ D loss: 0.741484, acc.: 67%] [G loss: 2.064938]\n",
            "1030 [ D loss: 0.274381, acc.: 93%] [G loss: 3.786510]\n",
            "1031 [ D loss: 0.333970, acc.: 91%] [G loss: 3.580491]\n",
            "1032 [ D loss: 0.172333, acc.: 98%] [G loss: 6.041112]\n",
            "1033 [ D loss: 0.182525, acc.: 98%] [G loss: 4.511801]\n",
            "1034 [ D loss: 0.337907, acc.: 86%] [G loss: 3.938263]\n",
            "1035 [ D loss: 0.526192, acc.: 69%] [G loss: 3.317441]\n",
            "1036 [ D loss: 0.294742, acc.: 93%] [G loss: 5.065267]\n",
            "1037 [ D loss: 0.329055, acc.: 91%] [G loss: 3.649484]\n",
            "1038 [ D loss: 0.279129, acc.: 96%] [G loss: 3.823861]\n",
            "1039 [ D loss: 0.167414, acc.: 100%] [G loss: 6.604586]\n",
            "1040 [ D loss: 0.243760, acc.: 93%] [G loss: 5.584498]\n",
            "1041 [ D loss: 0.167766, acc.: 96%] [G loss: 4.014746]\n",
            "1042 [ D loss: 0.795982, acc.: 62%] [G loss: 2.757435]\n",
            "1043 [ D loss: 0.286679, acc.: 88%] [G loss: 5.441298]\n",
            "1044 [ D loss: 0.209577, acc.: 95%] [G loss: 4.304078]\n",
            "1045 [ D loss: 0.202988, acc.: 95%] [G loss: 5.852048]\n",
            "1046 [ D loss: 0.310160, acc.: 87%] [G loss: 3.608003]\n",
            "1047 [ D loss: 0.457117, acc.: 77%] [G loss: 3.357346]\n",
            "1048 [ D loss: 0.441711, acc.: 74%] [G loss: 2.392165]\n",
            "1049 [ D loss: 0.298313, acc.: 92%] [G loss: 3.802960]\n",
            "1050 [ D loss: 0.211233, acc.: 97%] [G loss: 6.398506]\n",
            "1051 [ D loss: 0.342012, acc.: 88%] [G loss: 3.294248]\n",
            "1052 [ D loss: 0.347738, acc.: 83%] [G loss: 7.096121]\n",
            "1053 [ D loss: 0.266169, acc.: 90%] [G loss: 5.339840]\n",
            "1054 [ D loss: 0.372813, acc.: 84%] [G loss: 4.122599]\n",
            "1055 [ D loss: 0.432969, acc.: 79%] [G loss: 3.189154]\n",
            "1056 [ D loss: 0.364965, acc.: 84%] [G loss: 5.409483]\n",
            "1057 [ D loss: 0.453924, acc.: 77%] [G loss: 3.838300]\n",
            "1058 [ D loss: 0.262174, acc.: 91%] [G loss: 6.716058]\n",
            "1059 [ D loss: 0.215663, acc.: 96%] [G loss: 5.649702]\n",
            "1060 [ D loss: 0.367827, acc.: 84%] [G loss: 3.813837]\n",
            "1061 [ D loss: 0.322864, acc.: 87%] [G loss: 4.127870]\n",
            "1062 [ D loss: 0.302493, acc.: 91%] [G loss: 3.366051]\n",
            "1063 [ D loss: 0.514938, acc.: 76%] [G loss: 3.383849]\n",
            "1064 [ D loss: 0.665719, acc.: 67%] [G loss: 3.493822]\n",
            "1065 [ D loss: 0.470398, acc.: 82%] [G loss: 3.314441]\n",
            "1066 [ D loss: 0.225260, acc.: 94%] [G loss: 7.371459]\n",
            "1067 [ D loss: 0.533038, acc.: 73%] [G loss: 2.839691]\n",
            "1068 [ D loss: 0.278599, acc.: 89%] [G loss: 3.746250]\n",
            "1069 [ D loss: 0.185039, acc.: 97%] [G loss: 6.229887]\n",
            "1070 [ D loss: 0.181041, acc.: 98%] [G loss: 4.744862]\n",
            "1071 [ D loss: 0.165237, acc.: 96%] [G loss: 6.994295]\n",
            "1072 [ D loss: 0.337082, acc.: 84%] [G loss: 3.909328]\n",
            "1073 [ D loss: 0.175749, acc.: 98%] [G loss: 4.001114]\n",
            "1074 [ D loss: 0.404443, acc.: 79%] [G loss: 3.116068]\n",
            "1075 [ D loss: 0.500971, acc.: 75%] [G loss: 3.663847]\n",
            "1076 [ D loss: 0.403797, acc.: 80%] [G loss: 2.839129]\n",
            "1077 [ D loss: 0.413895, acc.: 81%] [G loss: 3.121955]\n",
            "1078 [ D loss: 0.375118, acc.: 90%] [G loss: 2.800465]\n",
            "1079 [ D loss: 0.212397, acc.: 98%] [G loss: 5.646938]\n",
            "1080 [ D loss: 0.166895, acc.: 98%] [G loss: 9.627833]\n",
            "1081 [ D loss: 0.372922, acc.: 84%] [G loss: 5.819255]\n",
            "1082 [ D loss: 0.128821, acc.: 98%] [G loss: 6.165085]\n",
            "1083 [ D loss: 0.488777, acc.: 75%] [G loss: 2.970550]\n",
            "1084 [ D loss: 0.656816, acc.: 68%] [G loss: 2.595165]\n",
            "1085 [ D loss: 0.326918, acc.: 88%] [G loss: 3.201731]\n",
            "1086 [ D loss: 0.244596, acc.: 94%] [G loss: 5.599683]\n",
            "1087 [ D loss: 0.190907, acc.: 96%] [G loss: 6.164929]\n",
            "1088 [ D loss: 0.228642, acc.: 93%] [G loss: 7.128720]\n",
            "1089 [ D loss: 0.451595, acc.: 77%] [G loss: 2.489328]\n",
            "1090 [ D loss: 0.571986, acc.: 66%] [G loss: 2.455367]\n",
            "1091 [ D loss: 0.275287, acc.: 92%] [G loss: 4.037379]\n",
            "1092 [ D loss: 0.166321, acc.: 98%] [G loss: 7.557685]\n",
            "1093 [ D loss: 0.314449, acc.: 87%] [G loss: 3.472143]\n",
            "1094 [ D loss: 0.261070, acc.: 90%] [G loss: 4.436789]\n",
            "1095 [ D loss: 0.386085, acc.: 80%] [G loss: 3.222616]\n",
            "1096 [ D loss: 0.193406, acc.: 96%] [G loss: 5.948723]\n",
            "1097 [ D loss: 0.179429, acc.: 97%] [G loss: 7.418715]\n",
            "1098 [ D loss: 0.254010, acc.: 94%] [G loss: 3.643775]\n",
            "1099 [ D loss: 0.244302, acc.: 92%] [G loss: 5.244786]\n",
            "1100 [ D loss: 0.216800, acc.: 95%] [G loss: 3.365449]\n",
            "1101 [ D loss: 0.210645, acc.: 93%] [G loss: 5.255157]\n",
            "1102 [ D loss: 0.472600, acc.: 75%] [G loss: 2.642441]\n",
            "1103 [ D loss: 0.497787, acc.: 79%] [G loss: 3.561337]\n",
            "1104 [ D loss: 0.417392, acc.: 80%] [G loss: 3.956062]\n",
            "1105 [ D loss: 0.334867, acc.: 85%] [G loss: 4.407721]\n",
            "1106 [ D loss: 0.163527, acc.: 98%] [G loss: 6.005726]\n",
            "1107 [ D loss: 0.191246, acc.: 98%] [G loss: 6.132554]\n",
            "1108 [ D loss: 0.416792, acc.: 81%] [G loss: 3.399657]\n",
            "1109 [ D loss: 0.161442, acc.: 96%] [G loss: 6.344914]\n",
            "1110 [ D loss: 0.498726, acc.: 76%] [G loss: 2.783510]\n",
            "1111 [ D loss: 0.565464, acc.: 68%] [G loss: 2.751181]\n",
            "1112 [ D loss: 0.336000, acc.: 89%] [G loss: 3.910718]\n",
            "1113 [ D loss: 0.259727, acc.: 95%] [G loss: 3.481730]\n",
            "1114 [ D loss: 0.322585, acc.: 91%] [G loss: 4.476012]\n",
            "1115 [ D loss: 0.176465, acc.: 96%] [G loss: 5.011955]\n",
            "1116 [ D loss: 0.288732, acc.: 90%] [G loss: 3.974215]\n",
            "1117 [ D loss: 0.329172, acc.: 87%] [G loss: 3.466795]\n",
            "1118 [ D loss: 0.206826, acc.: 98%] [G loss: 4.159006]\n",
            "1119 [ D loss: 0.185256, acc.: 98%] [G loss: 3.617306]\n",
            "1120 [ D loss: 0.653823, acc.: 64%] [G loss: 2.823880]\n",
            "1121 [ D loss: 0.466007, acc.: 77%] [G loss: 2.854846]\n",
            "1122 [ D loss: 0.471598, acc.: 75%] [G loss: 3.103353]\n",
            "1123 [ D loss: 0.195226, acc.: 97%] [G loss: 9.543273]\n",
            "1124 [ D loss: 0.623926, acc.: 63%] [G loss: 2.143609]\n",
            "1125 [ D loss: 0.260206, acc.: 90%] [G loss: 5.267324]\n",
            "1126 [ D loss: 0.174202, acc.: 95%] [G loss: 6.861382]\n",
            "1127 [ D loss: 0.401622, acc.: 77%] [G loss: 3.094460]\n",
            "1128 [ D loss: 0.403626, acc.: 80%] [G loss: 4.496363]\n",
            "1129 [ D loss: 0.431480, acc.: 80%] [G loss: 5.064514]\n",
            "1130 [ D loss: 0.221724, acc.: 95%] [G loss: 4.942349]\n",
            "1131 [ D loss: 0.263823, acc.: 93%] [G loss: 4.794422]\n",
            "1132 [ D loss: 0.773996, acc.: 61%] [G loss: 2.641215]\n",
            "1133 [ D loss: 0.206543, acc.: 95%] [G loss: 5.445166]\n",
            "1134 [ D loss: 0.299949, acc.: 89%] [G loss: 4.516381]\n",
            "1135 [ D loss: 0.547049, acc.: 73%] [G loss: 3.340779]\n",
            "1136 [ D loss: 0.596127, acc.: 70%] [G loss: 3.007364]\n",
            "1137 [ D loss: 0.426284, acc.: 78%] [G loss: 3.115563]\n",
            "1138 [ D loss: 0.390684, acc.: 86%] [G loss: 3.944650]\n",
            "1139 [ D loss: 0.219801, acc.: 94%] [G loss: 5.482183]\n",
            "1140 [ D loss: 0.235306, acc.: 94%] [G loss: 4.525333]\n",
            "1141 [ D loss: 0.331641, acc.: 88%] [G loss: 4.894305]\n",
            "1142 [ D loss: 0.449218, acc.: 80%] [G loss: 3.580193]\n",
            "1143 [ D loss: 0.454458, acc.: 79%] [G loss: 3.573490]\n",
            "1144 [ D loss: 0.272948, acc.: 92%] [G loss: 3.766432]\n",
            "1145 [ D loss: 0.324200, acc.: 86%] [G loss: 5.675368]\n",
            "1146 [ D loss: 0.252448, acc.: 93%] [G loss: 4.352403]\n",
            "1147 [ D loss: 0.229665, acc.: 95%] [G loss: 6.460352]\n",
            "1148 [ D loss: 0.544102, acc.: 75%] [G loss: 3.347046]\n",
            "1149 [ D loss: 0.300939, acc.: 88%] [G loss: 6.120878]\n",
            "1150 [ D loss: 0.576581, acc.: 69%] [G loss: 2.954927]\n",
            "1151 [ D loss: 0.315418, acc.: 87%] [G loss: 4.155754]\n",
            "1152 [ D loss: 0.262438, acc.: 96%] [G loss: 4.485451]\n",
            "1153 [ D loss: 0.198032, acc.: 95%] [G loss: 6.004836]\n",
            "1154 [ D loss: 0.198273, acc.: 93%] [G loss: 5.130391]\n",
            "1155 [ D loss: 0.499311, acc.: 71%] [G loss: 2.931131]\n",
            "1156 [ D loss: 0.358795, acc.: 83%] [G loss: 3.751724]\n",
            "1157 [ D loss: 0.307130, acc.: 89%] [G loss: 4.009816]\n",
            "1158 [ D loss: 0.214677, acc.: 95%] [G loss: 8.015699]\n",
            "1159 [ D loss: 0.449665, acc.: 77%] [G loss: 4.934363]\n",
            "1160 [ D loss: 0.557668, acc.: 71%] [G loss: 3.906126]\n",
            "1161 [ D loss: 0.528025, acc.: 70%] [G loss: 2.677816]\n",
            "1162 [ D loss: 0.466970, acc.: 77%] [G loss: 3.182684]\n",
            "1163 [ D loss: 0.248819, acc.: 95%] [G loss: 3.653767]\n",
            "1164 [ D loss: 0.246902, acc.: 93%] [G loss: 5.085456]\n",
            "1165 [ D loss: 0.150153, acc.: 99%] [G loss: 7.976920]\n",
            "1166 [ D loss: 0.300000, acc.: 91%] [G loss: 3.973220]\n",
            "1167 [ D loss: 0.448118, acc.: 77%] [G loss: 2.512123]\n",
            "1168 [ D loss: 0.267318, acc.: 93%] [G loss: 3.055083]\n",
            "1169 [ D loss: 0.221121, acc.: 94%] [G loss: 4.700167]\n",
            "1170 [ D loss: 0.271798, acc.: 93%] [G loss: 2.572455]\n",
            "1171 [ D loss: 0.360469, acc.: 84%] [G loss: 4.690926]\n",
            "1172 [ D loss: 0.471659, acc.: 77%] [G loss: 2.346782]\n",
            "1173 [ D loss: 0.358980, acc.: 85%] [G loss: 2.837525]\n",
            "1174 [ D loss: 0.186964, acc.: 98%] [G loss: 5.408969]\n",
            "1175 [ D loss: 0.174580, acc.: 96%] [G loss: 6.794138]\n",
            "1176 [ D loss: 0.436492, acc.: 77%] [G loss: 2.681329]\n",
            "1177 [ D loss: 0.446185, acc.: 73%] [G loss: 2.466105]\n",
            "1178 [ D loss: 0.285954, acc.: 91%] [G loss: 4.547517]\n",
            "1179 [ D loss: 0.320720, acc.: 89%] [G loss: 4.601928]\n",
            "1180 [ D loss: 0.407858, acc.: 77%] [G loss: 4.914304]\n",
            "1181 [ D loss: 0.427055, acc.: 79%] [G loss: 3.614865]\n",
            "1182 [ D loss: 0.318400, acc.: 88%] [G loss: 3.963478]\n",
            "1183 [ D loss: 0.586302, acc.: 69%] [G loss: 2.654273]\n",
            "1184 [ D loss: 0.481723, acc.: 74%] [G loss: 3.200242]\n",
            "1185 [ D loss: 0.210454, acc.: 96%] [G loss: 7.813796]\n",
            "1186 [ D loss: 0.194504, acc.: 96%] [G loss: 7.196372]\n",
            "1187 [ D loss: 0.363545, acc.: 83%] [G loss: 2.698831]\n",
            "1188 [ D loss: 0.269935, acc.: 92%] [G loss: 3.073147]\n",
            "1189 [ D loss: 0.160121, acc.: 98%] [G loss: 5.461841]\n",
            "1190 [ D loss: 0.512268, acc.: 70%] [G loss: 2.426183]\n",
            "1191 [ D loss: 0.770787, acc.: 57%] [G loss: 2.060668]\n",
            "1192 [ D loss: 0.633708, acc.: 66%] [G loss: 2.735840]\n",
            "1193 [ D loss: 0.343660, acc.: 91%] [G loss: 3.435900]\n",
            "1194 [ D loss: 0.259125, acc.: 92%] [G loss: 6.328198]\n",
            "1195 [ D loss: 0.540108, acc.: 73%] [G loss: 2.668341]\n",
            "1196 [ D loss: 0.198696, acc.: 95%] [G loss: 4.940796]\n",
            "1197 [ D loss: 0.308421, acc.: 90%] [G loss: 4.813628]\n",
            "1198 [ D loss: 0.146537, acc.: 98%] [G loss: 6.390276]\n",
            "1199 [ D loss: 0.376743, acc.: 83%] [G loss: 3.217646]\n",
            "1200 [ D loss: 0.229962, acc.: 93%] [G loss: 4.383992]\n",
            "1201 [ D loss: 0.244854, acc.: 92%] [G loss: 4.545375]\n",
            "1202 [ D loss: 0.558919, acc.: 70%] [G loss: 2.554504]\n",
            "1203 [ D loss: 0.496008, acc.: 73%] [G loss: 3.424120]\n",
            "1204 [ D loss: 0.530231, acc.: 65%] [G loss: 2.539067]\n",
            "1205 [ D loss: 0.446429, acc.: 77%] [G loss: 4.459620]\n",
            "1206 [ D loss: 0.373565, acc.: 88%] [G loss: 2.943132]\n",
            "1207 [ D loss: 0.262209, acc.: 92%] [G loss: 5.145744]\n",
            "1208 [ D loss: 0.368347, acc.: 84%] [G loss: 4.260714]\n",
            "1209 [ D loss: 0.406239, acc.: 81%] [G loss: 2.720430]\n",
            "1210 [ D loss: 0.212853, acc.: 96%] [G loss: 6.944734]\n",
            "1211 [ D loss: 0.293732, acc.: 90%] [G loss: 3.412181]\n",
            "1212 [ D loss: 0.363362, acc.: 85%] [G loss: 3.638404]\n",
            "1213 [ D loss: 0.427695, acc.: 78%] [G loss: 1.996709]\n",
            "1214 [ D loss: 0.261027, acc.: 91%] [G loss: 3.951558]\n",
            "1215 [ D loss: 0.240551, acc.: 97%] [G loss: 3.348958]\n",
            "1216 [ D loss: 0.173091, acc.: 98%] [G loss: 4.526243]\n",
            "1217 [ D loss: 0.260548, acc.: 91%] [G loss: 3.249429]\n",
            "1218 [ D loss: 0.449754, acc.: 77%] [G loss: 2.390988]\n",
            "1219 [ D loss: 0.400622, acc.: 80%] [G loss: 3.242721]\n",
            "1220 [ D loss: 0.367724, acc.: 87%] [G loss: 2.627217]\n",
            "1221 [ D loss: 0.217412, acc.: 93%] [G loss: 6.284585]\n",
            "1222 [ D loss: 0.666891, acc.: 60%] [G loss: 1.665001]\n",
            "1223 [ D loss: 0.230414, acc.: 94%] [G loss: 5.285495]\n",
            "1224 [ D loss: 0.222792, acc.: 94%] [G loss: 4.424902]\n",
            "1225 [ D loss: 0.532925, acc.: 68%] [G loss: 3.831368]\n",
            "1226 [ D loss: 0.337913, acc.: 85%] [G loss: 3.902767]\n",
            "1227 [ D loss: 0.207604, acc.: 95%] [G loss: 4.098286]\n",
            "1228 [ D loss: 0.432223, acc.: 79%] [G loss: 3.674367]\n",
            "1229 [ D loss: 0.299860, acc.: 88%] [G loss: 3.302801]\n",
            "1230 [ D loss: 0.193456, acc.: 97%] [G loss: 4.773121]\n",
            "1231 [ D loss: 0.325564, acc.: 87%] [G loss: 3.560698]\n",
            "1232 [ D loss: 0.213695, acc.: 94%] [G loss: 4.241200]\n",
            "1233 [ D loss: 0.499895, acc.: 72%] [G loss: 2.766347]\n",
            "1234 [ D loss: 0.521649, acc.: 71%] [G loss: 2.628296]\n",
            "1235 [ D loss: 0.366991, acc.: 84%] [G loss: 3.363809]\n",
            "1236 [ D loss: 0.223139, acc.: 94%] [G loss: 4.979495]\n",
            "1237 [ D loss: 0.208049, acc.: 95%] [G loss: 4.847213]\n",
            "1238 [ D loss: 0.433079, acc.: 77%] [G loss: 3.422163]\n",
            "1239 [ D loss: 0.375721, acc.: 83%] [G loss: 3.053292]\n",
            "1240 [ D loss: 0.220939, acc.: 94%] [G loss: 3.640229]\n",
            "1241 [ D loss: 0.384490, acc.: 82%] [G loss: 3.443291]\n",
            "1242 [ D loss: 0.586596, acc.: 70%] [G loss: 2.836638]\n",
            "1243 [ D loss: 0.558630, acc.: 68%] [G loss: 2.716674]\n",
            "1244 [ D loss: 0.496695, acc.: 74%] [G loss: 2.876276]\n",
            "1245 [ D loss: 0.306699, acc.: 92%] [G loss: 4.165654]\n",
            "1246 [ D loss: 0.194151, acc.: 96%] [G loss: 8.506107]\n",
            "1247 [ D loss: 0.520113, acc.: 68%] [G loss: 2.457826]\n",
            "1248 [ D loss: 0.564235, acc.: 62%] [G loss: 1.901242]\n",
            "1249 [ D loss: 0.389300, acc.: 83%] [G loss: 2.354907]\n",
            "1250 [ D loss: 0.353990, acc.: 87%] [G loss: 3.571745]\n",
            "1251 [ D loss: 0.230342, acc.: 95%] [G loss: 5.595670]\n",
            "1252 [ D loss: 0.246747, acc.: 96%] [G loss: 3.196709]\n",
            "1253 [ D loss: 0.274322, acc.: 90%] [G loss: 3.121150]\n",
            "1254 [ D loss: 0.512990, acc.: 70%] [G loss: 2.220093]\n",
            "1255 [ D loss: 0.670687, acc.: 61%] [G loss: 1.659754]\n",
            "1256 [ D loss: 0.563436, acc.: 70%] [G loss: 2.371554]\n",
            "1257 [ D loss: 0.447075, acc.: 80%] [G loss: 3.748249]\n",
            "1258 [ D loss: 0.235910, acc.: 93%] [G loss: 6.621855]\n",
            "1259 [ D loss: 0.297185, acc.: 88%] [G loss: 4.235075]\n",
            "1260 [ D loss: 0.505284, acc.: 74%] [G loss: 4.260052]\n",
            "1261 [ D loss: 0.536436, acc.: 70%] [G loss: 2.808524]\n",
            "1262 [ D loss: 0.229153, acc.: 96%] [G loss: 5.247772]\n",
            "1263 [ D loss: 0.218835, acc.: 96%] [G loss: 4.242965]\n",
            "1264 [ D loss: 0.498394, acc.: 73%] [G loss: 2.832965]\n",
            "1265 [ D loss: 0.281384, acc.: 93%] [G loss: 3.602366]\n",
            "1266 [ D loss: 0.283032, acc.: 90%] [G loss: 5.229669]\n",
            "1267 [ D loss: 0.411388, acc.: 82%] [G loss: 2.491477]\n",
            "1268 [ D loss: 0.576306, acc.: 66%] [G loss: 2.057415]\n",
            "1269 [ D loss: 0.423278, acc.: 79%] [G loss: 2.564772]\n",
            "1270 [ D loss: 0.303723, acc.: 91%] [G loss: 2.965728]\n",
            "1271 [ D loss: 0.377745, acc.: 84%] [G loss: 3.426569]\n",
            "1272 [ D loss: 0.299287, acc.: 89%] [G loss: 4.083031]\n",
            "1273 [ D loss: 0.350887, acc.: 86%] [G loss: 3.076844]\n",
            "1274 [ D loss: 0.439572, acc.: 75%] [G loss: 2.715656]\n",
            "1275 [ D loss: 0.442410, acc.: 77%] [G loss: 2.546409]\n",
            "1276 [ D loss: 0.417415, acc.: 84%] [G loss: 2.571560]\n",
            "1277 [ D loss: 0.438660, acc.: 75%] [G loss: 2.731026]\n",
            "1278 [ D loss: 0.446329, acc.: 76%] [G loss: 2.494604]\n",
            "1279 [ D loss: 0.267437, acc.: 92%] [G loss: 3.701710]\n",
            "1280 [ D loss: 0.404345, acc.: 80%] [G loss: 2.819295]\n",
            "1281 [ D loss: 0.468983, acc.: 77%] [G loss: 2.510918]\n",
            "1282 [ D loss: 0.494235, acc.: 73%] [G loss: 3.130842]\n",
            "1283 [ D loss: 0.640459, acc.: 65%] [G loss: 2.077275]\n",
            "1284 [ D loss: 0.328961, acc.: 91%] [G loss: 3.056863]\n",
            "1285 [ D loss: 0.234799, acc.: 92%] [G loss: 7.721733]\n",
            "1286 [ D loss: 0.540699, acc.: 68%] [G loss: 2.460785]\n",
            "1287 [ D loss: 0.143950, acc.: 99%] [G loss: 6.052884]\n",
            "1288 [ D loss: 0.376355, acc.: 85%] [G loss: 3.206147]\n",
            "1289 [ D loss: 0.188763, acc.: 95%] [G loss: 4.149718]\n",
            "1290 [ D loss: 0.600968, acc.: 61%] [G loss: 2.860255]\n",
            "1291 [ D loss: 0.191157, acc.: 95%] [G loss: 6.206290]\n",
            "1292 [ D loss: 0.488872, acc.: 72%] [G loss: 4.661457]\n",
            "1293 [ D loss: 0.575538, acc.: 67%] [G loss: 2.898121]\n",
            "1294 [ D loss: 0.577216, acc.: 66%] [G loss: 3.013355]\n",
            "1295 [ D loss: 0.444878, acc.: 79%] [G loss: 3.803822]\n",
            "1296 [ D loss: 0.459067, acc.: 73%] [G loss: 2.916166]\n",
            "1297 [ D loss: 0.542411, acc.: 71%] [G loss: 2.712988]\n",
            "1298 [ D loss: 0.513875, acc.: 71%] [G loss: 2.872708]\n",
            "1299 [ D loss: 0.367372, acc.: 84%] [G loss: 3.204247]\n",
            "1300 [ D loss: 0.361429, acc.: 87%] [G loss: 3.418103]\n",
            "1301 [ D loss: 0.265780, acc.: 93%] [G loss: 3.222898]\n",
            "1302 [ D loss: 0.461589, acc.: 77%] [G loss: 2.779088]\n",
            "1303 [ D loss: 0.501301, acc.: 73%] [G loss: 3.048395]\n",
            "1304 [ D loss: 0.235233, acc.: 94%] [G loss: 3.457962]\n",
            "1305 [ D loss: 0.321205, acc.: 90%] [G loss: 2.639032]\n",
            "1306 [ D loss: 0.448988, acc.: 77%] [G loss: 2.460608]\n",
            "1307 [ D loss: 0.504604, acc.: 72%] [G loss: 1.951609]\n",
            "1308 [ D loss: 0.646988, acc.: 57%] [G loss: 2.003465]\n",
            "1309 [ D loss: 0.328683, acc.: 91%] [G loss: 3.215185]\n",
            "1310 [ D loss: 0.284698, acc.: 95%] [G loss: 3.492442]\n",
            "1311 [ D loss: 0.639912, acc.: 62%] [G loss: 2.932993]\n",
            "1312 [ D loss: 0.250283, acc.: 93%] [G loss: 4.341583]\n",
            "1313 [ D loss: 0.315510, acc.: 87%] [G loss: 4.365911]\n",
            "1314 [ D loss: 0.590401, acc.: 66%] [G loss: 1.936499]\n",
            "1315 [ D loss: 0.487157, acc.: 74%] [G loss: 2.338351]\n",
            "1316 [ D loss: 0.679382, acc.: 57%] [G loss: 1.670862]\n",
            "1317 [ D loss: 0.348202, acc.: 91%] [G loss: 2.459103]\n",
            "1318 [ D loss: 0.459846, acc.: 82%] [G loss: 2.015749]\n",
            "1319 [ D loss: 0.425132, acc.: 80%] [G loss: 2.446468]\n",
            "1320 [ D loss: 0.519840, acc.: 70%] [G loss: 1.976264]\n",
            "1321 [ D loss: 0.659111, acc.: 56%] [G loss: 1.307643]\n",
            "1322 [ D loss: 0.570612, acc.: 65%] [G loss: 1.853946]\n",
            "1323 [ D loss: 0.387944, acc.: 87%] [G loss: 2.792847]\n",
            "1324 [ D loss: 0.351978, acc.: 88%] [G loss: 3.101510]\n",
            "1325 [ D loss: 0.390800, acc.: 83%] [G loss: 3.157660]\n",
            "1326 [ D loss: 0.257544, acc.: 94%] [G loss: 2.930153]\n",
            "1327 [ D loss: 0.452426, acc.: 80%] [G loss: 3.277642]\n",
            "1328 [ D loss: 0.286572, acc.: 93%] [G loss: 2.930036]\n",
            "1329 [ D loss: 0.251823, acc.: 96%] [G loss: 3.689238]\n",
            "1330 [ D loss: 0.466374, acc.: 75%] [G loss: 3.184425]\n",
            "1331 [ D loss: 0.289129, acc.: 91%] [G loss: 3.397072]\n",
            "1332 [ D loss: 0.381805, acc.: 88%] [G loss: 2.779289]\n",
            "1333 [ D loss: 0.414811, acc.: 83%] [G loss: 2.459715]\n",
            "1334 [ D loss: 0.501186, acc.: 71%] [G loss: 1.968807]\n",
            "1335 [ D loss: 0.588718, acc.: 63%] [G loss: 2.978424]\n",
            "1336 [ D loss: 0.487229, acc.: 72%] [G loss: 1.656747]\n",
            "1337 [ D loss: 0.521598, acc.: 67%] [G loss: 1.619094]\n",
            "1338 [ D loss: 0.703710, acc.: 55%] [G loss: 1.847111]\n",
            "1339 [ D loss: 0.453597, acc.: 81%] [G loss: 2.789035]\n",
            "1340 [ D loss: 0.319570, acc.: 86%] [G loss: 4.208946]\n",
            "1341 [ D loss: 0.341854, acc.: 90%] [G loss: 2.816678]\n",
            "1342 [ D loss: 0.425780, acc.: 76%] [G loss: 2.939488]\n",
            "1343 [ D loss: 0.349173, acc.: 86%] [G loss: 3.279460]\n",
            "1344 [ D loss: 0.215310, acc.: 93%] [G loss: 4.464803]\n",
            "1345 [ D loss: 0.385142, acc.: 83%] [G loss: 3.398653]\n",
            "1346 [ D loss: 0.234643, acc.: 95%] [G loss: 3.624712]\n",
            "1347 [ D loss: 0.637882, acc.: 59%] [G loss: 1.765238]\n",
            "1348 [ D loss: 0.550092, acc.: 63%] [G loss: 1.939319]\n",
            "1349 [ D loss: 0.511409, acc.: 70%] [G loss: 1.749321]\n",
            "1350 [ D loss: 0.451113, acc.: 80%] [G loss: 2.536134]\n",
            "1351 [ D loss: 0.271446, acc.: 94%] [G loss: 3.958149]\n",
            "1352 [ D loss: 0.425905, acc.: 82%] [G loss: 2.815681]\n",
            "1353 [ D loss: 0.234438, acc.: 95%] [G loss: 4.741976]\n",
            "1354 [ D loss: 0.157109, acc.: 98%] [G loss: 3.145156]\n",
            "1355 [ D loss: 0.518034, acc.: 70%] [G loss: 2.304141]\n",
            "1356 [ D loss: 0.184877, acc.: 95%] [G loss: 6.585633]\n",
            "1357 [ D loss: 0.521096, acc.: 71%] [G loss: 1.491083]\n",
            "1358 [ D loss: 0.313332, acc.: 87%] [G loss: 2.792575]\n",
            "1359 [ D loss: 0.328973, acc.: 88%] [G loss: 2.500005]\n",
            "1360 [ D loss: 0.579556, acc.: 69%] [G loss: 2.795569]\n",
            "1361 [ D loss: 0.403817, acc.: 85%] [G loss: 2.868030]\n",
            "1362 [ D loss: 0.396139, acc.: 86%] [G loss: 2.587267]\n",
            "1363 [ D loss: 0.207526, acc.: 95%] [G loss: 4.627631]\n",
            "1364 [ D loss: 0.475715, acc.: 75%] [G loss: 2.408278]\n",
            "1365 [ D loss: 0.533185, acc.: 65%] [G loss: 2.359056]\n",
            "1366 [ D loss: 0.488938, acc.: 73%] [G loss: 1.750863]\n",
            "1367 [ D loss: 0.431112, acc.: 83%] [G loss: 2.583003]\n",
            "1368 [ D loss: 0.241238, acc.: 95%] [G loss: 3.708543]\n",
            "1369 [ D loss: 0.293462, acc.: 91%] [G loss: 3.603413]\n",
            "1370 [ D loss: 0.269237, acc.: 91%] [G loss: 2.538721]\n",
            "1371 [ D loss: 0.440286, acc.: 73%] [G loss: 4.010134]\n",
            "1372 [ D loss: 0.591641, acc.: 62%] [G loss: 1.848670]\n",
            "1373 [ D loss: 0.228583, acc.: 94%] [G loss: 3.430209]\n",
            "1374 [ D loss: 0.549435, acc.: 70%] [G loss: 2.999617]\n",
            "1375 [ D loss: 0.440844, acc.: 82%] [G loss: 2.902531]\n",
            "1376 [ D loss: 0.406746, acc.: 84%] [G loss: 3.344392]\n",
            "1377 [ D loss: 0.250975, acc.: 91%] [G loss: 5.562425]\n",
            "1378 [ D loss: 0.240598, acc.: 96%] [G loss: 4.722644]\n",
            "1379 [ D loss: 0.718431, acc.: 58%] [G loss: 1.571827]\n",
            "1380 [ D loss: 0.580316, acc.: 65%] [G loss: 1.961987]\n",
            "1381 [ D loss: 0.721346, acc.: 54%] [G loss: 1.917534]\n",
            "1382 [ D loss: 0.410793, acc.: 81%] [G loss: 4.034781]\n",
            "1383 [ D loss: 0.315184, acc.: 86%] [G loss: 4.413291]\n",
            "1384 [ D loss: 0.497947, acc.: 73%] [G loss: 2.522421]\n",
            "1385 [ D loss: 0.607203, acc.: 59%] [G loss: 1.327440]\n",
            "1386 [ D loss: 0.619680, acc.: 58%] [G loss: 2.034410]\n",
            "1387 [ D loss: 0.377991, acc.: 85%] [G loss: 2.462579]\n",
            "1388 [ D loss: 0.260043, acc.: 93%] [G loss: 5.042112]\n",
            "1389 [ D loss: 0.190540, acc.: 97%] [G loss: 4.033549]\n",
            "1390 [ D loss: 0.544640, acc.: 59%] [G loss: 2.117221]\n",
            "1391 [ D loss: 0.277024, acc.: 92%] [G loss: 3.996474]\n",
            "1392 [ D loss: 0.306038, acc.: 88%] [G loss: 2.237134]\n",
            "1393 [ D loss: 0.669453, acc.: 59%] [G loss: 4.382842]\n",
            "1394 [ D loss: 0.183847, acc.: 97%] [G loss: 5.823991]\n",
            "1395 [ D loss: 0.338966, acc.: 84%] [G loss: 2.913746]\n",
            "1396 [ D loss: 0.238163, acc.: 93%] [G loss: 4.461333]\n",
            "1397 [ D loss: 0.167386, acc.: 98%] [G loss: 4.175601]\n",
            "1398 [ D loss: 0.606959, acc.: 64%] [G loss: 1.711940]\n",
            "1399 [ D loss: 0.362174, acc.: 85%] [G loss: 2.566103]\n",
            "1400 [ D loss: 0.249919, acc.: 96%] [G loss: 4.338476]\n",
            "1401 [ D loss: 0.702166, acc.: 55%] [G loss: 2.336410]\n",
            "1402 [ D loss: 0.528836, acc.: 63%] [G loss: 2.378963]\n",
            "1403 [ D loss: 0.485667, acc.: 79%] [G loss: 3.482642]\n",
            "1404 [ D loss: 0.346319, acc.: 87%] [G loss: 2.516683]\n",
            "1405 [ D loss: 0.669461, acc.: 59%] [G loss: 1.569559]\n",
            "1406 [ D loss: 0.594321, acc.: 62%] [G loss: 1.764342]\n",
            "1407 [ D loss: 0.601484, acc.: 66%] [G loss: 1.946558]\n",
            "1408 [ D loss: 0.442670, acc.: 80%] [G loss: 2.186848]\n",
            "1409 [ D loss: 0.425532, acc.: 81%] [G loss: 2.121503]\n",
            "1410 [ D loss: 0.498520, acc.: 69%] [G loss: 2.504757]\n",
            "1411 [ D loss: 0.368645, acc.: 84%] [G loss: 4.018340]\n",
            "1412 [ D loss: 0.261889, acc.: 91%] [G loss: 2.734641]\n",
            "1413 [ D loss: 0.471214, acc.: 73%] [G loss: 2.084844]\n",
            "1414 [ D loss: 0.450115, acc.: 77%] [G loss: 2.317177]\n",
            "1415 [ D loss: 0.339450, acc.: 88%] [G loss: 3.658604]\n",
            "1416 [ D loss: 0.352144, acc.: 89%] [G loss: 2.842678]\n",
            "1417 [ D loss: 0.243669, acc.: 91%] [G loss: 4.378527]\n",
            "1418 [ D loss: 0.263264, acc.: 92%] [G loss: 3.738326]\n",
            "1419 [ D loss: 0.547587, acc.: 66%] [G loss: 2.086785]\n",
            "1420 [ D loss: 0.508462, acc.: 72%] [G loss: 2.031025]\n",
            "1421 [ D loss: 0.406150, acc.: 80%] [G loss: 2.365412]\n",
            "1422 [ D loss: 0.462010, acc.: 73%] [G loss: 2.263410]\n",
            "1423 [ D loss: 0.602570, acc.: 60%] [G loss: 2.620634]\n",
            "1424 [ D loss: 0.263802, acc.: 94%] [G loss: 2.971179]\n",
            "1425 [ D loss: 0.251545, acc.: 93%] [G loss: 5.165452]\n",
            "1426 [ D loss: 0.201480, acc.: 95%] [G loss: 3.839775]\n",
            "1427 [ D loss: 0.581112, acc.: 59%] [G loss: 1.306334]\n",
            "1428 [ D loss: 0.465876, acc.: 73%] [G loss: 2.301667]\n",
            "1429 [ D loss: 0.246982, acc.: 94%] [G loss: 3.349948]\n",
            "1430 [ D loss: 0.694624, acc.: 57%] [G loss: 2.124368]\n",
            "1431 [ D loss: 0.415862, acc.: 83%] [G loss: 2.559689]\n",
            "1432 [ D loss: 0.749250, acc.: 55%] [G loss: 1.484132]\n",
            "1433 [ D loss: 0.354646, acc.: 88%] [G loss: 3.064498]\n",
            "1434 [ D loss: 0.313394, acc.: 88%] [G loss: 3.959720]\n",
            "1435 [ D loss: 0.411290, acc.: 83%] [G loss: 3.011141]\n",
            "1436 [ D loss: 0.369657, acc.: 82%] [G loss: 2.633077]\n",
            "1437 [ D loss: 0.452315, acc.: 74%] [G loss: 2.878741]\n",
            "1438 [ D loss: 0.484253, acc.: 73%] [G loss: 2.353998]\n",
            "1439 [ D loss: 0.302203, acc.: 89%] [G loss: 3.243356]\n",
            "1440 [ D loss: 0.390287, acc.: 83%] [G loss: 2.218773]\n",
            "1441 [ D loss: 0.573013, acc.: 62%] [G loss: 2.430225]\n",
            "1442 [ D loss: 0.443125, acc.: 83%] [G loss: 2.306721]\n",
            "1443 [ D loss: 0.360623, acc.: 88%] [G loss: 2.567890]\n",
            "1444 [ D loss: 0.450650, acc.: 82%] [G loss: 2.634212]\n",
            "1445 [ D loss: 0.477665, acc.: 79%] [G loss: 2.572869]\n",
            "1446 [ D loss: 0.409506, acc.: 82%] [G loss: 3.669182]\n",
            "1447 [ D loss: 0.217572, acc.: 97%] [G loss: 3.451137]\n",
            "1448 [ D loss: 0.550458, acc.: 67%] [G loss: 2.800323]\n",
            "1449 [ D loss: 0.531633, acc.: 70%] [G loss: 2.057037]\n",
            "1450 [ D loss: 0.566617, acc.: 64%] [G loss: 2.002326]\n",
            "1451 [ D loss: 0.442735, acc.: 78%] [G loss: 2.398937]\n",
            "1452 [ D loss: 0.269372, acc.: 95%] [G loss: 2.816443]\n",
            "1453 [ D loss: 0.322872, acc.: 89%] [G loss: 2.960313]\n",
            "1454 [ D loss: 0.330746, acc.: 89%] [G loss: 1.841421]\n",
            "1455 [ D loss: 0.486255, acc.: 70%] [G loss: 1.715742]\n",
            "1456 [ D loss: 0.256064, acc.: 89%] [G loss: 3.889236]\n",
            "1457 [ D loss: 0.451055, acc.: 80%] [G loss: 1.833686]\n",
            "1458 [ D loss: 0.329363, acc.: 86%] [G loss: 2.284796]\n",
            "1459 [ D loss: 0.354393, acc.: 86%] [G loss: 2.909032]\n",
            "1460 [ D loss: 0.573479, acc.: 68%] [G loss: 1.993225]\n",
            "1461 [ D loss: 0.635808, acc.: 58%] [G loss: 1.602970]\n",
            "1462 [ D loss: 0.355152, acc.: 88%] [G loss: 2.560210]\n",
            "1463 [ D loss: 0.328572, acc.: 89%] [G loss: 3.959518]\n",
            "1464 [ D loss: 0.536227, acc.: 75%] [G loss: 3.127025]\n",
            "1465 [ D loss: 0.745707, acc.: 51%] [G loss: 1.427622]\n",
            "1466 [ D loss: 0.516105, acc.: 70%] [G loss: 2.497623]\n",
            "1467 [ D loss: 0.220504, acc.: 95%] [G loss: 4.598414]\n",
            "1468 [ D loss: 0.580804, acc.: 62%] [G loss: 2.094883]\n",
            "1469 [ D loss: 0.649614, acc.: 58%] [G loss: 1.481872]\n",
            "1470 [ D loss: 0.688620, acc.: 54%] [G loss: 1.177598]\n",
            "1471 [ D loss: 0.458349, acc.: 73%] [G loss: 1.752775]\n",
            "1472 [ D loss: 0.511861, acc.: 75%] [G loss: 1.830323]\n",
            "1473 [ D loss: 0.409336, acc.: 83%] [G loss: 2.914240]\n",
            "1474 [ D loss: 0.323095, acc.: 88%] [G loss: 2.266411]\n",
            "1475 [ D loss: 0.544252, acc.: 65%] [G loss: 3.400031]\n",
            "1476 [ D loss: 0.492252, acc.: 70%] [G loss: 1.504412]\n",
            "1477 [ D loss: 0.233062, acc.: 94%] [G loss: 4.903979]\n",
            "1478 [ D loss: 0.239326, acc.: 97%] [G loss: 3.496211]\n",
            "1479 [ D loss: 0.449744, acc.: 73%] [G loss: 2.109938]\n",
            "1480 [ D loss: 0.560025, acc.: 59%] [G loss: 1.984611]\n",
            "1481 [ D loss: 0.610490, acc.: 61%] [G loss: 1.639523]\n",
            "1482 [ D loss: 0.501806, acc.: 72%] [G loss: 2.421443]\n",
            "1483 [ D loss: 0.305988, acc.: 89%] [G loss: 3.613122]\n",
            "1484 [ D loss: 0.380222, acc.: 88%] [G loss: 2.104262]\n",
            "1485 [ D loss: 0.748503, acc.: 50%] [G loss: 1.974876]\n",
            "1486 [ D loss: 0.692985, acc.: 54%] [G loss: 1.238320]\n",
            "1487 [ D loss: 0.656096, acc.: 53%] [G loss: 1.549016]\n",
            "1488 [ D loss: 0.587894, acc.: 65%] [G loss: 1.986429]\n",
            "1489 [ D loss: 0.444435, acc.: 80%] [G loss: 2.208221]\n",
            "1490 [ D loss: 0.305088, acc.: 93%] [G loss: 4.019086]\n",
            "1491 [ D loss: 0.395512, acc.: 85%] [G loss: 3.479893]\n",
            "1492 [ D loss: 0.495735, acc.: 69%] [G loss: 1.961810]\n",
            "1493 [ D loss: 0.663819, acc.: 52%] [G loss: 2.643149]\n",
            "1494 [ D loss: 0.379321, acc.: 85%] [G loss: 2.538141]\n",
            "1495 [ D loss: 0.453962, acc.: 84%] [G loss: 2.936623]\n",
            "1496 [ D loss: 0.335898, acc.: 85%] [G loss: 4.222531]\n",
            "1497 [ D loss: 0.645735, acc.: 54%] [G loss: 2.037899]\n",
            "1498 [ D loss: 0.302529, acc.: 91%] [G loss: 2.285229]\n",
            "1499 [ D loss: 0.377817, acc.: 85%] [G loss: 2.665546]\n",
            "1500 [ D loss: 0.637816, acc.: 55%] [G loss: 1.716519]\n",
            "1501 [ D loss: 0.558732, acc.: 64%] [G loss: 2.355786]\n",
            "1502 [ D loss: 0.253747, acc.: 93%] [G loss: 3.944658]\n",
            "1503 [ D loss: 0.283802, acc.: 91%] [G loss: 4.059496]\n",
            "1504 [ D loss: 0.244830, acc.: 94%] [G loss: 3.324811]\n",
            "1505 [ D loss: 0.481645, acc.: 71%] [G loss: 3.482967]\n",
            "1506 [ D loss: 0.192225, acc.: 95%] [G loss: 3.898559]\n",
            "1507 [ D loss: 0.384526, acc.: 77%] [G loss: 2.144518]\n",
            "1508 [ D loss: 0.204139, acc.: 95%] [G loss: 3.726098]\n",
            "1509 [ D loss: 0.483513, acc.: 72%] [G loss: 1.833849]\n",
            "1510 [ D loss: 0.647809, acc.: 58%] [G loss: 1.464383]\n",
            "1511 [ D loss: 0.533868, acc.: 75%] [G loss: 1.718863]\n",
            "1512 [ D loss: 0.566986, acc.: 70%] [G loss: 2.170361]\n",
            "1513 [ D loss: 0.538598, acc.: 69%] [G loss: 1.121161]\n",
            "1514 [ D loss: 0.551132, acc.: 67%] [G loss: 1.417709]\n",
            "1515 [ D loss: 0.316694, acc.: 96%] [G loss: 2.872644]\n",
            "1516 [ D loss: 0.263131, acc.: 94%] [G loss: 2.661660]\n",
            "1517 [ D loss: 0.546746, acc.: 70%] [G loss: 1.735686]\n",
            "1518 [ D loss: 0.596543, acc.: 64%] [G loss: 1.711078]\n",
            "1519 [ D loss: 0.302699, acc.: 91%] [G loss: 3.657048]\n",
            "1520 [ D loss: 0.283594, acc.: 93%] [G loss: 3.566394]\n",
            "1521 [ D loss: 0.526570, acc.: 65%] [G loss: 1.710310]\n",
            "1522 [ D loss: 0.362783, acc.: 88%] [G loss: 2.103173]\n",
            "1523 [ D loss: 0.456754, acc.: 78%] [G loss: 2.740967]\n",
            "1524 [ D loss: 0.362560, acc.: 87%] [G loss: 2.340008]\n",
            "1525 [ D loss: 0.218019, acc.: 95%] [G loss: 3.314268]\n",
            "1526 [ D loss: 0.505673, acc.: 71%] [G loss: 1.585215]\n",
            "1527 [ D loss: 0.592411, acc.: 56%] [G loss: 1.530288]\n",
            "1528 [ D loss: 0.395006, acc.: 86%] [G loss: 2.305748]\n",
            "1529 [ D loss: 0.482903, acc.: 75%] [G loss: 2.619045]\n",
            "1530 [ D loss: 0.416711, acc.: 80%] [G loss: 2.315128]\n",
            "1531 [ D loss: 0.238595, acc.: 95%] [G loss: 5.455963]\n",
            "1532 [ D loss: 0.456269, acc.: 80%] [G loss: 1.360623]\n",
            "1533 [ D loss: 0.379071, acc.: 84%] [G loss: 2.477484]\n",
            "1534 [ D loss: 0.373812, acc.: 85%] [G loss: 4.607161]\n",
            "1535 [ D loss: 0.722310, acc.: 57%] [G loss: 1.948750]\n",
            "1536 [ D loss: 0.404521, acc.: 80%] [G loss: 5.442151]\n",
            "1537 [ D loss: 0.360003, acc.: 88%] [G loss: 3.029224]\n",
            "1538 [ D loss: 0.609508, acc.: 61%] [G loss: 2.359893]\n",
            "1539 [ D loss: 0.596993, acc.: 64%] [G loss: 2.657625]\n",
            "1540 [ D loss: 0.364528, acc.: 84%] [G loss: 7.355119]\n",
            "1541 [ D loss: 0.247620, acc.: 96%] [G loss: 5.080700]\n",
            "1542 [ D loss: 0.269111, acc.: 95%] [G loss: 4.233297]\n",
            "1543 [ D loss: 0.650402, acc.: 58%] [G loss: 1.827890]\n",
            "1544 [ D loss: 0.593347, acc.: 70%] [G loss: 2.838886]\n",
            "1545 [ D loss: 0.336891, acc.: 84%] [G loss: 5.109586]\n",
            "1546 [ D loss: 0.521451, acc.: 66%] [G loss: 1.830929]\n",
            "1547 [ D loss: 0.362220, acc.: 86%] [G loss: 2.601834]\n",
            "1548 [ D loss: 0.337602, acc.: 88%] [G loss: 2.955176]\n",
            "1549 [ D loss: 0.589257, acc.: 60%] [G loss: 1.475251]\n",
            "1550 [ D loss: 0.435915, acc.: 82%] [G loss: 2.034703]\n",
            "1551 [ D loss: 0.609343, acc.: 61%] [G loss: 1.499744]\n",
            "1552 [ D loss: 0.645262, acc.: 56%] [G loss: 1.190563]\n",
            "1553 [ D loss: 0.619374, acc.: 57%] [G loss: 1.347794]\n",
            "1554 [ D loss: 0.541081, acc.: 70%] [G loss: 1.676648]\n",
            "1555 [ D loss: 0.622082, acc.: 59%] [G loss: 1.826946]\n",
            "1556 [ D loss: 0.482633, acc.: 80%] [G loss: 1.959834]\n",
            "1557 [ D loss: 0.539237, acc.: 63%] [G loss: 1.299383]\n",
            "1558 [ D loss: 0.483858, acc.: 79%] [G loss: 2.364380]\n",
            "1559 [ D loss: 0.604783, acc.: 62%] [G loss: 1.407513]\n",
            "1560 [ D loss: 0.562685, acc.: 62%] [G loss: 1.422554]\n",
            "1561 [ D loss: 0.651287, acc.: 56%] [G loss: 1.731641]\n",
            "1562 [ D loss: 0.630700, acc.: 58%] [G loss: 1.567472]\n",
            "1563 [ D loss: 0.433702, acc.: 87%] [G loss: 1.633545]\n",
            "1564 [ D loss: 0.574165, acc.: 66%] [G loss: 2.918752]\n",
            "1565 [ D loss: 0.345428, acc.: 88%] [G loss: 2.449024]\n",
            "1566 [ D loss: 0.428893, acc.: 77%] [G loss: 3.190711]\n",
            "1567 [ D loss: 0.429284, acc.: 79%] [G loss: 3.557697]\n",
            "1568 [ D loss: 0.623682, acc.: 60%] [G loss: 2.379187]\n",
            "1569 [ D loss: 0.428375, acc.: 76%] [G loss: 2.951290]\n",
            "1570 [ D loss: 0.331485, acc.: 84%] [G loss: 3.992568]\n",
            "1571 [ D loss: 0.221128, acc.: 96%] [G loss: 4.029530]\n",
            "1572 [ D loss: 0.457495, acc.: 77%] [G loss: 1.193661]\n",
            "1573 [ D loss: 0.518664, acc.: 70%] [G loss: 2.281957]\n",
            "1574 [ D loss: 0.441890, acc.: 80%] [G loss: 3.460840]\n",
            "1575 [ D loss: 0.517778, acc.: 74%] [G loss: 2.156411]\n",
            "1576 [ D loss: 0.612896, acc.: 62%] [G loss: 1.810090]\n",
            "1577 [ D loss: 0.545230, acc.: 64%] [G loss: 1.803668]\n",
            "1578 [ D loss: 0.589441, acc.: 62%] [G loss: 2.523004]\n",
            "1579 [ D loss: 0.704240, acc.: 54%] [G loss: 1.925416]\n",
            "1580 [ D loss: 0.803106, acc.: 39%] [G loss: 1.111949]\n",
            "1581 [ D loss: 0.417738, acc.: 88%] [G loss: 2.050158]\n",
            "1582 [ D loss: 0.368362, acc.: 83%] [G loss: 4.916145]\n",
            "1583 [ D loss: 0.432597, acc.: 87%] [G loss: 2.400273]\n",
            "1584 [ D loss: 0.582286, acc.: 65%] [G loss: 0.959084]\n",
            "1585 [ D loss: 0.653361, acc.: 56%] [G loss: 2.038975]\n",
            "1586 [ D loss: 0.657941, acc.: 57%] [G loss: 1.374680]\n",
            "1587 [ D loss: 0.656964, acc.: 57%] [G loss: 1.438926]\n",
            "1588 [ D loss: 0.590800, acc.: 60%] [G loss: 1.689238]\n",
            "1589 [ D loss: 0.413976, acc.: 91%] [G loss: 2.770641]\n",
            "1590 [ D loss: 0.327827, acc.: 91%] [G loss: 3.612643]\n",
            "1591 [ D loss: 0.448457, acc.: 80%] [G loss: 3.252673]\n",
            "1592 [ D loss: 0.503945, acc.: 73%] [G loss: 1.571531]\n",
            "1593 [ D loss: 0.496935, acc.: 73%] [G loss: 1.994228]\n",
            "1594 [ D loss: 0.265576, acc.: 95%] [G loss: 4.128742]\n",
            "1595 [ D loss: 0.246357, acc.: 93%] [G loss: 3.168236]\n",
            "1596 [ D loss: 0.499367, acc.: 74%] [G loss: 2.436178]\n",
            "1597 [ D loss: 0.374661, acc.: 84%] [G loss: 3.218918]\n",
            "1598 [ D loss: 0.376820, acc.: 82%] [G loss: 2.679518]\n",
            "1599 [ D loss: 0.498066, acc.: 73%] [G loss: 4.100416]\n",
            "1600 [ D loss: 0.582644, acc.: 59%] [G loss: 1.497578]\n",
            "1601 [ D loss: 0.533476, acc.: 69%] [G loss: 2.083174]\n",
            "1602 [ D loss: 0.468055, acc.: 78%] [G loss: 2.029701]\n",
            "1603 [ D loss: 0.532330, acc.: 74%] [G loss: 2.060364]\n",
            "1604 [ D loss: 0.381899, acc.: 85%] [G loss: 3.538615]\n",
            "1605 [ D loss: 0.244285, acc.: 96%] [G loss: 4.409458]\n",
            "1606 [ D loss: 0.491559, acc.: 72%] [G loss: 1.905024]\n",
            "1607 [ D loss: 0.696492, acc.: 49%] [G loss: 1.240457]\n",
            "1608 [ D loss: 0.445691, acc.: 82%] [G loss: 1.940543]\n",
            "1609 [ D loss: 0.525151, acc.: 67%] [G loss: 1.899108]\n",
            "1610 [ D loss: 0.301910, acc.: 93%] [G loss: 2.454602]\n",
            "1611 [ D loss: 0.495890, acc.: 73%] [G loss: 3.101630]\n",
            "1612 [ D loss: 0.559076, acc.: 66%] [G loss: 1.412691]\n",
            "1613 [ D loss: 0.390090, acc.: 87%] [G loss: 3.062745]\n",
            "1614 [ D loss: 0.282993, acc.: 92%] [G loss: 3.240697]\n",
            "1615 [ D loss: 0.542956, acc.: 70%] [G loss: 1.803174]\n",
            "1616 [ D loss: 0.284067, acc.: 93%] [G loss: 3.358874]\n",
            "1617 [ D loss: 0.517180, acc.: 70%] [G loss: 1.282480]\n",
            "1618 [ D loss: 0.334157, acc.: 94%] [G loss: 2.627249]\n",
            "1619 [ D loss: 0.397058, acc.: 87%] [G loss: 2.455066]\n",
            "1620 [ D loss: 0.381506, acc.: 84%] [G loss: 1.955628]\n",
            "1621 [ D loss: 0.222358, acc.: 95%] [G loss: 3.262638]\n",
            "1622 [ D loss: 0.482074, acc.: 75%] [G loss: 2.439161]\n",
            "1623 [ D loss: 0.393750, acc.: 82%] [G loss: 3.836915]\n",
            "1624 [ D loss: 0.581429, acc.: 64%] [G loss: 2.404645]\n",
            "1625 [ D loss: 0.500256, acc.: 78%] [G loss: 4.509562]\n",
            "1626 [ D loss: 0.604177, acc.: 62%] [G loss: 1.549178]\n",
            "1627 [ D loss: 0.486256, acc.: 70%] [G loss: 1.814124]\n",
            "1628 [ D loss: 0.549924, acc.: 66%] [G loss: 1.456587]\n",
            "1629 [ D loss: 0.584777, acc.: 61%] [G loss: 1.395737]\n",
            "1630 [ D loss: 0.549606, acc.: 76%] [G loss: 2.106449]\n",
            "1631 [ D loss: 0.501676, acc.: 73%] [G loss: 2.218308]\n",
            "1632 [ D loss: 0.473131, acc.: 78%] [G loss: 2.173518]\n",
            "1633 [ D loss: 0.432173, acc.: 82%] [G loss: 3.381542]\n",
            "1634 [ D loss: 0.415791, acc.: 84%] [G loss: 4.176227]\n",
            "1635 [ D loss: 0.310986, acc.: 87%] [G loss: 3.524216]\n",
            "1636 [ D loss: 0.544144, acc.: 69%] [G loss: 2.393207]\n",
            "1637 [ D loss: 0.264680, acc.: 93%] [G loss: 3.371336]\n",
            "1638 [ D loss: 0.426237, acc.: 74%] [G loss: 1.270136]\n",
            "1639 [ D loss: 0.443501, acc.: 80%] [G loss: 2.037119]\n",
            "1640 [ D loss: 0.393339, acc.: 84%] [G loss: 1.421981]\n",
            "1641 [ D loss: 0.533970, acc.: 63%] [G loss: 1.548668]\n",
            "1642 [ D loss: 0.602939, acc.: 66%] [G loss: 1.455599]\n",
            "1643 [ D loss: 0.628406, acc.: 55%] [G loss: 2.012313]\n",
            "1644 [ D loss: 0.425445, acc.: 82%] [G loss: 1.863560]\n",
            "1645 [ D loss: 0.552152, acc.: 63%] [G loss: 2.408430]\n",
            "1646 [ D loss: 0.464815, acc.: 80%] [G loss: 3.000042]\n",
            "1647 [ D loss: 0.494015, acc.: 76%] [G loss: 1.343077]\n",
            "1648 [ D loss: 0.451136, acc.: 81%] [G loss: 2.160603]\n",
            "1649 [ D loss: 0.537497, acc.: 73%] [G loss: 1.755282]\n",
            "1650 [ D loss: 0.445485, acc.: 76%] [G loss: 3.181355]\n",
            "1651 [ D loss: 0.437284, acc.: 79%] [G loss: 2.670311]\n",
            "1652 [ D loss: 0.322228, acc.: 92%] [G loss: 2.785275]\n",
            "1653 [ D loss: 0.308068, acc.: 88%] [G loss: 4.475260]\n",
            "1654 [ D loss: 0.176588, acc.: 97%] [G loss: 4.228764]\n",
            "1655 [ D loss: 0.243804, acc.: 93%] [G loss: 2.989690]\n",
            "1656 [ D loss: 0.442547, acc.: 76%] [G loss: 2.212631]\n",
            "1657 [ D loss: 0.371734, acc.: 81%] [G loss: 2.441596]\n",
            "1658 [ D loss: 0.405904, acc.: 83%] [G loss: 2.160831]\n",
            "1659 [ D loss: 0.564011, acc.: 58%] [G loss: 1.659906]\n",
            "1660 [ D loss: 0.436454, acc.: 81%] [G loss: 2.018522]\n",
            "1661 [ D loss: 0.434596, acc.: 84%] [G loss: 3.199852]\n",
            "1662 [ D loss: 0.486081, acc.: 73%] [G loss: 2.505359]\n",
            "1663 [ D loss: 0.341977, acc.: 88%] [G loss: 1.793864]\n",
            "1664 [ D loss: 0.618026, acc.: 55%] [G loss: 1.870480]\n",
            "1665 [ D loss: 0.170906, acc.: 96%] [G loss: 3.437603]\n",
            "1666 [ D loss: 0.571361, acc.: 70%] [G loss: 1.853112]\n",
            "1667 [ D loss: 0.645783, acc.: 56%] [G loss: 2.185374]\n",
            "1668 [ D loss: 0.267195, acc.: 91%] [G loss: 4.992146]\n",
            "1669 [ D loss: 0.481528, acc.: 77%] [G loss: 2.121331]\n",
            "1670 [ D loss: 0.662755, acc.: 55%] [G loss: 1.278032]\n",
            "1671 [ D loss: 0.578800, acc.: 62%] [G loss: 1.397000]\n",
            "1672 [ D loss: 0.453659, acc.: 82%] [G loss: 2.069913]\n",
            "1673 [ D loss: 0.443218, acc.: 79%] [G loss: 1.876946]\n",
            "1674 [ D loss: 0.443565, acc.: 80%] [G loss: 1.816883]\n",
            "1675 [ D loss: 0.367424, acc.: 84%] [G loss: 3.614902]\n",
            "1676 [ D loss: 0.501583, acc.: 70%] [G loss: 2.689187]\n",
            "1677 [ D loss: 0.527557, acc.: 66%] [G loss: 1.467189]\n",
            "1678 [ D loss: 0.255727, acc.: 95%] [G loss: 2.353590]\n",
            "1679 [ D loss: 0.611084, acc.: 62%] [G loss: 2.207311]\n",
            "1680 [ D loss: 0.470441, acc.: 73%] [G loss: 2.476461]\n",
            "1681 [ D loss: 0.567430, acc.: 68%] [G loss: 2.642190]\n",
            "1682 [ D loss: 0.416792, acc.: 86%] [G loss: 3.767910]\n",
            "1683 [ D loss: 0.439608, acc.: 77%] [G loss: 2.578835]\n",
            "1684 [ D loss: 0.381891, acc.: 84%] [G loss: 2.861140]\n",
            "1685 [ D loss: 0.389887, acc.: 81%] [G loss: 2.553614]\n",
            "1686 [ D loss: 0.467720, acc.: 77%] [G loss: 4.034521]\n",
            "1687 [ D loss: 0.316774, acc.: 89%] [G loss: 3.396005]\n",
            "1688 [ D loss: 0.426638, acc.: 78%] [G loss: 1.996648]\n",
            "1689 [ D loss: 0.406085, acc.: 82%] [G loss: 2.337201]\n",
            "1690 [ D loss: 0.518447, acc.: 68%] [G loss: 4.451038]\n",
            "1691 [ D loss: 0.314390, acc.: 90%] [G loss: 6.027131]\n",
            "1692 [ D loss: 0.359724, acc.: 87%] [G loss: 5.000698]\n",
            "1693 [ D loss: 0.156557, acc.: 97%] [G loss: 5.804680]\n",
            "1694 [ D loss: 0.362618, acc.: 87%] [G loss: 3.210172]\n",
            "1695 [ D loss: 0.352367, acc.: 84%] [G loss: 1.919393]\n",
            "1696 [ D loss: 0.495385, acc.: 67%] [G loss: 2.390069]\n",
            "1697 [ D loss: 0.278393, acc.: 91%] [G loss: 2.759401]\n",
            "1698 [ D loss: 0.488857, acc.: 67%] [G loss: 2.306369]\n",
            "1699 [ D loss: 0.304976, acc.: 90%] [G loss: 3.532233]\n",
            "1700 [ D loss: 0.450307, acc.: 76%] [G loss: 2.513909]\n",
            "1701 [ D loss: 0.385710, acc.: 81%] [G loss: 2.025653]\n",
            "1702 [ D loss: 0.600721, acc.: 57%] [G loss: 1.610977]\n",
            "1703 [ D loss: 0.319167, acc.: 94%] [G loss: 2.742497]\n",
            "1704 [ D loss: 0.290753, acc.: 95%] [G loss: 4.131713]\n",
            "1705 [ D loss: 0.370449, acc.: 88%] [G loss: 3.278371]\n",
            "1706 [ D loss: 0.380174, acc.: 84%] [G loss: 2.734316]\n",
            "1707 [ D loss: 0.489190, acc.: 67%] [G loss: 1.197380]\n",
            "1708 [ D loss: 0.349619, acc.: 83%] [G loss: 2.575482]\n",
            "1709 [ D loss: 0.281671, acc.: 90%] [G loss: 3.393034]\n",
            "1710 [ D loss: 0.480044, acc.: 70%] [G loss: 1.810771]\n",
            "1711 [ D loss: 0.410712, acc.: 87%] [G loss: 2.114850]\n",
            "1712 [ D loss: 0.374021, acc.: 91%] [G loss: 2.334497]\n",
            "1713 [ D loss: 0.415845, acc.: 79%] [G loss: 1.654369]\n",
            "1714 [ D loss: 0.484761, acc.: 74%] [G loss: 1.474488]\n",
            "1715 [ D loss: 0.541637, acc.: 74%] [G loss: 1.828532]\n",
            "1716 [ D loss: 0.411325, acc.: 83%] [G loss: 2.174080]\n",
            "1717 [ D loss: 0.469157, acc.: 71%] [G loss: 1.768086]\n",
            "1718 [ D loss: 0.498216, acc.: 70%] [G loss: 2.046452]\n",
            "1719 [ D loss: 0.328307, acc.: 91%] [G loss: 5.445882]\n",
            "1720 [ D loss: 0.482716, acc.: 80%] [G loss: 1.792993]\n",
            "1721 [ D loss: 0.310134, acc.: 91%] [G loss: 3.307129]\n",
            "1722 [ D loss: 0.687965, acc.: 54%] [G loss: 1.149294]\n",
            "1723 [ D loss: 0.358077, acc.: 87%] [G loss: 2.488579]\n",
            "1724 [ D loss: 0.442694, acc.: 81%] [G loss: 3.862016]\n",
            "1725 [ D loss: 0.361418, acc.: 82%] [G loss: 3.442997]\n",
            "1726 [ D loss: 0.290084, acc.: 92%] [G loss: 3.026019]\n",
            "1727 [ D loss: 0.486882, acc.: 71%] [G loss: 2.508934]\n",
            "1728 [ D loss: 0.320918, acc.: 88%] [G loss: 3.692953]\n",
            "1729 [ D loss: 0.443911, acc.: 76%] [G loss: 1.724616]\n",
            "1730 [ D loss: 0.554285, acc.: 65%] [G loss: 3.591026]\n",
            "1731 [ D loss: 0.320434, acc.: 88%] [G loss: 4.441131]\n",
            "1732 [ D loss: 0.474060, acc.: 73%] [G loss: 3.913607]\n",
            "1733 [ D loss: 0.446489, acc.: 74%] [G loss: 2.329158]\n",
            "1734 [ D loss: 0.496442, acc.: 72%] [G loss: 2.046307]\n",
            "1735 [ D loss: 0.220108, acc.: 98%] [G loss: 4.107791]\n",
            "1736 [ D loss: 0.384557, acc.: 81%] [G loss: 2.418567]\n",
            "1737 [ D loss: 0.471736, acc.: 77%] [G loss: 3.015656]\n",
            "1738 [ D loss: 0.436217, acc.: 82%] [G loss: 2.384172]\n",
            "1739 [ D loss: 0.522386, acc.: 70%] [G loss: 2.752094]\n",
            "1740 [ D loss: 0.600789, acc.: 57%] [G loss: 1.443099]\n",
            "1741 [ D loss: 0.341770, acc.: 87%] [G loss: 3.352591]\n",
            "1742 [ D loss: 0.344908, acc.: 88%] [G loss: 2.312912]\n",
            "1743 [ D loss: 0.328234, acc.: 91%] [G loss: 2.323866]\n",
            "1744 [ D loss: 0.386492, acc.: 85%] [G loss: 4.033004]\n",
            "1745 [ D loss: 0.254362, acc.: 95%] [G loss: 3.595165]\n",
            "1746 [ D loss: 0.373473, acc.: 87%] [G loss: 2.691133]\n",
            "1747 [ D loss: 0.318180, acc.: 82%] [G loss: 4.964364]\n",
            "1748 [ D loss: 0.401945, acc.: 82%] [G loss: 5.003947]\n",
            "1749 [ D loss: 0.570327, acc.: 71%] [G loss: 2.800036]\n",
            "1750 [ D loss: 0.424054, acc.: 80%] [G loss: 3.176290]\n",
            "1751 [ D loss: 0.367569, acc.: 86%] [G loss: 4.671026]\n",
            "1752 [ D loss: 0.372123, acc.: 81%] [G loss: 3.738494]\n",
            "1753 [ D loss: 0.305906, acc.: 91%] [G loss: 2.199025]\n",
            "1754 [ D loss: 0.458760, acc.: 72%] [G loss: 2.329331]\n",
            "1755 [ D loss: 0.447848, acc.: 78%] [G loss: 2.034407]\n",
            "1756 [ D loss: 0.451247, acc.: 70%] [G loss: 2.301399]\n",
            "1757 [ D loss: 0.495339, acc.: 73%] [G loss: 2.952559]\n",
            "1758 [ D loss: 0.241652, acc.: 91%] [G loss: 4.727702]\n",
            "1759 [ D loss: 0.483470, acc.: 75%] [G loss: 2.347280]\n",
            "1760 [ D loss: 0.225999, acc.: 95%] [G loss: 5.432014]\n",
            "1761 [ D loss: 0.323841, acc.: 88%] [G loss: 3.474384]\n",
            "1762 [ D loss: 0.232586, acc.: 98%] [G loss: 3.100451]\n",
            "1763 [ D loss: 0.421108, acc.: 88%] [G loss: 2.768221]\n",
            "1764 [ D loss: 0.474558, acc.: 78%] [G loss: 2.418204]\n",
            "1765 [ D loss: 0.507723, acc.: 75%] [G loss: 3.459859]\n",
            "1766 [ D loss: 0.298024, acc.: 91%] [G loss: 3.057299]\n",
            "1767 [ D loss: 0.285526, acc.: 93%] [G loss: 3.709337]\n",
            "1768 [ D loss: 0.553902, acc.: 65%] [G loss: 1.141559]\n",
            "1769 [ D loss: 0.240172, acc.: 95%] [G loss: 4.562544]\n",
            "1770 [ D loss: 0.370962, acc.: 88%] [G loss: 4.027689]\n",
            "1771 [ D loss: 0.479685, acc.: 77%] [G loss: 2.013775]\n",
            "1772 [ D loss: 0.403235, acc.: 79%] [G loss: 4.722670]\n",
            "1773 [ D loss: 0.256064, acc.: 91%] [G loss: 3.387820]\n",
            "1774 [ D loss: 0.253734, acc.: 91%] [G loss: 4.172994]\n",
            "1775 [ D loss: 0.550684, acc.: 68%] [G loss: 1.770151]\n",
            "1776 [ D loss: 0.422394, acc.: 79%] [G loss: 2.384169]\n",
            "1777 [ D loss: 0.519210, acc.: 73%] [G loss: 2.086270]\n",
            "1778 [ D loss: 0.290954, acc.: 93%] [G loss: 2.977196]\n",
            "1779 [ D loss: 0.573357, acc.: 70%] [G loss: 2.191075]\n",
            "1780 [ D loss: 0.333162, acc.: 90%] [G loss: 2.536093]\n",
            "1781 [ D loss: 0.592779, acc.: 59%] [G loss: 1.759187]\n",
            "1782 [ D loss: 0.360864, acc.: 87%] [G loss: 2.684177]\n",
            "1783 [ D loss: 0.457081, acc.: 81%] [G loss: 2.788373]\n",
            "1784 [ D loss: 0.641596, acc.: 56%] [G loss: 2.250270]\n",
            "1785 [ D loss: 0.528712, acc.: 71%] [G loss: 1.852246]\n",
            "1786 [ D loss: 0.376213, acc.: 90%] [G loss: 3.339088]\n",
            "1787 [ D loss: 0.629857, acc.: 54%] [G loss: 3.117627]\n",
            "1788 [ D loss: 0.344223, acc.: 84%] [G loss: 5.598007]\n",
            "1789 [ D loss: 0.594297, acc.: 66%] [G loss: 2.383331]\n",
            "1790 [ D loss: 0.435049, acc.: 69%] [G loss: 2.523855]\n",
            "1791 [ D loss: 0.530333, acc.: 57%] [G loss: 1.672971]\n",
            "1792 [ D loss: 0.466241, acc.: 76%] [G loss: 2.095064]\n",
            "1793 [ D loss: 0.543047, acc.: 73%] [G loss: 1.546708]\n",
            "1794 [ D loss: 0.465707, acc.: 81%] [G loss: 2.426516]\n",
            "1795 [ D loss: 0.503624, acc.: 77%] [G loss: 3.317386]\n",
            "1796 [ D loss: 0.483549, acc.: 76%] [G loss: 4.055215]\n",
            "1797 [ D loss: 0.350137, acc.: 91%] [G loss: 3.943388]\n",
            "1798 [ D loss: 0.401545, acc.: 84%] [G loss: 1.637852]\n",
            "1799 [ D loss: 0.435354, acc.: 78%] [G loss: 1.719110]\n",
            "1800 [ D loss: 0.401703, acc.: 86%] [G loss: 1.886799]\n",
            "1801 [ D loss: 0.417907, acc.: 77%] [G loss: 2.195709]\n",
            "1802 [ D loss: 0.347862, acc.: 91%] [G loss: 3.454577]\n",
            "1803 [ D loss: 0.557234, acc.: 62%] [G loss: 3.449945]\n",
            "1804 [ D loss: 0.213015, acc.: 95%] [G loss: 5.821403]\n",
            "1805 [ D loss: 0.412664, acc.: 86%] [G loss: 4.484891]\n",
            "1806 [ D loss: 0.346793, acc.: 80%] [G loss: 2.627125]\n",
            "1807 [ D loss: 0.206180, acc.: 95%] [G loss: 5.973172]\n",
            "1808 [ D loss: 0.349476, acc.: 86%] [G loss: 3.818706]\n",
            "1809 [ D loss: 0.394490, acc.: 84%] [G loss: 4.579534]\n",
            "1810 [ D loss: 0.501831, acc.: 73%] [G loss: 2.636041]\n",
            "1811 [ D loss: 0.392025, acc.: 83%] [G loss: 4.376542]\n",
            "1812 [ D loss: 0.324316, acc.: 89%] [G loss: 4.915661]\n",
            "1813 [ D loss: 0.569281, acc.: 63%] [G loss: 2.574593]\n",
            "1814 [ D loss: 0.270371, acc.: 87%] [G loss: 2.179953]\n",
            "1815 [ D loss: 0.322435, acc.: 84%] [G loss: 1.911773]\n",
            "1816 [ D loss: 0.388913, acc.: 78%] [G loss: 3.018468]\n",
            "1817 [ D loss: 0.432305, acc.: 77%] [G loss: 2.634244]\n",
            "1818 [ D loss: 0.293077, acc.: 91%] [G loss: 3.095816]\n",
            "1819 [ D loss: 0.467639, acc.: 80%] [G loss: 3.134588]\n",
            "1820 [ D loss: 0.202614, acc.: 98%] [G loss: 4.938839]\n",
            "1821 [ D loss: 0.349503, acc.: 86%] [G loss: 2.188788]\n",
            "1822 [ D loss: 0.456445, acc.: 74%] [G loss: 2.309724]\n",
            "1823 [ D loss: 0.336183, acc.: 90%] [G loss: 2.670919]\n",
            "1824 [ D loss: 0.366192, acc.: 79%] [G loss: 3.813015]\n",
            "1825 [ D loss: 0.514731, acc.: 70%] [G loss: 1.427436]\n",
            "1826 [ D loss: 0.319467, acc.: 90%] [G loss: 2.776609]\n",
            "1827 [ D loss: 0.401135, acc.: 80%] [G loss: 1.916589]\n",
            "1828 [ D loss: 0.366358, acc.: 85%] [G loss: 2.141024]\n",
            "1829 [ D loss: 0.406697, acc.: 82%] [G loss: 5.508478]\n",
            "1830 [ D loss: 0.380157, acc.: 80%] [G loss: 2.969174]\n",
            "1831 [ D loss: 0.399036, acc.: 80%] [G loss: 3.050129]\n",
            "1832 [ D loss: 0.306499, acc.: 91%] [G loss: 4.273380]\n",
            "1833 [ D loss: 0.343891, acc.: 87%] [G loss: 2.613065]\n",
            "1834 [ D loss: 0.211945, acc.: 92%] [G loss: 5.235822]\n",
            "1835 [ D loss: 0.417752, acc.: 79%] [G loss: 2.123052]\n",
            "1836 [ D loss: 0.245653, acc.: 94%] [G loss: 4.152070]\n",
            "1837 [ D loss: 0.474542, acc.: 72%] [G loss: 2.037704]\n",
            "1838 [ D loss: 0.483980, acc.: 74%] [G loss: 2.609887]\n",
            "1839 [ D loss: 0.439935, acc.: 79%] [G loss: 2.522229]\n",
            "1840 [ D loss: 0.475510, acc.: 74%] [G loss: 2.617855]\n",
            "1841 [ D loss: 0.545845, acc.: 64%] [G loss: 2.310199]\n",
            "1842 [ D loss: 0.292194, acc.: 88%] [G loss: 4.568052]\n",
            "1843 [ D loss: 0.267163, acc.: 92%] [G loss: 3.009593]\n",
            "1844 [ D loss: 0.478887, acc.: 70%] [G loss: 2.257902]\n",
            "1845 [ D loss: 0.568260, acc.: 70%] [G loss: 3.476537]\n",
            "1846 [ D loss: 0.274499, acc.: 93%] [G loss: 4.260724]\n",
            "1847 [ D loss: 0.307469, acc.: 87%] [G loss: 3.264459]\n",
            "1848 [ D loss: 0.318137, acc.: 89%] [G loss: 2.888419]\n",
            "1849 [ D loss: 0.507088, acc.: 74%] [G loss: 2.151167]\n",
            "1850 [ D loss: 0.479731, acc.: 76%] [G loss: 1.721523]\n",
            "1851 [ D loss: 0.556581, acc.: 64%] [G loss: 2.210959]\n",
            "1852 [ D loss: 0.312530, acc.: 92%] [G loss: 3.010331]\n",
            "1853 [ D loss: 0.428479, acc.: 87%] [G loss: 1.732485]\n",
            "1854 [ D loss: 0.515097, acc.: 74%] [G loss: 1.850867]\n",
            "1855 [ D loss: 0.383987, acc.: 78%] [G loss: 1.984983]\n",
            "1856 [ D loss: 0.513640, acc.: 68%] [G loss: 5.133176]\n",
            "1857 [ D loss: 0.306016, acc.: 89%] [G loss: 3.593176]\n",
            "1858 [ D loss: 0.576539, acc.: 62%] [G loss: 1.781923]\n",
            "1859 [ D loss: 0.404992, acc.: 83%] [G loss: 2.529122]\n",
            "1860 [ D loss: 0.538546, acc.: 66%] [G loss: 1.386735]\n",
            "1861 [ D loss: 0.534080, acc.: 63%] [G loss: 1.895539]\n",
            "1862 [ D loss: 0.417416, acc.: 80%] [G loss: 3.470573]\n",
            "1863 [ D loss: 0.326901, acc.: 87%] [G loss: 2.933805]\n",
            "1864 [ D loss: 0.283300, acc.: 89%] [G loss: 10.060689]\n",
            "1865 [ D loss: 0.360479, acc.: 85%] [G loss: 3.139470]\n",
            "1866 [ D loss: 0.284086, acc.: 88%] [G loss: 3.030583]\n",
            "1867 [ D loss: 0.404656, acc.: 73%] [G loss: 3.438792]\n",
            "1868 [ D loss: 0.374339, acc.: 82%] [G loss: 2.924148]\n",
            "1869 [ D loss: 0.328140, acc.: 88%] [G loss: 3.041560]\n",
            "1870 [ D loss: 0.342128, acc.: 81%] [G loss: 3.370294]\n",
            "1871 [ D loss: 0.245352, acc.: 95%] [G loss: 3.770267]\n",
            "1872 [ D loss: 0.463258, acc.: 73%] [G loss: 1.782985]\n",
            "1873 [ D loss: 0.533662, acc.: 68%] [G loss: 1.775062]\n",
            "1874 [ D loss: 0.534340, acc.: 72%] [G loss: 2.280663]\n",
            "1875 [ D loss: 0.248271, acc.: 94%] [G loss: 5.435424]\n",
            "1876 [ D loss: 0.437129, acc.: 81%] [G loss: 2.415215]\n",
            "1877 [ D loss: 0.389649, acc.: 83%] [G loss: 1.555481]\n",
            "1878 [ D loss: 0.535341, acc.: 62%] [G loss: 1.563256]\n",
            "1879 [ D loss: 0.403892, acc.: 83%] [G loss: 1.799192]\n",
            "1880 [ D loss: 0.480024, acc.: 78%] [G loss: 2.202049]\n",
            "1881 [ D loss: 0.420010, acc.: 83%] [G loss: 2.222176]\n",
            "1882 [ D loss: 0.528263, acc.: 66%] [G loss: 1.816513]\n",
            "1883 [ D loss: 0.270635, acc.: 91%] [G loss: 3.047145]\n",
            "1884 [ D loss: 0.304911, acc.: 91%] [G loss: 2.558453]\n",
            "1885 [ D loss: 0.458645, acc.: 76%] [G loss: 1.903160]\n",
            "1886 [ D loss: 0.403363, acc.: 85%] [G loss: 3.129206]\n",
            "1887 [ D loss: 0.261978, acc.: 94%] [G loss: 4.241282]\n",
            "1888 [ D loss: 0.389574, acc.: 86%] [G loss: 7.603933]\n",
            "1889 [ D loss: 0.176206, acc.: 95%] [G loss: 3.734891]\n",
            "1890 [ D loss: 0.170213, acc.: 98%] [G loss: 3.348570]\n",
            "1891 [ D loss: 0.320616, acc.: 85%] [G loss: 3.863171]\n",
            "1892 [ D loss: 0.331591, acc.: 87%] [G loss: 2.647896]\n",
            "1893 [ D loss: 0.442296, acc.: 77%] [G loss: 2.083174]\n",
            "1894 [ D loss: 0.448913, acc.: 76%] [G loss: 1.863661]\n",
            "1895 [ D loss: 0.491727, acc.: 79%] [G loss: 2.515357]\n",
            "1896 [ D loss: 0.434753, acc.: 83%] [G loss: 2.560138]\n",
            "1897 [ D loss: 0.318430, acc.: 95%] [G loss: 3.281064]\n",
            "1898 [ D loss: 0.498575, acc.: 73%] [G loss: 1.059970]\n",
            "1899 [ D loss: 0.229249, acc.: 93%] [G loss: 1.684505]\n",
            "1900 [ D loss: 0.512723, acc.: 69%] [G loss: 1.403136]\n",
            "1901 [ D loss: 0.280971, acc.: 90%] [G loss: 2.689131]\n",
            "1902 [ D loss: 0.292088, acc.: 91%] [G loss: 2.628367]\n",
            "1903 [ D loss: 0.384501, acc.: 87%] [G loss: 2.931023]\n",
            "1904 [ D loss: 0.421997, acc.: 83%] [G loss: 6.513793]\n",
            "1905 [ D loss: 0.470216, acc.: 75%] [G loss: 1.703615]\n",
            "1906 [ D loss: 0.334758, acc.: 88%] [G loss: 3.795507]\n",
            "1907 [ D loss: 0.342540, acc.: 86%] [G loss: 3.270290]\n",
            "1908 [ D loss: 0.322485, acc.: 89%] [G loss: 4.793469]\n",
            "1909 [ D loss: 0.338431, acc.: 86%] [G loss: 3.743252]\n",
            "1910 [ D loss: 0.487477, acc.: 72%] [G loss: 1.628977]\n",
            "1911 [ D loss: 0.370432, acc.: 86%] [G loss: 3.029432]\n",
            "1912 [ D loss: 0.580587, acc.: 67%] [G loss: 2.082518]\n",
            "1913 [ D loss: 0.440353, acc.: 78%] [G loss: 3.894808]\n",
            "1914 [ D loss: 0.450276, acc.: 80%] [G loss: 3.987936]\n",
            "1915 [ D loss: 0.258386, acc.: 92%] [G loss: 5.193195]\n",
            "1916 [ D loss: 0.405160, acc.: 80%] [G loss: 4.769266]\n",
            "1917 [ D loss: 0.308322, acc.: 88%] [G loss: 4.024900]\n",
            "1918 [ D loss: 0.357786, acc.: 85%] [G loss: 2.683895]\n",
            "1919 [ D loss: 0.314575, acc.: 86%] [G loss: 2.228657]\n",
            "1920 [ D loss: 0.494849, acc.: 74%] [G loss: 2.543509]\n",
            "1921 [ D loss: 0.563173, acc.: 68%] [G loss: 1.337999]\n",
            "1922 [ D loss: 0.507485, acc.: 74%] [G loss: 2.048197]\n",
            "1923 [ D loss: 0.607056, acc.: 69%] [G loss: 2.640652]\n",
            "1924 [ D loss: 0.301628, acc.: 96%] [G loss: 3.303606]\n",
            "1925 [ D loss: 0.560196, acc.: 66%] [G loss: 2.425694]\n",
            "1926 [ D loss: 0.499806, acc.: 73%] [G loss: 1.738831]\n",
            "1927 [ D loss: 0.288653, acc.: 92%] [G loss: 4.184266]\n",
            "1928 [ D loss: 0.287321, acc.: 92%] [G loss: 6.053968]\n",
            "1929 [ D loss: 0.557171, acc.: 70%] [G loss: 1.304472]\n",
            "1930 [ D loss: 0.194145, acc.: 96%] [G loss: 2.273945]\n",
            "1931 [ D loss: 0.530455, acc.: 66%] [G loss: 1.617539]\n",
            "1932 [ D loss: 0.517162, acc.: 71%] [G loss: 2.608410]\n",
            "1933 [ D loss: 0.446541, acc.: 83%] [G loss: 2.021146]\n",
            "1934 [ D loss: 0.537602, acc.: 73%] [G loss: 1.350212]\n",
            "1935 [ D loss: 0.517594, acc.: 73%] [G loss: 1.830210]\n",
            "1936 [ D loss: 0.433860, acc.: 85%] [G loss: 3.077907]\n",
            "1937 [ D loss: 0.344112, acc.: 84%] [G loss: 2.020298]\n",
            "1938 [ D loss: 0.530368, acc.: 69%] [G loss: 4.520612]\n",
            "1939 [ D loss: 0.258674, acc.: 93%] [G loss: 9.179479]\n",
            "1940 [ D loss: 0.391332, acc.: 79%] [G loss: 6.837910]\n",
            "1941 [ D loss: 0.413883, acc.: 80%] [G loss: 3.052024]\n",
            "1942 [ D loss: 0.377818, acc.: 79%] [G loss: 2.940361]\n",
            "1943 [ D loss: 0.415504, acc.: 81%] [G loss: 2.487522]\n",
            "1944 [ D loss: 0.433804, acc.: 84%] [G loss: 2.495848]\n",
            "1945 [ D loss: 0.363260, acc.: 84%] [G loss: 2.598318]\n",
            "1946 [ D loss: 0.383330, acc.: 81%] [G loss: 2.413404]\n",
            "1947 [ D loss: 0.365210, acc.: 91%] [G loss: 2.593599]\n",
            "1948 [ D loss: 0.387355, acc.: 89%] [G loss: 4.639355]\n",
            "1949 [ D loss: 0.290977, acc.: 91%] [G loss: 4.798131]\n",
            "1950 [ D loss: 0.296351, acc.: 90%] [G loss: 2.138170]\n",
            "1951 [ D loss: 0.441191, acc.: 80%] [G loss: 1.828580]\n",
            "1952 [ D loss: 0.361932, acc.: 87%] [G loss: 2.099602]\n",
            "1953 [ D loss: 0.439700, acc.: 82%] [G loss: 1.769485]\n",
            "1954 [ D loss: 0.348402, acc.: 91%] [G loss: 2.280675]\n",
            "1955 [ D loss: 0.413320, acc.: 86%] [G loss: 2.443934]\n",
            "1956 [ D loss: 0.388438, acc.: 84%] [G loss: 3.673544]\n",
            "1957 [ D loss: 0.300727, acc.: 93%] [G loss: 3.440678]\n",
            "1958 [ D loss: 0.426905, acc.: 80%] [G loss: 2.546647]\n",
            "1959 [ D loss: 0.461754, acc.: 80%] [G loss: 2.572436]\n",
            "1960 [ D loss: 0.437148, acc.: 81%] [G loss: 3.676351]\n",
            "1961 [ D loss: 0.516211, acc.: 79%] [G loss: 3.224418]\n",
            "1962 [ D loss: 0.511639, acc.: 80%] [G loss: 2.639852]\n",
            "1963 [ D loss: 0.315643, acc.: 87%] [G loss: 2.866908]\n",
            "1964 [ D loss: 0.310247, acc.: 86%] [G loss: 4.642985]\n",
            "1965 [ D loss: 0.170480, acc.: 97%] [G loss: 5.769302]\n",
            "1966 [ D loss: 0.520037, acc.: 69%] [G loss: 3.131046]\n",
            "1967 [ D loss: 0.455321, acc.: 77%] [G loss: 2.845674]\n",
            "1968 [ D loss: 0.365700, acc.: 86%] [G loss: 3.220333]\n",
            "1969 [ D loss: 0.362355, acc.: 88%] [G loss: 3.500506]\n",
            "1970 [ D loss: 0.375585, acc.: 84%] [G loss: 2.918416]\n",
            "1971 [ D loss: 0.295542, acc.: 90%] [G loss: 1.838577]\n",
            "1972 [ D loss: 0.442012, acc.: 78%] [G loss: 2.221181]\n",
            "1973 [ D loss: 0.466515, acc.: 75%] [G loss: 3.816942]\n",
            "1974 [ D loss: 0.376484, acc.: 83%] [G loss: 3.424267]\n",
            "1975 [ D loss: 0.546286, acc.: 69%] [G loss: 2.198830]\n",
            "1976 [ D loss: 0.402307, acc.: 79%] [G loss: 3.176032]\n",
            "1977 [ D loss: 0.406827, acc.: 82%] [G loss: 3.705748]\n",
            "1978 [ D loss: 0.575866, acc.: 66%] [G loss: 2.773583]\n",
            "1979 [ D loss: 0.348175, acc.: 91%] [G loss: 4.652160]\n",
            "1980 [ D loss: 0.527928, acc.: 70%] [G loss: 2.019877]\n",
            "1981 [ D loss: 0.329738, acc.: 92%] [G loss: 2.740046]\n",
            "1982 [ D loss: 0.407542, acc.: 84%] [G loss: 2.703061]\n",
            "1983 [ D loss: 0.656533, acc.: 63%] [G loss: 1.672156]\n",
            "1984 [ D loss: 0.262392, acc.: 96%] [G loss: 3.243251]\n",
            "1985 [ D loss: 0.491748, acc.: 77%] [G loss: 2.622588]\n",
            "1986 [ D loss: 0.381629, acc.: 83%] [G loss: 3.129689]\n",
            "1987 [ D loss: 0.419437, acc.: 84%] [G loss: 2.316268]\n",
            "1988 [ D loss: 0.488562, acc.: 78%] [G loss: 2.319206]\n",
            "1989 [ D loss: 0.314703, acc.: 92%] [G loss: 3.525787]\n",
            "1990 [ D loss: 0.378813, acc.: 88%] [G loss: 2.437794]\n",
            "1991 [ D loss: 0.370693, acc.: 88%] [G loss: 2.291649]\n",
            "1992 [ D loss: 0.318080, acc.: 91%] [G loss: 3.667562]\n",
            "1993 [ D loss: 0.527606, acc.: 71%] [G loss: 3.555435]\n",
            "1994 [ D loss: 0.254522, acc.: 95%] [G loss: 4.924124]\n",
            "1995 [ D loss: 0.336946, acc.: 88%] [G loss: 3.812216]\n",
            "1996 [ D loss: 0.465633, acc.: 72%] [G loss: 1.818238]\n",
            "1997 [ D loss: 0.380214, acc.: 88%] [G loss: 5.624971]\n",
            "1998 [ D loss: 0.298040, acc.: 93%] [G loss: 3.332263]\n",
            "1999 [ D loss: 0.467308, acc.: 77%] [G loss: 2.252876]\n",
            "2000 [ D loss: 0.296663, acc.: 90%] [G loss: 3.536594]\n",
            "2001 [ D loss: 0.374126, acc.: 82%] [G loss: 3.178186]\n",
            "2002 [ D loss: 0.256583, acc.: 95%] [G loss: 3.520005]\n",
            "2003 [ D loss: 0.273985, acc.: 94%] [G loss: 2.633891]\n",
            "2004 [ D loss: 0.191478, acc.: 98%] [G loss: 5.418676]\n",
            "2005 [ D loss: 0.319716, acc.: 88%] [G loss: 3.822370]\n",
            "2006 [ D loss: 0.286555, acc.: 89%] [G loss: 2.618752]\n",
            "2007 [ D loss: 0.420510, acc.: 77%] [G loss: 2.360115]\n",
            "2008 [ D loss: 0.392763, acc.: 83%] [G loss: 3.461833]\n",
            "2009 [ D loss: 0.465702, acc.: 84%] [G loss: 2.457255]\n",
            "2010 [ D loss: 0.292875, acc.: 93%] [G loss: 2.815915]\n",
            "2011 [ D loss: 0.442976, acc.: 82%] [G loss: 2.257959]\n",
            "2012 [ D loss: 0.402669, acc.: 88%] [G loss: 2.197494]\n",
            "2013 [ D loss: 0.386172, acc.: 87%] [G loss: 2.201353]\n",
            "2014 [ D loss: 0.402855, acc.: 87%] [G loss: 3.247310]\n",
            "2015 [ D loss: 0.384524, acc.: 88%] [G loss: 5.330218]\n",
            "2016 [ D loss: 0.327820, acc.: 87%] [G loss: 3.317535]\n",
            "2017 [ D loss: 0.212034, acc.: 94%] [G loss: 4.842537]\n",
            "2018 [ D loss: 0.327751, acc.: 90%] [G loss: 3.889301]\n",
            "2019 [ D loss: 0.349797, acc.: 88%] [G loss: 4.563164]\n",
            "2020 [ D loss: 0.168978, acc.: 97%] [G loss: 7.212477]\n",
            "2021 [ D loss: 0.298145, acc.: 88%] [G loss: 3.847294]\n",
            "2022 [ D loss: 0.316143, acc.: 87%] [G loss: 4.166060]\n",
            "2023 [ D loss: 0.187595, acc.: 93%] [G loss: 5.167856]\n",
            "2024 [ D loss: 0.291625, acc.: 88%] [G loss: 3.333721]\n",
            "2025 [ D loss: 0.398536, acc.: 83%] [G loss: 2.385125]\n",
            "2026 [ D loss: 0.439449, acc.: 74%] [G loss: 3.575639]\n",
            "2027 [ D loss: 0.385666, acc.: 84%] [G loss: 2.671003]\n",
            "2028 [ D loss: 0.412652, acc.: 80%] [G loss: 3.073323]\n",
            "2029 [ D loss: 0.315259, acc.: 95%] [G loss: 4.072397]\n",
            "2030 [ D loss: 0.255689, acc.: 95%] [G loss: 5.333691]\n",
            "2031 [ D loss: 0.283438, acc.: 88%] [G loss: 3.009148]\n",
            "2032 [ D loss: 0.443763, acc.: 83%] [G loss: 2.014434]\n",
            "2033 [ D loss: 0.309959, acc.: 93%] [G loss: 5.450829]\n",
            "2034 [ D loss: 0.230014, acc.: 97%] [G loss: 3.993511]\n",
            "2035 [ D loss: 0.361457, acc.: 86%] [G loss: 5.156370]\n",
            "2036 [ D loss: 0.196284, acc.: 94%] [G loss: 6.660557]\n",
            "2037 [ D loss: 0.257865, acc.: 92%] [G loss: 5.123713]\n",
            "2038 [ D loss: 0.281271, acc.: 88%] [G loss: 4.022158]\n",
            "2039 [ D loss: 0.354235, acc.: 81%] [G loss: 2.370184]\n",
            "2040 [ D loss: 0.334717, acc.: 89%] [G loss: 2.775303]\n",
            "2041 [ D loss: 0.285261, acc.: 91%] [G loss: 2.449203]\n",
            "2042 [ D loss: 0.321360, acc.: 88%] [G loss: 2.114441]\n",
            "2043 [ D loss: 0.353537, acc.: 85%] [G loss: 3.545113]\n",
            "2044 [ D loss: 0.244199, acc.: 93%] [G loss: 4.008802]\n",
            "2045 [ D loss: 0.336399, acc.: 85%] [G loss: 3.652557]\n",
            "2046 [ D loss: 0.306358, acc.: 91%] [G loss: 4.660185]\n",
            "2047 [ D loss: 0.211387, acc.: 96%] [G loss: 4.671849]\n",
            "2048 [ D loss: 0.384383, acc.: 81%] [G loss: 3.804061]\n",
            "2049 [ D loss: 0.379956, acc.: 82%] [G loss: 4.375782]\n",
            "2050 [ D loss: 0.227028, acc.: 95%] [G loss: 4.606188]\n",
            "2051 [ D loss: 0.420942, acc.: 85%] [G loss: 2.749110]\n",
            "2052 [ D loss: 0.437522, acc.: 78%] [G loss: 2.332141]\n",
            "2053 [ D loss: 0.351786, acc.: 90%] [G loss: 3.191691]\n",
            "2054 [ D loss: 0.305616, acc.: 86%] [G loss: 3.285496]\n",
            "2055 [ D loss: 0.441526, acc.: 80%] [G loss: 2.211172]\n",
            "2056 [ D loss: 0.312832, acc.: 95%] [G loss: 2.576910]\n",
            "2057 [ D loss: 0.413992, acc.: 84%] [G loss: 3.492729]\n",
            "2058 [ D loss: 0.449952, acc.: 83%] [G loss: 1.433084]\n",
            "2059 [ D loss: 0.311025, acc.: 90%] [G loss: 3.906449]\n",
            "2060 [ D loss: 0.387626, acc.: 85%] [G loss: 5.012363]\n",
            "2061 [ D loss: 0.284517, acc.: 92%] [G loss: 5.218108]\n",
            "2062 [ D loss: 0.216403, acc.: 93%] [G loss: 3.681262]\n",
            "2063 [ D loss: 0.325127, acc.: 91%] [G loss: 5.149918]\n",
            "2064 [ D loss: 0.259923, acc.: 95%] [G loss: 4.119589]\n",
            "2065 [ D loss: 0.200674, acc.: 98%] [G loss: 3.346437]\n",
            "2066 [ D loss: 0.252721, acc.: 91%] [G loss: 3.538719]\n",
            "2067 [ D loss: 0.352086, acc.: 81%] [G loss: 6.196702]\n",
            "2068 [ D loss: 0.179921, acc.: 95%] [G loss: 4.383532]\n",
            "2069 [ D loss: 0.297675, acc.: 88%] [G loss: 3.766103]\n",
            "2070 [ D loss: 0.283685, acc.: 95%] [G loss: 6.081599]\n",
            "2071 [ D loss: 0.169099, acc.: 97%] [G loss: 4.881964]\n",
            "2072 [ D loss: 0.318322, acc.: 88%] [G loss: 1.755960]\n",
            "2073 [ D loss: 0.373536, acc.: 86%] [G loss: 2.588464]\n",
            "2074 [ D loss: 0.292753, acc.: 94%] [G loss: 3.122385]\n",
            "2075 [ D loss: 0.374603, acc.: 88%] [G loss: 1.506798]\n",
            "2076 [ D loss: 0.329471, acc.: 89%] [G loss: 2.556017]\n",
            "2077 [ D loss: 0.444883, acc.: 80%] [G loss: 1.447526]\n",
            "2078 [ D loss: 0.346321, acc.: 91%] [G loss: 1.804623]\n",
            "2079 [ D loss: 0.395245, acc.: 88%] [G loss: 2.378633]\n",
            "2080 [ D loss: 0.262845, acc.: 94%] [G loss: 3.736696]\n",
            "2081 [ D loss: 0.333795, acc.: 88%] [G loss: 2.632299]\n",
            "2082 [ D loss: 0.219179, acc.: 92%] [G loss: 4.811069]\n",
            "2083 [ D loss: 0.315635, acc.: 95%] [G loss: 1.609547]\n",
            "2084 [ D loss: 0.270294, acc.: 89%] [G loss: 3.340075]\n",
            "2085 [ D loss: 0.258166, acc.: 90%] [G loss: 3.728580]\n",
            "2086 [ D loss: 0.283217, acc.: 90%] [G loss: 4.764541]\n",
            "2087 [ D loss: 0.212025, acc.: 91%] [G loss: 5.747914]\n",
            "2088 [ D loss: 0.170715, acc.: 95%] [G loss: 6.945032]\n",
            "2089 [ D loss: 0.259732, acc.: 91%] [G loss: 4.188958]\n",
            "2090 [ D loss: 0.177150, acc.: 96%] [G loss: 4.196337]\n",
            "2091 [ D loss: 0.427548, acc.: 80%] [G loss: 3.077420]\n",
            "2092 [ D loss: 0.234046, acc.: 92%] [G loss: 4.302790]\n",
            "2093 [ D loss: 0.328548, acc.: 82%] [G loss: 2.833488]\n",
            "2094 [ D loss: 0.411480, acc.: 79%] [G loss: 3.284632]\n",
            "2095 [ D loss: 0.436808, acc.: 82%] [G loss: 2.728899]\n",
            "2096 [ D loss: 0.373250, acc.: 80%] [G loss: 4.547654]\n",
            "2097 [ D loss: 0.538224, acc.: 72%] [G loss: 2.028488]\n",
            "2098 [ D loss: 0.543611, acc.: 66%] [G loss: 2.269867]\n",
            "2099 [ D loss: 0.304036, acc.: 91%] [G loss: 4.370898]\n",
            "2100 [ D loss: 0.319170, acc.: 91%] [G loss: 2.853206]\n",
            "2101 [ D loss: 0.266273, acc.: 93%] [G loss: 4.182974]\n",
            "2102 [ D loss: 0.310578, acc.: 90%] [G loss: 3.313745]\n",
            "2103 [ D loss: 0.198605, acc.: 95%] [G loss: 3.506687]\n",
            "2104 [ D loss: 0.314840, acc.: 88%] [G loss: 2.665681]\n",
            "2105 [ D loss: 0.189086, acc.: 98%] [G loss: 4.889611]\n",
            "2106 [ D loss: 0.344982, acc.: 87%] [G loss: 3.241652]\n",
            "2107 [ D loss: 0.540393, acc.: 70%] [G loss: 2.564132]\n",
            "2108 [ D loss: 0.494168, acc.: 76%] [G loss: 2.037703]\n",
            "2109 [ D loss: 0.407789, acc.: 92%] [G loss: 2.190815]\n",
            "2110 [ D loss: 0.355520, acc.: 86%] [G loss: 6.698788]\n",
            "2111 [ D loss: 0.492424, acc.: 71%] [G loss: 2.192999]\n",
            "2112 [ D loss: 0.318485, acc.: 88%] [G loss: 2.712268]\n",
            "2113 [ D loss: 0.236402, acc.: 95%] [G loss: 4.282938]\n",
            "2114 [ D loss: 0.216226, acc.: 95%] [G loss: 4.670250]\n",
            "2115 [ D loss: 0.291543, acc.: 89%] [G loss: 5.290463]\n",
            "2116 [ D loss: 0.266414, acc.: 90%] [G loss: 3.352853]\n",
            "2117 [ D loss: 0.235199, acc.: 94%] [G loss: 4.019125]\n",
            "2118 [ D loss: 0.280252, acc.: 91%] [G loss: 3.207708]\n",
            "2119 [ D loss: 0.309330, acc.: 89%] [G loss: 4.833185]\n",
            "2120 [ D loss: 0.483000, acc.: 77%] [G loss: 2.166360]\n",
            "2121 [ D loss: 0.318737, acc.: 88%] [G loss: 3.283114]\n",
            "2122 [ D loss: 0.336058, acc.: 87%] [G loss: 3.017705]\n",
            "2123 [ D loss: 0.454388, acc.: 78%] [G loss: 2.671136]\n",
            "2124 [ D loss: 0.377143, acc.: 89%] [G loss: 2.100029]\n",
            "2125 [ D loss: 0.429571, acc.: 80%] [G loss: 2.234588]\n",
            "2126 [ D loss: 0.543505, acc.: 76%] [G loss: 2.112536]\n",
            "2127 [ D loss: 0.678784, acc.: 62%] [G loss: 2.454978]\n",
            "2128 [ D loss: 0.526608, acc.: 81%] [G loss: 3.310924]\n",
            "2129 [ D loss: 0.547790, acc.: 77%] [G loss: 2.561689]\n",
            "2130 [ D loss: 0.459064, acc.: 76%] [G loss: 2.536385]\n",
            "2131 [ D loss: 0.537927, acc.: 77%] [G loss: 2.803240]\n",
            "2132 [ D loss: 0.196884, acc.: 95%] [G loss: 5.199012]\n",
            "2133 [ D loss: 0.489048, acc.: 75%] [G loss: 2.261592]\n",
            "2134 [ D loss: 0.265373, acc.: 92%] [G loss: 2.949119]\n",
            "2135 [ D loss: 0.289447, acc.: 91%] [G loss: 4.096876]\n",
            "2136 [ D loss: 0.424995, acc.: 80%] [G loss: 5.626517]\n",
            "2137 [ D loss: 0.369676, acc.: 84%] [G loss: 3.288021]\n",
            "2138 [ D loss: 0.359184, acc.: 88%] [G loss: 3.776253]\n",
            "2139 [ D loss: 0.299591, acc.: 91%] [G loss: 3.504546]\n",
            "2140 [ D loss: 0.382739, acc.: 79%] [G loss: 2.586372]\n",
            "2141 [ D loss: 0.326066, acc.: 88%] [G loss: 3.388123]\n",
            "2142 [ D loss: 0.477936, acc.: 77%] [G loss: 3.867528]\n",
            "2143 [ D loss: 0.311720, acc.: 97%] [G loss: 3.612247]\n",
            "2144 [ D loss: 0.506394, acc.: 77%] [G loss: 2.202823]\n",
            "2145 [ D loss: 0.350693, acc.: 86%] [G loss: 5.603249]\n",
            "2146 [ D loss: 0.272432, acc.: 92%] [G loss: 8.184546]\n",
            "2147 [ D loss: 0.219233, acc.: 92%] [G loss: 3.871244]\n",
            "2148 [ D loss: 0.298743, acc.: 82%] [G loss: 10.440470]\n",
            "2149 [ D loss: 0.162727, acc.: 94%] [G loss: 3.244611]\n",
            "2150 [ D loss: 0.325433, acc.: 86%] [G loss: 3.446573]\n",
            "2151 [ D loss: 0.352145, acc.: 87%] [G loss: 4.322347]\n",
            "2152 [ D loss: 0.290945, acc.: 88%] [G loss: 4.546990]\n",
            "2153 [ D loss: 0.468416, acc.: 74%] [G loss: 4.485505]\n",
            "2154 [ D loss: 0.385874, acc.: 84%] [G loss: 3.559489]\n",
            "2155 [ D loss: 0.440976, acc.: 80%] [G loss: 2.206068]\n",
            "2156 [ D loss: 0.246726, acc.: 96%] [G loss: 2.310859]\n",
            "2157 [ D loss: 0.346453, acc.: 86%] [G loss: 3.114162]\n",
            "2158 [ D loss: 0.386169, acc.: 86%] [G loss: 2.701965]\n",
            "2159 [ D loss: 0.599298, acc.: 72%] [G loss: 2.169381]\n",
            "2160 [ D loss: 0.417396, acc.: 84%] [G loss: 2.041583]\n",
            "2161 [ D loss: 0.367820, acc.: 91%] [G loss: 2.811814]\n",
            "2162 [ D loss: 0.305555, acc.: 91%] [G loss: 2.950000]\n",
            "2163 [ D loss: 0.343790, acc.: 89%] [G loss: 3.539680]\n",
            "2164 [ D loss: 0.323952, acc.: 89%] [G loss: 3.373685]\n",
            "2165 [ D loss: 0.385260, acc.: 83%] [G loss: 3.419554]\n",
            "2166 [ D loss: 0.255716, acc.: 95%] [G loss: 3.739480]\n",
            "2167 [ D loss: 0.242648, acc.: 91%] [G loss: 3.964465]\n",
            "2168 [ D loss: 0.367049, acc.: 84%] [G loss: 3.421836]\n",
            "2169 [ D loss: 0.246508, acc.: 95%] [G loss: 3.543954]\n",
            "2170 [ D loss: 0.462271, acc.: 80%] [G loss: 3.113545]\n",
            "2171 [ D loss: 0.241873, acc.: 92%] [G loss: 5.255979]\n",
            "2172 [ D loss: 0.568977, acc.: 68%] [G loss: 2.437360]\n",
            "2173 [ D loss: 0.238429, acc.: 95%] [G loss: 6.332894]\n",
            "2174 [ D loss: 0.267154, acc.: 94%] [G loss: 5.510881]\n",
            "2175 [ D loss: 0.241315, acc.: 95%] [G loss: 4.705991]\n",
            "2176 [ D loss: 0.457547, acc.: 72%] [G loss: 2.141290]\n",
            "2177 [ D loss: 0.290465, acc.: 93%] [G loss: 3.053107]\n",
            "2178 [ D loss: 0.419649, acc.: 90%] [G loss: 3.225755]\n",
            "2179 [ D loss: 0.322982, acc.: 88%] [G loss: 2.480655]\n",
            "2180 [ D loss: 0.339428, acc.: 90%] [G loss: 4.015090]\n",
            "2181 [ D loss: 0.304484, acc.: 90%] [G loss: 4.302972]\n",
            "2182 [ D loss: 0.119829, acc.: 99%] [G loss: 5.090915]\n",
            "2183 [ D loss: 0.291135, acc.: 90%] [G loss: 6.874604]\n",
            "2184 [ D loss: 0.216349, acc.: 91%] [G loss: 5.263768]\n",
            "2185 [ D loss: 0.140224, acc.: 97%] [G loss: 7.505885]\n",
            "2186 [ D loss: 0.204004, acc.: 95%] [G loss: 2.934678]\n",
            "2187 [ D loss: 0.616598, acc.: 66%] [G loss: 2.937232]\n",
            "2188 [ D loss: 0.407794, acc.: 83%] [G loss: 2.931672]\n",
            "2189 [ D loss: 0.370002, acc.: 89%] [G loss: 3.055549]\n",
            "2190 [ D loss: 0.384598, acc.: 84%] [G loss: 4.104122]\n",
            "2191 [ D loss: 0.421735, acc.: 77%] [G loss: 2.200074]\n",
            "2192 [ D loss: 0.354446, acc.: 85%] [G loss: 2.669554]\n",
            "2193 [ D loss: 0.246472, acc.: 96%] [G loss: 5.542977]\n",
            "2194 [ D loss: 0.275955, acc.: 88%] [G loss: 4.679737]\n",
            "2195 [ D loss: 0.267821, acc.: 96%] [G loss: 2.712749]\n",
            "2196 [ D loss: 0.317226, acc.: 87%] [G loss: 2.973420]\n",
            "2197 [ D loss: 0.236887, acc.: 93%] [G loss: 4.064162]\n",
            "2198 [ D loss: 0.274203, acc.: 91%] [G loss: 3.748498]\n",
            "2199 [ D loss: 0.420914, acc.: 81%] [G loss: 2.299050]\n",
            "2200 [ D loss: 0.415841, acc.: 80%] [G loss: 3.631042]\n",
            "2201 [ D loss: 0.324702, acc.: 86%] [G loss: 6.684844]\n",
            "2202 [ D loss: 0.224282, acc.: 96%] [G loss: 3.451754]\n",
            "2203 [ D loss: 0.312985, acc.: 84%] [G loss: 4.018067]\n",
            "2204 [ D loss: 0.358438, acc.: 85%] [G loss: 4.476682]\n",
            "2205 [ D loss: 0.416631, acc.: 79%] [G loss: 2.437987]\n",
            "2206 [ D loss: 0.357733, acc.: 86%] [G loss: 2.885280]\n",
            "2207 [ D loss: 0.306573, acc.: 89%] [G loss: 4.430667]\n",
            "2208 [ D loss: 0.338479, acc.: 87%] [G loss: 2.795574]\n",
            "2209 [ D loss: 0.409186, acc.: 80%] [G loss: 2.761338]\n",
            "2210 [ D loss: 0.481933, acc.: 75%] [G loss: 1.942529]\n",
            "2211 [ D loss: 0.406587, acc.: 83%] [G loss: 2.336520]\n",
            "2212 [ D loss: 0.288162, acc.: 94%] [G loss: 2.698200]\n",
            "2213 [ D loss: 0.476431, acc.: 76%] [G loss: 2.581174]\n",
            "2214 [ D loss: 0.383020, acc.: 86%] [G loss: 2.885825]\n",
            "2215 [ D loss: 0.374659, acc.: 87%] [G loss: 2.495514]\n",
            "2216 [ D loss: 0.344372, acc.: 90%] [G loss: 5.948253]\n",
            "2217 [ D loss: 0.269202, acc.: 93%] [G loss: 4.062179]\n",
            "2218 [ D loss: 0.204533, acc.: 97%] [G loss: 4.084627]\n",
            "2219 [ D loss: 0.387424, acc.: 81%] [G loss: 3.793858]\n",
            "2220 [ D loss: 0.266431, acc.: 93%] [G loss: 2.444889]\n",
            "2221 [ D loss: 0.284762, acc.: 88%] [G loss: 4.850921]\n",
            "2222 [ D loss: 0.363539, acc.: 82%] [G loss: 2.880551]\n",
            "2223 [ D loss: 0.216092, acc.: 94%] [G loss: 3.303727]\n",
            "2224 [ D loss: 0.529901, acc.: 75%] [G loss: 3.916437]\n",
            "2225 [ D loss: 0.231189, acc.: 94%] [G loss: 7.314251]\n",
            "2226 [ D loss: 0.224246, acc.: 92%] [G loss: 5.202908]\n",
            "2227 [ D loss: 0.389599, acc.: 82%] [G loss: 4.633224]\n",
            "2228 [ D loss: 0.196713, acc.: 93%] [G loss: 2.833159]\n",
            "2229 [ D loss: 0.194536, acc.: 93%] [G loss: 3.445266]\n",
            "2230 [ D loss: 0.149886, acc.: 96%] [G loss: 7.835882]\n",
            "2231 [ D loss: 0.276575, acc.: 90%] [G loss: 8.048249]\n",
            "2232 [ D loss: 0.526418, acc.: 71%] [G loss: 2.410444]\n",
            "2233 [ D loss: 0.239695, acc.: 91%] [G loss: 4.185420]\n",
            "2234 [ D loss: 0.406729, acc.: 81%] [G loss: 4.268213]\n",
            "2235 [ D loss: 0.348709, acc.: 83%] [G loss: 3.524543]\n",
            "2236 [ D loss: 0.436442, acc.: 80%] [G loss: 2.341897]\n",
            "2237 [ D loss: 0.385482, acc.: 83%] [G loss: 2.626993]\n",
            "2238 [ D loss: 0.403943, acc.: 85%] [G loss: 2.242495]\n",
            "2239 [ D loss: 0.306622, acc.: 92%] [G loss: 5.258740]\n",
            "2240 [ D loss: 0.256755, acc.: 93%] [G loss: 3.383950]\n",
            "2241 [ D loss: 0.312829, acc.: 89%] [G loss: 2.734193]\n",
            "2242 [ D loss: 0.379678, acc.: 84%] [G loss: 3.305404]\n",
            "2243 [ D loss: 0.545500, acc.: 71%] [G loss: 1.964797]\n",
            "2244 [ D loss: 0.309591, acc.: 90%] [G loss: 2.952499]\n",
            "2245 [ D loss: 0.416332, acc.: 84%] [G loss: 3.436371]\n",
            "2246 [ D loss: 0.349879, acc.: 80%] [G loss: 6.927991]\n",
            "2247 [ D loss: 0.192324, acc.: 95%] [G loss: 9.888529]\n",
            "2248 [ D loss: 0.200583, acc.: 94%] [G loss: 8.132397]\n",
            "2249 [ D loss: 0.271031, acc.: 90%] [G loss: 5.359929]\n",
            "2250 [ D loss: 0.306487, acc.: 89%] [G loss: 3.646732]\n",
            "2251 [ D loss: 0.295270, acc.: 88%] [G loss: 3.008649]\n",
            "2252 [ D loss: 0.412660, acc.: 80%] [G loss: 2.534636]\n",
            "2253 [ D loss: 0.343804, acc.: 91%] [G loss: 2.501319]\n",
            "2254 [ D loss: 0.331267, acc.: 91%] [G loss: 2.629679]\n",
            "2255 [ D loss: 0.314099, acc.: 88%] [G loss: 3.158974]\n",
            "2256 [ D loss: 0.319183, acc.: 91%] [G loss: 2.805804]\n",
            "2257 [ D loss: 0.307218, acc.: 91%] [G loss: 2.581946]\n",
            "2258 [ D loss: 0.436446, acc.: 81%] [G loss: 2.699074]\n",
            "2259 [ D loss: 0.543692, acc.: 72%] [G loss: 2.637166]\n",
            "2260 [ D loss: 0.531344, acc.: 76%] [G loss: 1.825327]\n",
            "2261 [ D loss: 0.417630, acc.: 82%] [G loss: 2.821429]\n",
            "2262 [ D loss: 0.413542, acc.: 83%] [G loss: 3.791126]\n",
            "2263 [ D loss: 0.312268, acc.: 88%] [G loss: 3.112262]\n",
            "2264 [ D loss: 0.449764, acc.: 80%] [G loss: 2.644613]\n",
            "2265 [ D loss: 0.341084, acc.: 85%] [G loss: 3.710009]\n",
            "2266 [ D loss: 0.370326, acc.: 86%] [G loss: 2.111133]\n",
            "2267 [ D loss: 0.371868, acc.: 90%] [G loss: 3.429397]\n",
            "2268 [ D loss: 0.244180, acc.: 92%] [G loss: 5.030402]\n",
            "2269 [ D loss: 0.337007, acc.: 91%] [G loss: 2.178517]\n",
            "2270 [ D loss: 0.376566, acc.: 88%] [G loss: 2.937950]\n",
            "2271 [ D loss: 0.515481, acc.: 75%] [G loss: 3.552231]\n",
            "2272 [ D loss: 0.447708, acc.: 72%] [G loss: 3.818319]\n",
            "2273 [ D loss: 0.276143, acc.: 91%] [G loss: 3.434510]\n",
            "2274 [ D loss: 0.296519, acc.: 94%] [G loss: 3.052860]\n",
            "2275 [ D loss: 0.326099, acc.: 90%] [G loss: 3.747818]\n",
            "2276 [ D loss: 0.409144, acc.: 84%] [G loss: 2.643515]\n",
            "2277 [ D loss: 0.418550, acc.: 84%] [G loss: 2.106351]\n",
            "2278 [ D loss: 0.380468, acc.: 83%] [G loss: 3.568916]\n",
            "2279 [ D loss: 0.432430, acc.: 78%] [G loss: 3.366693]\n",
            "2280 [ D loss: 0.259938, acc.: 92%] [G loss: 2.880841]\n",
            "2281 [ D loss: 0.333112, acc.: 87%] [G loss: 3.481149]\n",
            "2282 [ D loss: 0.382316, acc.: 80%] [G loss: 3.546546]\n",
            "2283 [ D loss: 0.473845, acc.: 80%] [G loss: 3.056248]\n",
            "2284 [ D loss: 0.422507, acc.: 83%] [G loss: 2.307757]\n",
            "2285 [ D loss: 0.467602, acc.: 83%] [G loss: 4.975622]\n",
            "2286 [ D loss: 0.347256, acc.: 85%] [G loss: 4.665642]\n",
            "2287 [ D loss: 0.296242, acc.: 89%] [G loss: 3.135473]\n",
            "2288 [ D loss: 0.246829, acc.: 91%] [G loss: 3.686692]\n",
            "2289 [ D loss: 0.551873, acc.: 72%] [G loss: 2.922272]\n",
            "2290 [ D loss: 0.257244, acc.: 91%] [G loss: 5.921576]\n",
            "2291 [ D loss: 0.451974, acc.: 81%] [G loss: 2.556644]\n",
            "2292 [ D loss: 0.238499, acc.: 95%] [G loss: 4.161674]\n",
            "2293 [ D loss: 0.475249, acc.: 77%] [G loss: 1.494395]\n",
            "2294 [ D loss: 0.378991, acc.: 87%] [G loss: 3.471964]\n",
            "2295 [ D loss: 0.459042, acc.: 77%] [G loss: 2.575404]\n",
            "2296 [ D loss: 0.369162, acc.: 91%] [G loss: 3.297739]\n",
            "2297 [ D loss: 0.492831, acc.: 77%] [G loss: 3.255955]\n",
            "2298 [ D loss: 0.330796, acc.: 91%] [G loss: 2.962489]\n",
            "2299 [ D loss: 0.415976, acc.: 88%] [G loss: 2.729752]\n",
            "2300 [ D loss: 0.370664, acc.: 88%] [G loss: 4.961251]\n",
            "2301 [ D loss: 0.429420, acc.: 81%] [G loss: 2.098572]\n",
            "2302 [ D loss: 0.322085, acc.: 91%] [G loss: 3.521331]\n",
            "2303 [ D loss: 0.230664, acc.: 94%] [G loss: 4.192987]\n",
            "2304 [ D loss: 0.328114, acc.: 89%] [G loss: 3.193093]\n",
            "2305 [ D loss: 0.219016, acc.: 91%] [G loss: 4.038869]\n",
            "2306 [ D loss: 0.348503, acc.: 87%] [G loss: 3.224302]\n",
            "2307 [ D loss: 0.342426, acc.: 83%] [G loss: 4.427091]\n",
            "2308 [ D loss: 0.275394, acc.: 93%] [G loss: 7.762992]\n",
            "2309 [ D loss: 0.209840, acc.: 96%] [G loss: 5.487303]\n",
            "2310 [ D loss: 0.367614, acc.: 80%] [G loss: 5.045159]\n",
            "2311 [ D loss: 0.197320, acc.: 96%] [G loss: 3.609645]\n",
            "2312 [ D loss: 0.235523, acc.: 95%] [G loss: 5.388393]\n",
            "2313 [ D loss: 0.275663, acc.: 91%] [G loss: 4.270301]\n",
            "2314 [ D loss: 0.388639, acc.: 83%] [G loss: 4.390271]\n",
            "2315 [ D loss: 0.421183, acc.: 88%] [G loss: 3.864105]\n",
            "2316 [ D loss: 0.252307, acc.: 91%] [G loss: 5.493868]\n",
            "2317 [ D loss: 0.329452, acc.: 90%] [G loss: 3.346930]\n",
            "2318 [ D loss: 0.359893, acc.: 85%] [G loss: 2.579558]\n",
            "2319 [ D loss: 0.353422, acc.: 84%] [G loss: 2.980390]\n",
            "2320 [ D loss: 0.345013, acc.: 90%] [G loss: 3.338774]\n",
            "2321 [ D loss: 0.384588, acc.: 84%] [G loss: 2.456332]\n",
            "2322 [ D loss: 0.399841, acc.: 86%] [G loss: 3.481239]\n",
            "2323 [ D loss: 0.402811, acc.: 84%] [G loss: 3.137807]\n",
            "2324 [ D loss: 0.377524, acc.: 86%] [G loss: 2.503696]\n",
            "2325 [ D loss: 0.400669, acc.: 85%] [G loss: 2.438959]\n",
            "2326 [ D loss: 0.386794, acc.: 91%] [G loss: 3.002098]\n",
            "2327 [ D loss: 0.406451, acc.: 84%] [G loss: 2.431210]\n",
            "2328 [ D loss: 0.369003, acc.: 87%] [G loss: 2.431346]\n",
            "2329 [ D loss: 0.406590, acc.: 88%] [G loss: 2.182673]\n",
            "2330 [ D loss: 0.414374, acc.: 91%] [G loss: 2.689458]\n",
            "2331 [ D loss: 0.262569, acc.: 94%] [G loss: 2.043425]\n",
            "2332 [ D loss: 0.379838, acc.: 88%] [G loss: 3.100595]\n",
            "2333 [ D loss: 0.437395, acc.: 85%] [G loss: 2.450482]\n",
            "2334 [ D loss: 0.383369, acc.: 83%] [G loss: 2.859797]\n",
            "2335 [ D loss: 0.477043, acc.: 79%] [G loss: 3.970483]\n",
            "2336 [ D loss: 0.397972, acc.: 77%] [G loss: 4.059994]\n",
            "2337 [ D loss: 0.222926, acc.: 95%] [G loss: 5.259887]\n",
            "2338 [ D loss: 0.318507, acc.: 91%] [G loss: 2.508993]\n",
            "2339 [ D loss: 0.230641, acc.: 90%] [G loss: 3.838627]\n",
            "2340 [ D loss: 0.330059, acc.: 86%] [G loss: 2.853453]\n",
            "2341 [ D loss: 0.294564, acc.: 95%] [G loss: 7.898938]\n",
            "2342 [ D loss: 0.251194, acc.: 94%] [G loss: 5.125105]\n",
            "2343 [ D loss: 0.300189, acc.: 88%] [G loss: 3.546393]\n",
            "2344 [ D loss: 0.336948, acc.: 86%] [G loss: 6.302353]\n",
            "2345 [ D loss: 0.217156, acc.: 96%] [G loss: 3.558669]\n",
            "2346 [ D loss: 0.352149, acc.: 83%] [G loss: 2.420804]\n",
            "2347 [ D loss: 0.291737, acc.: 89%] [G loss: 6.661089]\n",
            "2348 [ D loss: 0.152513, acc.: 96%] [G loss: 5.435794]\n",
            "2349 [ D loss: 0.227148, acc.: 91%] [G loss: 7.496495]\n",
            "2350 [ D loss: 0.141541, acc.: 98%] [G loss: 6.644410]\n",
            "2351 [ D loss: 0.223816, acc.: 90%] [G loss: 3.322709]\n",
            "2352 [ D loss: 0.245924, acc.: 91%] [G loss: 7.167109]\n",
            "2353 [ D loss: 0.287500, acc.: 90%] [G loss: 3.306726]\n",
            "2354 [ D loss: 0.327992, acc.: 88%] [G loss: 3.343650]\n",
            "2355 [ D loss: 0.398643, acc.: 87%] [G loss: 2.768911]\n",
            "2356 [ D loss: 0.381774, acc.: 89%] [G loss: 3.472105]\n",
            "2357 [ D loss: 0.366174, acc.: 90%] [G loss: 2.554725]\n",
            "2358 [ D loss: 0.407847, acc.: 82%] [G loss: 2.481497]\n",
            "2359 [ D loss: 0.554511, acc.: 76%] [G loss: 2.488456]\n",
            "2360 [ D loss: 0.383231, acc.: 84%] [G loss: 2.714778]\n",
            "2361 [ D loss: 0.535616, acc.: 73%] [G loss: 3.483316]\n",
            "2362 [ D loss: 0.222146, acc.: 93%] [G loss: 5.482468]\n",
            "2363 [ D loss: 0.370679, acc.: 78%] [G loss: 2.716221]\n",
            "2364 [ D loss: 0.353454, acc.: 86%] [G loss: 5.160470]\n",
            "2365 [ D loss: 0.295370, acc.: 88%] [G loss: 7.460933]\n",
            "2366 [ D loss: 0.171560, acc.: 95%] [G loss: 6.591138]\n",
            "2367 [ D loss: 0.319363, acc.: 85%] [G loss: 6.375738]\n",
            "2368 [ D loss: 0.175579, acc.: 95%] [G loss: 8.472428]\n",
            "2369 [ D loss: 0.224751, acc.: 94%] [G loss: 5.808158]\n",
            "2370 [ D loss: 0.433572, acc.: 78%] [G loss: 2.390242]\n",
            "2371 [ D loss: 0.313798, acc.: 93%] [G loss: 3.220324]\n",
            "2372 [ D loss: 0.354121, acc.: 91%] [G loss: 2.779647]\n",
            "2373 [ D loss: 0.349296, acc.: 90%] [G loss: 3.151805]\n",
            "2374 [ D loss: 0.365765, acc.: 91%] [G loss: 2.928016]\n",
            "2375 [ D loss: 0.287610, acc.: 92%] [G loss: 2.851526]\n",
            "2376 [ D loss: 0.345161, acc.: 91%] [G loss: 2.886311]\n",
            "2377 [ D loss: 0.291854, acc.: 92%] [G loss: 3.133245]\n",
            "2378 [ D loss: 0.358013, acc.: 88%] [G loss: 2.160062]\n",
            "2379 [ D loss: 0.199310, acc.: 95%] [G loss: 2.094470]\n",
            "2380 [ D loss: 0.309249, acc.: 88%] [G loss: 4.274444]\n",
            "2381 [ D loss: 0.493204, acc.: 83%] [G loss: 3.134831]\n",
            "2382 [ D loss: 0.324671, acc.: 90%] [G loss: 4.729671]\n",
            "2383 [ D loss: 0.257887, acc.: 93%] [G loss: 5.721257]\n",
            "2384 [ D loss: 0.395454, acc.: 87%] [G loss: 2.918968]\n",
            "2385 [ D loss: 0.296561, acc.: 91%] [G loss: 3.806739]\n",
            "2386 [ D loss: 0.448223, acc.: 83%] [G loss: 4.051971]\n",
            "2387 [ D loss: 0.265498, acc.: 97%] [G loss: 3.656898]\n",
            "2388 [ D loss: 0.321130, acc.: 90%] [G loss: 3.752813]\n",
            "2389 [ D loss: 0.407112, acc.: 88%] [G loss: 3.508301]\n",
            "2390 [ D loss: 0.287625, acc.: 96%] [G loss: 3.209189]\n",
            "2391 [ D loss: 0.305961, acc.: 92%] [G loss: 3.471375]\n",
            "2392 [ D loss: 0.275997, acc.: 93%] [G loss: 3.219543]\n",
            "2393 [ D loss: 0.351909, acc.: 89%] [G loss: 3.140318]\n",
            "2394 [ D loss: 0.364885, acc.: 88%] [G loss: 2.799637]\n",
            "2395 [ D loss: 0.494940, acc.: 78%] [G loss: 2.830097]\n",
            "2396 [ D loss: 0.376051, acc.: 83%] [G loss: 3.402086]\n",
            "2397 [ D loss: 0.307124, acc.: 91%] [G loss: 3.291934]\n",
            "2398 [ D loss: 0.239344, acc.: 92%] [G loss: 3.502664]\n",
            "2399 [ D loss: 0.348284, acc.: 90%] [G loss: 3.058481]\n",
            "2400 [ D loss: 0.202515, acc.: 97%] [G loss: 3.532962]\n",
            "2401 [ D loss: 0.360448, acc.: 88%] [G loss: 2.738674]\n",
            "2402 [ D loss: 0.237466, acc.: 96%] [G loss: 3.332762]\n",
            "2403 [ D loss: 0.280781, acc.: 94%] [G loss: 2.298238]\n",
            "2404 [ D loss: 0.355535, acc.: 91%] [G loss: 3.563738]\n",
            "2405 [ D loss: 0.269041, acc.: 95%] [G loss: 4.520350]\n",
            "2406 [ D loss: 0.277507, acc.: 94%] [G loss: 3.914892]\n",
            "2407 [ D loss: 0.165735, acc.: 97%] [G loss: 8.842863]\n",
            "2408 [ D loss: 0.145022, acc.: 95%] [G loss: 4.127956]\n",
            "2409 [ D loss: 0.394752, acc.: 83%] [G loss: 5.935421]\n",
            "2410 [ D loss: 0.241172, acc.: 90%] [G loss: 3.495667]\n",
            "2411 [ D loss: 0.429434, acc.: 81%] [G loss: 3.306990]\n",
            "2412 [ D loss: 0.315276, acc.: 93%] [G loss: 3.288368]\n",
            "2413 [ D loss: 0.271084, acc.: 93%] [G loss: 3.857850]\n",
            "2414 [ D loss: 0.322115, acc.: 88%] [G loss: 4.622950]\n",
            "2415 [ D loss: 0.422021, acc.: 82%] [G loss: 2.417593]\n",
            "2416 [ D loss: 0.289443, acc.: 90%] [G loss: 2.552163]\n",
            "2417 [ D loss: 0.405667, acc.: 85%] [G loss: 2.332096]\n",
            "2418 [ D loss: 0.488367, acc.: 79%] [G loss: 2.919194]\n",
            "2419 [ D loss: 0.393154, acc.: 85%] [G loss: 4.790332]\n",
            "2420 [ D loss: 0.260214, acc.: 93%] [G loss: 2.516030]\n",
            "2421 [ D loss: 0.354464, acc.: 87%] [G loss: 3.716257]\n",
            "2422 [ D loss: 0.282611, acc.: 90%] [G loss: 6.548347]\n",
            "2423 [ D loss: 0.301758, acc.: 91%] [G loss: 3.603438]\n",
            "2424 [ D loss: 0.271338, acc.: 90%] [G loss: 3.934284]\n",
            "2425 [ D loss: 0.260446, acc.: 94%] [G loss: 3.103741]\n",
            "2426 [ D loss: 0.333738, acc.: 89%] [G loss: 3.349786]\n",
            "2427 [ D loss: 0.301288, acc.: 91%] [G loss: 3.064081]\n",
            "2428 [ D loss: 0.413351, acc.: 87%] [G loss: 2.926598]\n",
            "2429 [ D loss: 0.282051, acc.: 92%] [G loss: 3.770702]\n",
            "2430 [ D loss: 0.339642, acc.: 92%] [G loss: 2.459728]\n",
            "2431 [ D loss: 0.249763, acc.: 94%] [G loss: 3.249972]\n",
            "2432 [ D loss: 0.380068, acc.: 84%] [G loss: 2.476217]\n",
            "2433 [ D loss: 0.290164, acc.: 91%] [G loss: 2.664814]\n",
            "2434 [ D loss: 0.255030, acc.: 95%] [G loss: 4.511182]\n",
            "2435 [ D loss: 0.323404, acc.: 90%] [G loss: 2.673428]\n",
            "2436 [ D loss: 0.370745, acc.: 86%] [G loss: 3.664098]\n",
            "2437 [ D loss: 0.232319, acc.: 94%] [G loss: 2.906303]\n",
            "2438 [ D loss: 0.310540, acc.: 88%] [G loss: 5.802829]\n",
            "2439 [ D loss: 0.142434, acc.: 98%] [G loss: 4.712590]\n",
            "2440 [ D loss: 0.238792, acc.: 93%] [G loss: 3.316524]\n",
            "2441 [ D loss: 0.306503, acc.: 88%] [G loss: 4.935869]\n",
            "2442 [ D loss: 0.237082, acc.: 91%] [G loss: 2.664241]\n",
            "2443 [ D loss: 0.179044, acc.: 95%] [G loss: 2.648949]\n",
            "2444 [ D loss: 0.394671, acc.: 76%] [G loss: 3.859080]\n",
            "2445 [ D loss: 0.446986, acc.: 75%] [G loss: 3.762432]\n",
            "2446 [ D loss: 0.321755, acc.: 96%] [G loss: 3.056813]\n",
            "2447 [ D loss: 0.379241, acc.: 87%] [G loss: 4.422654]\n",
            "2448 [ D loss: 0.285545, acc.: 91%] [G loss: 3.830468]\n",
            "2449 [ D loss: 0.233820, acc.: 93%] [G loss: 4.365014]\n",
            "2450 [ D loss: 0.461031, acc.: 73%] [G loss: 2.610403]\n",
            "2451 [ D loss: 0.413068, acc.: 80%] [G loss: 4.032634]\n",
            "2452 [ D loss: 0.498781, acc.: 73%] [G loss: 2.315242]\n",
            "2453 [ D loss: 0.310228, acc.: 89%] [G loss: 3.678821]\n",
            "2454 [ D loss: 0.356691, acc.: 91%] [G loss: 3.900689]\n",
            "2455 [ D loss: 0.344527, acc.: 90%] [G loss: 3.095396]\n",
            "2456 [ D loss: 0.396420, acc.: 80%] [G loss: 3.385720]\n",
            "2457 [ D loss: 0.296535, acc.: 92%] [G loss: 3.103213]\n",
            "2458 [ D loss: 0.250836, acc.: 95%] [G loss: 3.376908]\n",
            "2459 [ D loss: 0.295473, acc.: 92%] [G loss: 2.792059]\n",
            "2460 [ D loss: 0.385625, acc.: 87%] [G loss: 4.995539]\n",
            "2461 [ D loss: 0.441528, acc.: 77%] [G loss: 3.561728]\n",
            "2462 [ D loss: 0.252764, acc.: 91%] [G loss: 4.329981]\n",
            "2463 [ D loss: 0.371044, acc.: 88%] [G loss: 3.068990]\n",
            "2464 [ D loss: 0.234347, acc.: 95%] [G loss: 2.982512]\n",
            "2465 [ D loss: 0.328341, acc.: 87%] [G loss: 2.922232]\n",
            "2466 [ D loss: 0.250916, acc.: 94%] [G loss: 2.505672]\n",
            "2467 [ D loss: 0.483808, acc.: 76%] [G loss: 2.131002]\n",
            "2468 [ D loss: 0.354784, acc.: 91%] [G loss: 4.766494]\n",
            "2469 [ D loss: 0.288954, acc.: 88%] [G loss: 3.253943]\n",
            "2470 [ D loss: 0.289091, acc.: 92%] [G loss: 5.557661]\n",
            "2471 [ D loss: 0.279862, acc.: 92%] [G loss: 5.223303]\n",
            "2472 [ D loss: 0.318942, acc.: 88%] [G loss: 2.792950]\n",
            "2473 [ D loss: 0.227864, acc.: 93%] [G loss: 2.486300]\n",
            "2474 [ D loss: 0.260998, acc.: 91%] [G loss: 3.935180]\n",
            "2475 [ D loss: 0.251066, acc.: 91%] [G loss: 5.870788]\n",
            "2476 [ D loss: 0.197826, acc.: 95%] [G loss: 3.364526]\n",
            "2477 [ D loss: 0.381920, acc.: 82%] [G loss: 3.077016]\n",
            "2478 [ D loss: 0.251319, acc.: 95%] [G loss: 3.951576]\n",
            "2479 [ D loss: 0.455446, acc.: 71%] [G loss: 2.631970]\n",
            "2480 [ D loss: 0.368415, acc.: 90%] [G loss: 2.688563]\n",
            "2481 [ D loss: 0.356023, acc.: 90%] [G loss: 3.070935]\n",
            "2482 [ D loss: 0.303583, acc.: 89%] [G loss: 4.122129]\n",
            "2483 [ D loss: 0.268201, acc.: 95%] [G loss: 4.285176]\n",
            "2484 [ D loss: 0.225056, acc.: 93%] [G loss: 3.110021]\n",
            "2485 [ D loss: 0.299262, acc.: 92%] [G loss: 3.875399]\n",
            "2486 [ D loss: 0.348014, acc.: 93%] [G loss: 4.823915]\n",
            "2487 [ D loss: 0.207430, acc.: 93%] [G loss: 8.369541]\n",
            "2488 [ D loss: 0.346805, acc.: 87%] [G loss: 4.617039]\n",
            "2489 [ D loss: 0.217069, acc.: 93%] [G loss: 8.196031]\n",
            "2490 [ D loss: 0.229977, acc.: 95%] [G loss: 3.324709]\n",
            "2491 [ D loss: 0.327174, acc.: 90%] [G loss: 3.545228]\n",
            "2492 [ D loss: 0.286248, acc.: 90%] [G loss: 3.658208]\n",
            "2493 [ D loss: 0.247514, acc.: 89%] [G loss: 5.322997]\n",
            "2494 [ D loss: 0.287756, acc.: 91%] [G loss: 3.079066]\n",
            "2495 [ D loss: 0.348294, acc.: 89%] [G loss: 3.924574]\n",
            "2496 [ D loss: 0.170859, acc.: 95%] [G loss: 6.620774]\n",
            "2497 [ D loss: 0.450380, acc.: 77%] [G loss: 2.767855]\n",
            "2498 [ D loss: 0.296914, acc.: 90%] [G loss: 3.801478]\n",
            "2499 [ D loss: 0.373867, acc.: 88%] [G loss: 3.113566]\n",
            "2500 [ D loss: 0.339809, acc.: 90%] [G loss: 2.537883]\n",
            "2501 [ D loss: 0.325004, acc.: 95%] [G loss: 2.457527]\n",
            "2502 [ D loss: 0.232066, acc.: 96%] [G loss: 4.808658]\n",
            "2503 [ D loss: 0.448620, acc.: 78%] [G loss: 2.767443]\n",
            "2504 [ D loss: 0.189228, acc.: 95%] [G loss: 3.490113]\n",
            "2505 [ D loss: 0.278749, acc.: 91%] [G loss: 3.716465]\n",
            "2506 [ D loss: 0.212750, acc.: 93%] [G loss: 4.813991]\n",
            "2507 [ D loss: 0.219618, acc.: 95%] [G loss: 4.641141]\n",
            "2508 [ D loss: 0.377214, acc.: 85%] [G loss: 3.126303]\n",
            "2509 [ D loss: 0.364068, acc.: 89%] [G loss: 2.540339]\n",
            "2510 [ D loss: 0.230688, acc.: 95%] [G loss: 5.706447]\n",
            "2511 [ D loss: 0.392448, acc.: 84%] [G loss: 3.655198]\n",
            "2512 [ D loss: 0.175790, acc.: 99%] [G loss: 5.918220]\n",
            "2513 [ D loss: 0.214218, acc.: 95%] [G loss: 2.674126]\n",
            "2514 [ D loss: 0.280069, acc.: 91%] [G loss: 3.661571]\n",
            "2515 [ D loss: 0.286281, acc.: 90%] [G loss: 3.277362]\n",
            "2516 [ D loss: 0.364207, acc.: 89%] [G loss: 3.632307]\n",
            "2517 [ D loss: 0.234406, acc.: 93%] [G loss: 4.679144]\n",
            "2518 [ D loss: 0.317633, acc.: 90%] [G loss: 2.574067]\n",
            "2519 [ D loss: 0.290761, acc.: 93%] [G loss: 2.913040]\n",
            "2520 [ D loss: 0.346021, acc.: 89%] [G loss: 2.782556]\n",
            "2521 [ D loss: 0.430428, acc.: 84%] [G loss: 2.155837]\n",
            "2522 [ D loss: 0.282867, acc.: 94%] [G loss: 2.948362]\n",
            "2523 [ D loss: 0.276819, acc.: 91%] [G loss: 3.783130]\n",
            "2524 [ D loss: 0.347128, acc.: 91%] [G loss: 2.974096]\n",
            "2525 [ D loss: 0.293383, acc.: 90%] [G loss: 3.324699]\n",
            "2526 [ D loss: 0.350146, acc.: 86%] [G loss: 2.752501]\n",
            "2527 [ D loss: 0.338476, acc.: 85%] [G loss: 2.169552]\n",
            "2528 [ D loss: 0.357595, acc.: 90%] [G loss: 2.962189]\n",
            "2529 [ D loss: 0.272532, acc.: 92%] [G loss: 4.250239]\n",
            "2530 [ D loss: 0.232775, acc.: 95%] [G loss: 3.265694]\n",
            "2531 [ D loss: 0.251223, acc.: 93%] [G loss: 4.014355]\n",
            "2532 [ D loss: 0.412293, acc.: 84%] [G loss: 2.540994]\n",
            "2533 [ D loss: 0.293854, acc.: 93%] [G loss: 3.397419]\n",
            "2534 [ D loss: 0.426107, acc.: 85%] [G loss: 2.759072]\n",
            "2535 [ D loss: 0.348647, acc.: 88%] [G loss: 4.755601]\n",
            "2536 [ D loss: 0.317199, acc.: 88%] [G loss: 5.342603]\n",
            "2537 [ D loss: 0.168278, acc.: 96%] [G loss: 8.024343]\n",
            "2538 [ D loss: 0.208812, acc.: 91%] [G loss: 3.768108]\n",
            "2539 [ D loss: 0.361259, acc.: 83%] [G loss: 8.853802]\n",
            "2540 [ D loss: 0.175050, acc.: 98%] [G loss: 5.429822]\n",
            "2541 [ D loss: 0.283527, acc.: 91%] [G loss: 5.232405]\n",
            "2542 [ D loss: 0.282323, acc.: 90%] [G loss: 3.663577]\n",
            "2543 [ D loss: 0.186804, acc.: 96%] [G loss: 6.392501]\n",
            "2544 [ D loss: 0.245170, acc.: 93%] [G loss: 5.378125]\n",
            "2545 [ D loss: 0.267229, acc.: 89%] [G loss: 9.215101]\n",
            "2546 [ D loss: 0.145307, acc.: 97%] [G loss: 6.850155]\n",
            "2547 [ D loss: 0.250676, acc.: 90%] [G loss: 3.893854]\n",
            "2548 [ D loss: 0.207722, acc.: 93%] [G loss: 6.776491]\n",
            "2549 [ D loss: 0.222063, acc.: 91%] [G loss: 5.144426]\n",
            "2550 [ D loss: 0.420111, acc.: 80%] [G loss: 2.967425]\n",
            "2551 [ D loss: 0.195368, acc.: 96%] [G loss: 5.214618]\n",
            "2552 [ D loss: 0.216928, acc.: 94%] [G loss: 3.166937]\n",
            "2553 [ D loss: 0.377196, acc.: 83%] [G loss: 2.975531]\n",
            "2554 [ D loss: 0.264575, acc.: 95%] [G loss: 4.705940]\n",
            "2555 [ D loss: 0.289029, acc.: 91%] [G loss: 2.815043]\n",
            "2556 [ D loss: 0.402194, acc.: 87%] [G loss: 2.760409]\n",
            "2557 [ D loss: 0.206961, acc.: 97%] [G loss: 3.198001]\n",
            "2558 [ D loss: 0.464181, acc.: 77%] [G loss: 3.480760]\n",
            "2559 [ D loss: 0.253098, acc.: 94%] [G loss: 3.033136]\n",
            "2560 [ D loss: 0.303213, acc.: 91%] [G loss: 3.481442]\n",
            "2561 [ D loss: 0.226339, acc.: 92%] [G loss: 5.699309]\n",
            "2562 [ D loss: 0.382493, acc.: 87%] [G loss: 4.648290]\n",
            "2563 [ D loss: 0.264379, acc.: 91%] [G loss: 4.668940]\n",
            "2564 [ D loss: 0.237367, acc.: 95%] [G loss: 3.613910]\n",
            "2565 [ D loss: 0.404542, acc.: 84%] [G loss: 3.393931]\n",
            "2566 [ D loss: 0.284743, acc.: 89%] [G loss: 3.854247]\n",
            "2567 [ D loss: 0.314250, acc.: 93%] [G loss: 2.845699]\n",
            "2568 [ D loss: 0.287199, acc.: 92%] [G loss: 3.532588]\n",
            "2569 [ D loss: 0.313173, acc.: 91%] [G loss: 2.752745]\n",
            "2570 [ D loss: 0.319521, acc.: 93%] [G loss: 3.874790]\n",
            "2571 [ D loss: 0.209258, acc.: 98%] [G loss: 6.427810]\n",
            "2572 [ D loss: 0.266006, acc.: 93%] [G loss: 4.293701]\n",
            "2573 [ D loss: 0.263782, acc.: 89%] [G loss: 3.332391]\n",
            "2574 [ D loss: 0.231097, acc.: 94%] [G loss: 3.766913]\n",
            "2575 [ D loss: 0.338436, acc.: 90%] [G loss: 3.107480]\n",
            "2576 [ D loss: 0.401587, acc.: 86%] [G loss: 4.863407]\n",
            "2577 [ D loss: 0.223882, acc.: 94%] [G loss: 6.997225]\n",
            "2578 [ D loss: 0.220149, acc.: 91%] [G loss: 3.350376]\n",
            "2579 [ D loss: 0.232956, acc.: 95%] [G loss: 5.074368]\n",
            "2580 [ D loss: 0.272597, acc.: 90%] [G loss: 3.775371]\n",
            "2581 [ D loss: 0.275854, acc.: 91%] [G loss: 3.407403]\n",
            "2582 [ D loss: 0.351594, acc.: 90%] [G loss: 2.698503]\n",
            "2583 [ D loss: 0.309352, acc.: 90%] [G loss: 3.203109]\n",
            "2584 [ D loss: 0.333468, acc.: 95%] [G loss: 2.268273]\n",
            "2585 [ D loss: 0.369728, acc.: 90%] [G loss: 3.330200]\n",
            "2586 [ D loss: 0.306613, acc.: 94%] [G loss: 3.594826]\n",
            "2587 [ D loss: 0.266731, acc.: 94%] [G loss: 2.774642]\n",
            "2588 [ D loss: 0.235002, acc.: 95%] [G loss: 3.604620]\n",
            "2589 [ D loss: 0.360576, acc.: 90%] [G loss: 3.144613]\n",
            "2590 [ D loss: 0.236973, acc.: 95%] [G loss: 5.275644]\n",
            "2591 [ D loss: 0.318699, acc.: 91%] [G loss: 3.986229]\n",
            "2592 [ D loss: 0.161379, acc.: 95%] [G loss: 5.798495]\n",
            "2593 [ D loss: 0.186497, acc.: 97%] [G loss: 4.236790]\n",
            "2594 [ D loss: 0.188541, acc.: 94%] [G loss: 6.443161]\n",
            "2595 [ D loss: 0.234300, acc.: 93%] [G loss: 3.627580]\n",
            "2596 [ D loss: 0.293327, acc.: 92%] [G loss: 5.241580]\n",
            "2597 [ D loss: 0.213161, acc.: 96%] [G loss: 6.624114]\n",
            "2598 [ D loss: 0.240520, acc.: 95%] [G loss: 3.213189]\n",
            "2599 [ D loss: 0.191040, acc.: 96%] [G loss: 4.913224]\n",
            "2600 [ D loss: 0.384692, acc.: 86%] [G loss: 3.058665]\n",
            "2601 [ D loss: 0.217930, acc.: 98%] [G loss: 3.645329]\n",
            "2602 [ D loss: 0.274887, acc.: 90%] [G loss: 3.826066]\n",
            "2603 [ D loss: 0.264656, acc.: 95%] [G loss: 5.158190]\n",
            "2604 [ D loss: 0.346830, acc.: 85%] [G loss: 3.085160]\n",
            "2605 [ D loss: 0.313762, acc.: 90%] [G loss: 3.380823]\n",
            "2606 [ D loss: 0.456324, acc.: 81%] [G loss: 3.914795]\n",
            "2607 [ D loss: 0.552390, acc.: 75%] [G loss: 2.491639]\n",
            "2608 [ D loss: 0.218466, acc.: 97%] [G loss: 3.054258]\n",
            "2609 [ D loss: 0.320870, acc.: 88%] [G loss: 3.821662]\n",
            "2610 [ D loss: 0.308834, acc.: 91%] [G loss: 10.319155]\n",
            "2611 [ D loss: 0.274848, acc.: 88%] [G loss: 4.955451]\n",
            "2612 [ D loss: 0.315259, acc.: 87%] [G loss: 3.450736]\n",
            "2613 [ D loss: 0.255411, acc.: 92%] [G loss: 3.256103]\n",
            "2614 [ D loss: 0.384190, acc.: 85%] [G loss: 3.236300]\n",
            "2615 [ D loss: 0.360406, acc.: 85%] [G loss: 2.511356]\n",
            "2616 [ D loss: 0.285245, acc.: 94%] [G loss: 3.941666]\n",
            "2617 [ D loss: 0.164419, acc.: 98%] [G loss: 4.998576]\n",
            "2618 [ D loss: 0.251013, acc.: 88%] [G loss: 3.950590]\n",
            "2619 [ D loss: 0.287510, acc.: 90%] [G loss: 3.303814]\n",
            "2620 [ D loss: 0.179087, acc.: 96%] [G loss: 4.890100]\n",
            "2621 [ D loss: 0.233077, acc.: 95%] [G loss: 4.125858]\n",
            "2622 [ D loss: 0.257096, acc.: 88%] [G loss: 3.852327]\n",
            "2623 [ D loss: 0.249633, acc.: 91%] [G loss: 3.999044]\n",
            "2624 [ D loss: 0.219747, acc.: 95%] [G loss: 3.684272]\n",
            "2625 [ D loss: 0.332539, acc.: 86%] [G loss: 4.619296]\n",
            "2626 [ D loss: 0.265622, acc.: 88%] [G loss: 4.546150]\n",
            "2627 [ D loss: 0.270315, acc.: 93%] [G loss: 2.713016]\n",
            "2628 [ D loss: 0.261125, acc.: 90%] [G loss: 3.355346]\n",
            "2629 [ D loss: 0.490254, acc.: 86%] [G loss: 2.572687]\n",
            "2630 [ D loss: 0.394936, acc.: 84%] [G loss: 4.018266]\n",
            "2631 [ D loss: 0.341979, acc.: 88%] [G loss: 3.875301]\n",
            "2632 [ D loss: 0.193075, acc.: 94%] [G loss: 4.739108]\n",
            "2633 [ D loss: 0.399358, acc.: 87%] [G loss: 3.377670]\n",
            "2634 [ D loss: 0.304206, acc.: 93%] [G loss: 3.591370]\n",
            "2635 [ D loss: 0.250514, acc.: 91%] [G loss: 4.334182]\n",
            "2636 [ D loss: 0.312872, acc.: 88%] [G loss: 2.531002]\n",
            "2637 [ D loss: 0.256242, acc.: 92%] [G loss: 3.667315]\n",
            "2638 [ D loss: 0.265881, acc.: 92%] [G loss: 4.061329]\n",
            "2639 [ D loss: 0.296436, acc.: 94%] [G loss: 2.547205]\n",
            "2640 [ D loss: 0.352616, acc.: 91%] [G loss: 3.468221]\n",
            "2641 [ D loss: 0.244273, acc.: 96%] [G loss: 3.737018]\n",
            "2642 [ D loss: 0.298398, acc.: 90%] [G loss: 3.938723]\n",
            "2643 [ D loss: 0.227205, acc.: 93%] [G loss: 6.848899]\n",
            "2644 [ D loss: 0.403841, acc.: 83%] [G loss: 3.262014]\n",
            "2645 [ D loss: 0.155060, acc.: 97%] [G loss: 4.913057]\n",
            "2646 [ D loss: 0.302887, acc.: 89%] [G loss: 4.650536]\n",
            "2647 [ D loss: 0.198575, acc.: 95%] [G loss: 7.866139]\n",
            "2648 [ D loss: 0.239370, acc.: 92%] [G loss: 2.533964]\n",
            "2649 [ D loss: 0.223927, acc.: 95%] [G loss: 5.676474]\n",
            "2650 [ D loss: 0.165369, acc.: 95%] [G loss: 9.321033]\n",
            "2651 [ D loss: 0.307385, acc.: 88%] [G loss: 3.952920]\n",
            "2652 [ D loss: 0.171086, acc.: 97%] [G loss: 3.524924]\n",
            "2653 [ D loss: 0.350467, acc.: 84%] [G loss: 4.475678]\n",
            "2654 [ D loss: 0.194827, acc.: 98%] [G loss: 4.566504]\n",
            "2655 [ D loss: 0.272634, acc.: 94%] [G loss: 3.921233]\n",
            "2656 [ D loss: 0.243794, acc.: 91%] [G loss: 4.890784]\n",
            "2657 [ D loss: 0.345432, acc.: 84%] [G loss: 4.938079]\n",
            "2658 [ D loss: 0.216883, acc.: 92%] [G loss: 4.135872]\n",
            "2659 [ D loss: 0.282799, acc.: 92%] [G loss: 4.435809]\n",
            "2660 [ D loss: 0.188499, acc.: 95%] [G loss: 6.425895]\n",
            "2661 [ D loss: 0.338608, acc.: 84%] [G loss: 3.476817]\n",
            "2662 [ D loss: 0.270913, acc.: 91%] [G loss: 3.395840]\n",
            "2663 [ D loss: 0.269719, acc.: 89%] [G loss: 4.264984]\n",
            "2664 [ D loss: 0.338894, acc.: 88%] [G loss: 3.598987]\n",
            "2665 [ D loss: 0.301011, acc.: 88%] [G loss: 2.845818]\n",
            "2666 [ D loss: 0.223475, acc.: 94%] [G loss: 3.830225]\n",
            "2667 [ D loss: 0.263964, acc.: 89%] [G loss: 3.471042]\n",
            "2668 [ D loss: 0.242584, acc.: 94%] [G loss: 3.571797]\n",
            "2669 [ D loss: 0.312074, acc.: 89%] [G loss: 3.322732]\n",
            "2670 [ D loss: 0.289286, acc.: 92%] [G loss: 3.826297]\n",
            "2671 [ D loss: 0.254241, acc.: 92%] [G loss: 5.199503]\n",
            "2672 [ D loss: 0.273151, acc.: 91%] [G loss: 2.621209]\n",
            "2673 [ D loss: 0.206394, acc.: 98%] [G loss: 3.214733]\n",
            "2674 [ D loss: 0.277575, acc.: 91%] [G loss: 4.099416]\n",
            "2675 [ D loss: 0.328983, acc.: 88%] [G loss: 3.379108]\n",
            "2676 [ D loss: 0.274752, acc.: 87%] [G loss: 3.277683]\n",
            "2677 [ D loss: 0.223449, acc.: 95%] [G loss: 3.464011]\n",
            "2678 [ D loss: 0.374392, acc.: 84%] [G loss: 2.940067]\n",
            "2679 [ D loss: 0.322636, acc.: 84%] [G loss: 4.445049]\n",
            "2680 [ D loss: 0.616866, acc.: 69%] [G loss: 3.119274]\n",
            "2681 [ D loss: 0.290034, acc.: 90%] [G loss: 5.014879]\n",
            "2682 [ D loss: 0.242636, acc.: 95%] [G loss: 4.504465]\n",
            "2683 [ D loss: 0.369918, acc.: 88%] [G loss: 3.551702]\n",
            "2684 [ D loss: 0.253430, acc.: 93%] [G loss: 3.386378]\n",
            "2685 [ D loss: 0.259724, acc.: 93%] [G loss: 3.295789]\n",
            "2686 [ D loss: 0.334534, acc.: 88%] [G loss: 4.067491]\n",
            "2687 [ D loss: 0.253970, acc.: 93%] [G loss: 4.374481]\n",
            "2688 [ D loss: 0.279452, acc.: 93%] [G loss: 2.988088]\n",
            "2689 [ D loss: 0.213242, acc.: 95%] [G loss: 4.527059]\n",
            "2690 [ D loss: 0.365645, acc.: 84%] [G loss: 3.297658]\n",
            "2691 [ D loss: 0.302221, acc.: 91%] [G loss: 3.435495]\n",
            "2692 [ D loss: 0.324281, acc.: 88%] [G loss: 3.139265]\n",
            "2693 [ D loss: 0.306791, acc.: 87%] [G loss: 2.929890]\n",
            "2694 [ D loss: 0.242437, acc.: 95%] [G loss: 3.397094]\n",
            "2695 [ D loss: 0.317305, acc.: 90%] [G loss: 2.914309]\n",
            "2696 [ D loss: 0.208163, acc.: 95%] [G loss: 3.450142]\n",
            "2697 [ D loss: 0.331123, acc.: 88%] [G loss: 3.422620]\n",
            "2698 [ D loss: 0.302348, acc.: 89%] [G loss: 2.944724]\n",
            "2699 [ D loss: 0.206496, acc.: 93%] [G loss: 4.817620]\n",
            "2700 [ D loss: 0.291754, acc.: 89%] [G loss: 3.055811]\n",
            "2701 [ D loss: 0.382181, acc.: 83%] [G loss: 4.746888]\n",
            "2702 [ D loss: 0.203648, acc.: 97%] [G loss: 7.288815]\n",
            "2703 [ D loss: 0.245193, acc.: 94%] [G loss: 3.468535]\n",
            "2704 [ D loss: 0.226686, acc.: 93%] [G loss: 4.666249]\n",
            "2705 [ D loss: 0.241519, acc.: 93%] [G loss: 9.233698]\n",
            "2706 [ D loss: 0.183647, acc.: 95%] [G loss: 4.455709]\n",
            "2707 [ D loss: 0.269549, acc.: 89%] [G loss: 6.136774]\n",
            "2708 [ D loss: 0.301413, acc.: 88%] [G loss: 4.767726]\n",
            "2709 [ D loss: 0.270768, acc.: 90%] [G loss: 4.799401]\n",
            "2710 [ D loss: 0.224658, acc.: 93%] [G loss: 5.957806]\n",
            "2711 [ D loss: 0.318155, acc.: 86%] [G loss: 3.375001]\n",
            "2712 [ D loss: 0.274826, acc.: 89%] [G loss: 4.866562]\n",
            "2713 [ D loss: 0.180116, acc.: 98%] [G loss: 5.250562]\n",
            "2714 [ D loss: 0.259107, acc.: 88%] [G loss: 3.011861]\n",
            "2715 [ D loss: 0.270226, acc.: 90%] [G loss: 4.404955]\n",
            "2716 [ D loss: 0.299508, acc.: 92%] [G loss: 3.026573]\n",
            "2717 [ D loss: 0.363082, acc.: 91%] [G loss: 2.959836]\n",
            "2718 [ D loss: 0.354594, acc.: 89%] [G loss: 2.940443]\n",
            "2719 [ D loss: 0.333551, acc.: 88%] [G loss: 3.188620]\n",
            "2720 [ D loss: 0.237744, acc.: 91%] [G loss: 4.742606]\n",
            "2721 [ D loss: 0.282101, acc.: 90%] [G loss: 2.629004]\n",
            "2722 [ D loss: 0.155415, acc.: 98%] [G loss: 5.866588]\n",
            "2723 [ D loss: 0.198443, acc.: 91%] [G loss: 7.885990]\n",
            "2724 [ D loss: 0.321077, acc.: 88%] [G loss: 3.469420]\n",
            "2725 [ D loss: 0.213029, acc.: 93%] [G loss: 4.526957]\n",
            "2726 [ D loss: 0.213213, acc.: 92%] [G loss: 5.258640]\n",
            "2727 [ D loss: 0.253095, acc.: 90%] [G loss: 3.013115]\n",
            "2728 [ D loss: 0.255644, acc.: 92%] [G loss: 3.171454]\n",
            "2729 [ D loss: 0.203003, acc.: 96%] [G loss: 2.535086]\n",
            "2730 [ D loss: 0.302457, acc.: 86%] [G loss: 7.245367]\n",
            "2731 [ D loss: 0.182274, acc.: 94%] [G loss: 5.014871]\n",
            "2732 [ D loss: 0.301414, acc.: 87%] [G loss: 6.712873]\n",
            "2733 [ D loss: 0.164240, acc.: 97%] [G loss: 7.719662]\n",
            "2734 [ D loss: 0.277575, acc.: 88%] [G loss: 4.382059]\n",
            "2735 [ D loss: 0.182918, acc.: 94%] [G loss: 4.900616]\n",
            "2736 [ D loss: 0.262346, acc.: 91%] [G loss: 3.232524]\n",
            "2737 [ D loss: 0.299396, acc.: 91%] [G loss: 3.234645]\n",
            "2738 [ D loss: 0.384353, acc.: 84%] [G loss: 3.777826]\n",
            "2739 [ D loss: 0.325589, acc.: 88%] [G loss: 4.147986]\n",
            "2740 [ D loss: 0.370702, acc.: 84%] [G loss: 2.839024]\n",
            "2741 [ D loss: 0.240162, acc.: 95%] [G loss: 4.093009]\n",
            "2742 [ D loss: 0.410283, acc.: 85%] [G loss: 4.273157]\n",
            "2743 [ D loss: 0.275687, acc.: 93%] [G loss: 10.048353]\n",
            "2744 [ D loss: 0.218529, acc.: 95%] [G loss: 7.864789]\n",
            "2745 [ D loss: 0.182106, acc.: 94%] [G loss: 4.159575]\n",
            "2746 [ D loss: 0.175104, acc.: 95%] [G loss: 8.790345]\n",
            "2747 [ D loss: 0.204877, acc.: 91%] [G loss: 5.131766]\n",
            "2748 [ D loss: 0.185698, acc.: 96%] [G loss: 4.719450]\n",
            "2749 [ D loss: 0.277441, acc.: 93%] [G loss: 4.181976]\n",
            "2750 [ D loss: 0.232331, acc.: 91%] [G loss: 9.896811]\n",
            "2751 [ D loss: 0.247354, acc.: 89%] [G loss: 4.725507]\n",
            "2752 [ D loss: 0.223615, acc.: 95%] [G loss: 4.775286]\n",
            "2753 [ D loss: 0.264684, acc.: 91%] [G loss: 3.556898]\n",
            "2754 [ D loss: 0.174439, acc.: 96%] [G loss: 3.489334]\n",
            "2755 [ D loss: 0.357649, acc.: 83%] [G loss: 4.404606]\n",
            "2756 [ D loss: 0.298359, acc.: 91%] [G loss: 2.643335]\n",
            "2757 [ D loss: 0.293274, acc.: 89%] [G loss: 3.573114]\n",
            "2758 [ D loss: 0.291621, acc.: 90%] [G loss: 5.143532]\n",
            "2759 [ D loss: 0.135573, acc.: 99%] [G loss: 3.035425]\n",
            "2760 [ D loss: 0.238203, acc.: 94%] [G loss: 4.848080]\n",
            "2761 [ D loss: 0.250967, acc.: 91%] [G loss: 5.291449]\n",
            "2762 [ D loss: 0.202799, acc.: 95%] [G loss: 3.567142]\n",
            "2763 [ D loss: 0.171611, acc.: 95%] [G loss: 7.709815]\n",
            "2764 [ D loss: 0.243653, acc.: 92%] [G loss: 4.381306]\n",
            "2765 [ D loss: 0.205837, acc.: 95%] [G loss: 5.113800]\n",
            "2766 [ D loss: 0.192496, acc.: 98%] [G loss: 8.490445]\n",
            "2767 [ D loss: 0.222164, acc.: 94%] [G loss: 3.600606]\n",
            "2768 [ D loss: 0.227989, acc.: 95%] [G loss: 8.956264]\n",
            "2769 [ D loss: 0.167537, acc.: 95%] [G loss: 8.933007]\n",
            "2770 [ D loss: 0.248399, acc.: 92%] [G loss: 5.695423]\n",
            "2771 [ D loss: 0.141613, acc.: 97%] [G loss: 5.538055]\n",
            "2772 [ D loss: 0.222264, acc.: 95%] [G loss: 3.172143]\n",
            "2773 [ D loss: 0.175874, acc.: 98%] [G loss: 4.070018]\n",
            "2774 [ D loss: 0.294898, acc.: 88%] [G loss: 4.249711]\n",
            "2775 [ D loss: 0.178514, acc.: 98%] [G loss: 2.939055]\n",
            "2776 [ D loss: 0.204449, acc.: 95%] [G loss: 3.487482]\n",
            "2777 [ D loss: 0.158895, acc.: 94%] [G loss: 5.115582]\n",
            "2778 [ D loss: 0.307285, acc.: 87%] [G loss: 2.783639]\n",
            "2779 [ D loss: 0.205715, acc.: 96%] [G loss: 5.311452]\n",
            "2780 [ D loss: 0.182058, acc.: 95%] [G loss: 5.663459]\n",
            "2781 [ D loss: 0.247341, acc.: 93%] [G loss: 3.407857]\n",
            "2782 [ D loss: 0.274190, acc.: 95%] [G loss: 3.678079]\n",
            "2783 [ D loss: 0.279570, acc.: 90%] [G loss: 3.414185]\n",
            "2784 [ D loss: 0.316096, acc.: 91%] [G loss: 2.916331]\n",
            "2785 [ D loss: 0.295587, acc.: 96%] [G loss: 3.425594]\n",
            "2786 [ D loss: 0.207411, acc.: 91%] [G loss: 4.119081]\n",
            "2787 [ D loss: 0.294239, acc.: 89%] [G loss: 3.082138]\n",
            "2788 [ D loss: 0.188471, acc.: 98%] [G loss: 3.955412]\n",
            "2789 [ D loss: 0.307445, acc.: 91%] [G loss: 3.008805]\n",
            "2790 [ D loss: 0.230854, acc.: 97%] [G loss: 4.059894]\n",
            "2791 [ D loss: 0.224075, acc.: 98%] [G loss: 2.839868]\n",
            "2792 [ D loss: 0.302020, acc.: 91%] [G loss: 2.849717]\n",
            "2793 [ D loss: 0.206553, acc.: 92%] [G loss: 6.264569]\n",
            "2794 [ D loss: 0.212976, acc.: 95%] [G loss: 3.410022]\n",
            "2795 [ D loss: 0.147519, acc.: 95%] [G loss: 6.547768]\n",
            "2796 [ D loss: 0.259034, acc.: 90%] [G loss: 3.958621]\n",
            "2797 [ D loss: 0.164399, acc.: 96%] [G loss: 7.905293]\n",
            "2798 [ D loss: 0.212805, acc.: 94%] [G loss: 6.497332]\n",
            "2799 [ D loss: 0.222795, acc.: 95%] [G loss: 3.708932]\n",
            "2800 [ D loss: 0.215373, acc.: 95%] [G loss: 5.627168]\n",
            "2801 [ D loss: 0.180271, acc.: 95%] [G loss: 5.805539]\n",
            "2802 [ D loss: 0.132356, acc.: 97%] [G loss: 6.244765]\n",
            "2803 [ D loss: 0.177428, acc.: 95%] [G loss: 6.399475]\n",
            "2804 [ D loss: 0.215028, acc.: 95%] [G loss: 5.418827]\n",
            "2805 [ D loss: 0.173184, acc.: 94%] [G loss: 6.377882]\n",
            "2806 [ D loss: 0.270031, acc.: 92%] [G loss: 6.608829]\n",
            "2807 [ D loss: 0.091426, acc.: 100%] [G loss: 9.785738]\n",
            "2808 [ D loss: 0.172813, acc.: 95%] [G loss: 3.844117]\n",
            "2809 [ D loss: 0.167654, acc.: 95%] [G loss: 5.066099]\n",
            "2810 [ D loss: 0.084384, acc.: 99%] [G loss: 3.961906]\n",
            "2811 [ D loss: 0.136838, acc.: 94%] [G loss: 2.465816]\n",
            "2812 [ D loss: 0.127058, acc.: 95%] [G loss: 9.171654]\n",
            "2813 [ D loss: 0.454619, acc.: 74%] [G loss: 3.579021]\n",
            "2814 [ D loss: 0.278558, acc.: 85%] [G loss: 4.831284]\n",
            "2815 [ D loss: 0.232914, acc.: 95%] [G loss: 5.159868]\n",
            "2816 [ D loss: 0.205366, acc.: 93%] [G loss: 3.054054]\n",
            "2817 [ D loss: 0.201793, acc.: 93%] [G loss: 6.949416]\n",
            "2818 [ D loss: 0.275400, acc.: 91%] [G loss: 2.726692]\n",
            "2819 [ D loss: 0.236616, acc.: 95%] [G loss: 3.926922]\n",
            "2820 [ D loss: 0.213283, acc.: 95%] [G loss: 3.765270]\n",
            "2821 [ D loss: 0.331611, acc.: 88%] [G loss: 3.318832]\n",
            "2822 [ D loss: 0.200470, acc.: 95%] [G loss: 5.170444]\n",
            "2823 [ D loss: 0.259682, acc.: 91%] [G loss: 4.007930]\n",
            "2824 [ D loss: 0.223313, acc.: 92%] [G loss: 4.634836]\n",
            "2825 [ D loss: 0.230010, acc.: 94%] [G loss: 4.506931]\n",
            "2826 [ D loss: 0.196067, acc.: 95%] [G loss: 2.928323]\n",
            "2827 [ D loss: 0.219514, acc.: 96%] [G loss: 3.706134]\n",
            "2828 [ D loss: 0.232853, acc.: 94%] [G loss: 4.579749]\n",
            "2829 [ D loss: 0.225170, acc.: 92%] [G loss: 4.374886]\n",
            "2830 [ D loss: 0.279589, acc.: 89%] [G loss: 5.513829]\n",
            "2831 [ D loss: 0.179356, acc.: 96%] [G loss: 3.853215]\n",
            "2832 [ D loss: 0.357034, acc.: 85%] [G loss: 3.498665]\n",
            "2833 [ D loss: 0.211871, acc.: 92%] [G loss: 4.600522]\n",
            "2834 [ D loss: 0.205942, acc.: 95%] [G loss: 3.852533]\n",
            "2835 [ D loss: 0.200462, acc.: 95%] [G loss: 5.515620]\n",
            "2836 [ D loss: 0.207616, acc.: 94%] [G loss: 3.149605]\n",
            "2837 [ D loss: 0.244392, acc.: 93%] [G loss: 2.733626]\n",
            "2838 [ D loss: 0.214458, acc.: 96%] [G loss: 3.816910]\n",
            "2839 [ D loss: 0.229827, acc.: 94%] [G loss: 4.755188]\n",
            "2840 [ D loss: 0.201268, acc.: 93%] [G loss: 4.694112]\n",
            "2841 [ D loss: 0.319533, acc.: 92%] [G loss: 5.209331]\n",
            "2842 [ D loss: 0.113464, acc.: 99%] [G loss: 7.322952]\n",
            "2843 [ D loss: 0.293825, acc.: 90%] [G loss: 4.413766]\n",
            "2844 [ D loss: 0.157401, acc.: 94%] [G loss: 7.561693]\n",
            "2845 [ D loss: 0.310615, acc.: 86%] [G loss: 3.855570]\n",
            "2846 [ D loss: 0.260831, acc.: 88%] [G loss: 4.517302]\n",
            "2847 [ D loss: 0.115373, acc.: 98%] [G loss: 5.808689]\n",
            "2848 [ D loss: 0.303739, acc.: 88%] [G loss: 4.006106]\n",
            "2849 [ D loss: 0.137733, acc.: 98%] [G loss: 2.883768]\n",
            "2850 [ D loss: 0.122506, acc.: 98%] [G loss: 4.121361]\n",
            "2851 [ D loss: 0.170466, acc.: 94%] [G loss: 3.177111]\n",
            "2852 [ D loss: 0.203929, acc.: 91%] [G loss: 6.411827]\n",
            "2853 [ D loss: 0.199127, acc.: 94%] [G loss: 4.793502]\n",
            "2854 [ D loss: 0.232976, acc.: 94%] [G loss: 3.727808]\n",
            "2855 [ D loss: 0.180054, acc.: 95%] [G loss: 9.126401]\n",
            "2856 [ D loss: 0.247996, acc.: 92%] [G loss: 7.022675]\n",
            "2857 [ D loss: 0.328350, acc.: 87%] [G loss: 3.226824]\n",
            "2858 [ D loss: 0.243518, acc.: 89%] [G loss: 3.483736]\n",
            "2859 [ D loss: 0.275940, acc.: 91%] [G loss: 3.885319]\n",
            "2860 [ D loss: 0.195789, acc.: 92%] [G loss: 3.137684]\n",
            "2861 [ D loss: 0.093682, acc.: 99%] [G loss: 7.790713]\n",
            "2862 [ D loss: 0.229896, acc.: 92%] [G loss: 3.220260]\n",
            "2863 [ D loss: 0.163868, acc.: 98%] [G loss: 4.219899]\n",
            "2864 [ D loss: 0.216771, acc.: 95%] [G loss: 3.912457]\n",
            "2865 [ D loss: 0.318119, acc.: 89%] [G loss: 3.633211]\n",
            "2866 [ D loss: 0.259625, acc.: 95%] [G loss: 2.433953]\n",
            "2867 [ D loss: 0.326263, acc.: 91%] [G loss: 3.198603]\n",
            "2868 [ D loss: 0.293286, acc.: 92%] [G loss: 3.149672]\n",
            "2869 [ D loss: 0.354951, acc.: 85%] [G loss: 2.708332]\n",
            "2870 [ D loss: 0.206575, acc.: 96%] [G loss: 3.573954]\n",
            "2871 [ D loss: 0.276397, acc.: 91%] [G loss: 3.644822]\n",
            "2872 [ D loss: 0.349275, acc.: 89%] [G loss: 3.741883]\n",
            "2873 [ D loss: 0.205672, acc.: 98%] [G loss: 3.354383]\n",
            "2874 [ D loss: 0.285191, acc.: 91%] [G loss: 2.260334]\n",
            "2875 [ D loss: 0.263639, acc.: 91%] [G loss: 3.108495]\n",
            "2876 [ D loss: 0.302629, acc.: 87%] [G loss: 2.260343]\n",
            "2877 [ D loss: 0.238418, acc.: 95%] [G loss: 2.697707]\n",
            "2878 [ D loss: 0.228086, acc.: 95%] [G loss: 5.824177]\n",
            "2879 [ D loss: 0.208182, acc.: 98%] [G loss: 3.651146]\n",
            "2880 [ D loss: 0.341403, acc.: 91%] [G loss: 2.755195]\n",
            "2881 [ D loss: 0.278627, acc.: 88%] [G loss: 3.313052]\n",
            "2882 [ D loss: 0.255181, acc.: 93%] [G loss: 4.489837]\n",
            "2883 [ D loss: 0.233382, acc.: 93%] [G loss: 6.321122]\n",
            "2884 [ D loss: 0.296631, acc.: 89%] [G loss: 3.423678]\n",
            "2885 [ D loss: 0.304695, acc.: 91%] [G loss: 3.316308]\n",
            "2886 [ D loss: 0.224775, acc.: 96%] [G loss: 4.621174]\n",
            "2887 [ D loss: 0.219504, acc.: 92%] [G loss: 3.283332]\n",
            "2888 [ D loss: 0.161721, acc.: 97%] [G loss: 5.074308]\n",
            "2889 [ D loss: 0.164991, acc.: 97%] [G loss: 5.944494]\n",
            "2890 [ D loss: 0.164533, acc.: 95%] [G loss: 5.161465]\n",
            "2891 [ D loss: 0.322506, acc.: 89%] [G loss: 4.228116]\n",
            "2892 [ D loss: 0.223937, acc.: 95%] [G loss: 4.182034]\n",
            "2893 [ D loss: 0.369259, acc.: 83%] [G loss: 4.387271]\n",
            "2894 [ D loss: 0.236190, acc.: 93%] [G loss: 5.596469]\n",
            "2895 [ D loss: 0.231562, acc.: 95%] [G loss: 2.945195]\n",
            "2896 [ D loss: 0.230513, acc.: 94%] [G loss: 3.993385]\n",
            "2897 [ D loss: 0.206130, acc.: 95%] [G loss: 4.880672]\n",
            "2898 [ D loss: 0.226105, acc.: 93%] [G loss: 5.734015]\n",
            "2899 [ D loss: 0.164951, acc.: 95%] [G loss: 5.187863]\n",
            "2900 [ D loss: 0.236241, acc.: 94%] [G loss: 4.701492]\n",
            "2901 [ D loss: 0.201132, acc.: 95%] [G loss: 5.438941]\n",
            "2902 [ D loss: 0.220507, acc.: 96%] [G loss: 3.683398]\n",
            "2903 [ D loss: 0.374383, acc.: 84%] [G loss: 4.375691]\n",
            "2904 [ D loss: 0.306703, acc.: 90%] [G loss: 3.937399]\n",
            "2905 [ D loss: 0.250711, acc.: 92%] [G loss: 4.400196]\n",
            "2906 [ D loss: 0.217448, acc.: 94%] [G loss: 4.924052]\n",
            "2907 [ D loss: 0.344537, acc.: 85%] [G loss: 4.624459]\n",
            "2908 [ D loss: 0.168133, acc.: 91%] [G loss: 7.832892]\n",
            "2909 [ D loss: 0.243048, acc.: 93%] [G loss: 7.004702]\n",
            "2910 [ D loss: 0.180455, acc.: 93%] [G loss: 8.786957]\n",
            "2911 [ D loss: 0.156949, acc.: 95%] [G loss: 5.330609]\n",
            "2912 [ D loss: 0.217012, acc.: 93%] [G loss: 3.225709]\n",
            "2913 [ D loss: 0.172725, acc.: 98%] [G loss: 3.673193]\n",
            "2914 [ D loss: 0.197471, acc.: 93%] [G loss: 3.499134]\n",
            "2915 [ D loss: 0.429001, acc.: 79%] [G loss: 2.311210]\n",
            "2916 [ D loss: 0.261471, acc.: 91%] [G loss: 4.661793]\n",
            "2917 [ D loss: 0.302093, acc.: 91%] [G loss: 2.804471]\n",
            "2918 [ D loss: 0.182467, acc.: 97%] [G loss: 4.664266]\n",
            "2919 [ D loss: 0.209175, acc.: 93%] [G loss: 4.958451]\n",
            "2920 [ D loss: 0.273208, acc.: 94%] [G loss: 4.226110]\n",
            "2921 [ D loss: 0.322667, acc.: 89%] [G loss: 3.692845]\n",
            "2922 [ D loss: 0.273984, acc.: 91%] [G loss: 3.506126]\n",
            "2923 [ D loss: 0.311225, acc.: 89%] [G loss: 3.197086]\n",
            "2924 [ D loss: 0.297986, acc.: 87%] [G loss: 7.349823]\n",
            "2925 [ D loss: 0.195294, acc.: 93%] [G loss: 3.664504]\n",
            "2926 [ D loss: 0.172778, acc.: 97%] [G loss: 3.630820]\n",
            "2927 [ D loss: 0.345533, acc.: 89%] [G loss: 3.498080]\n",
            "2928 [ D loss: 0.318573, acc.: 84%] [G loss: 4.033108]\n",
            "2929 [ D loss: 0.366446, acc.: 88%] [G loss: 2.438721]\n",
            "2930 [ D loss: 0.275959, acc.: 91%] [G loss: 3.529144]\n",
            "2931 [ D loss: 0.374944, acc.: 87%] [G loss: 3.463398]\n",
            "2932 [ D loss: 0.235571, acc.: 91%] [G loss: 4.191744]\n",
            "2933 [ D loss: 0.278440, acc.: 92%] [G loss: 3.802104]\n",
            "2934 [ D loss: 0.259168, acc.: 94%] [G loss: 3.111666]\n",
            "2935 [ D loss: 0.166031, acc.: 97%] [G loss: 5.396588]\n",
            "2936 [ D loss: 0.337978, acc.: 90%] [G loss: 4.717755]\n",
            "2937 [ D loss: 0.171982, acc.: 95%] [G loss: 7.481988]\n",
            "2938 [ D loss: 0.253196, acc.: 95%] [G loss: 3.869570]\n",
            "2939 [ D loss: 0.260751, acc.: 92%] [G loss: 4.398830]\n",
            "2940 [ D loss: 0.230107, acc.: 97%] [G loss: 3.628799]\n",
            "2941 [ D loss: 0.263376, acc.: 94%] [G loss: 3.280838]\n",
            "2942 [ D loss: 0.255602, acc.: 91%] [G loss: 5.575780]\n",
            "2943 [ D loss: 0.281512, acc.: 88%] [G loss: 4.124195]\n",
            "2944 [ D loss: 0.208126, acc.: 93%] [G loss: 3.734836]\n",
            "2945 [ D loss: 0.263982, acc.: 91%] [G loss: 3.974646]\n",
            "2946 [ D loss: 0.298961, acc.: 91%] [G loss: 3.066889]\n",
            "2947 [ D loss: 0.196331, acc.: 95%] [G loss: 3.866333]\n",
            "2948 [ D loss: 0.288121, acc.: 89%] [G loss: 3.706535]\n",
            "2949 [ D loss: 0.200017, acc.: 98%] [G loss: 4.469174]\n",
            "2950 [ D loss: 0.261003, acc.: 91%] [G loss: 3.070691]\n",
            "2951 [ D loss: 0.235688, acc.: 95%] [G loss: 3.370880]\n",
            "2952 [ D loss: 0.227489, acc.: 94%] [G loss: 4.911148]\n",
            "2953 [ D loss: 0.238375, acc.: 91%] [G loss: 3.004235]\n",
            "2954 [ D loss: 0.223218, acc.: 96%] [G loss: 6.479782]\n",
            "2955 [ D loss: 0.164376, acc.: 96%] [G loss: 3.015619]\n",
            "2956 [ D loss: 0.141160, acc.: 98%] [G loss: 7.179172]\n",
            "2957 [ D loss: 0.188826, acc.: 95%] [G loss: 3.925540]\n",
            "2958 [ D loss: 0.194137, acc.: 97%] [G loss: 4.053895]\n",
            "2959 [ D loss: 0.209607, acc.: 95%] [G loss: 3.504796]\n",
            "2960 [ D loss: 0.138068, acc.: 96%] [G loss: 4.499465]\n",
            "2961 [ D loss: 0.215725, acc.: 93%] [G loss: 5.321283]\n",
            "2962 [ D loss: 0.194330, acc.: 95%] [G loss: 3.566946]\n",
            "2963 [ D loss: 0.380113, acc.: 88%] [G loss: 2.960273]\n",
            "2964 [ D loss: 0.267825, acc.: 91%] [G loss: 2.871841]\n",
            "2965 [ D loss: 0.337793, acc.: 90%] [G loss: 3.585308]\n",
            "2966 [ D loss: 0.297946, acc.: 92%] [G loss: 2.730020]\n",
            "2967 [ D loss: 0.275074, acc.: 90%] [G loss: 3.236600]\n",
            "2968 [ D loss: 0.219393, acc.: 95%] [G loss: 3.908476]\n",
            "2969 [ D loss: 0.249535, acc.: 91%] [G loss: 3.255547]\n",
            "2970 [ D loss: 0.329598, acc.: 88%] [G loss: 5.938856]\n",
            "2971 [ D loss: 0.210078, acc.: 92%] [G loss: 5.032666]\n",
            "2972 [ D loss: 0.250603, acc.: 90%] [G loss: 4.331365]\n",
            "2973 [ D loss: 0.258409, acc.: 91%] [G loss: 5.416423]\n",
            "2974 [ D loss: 0.168826, acc.: 97%] [G loss: 5.064746]\n",
            "2975 [ D loss: 0.402966, acc.: 83%] [G loss: 2.737544]\n",
            "2976 [ D loss: 0.308391, acc.: 89%] [G loss: 2.738623]\n",
            "2977 [ D loss: 0.278642, acc.: 93%] [G loss: 2.970267]\n",
            "2978 [ D loss: 0.392976, acc.: 82%] [G loss: 2.999941]\n",
            "2979 [ D loss: 0.374214, acc.: 90%] [G loss: 3.044668]\n",
            "2980 [ D loss: 0.231891, acc.: 94%] [G loss: 3.376396]\n",
            "2981 [ D loss: 0.239609, acc.: 95%] [G loss: 4.541446]\n",
            "2982 [ D loss: 0.321249, acc.: 92%] [G loss: 4.635105]\n",
            "2983 [ D loss: 0.243149, acc.: 91%] [G loss: 3.787416]\n",
            "2984 [ D loss: 0.284782, acc.: 89%] [G loss: 3.630565]\n",
            "2985 [ D loss: 0.267875, acc.: 95%] [G loss: 4.249183]\n",
            "2986 [ D loss: 0.236853, acc.: 92%] [G loss: 3.592402]\n",
            "2987 [ D loss: 0.232828, acc.: 95%] [G loss: 4.952187]\n",
            "2988 [ D loss: 0.157092, acc.: 95%] [G loss: 6.047495]\n",
            "2989 [ D loss: 0.233879, acc.: 91%] [G loss: 3.933055]\n",
            "2990 [ D loss: 0.211492, acc.: 95%] [G loss: 3.916743]\n",
            "2991 [ D loss: 0.174584, acc.: 94%] [G loss: 13.667321]\n",
            "2992 [ D loss: 0.111500, acc.: 99%] [G loss: 7.058273]\n",
            "2993 [ D loss: 0.241453, acc.: 91%] [G loss: 4.013640]\n",
            "2994 [ D loss: 0.177042, acc.: 95%] [G loss: 4.583732]\n",
            "2995 [ D loss: 0.172053, acc.: 96%] [G loss: 4.311507]\n",
            "2996 [ D loss: 0.200872, acc.: 93%] [G loss: 4.160082]\n",
            "2997 [ D loss: 0.235231, acc.: 97%] [G loss: 3.743721]\n",
            "2998 [ D loss: 0.329655, acc.: 88%] [G loss: 3.485699]\n",
            "2999 [ D loss: 0.286592, acc.: 95%] [G loss: 2.936692]\n",
            "3000 [ D loss: 0.269818, acc.: 91%] [G loss: 2.636091]\n",
            "3001 [ D loss: 0.323906, acc.: 88%] [G loss: 3.482707]\n",
            "3002 [ D loss: 0.339700, acc.: 84%] [G loss: 3.736452]\n",
            "3003 [ D loss: 0.315420, acc.: 92%] [G loss: 3.750958]\n",
            "3004 [ D loss: 0.199198, acc.: 94%] [G loss: 3.580154]\n",
            "3005 [ D loss: 0.285772, acc.: 95%] [G loss: 4.434782]\n",
            "3006 [ D loss: 0.195033, acc.: 95%] [G loss: 6.480064]\n",
            "3007 [ D loss: 0.351418, acc.: 80%] [G loss: 3.349520]\n",
            "3008 [ D loss: 0.219342, acc.: 93%] [G loss: 6.172440]\n",
            "3009 [ D loss: 0.277751, acc.: 92%] [G loss: 3.781575]\n",
            "3010 [ D loss: 0.173002, acc.: 92%] [G loss: 11.730316]\n",
            "3011 [ D loss: 0.137040, acc.: 95%] [G loss: 6.360857]\n",
            "3012 [ D loss: 0.135791, acc.: 98%] [G loss: 4.561490]\n",
            "3013 [ D loss: 0.160796, acc.: 97%] [G loss: 3.796865]\n",
            "3014 [ D loss: 0.126631, acc.: 98%] [G loss: 8.327437]\n",
            "3015 [ D loss: 0.187707, acc.: 95%] [G loss: 4.164326]\n",
            "3016 [ D loss: 0.101149, acc.: 97%] [G loss: 8.180954]\n",
            "3017 [ D loss: 0.212918, acc.: 92%] [G loss: 2.828855]\n",
            "3018 [ D loss: 0.206861, acc.: 95%] [G loss: 3.123707]\n",
            "3019 [ D loss: 0.125030, acc.: 97%] [G loss: 5.385671]\n",
            "3020 [ D loss: 0.243207, acc.: 92%] [G loss: 3.430630]\n",
            "3021 [ D loss: 0.256538, acc.: 91%] [G loss: 2.569336]\n",
            "3022 [ D loss: 0.167996, acc.: 97%] [G loss: 5.283982]\n",
            "3023 [ D loss: 0.327723, acc.: 89%] [G loss: 3.479662]\n",
            "3024 [ D loss: 0.300589, acc.: 89%] [G loss: 2.504783]\n",
            "3025 [ D loss: 0.251201, acc.: 93%] [G loss: 3.053442]\n",
            "3026 [ D loss: 0.164738, acc.: 97%] [G loss: 3.359425]\n",
            "3027 [ D loss: 0.232163, acc.: 92%] [G loss: 4.315446]\n",
            "3028 [ D loss: 0.172421, acc.: 95%] [G loss: 5.384278]\n",
            "3029 [ D loss: 0.220635, acc.: 93%] [G loss: 3.603447]\n",
            "3030 [ D loss: 0.214849, acc.: 97%] [G loss: 5.051783]\n",
            "3031 [ D loss: 0.271186, acc.: 90%] [G loss: 4.414185]\n",
            "3032 [ D loss: 0.278234, acc.: 89%] [G loss: 2.994330]\n",
            "3033 [ D loss: 0.346844, acc.: 85%] [G loss: 3.168374]\n",
            "3034 [ D loss: 0.264895, acc.: 93%] [G loss: 3.335946]\n",
            "3035 [ D loss: 0.199453, acc.: 97%] [G loss: 4.654408]\n",
            "3036 [ D loss: 0.185442, acc.: 96%] [G loss: 4.508594]\n",
            "3037 [ D loss: 0.244702, acc.: 95%] [G loss: 3.966311]\n",
            "3038 [ D loss: 0.237252, acc.: 95%] [G loss: 3.942374]\n",
            "3039 [ D loss: 0.223875, acc.: 94%] [G loss: 3.680315]\n",
            "3040 [ D loss: 0.387180, acc.: 82%] [G loss: 2.816765]\n",
            "3041 [ D loss: 0.272908, acc.: 91%] [G loss: 3.147508]\n",
            "3042 [ D loss: 0.315415, acc.: 92%] [G loss: 3.499478]\n",
            "3043 [ D loss: 0.279083, acc.: 95%] [G loss: 3.321153]\n",
            "3044 [ D loss: 0.217686, acc.: 98%] [G loss: 2.857161]\n",
            "3045 [ D loss: 0.274652, acc.: 91%] [G loss: 3.105227]\n",
            "3046 [ D loss: 0.232602, acc.: 97%] [G loss: 3.034017]\n",
            "3047 [ D loss: 0.236402, acc.: 91%] [G loss: 3.661294]\n",
            "3048 [ D loss: 0.195585, acc.: 96%] [G loss: 4.100337]\n",
            "3049 [ D loss: 0.182891, acc.: 97%] [G loss: 3.843367]\n",
            "3050 [ D loss: 0.323806, acc.: 90%] [G loss: 3.502132]\n",
            "3051 [ D loss: 0.230187, acc.: 92%] [G loss: 4.278535]\n",
            "3052 [ D loss: 0.252768, acc.: 92%] [G loss: 5.458880]\n",
            "3053 [ D loss: 0.230964, acc.: 95%] [G loss: 3.844220]\n",
            "3054 [ D loss: 0.168886, acc.: 95%] [G loss: 5.234233]\n",
            "3055 [ D loss: 0.268532, acc.: 86%] [G loss: 3.462759]\n",
            "3056 [ D loss: 0.328807, acc.: 89%] [G loss: 3.088912]\n",
            "3057 [ D loss: 0.165031, acc.: 96%] [G loss: 4.403377]\n",
            "3058 [ D loss: 0.252430, acc.: 94%] [G loss: 3.419844]\n",
            "3059 [ D loss: 0.201709, acc.: 97%] [G loss: 2.687838]\n",
            "3060 [ D loss: 0.225261, acc.: 95%] [G loss: 3.598276]\n",
            "3061 [ D loss: 0.210686, acc.: 95%] [G loss: 3.063483]\n",
            "3062 [ D loss: 0.226283, acc.: 97%] [G loss: 3.755317]\n",
            "3063 [ D loss: 0.250530, acc.: 92%] [G loss: 3.981916]\n",
            "3064 [ D loss: 0.194190, acc.: 95%] [G loss: 6.459332]\n",
            "3065 [ D loss: 0.200350, acc.: 98%] [G loss: 3.699006]\n",
            "3066 [ D loss: 0.167855, acc.: 99%] [G loss: 4.072106]\n",
            "3067 [ D loss: 0.218865, acc.: 91%] [G loss: 4.446420]\n",
            "3068 [ D loss: 0.195310, acc.: 95%] [G loss: 7.279833]\n",
            "3069 [ D loss: 0.091552, acc.: 100%] [G loss: 6.603263]\n",
            "3070 [ D loss: 0.121984, acc.: 98%] [G loss: 8.969343]\n",
            "3071 [ D loss: 0.138867, acc.: 96%] [G loss: 8.300084]\n",
            "3072 [ D loss: 0.232503, acc.: 91%] [G loss: 6.747684]\n",
            "3073 [ D loss: 0.235170, acc.: 93%] [G loss: 7.374650]\n",
            "3074 [ D loss: 0.213102, acc.: 95%] [G loss: 7.272822]\n",
            "3075 [ D loss: 0.332362, acc.: 88%] [G loss: 4.995644]\n",
            "3076 [ D loss: 0.228626, acc.: 92%] [G loss: 3.422098]\n",
            "3077 [ D loss: 0.226051, acc.: 95%] [G loss: 5.580826]\n",
            "3078 [ D loss: 0.253097, acc.: 91%] [G loss: 2.949569]\n",
            "3079 [ D loss: 0.251912, acc.: 95%] [G loss: 3.478057]\n",
            "3080 [ D loss: 0.177277, acc.: 97%] [G loss: 3.778584]\n",
            "3081 [ D loss: 0.237863, acc.: 91%] [G loss: 3.528708]\n",
            "3082 [ D loss: 0.199246, acc.: 95%] [G loss: 4.029593]\n",
            "3083 [ D loss: 0.185776, acc.: 96%] [G loss: 3.625498]\n",
            "3084 [ D loss: 0.195481, acc.: 97%] [G loss: 3.698302]\n",
            "3085 [ D loss: 0.209677, acc.: 96%] [G loss: 3.255086]\n",
            "3086 [ D loss: 0.170565, acc.: 95%] [G loss: 3.100462]\n",
            "3087 [ D loss: 0.224651, acc.: 94%] [G loss: 2.975250]\n",
            "3088 [ D loss: 0.283358, acc.: 93%] [G loss: 5.168246]\n",
            "3089 [ D loss: 0.204160, acc.: 94%] [G loss: 5.533223]\n",
            "3090 [ D loss: 0.230218, acc.: 94%] [G loss: 3.270819]\n",
            "3091 [ D loss: 0.207614, acc.: 95%] [G loss: 4.307561]\n",
            "3092 [ D loss: 0.222685, acc.: 93%] [G loss: 4.253087]\n",
            "3093 [ D loss: 0.183329, acc.: 95%] [G loss: 3.847378]\n",
            "3094 [ D loss: 0.246184, acc.: 91%] [G loss: 3.521131]\n",
            "3095 [ D loss: 0.247751, acc.: 96%] [G loss: 2.246118]\n",
            "3096 [ D loss: 0.176804, acc.: 94%] [G loss: 2.445045]\n",
            "3097 [ D loss: 0.243876, acc.: 95%] [G loss: 3.927817]\n",
            "3098 [ D loss: 0.204258, acc.: 93%] [G loss: 3.578866]\n",
            "3099 [ D loss: 0.324882, acc.: 87%] [G loss: 3.226937]\n",
            "3100 [ D loss: 0.196809, acc.: 97%] [G loss: 3.080385]\n",
            "3101 [ D loss: 0.202762, acc.: 97%] [G loss: 2.870865]\n",
            "3102 [ D loss: 0.384110, acc.: 84%] [G loss: 3.609643]\n",
            "3103 [ D loss: 0.219519, acc.: 95%] [G loss: 3.669717]\n",
            "3104 [ D loss: 0.281388, acc.: 92%] [G loss: 2.477792]\n",
            "3105 [ D loss: 0.262519, acc.: 93%] [G loss: 4.561113]\n",
            "3106 [ D loss: 0.302441, acc.: 91%] [G loss: 3.587248]\n",
            "3107 [ D loss: 0.185955, acc.: 95%] [G loss: 4.549221]\n",
            "3108 [ D loss: 0.316601, acc.: 85%] [G loss: 3.102385]\n",
            "3109 [ D loss: 0.198811, acc.: 96%] [G loss: 3.805189]\n",
            "3110 [ D loss: 0.245349, acc.: 91%] [G loss: 3.710991]\n",
            "3111 [ D loss: 0.280896, acc.: 89%] [G loss: 3.342465]\n",
            "3112 [ D loss: 0.219288, acc.: 93%] [G loss: 3.891246]\n",
            "3113 [ D loss: 0.328341, acc.: 91%] [G loss: 3.720840]\n",
            "3114 [ D loss: 0.234076, acc.: 95%] [G loss: 3.648402]\n",
            "3115 [ D loss: 0.324591, acc.: 88%] [G loss: 5.087280]\n",
            "3116 [ D loss: 0.145125, acc.: 95%] [G loss: 5.073792]\n",
            "3117 [ D loss: 0.258265, acc.: 91%] [G loss: 4.311365]\n",
            "3118 [ D loss: 0.162818, acc.: 97%] [G loss: 3.084987]\n",
            "3119 [ D loss: 0.158903, acc.: 98%] [G loss: 3.245784]\n",
            "3120 [ D loss: 0.194418, acc.: 95%] [G loss: 4.292723]\n",
            "3121 [ D loss: 0.150020, acc.: 98%] [G loss: 4.316901]\n",
            "3122 [ D loss: 0.094296, acc.: 98%] [G loss: 10.384316]\n",
            "3123 [ D loss: 0.203560, acc.: 92%] [G loss: 8.912305]\n",
            "3124 [ D loss: 0.162247, acc.: 95%] [G loss: 5.268381]\n",
            "3125 [ D loss: 0.229122, acc.: 92%] [G loss: 3.871801]\n",
            "3126 [ D loss: 0.193626, acc.: 91%] [G loss: 6.645613]\n",
            "3127 [ D loss: 0.123554, acc.: 98%] [G loss: 5.574150]\n",
            "3128 [ D loss: 0.218978, acc.: 95%] [G loss: 3.836979]\n",
            "3129 [ D loss: 0.282010, acc.: 91%] [G loss: 3.363885]\n",
            "3130 [ D loss: 0.244436, acc.: 91%] [G loss: 3.930326]\n",
            "3131 [ D loss: 0.234152, acc.: 92%] [G loss: 3.558317]\n",
            "3132 [ D loss: 0.234445, acc.: 94%] [G loss: 6.767042]\n",
            "3133 [ D loss: 0.231341, acc.: 96%] [G loss: 3.294008]\n",
            "3134 [ D loss: 0.211741, acc.: 93%] [G loss: 4.301599]\n",
            "3135 [ D loss: 0.190792, acc.: 94%] [G loss: 4.500860]\n",
            "3136 [ D loss: 0.184742, acc.: 97%] [G loss: 3.449889]\n",
            "3137 [ D loss: 0.319135, acc.: 88%] [G loss: 3.609636]\n",
            "3138 [ D loss: 0.379142, acc.: 83%] [G loss: 3.418262]\n",
            "3139 [ D loss: 0.249398, acc.: 91%] [G loss: 3.987825]\n",
            "3140 [ D loss: 0.250793, acc.: 93%] [G loss: 3.878125]\n",
            "3141 [ D loss: 0.165958, acc.: 95%] [G loss: 3.609101]\n",
            "3142 [ D loss: 0.225318, acc.: 92%] [G loss: 4.327035]\n",
            "3143 [ D loss: 0.210991, acc.: 97%] [G loss: 3.544442]\n",
            "3144 [ D loss: 0.244713, acc.: 94%] [G loss: 4.553554]\n",
            "3145 [ D loss: 0.234231, acc.: 94%] [G loss: 3.240686]\n",
            "3146 [ D loss: 0.191100, acc.: 95%] [G loss: 3.450071]\n",
            "3147 [ D loss: 0.256928, acc.: 93%] [G loss: 5.491019]\n",
            "3148 [ D loss: 0.163500, acc.: 95%] [G loss: 4.743547]\n",
            "3149 [ D loss: 0.195616, acc.: 95%] [G loss: 14.214832]\n",
            "3150 [ D loss: 0.137904, acc.: 96%] [G loss: 5.396717]\n",
            "3151 [ D loss: 0.130111, acc.: 98%] [G loss: 8.069889]\n",
            "3152 [ D loss: 0.143856, acc.: 95%] [G loss: 7.114245]\n",
            "3153 [ D loss: 0.218582, acc.: 93%] [G loss: 5.259891]\n",
            "3154 [ D loss: 0.135460, acc.: 96%] [G loss: 5.669321]\n",
            "3155 [ D loss: 0.245331, acc.: 90%] [G loss: 4.542708]\n",
            "3156 [ D loss: 0.209035, acc.: 96%] [G loss: 3.608177]\n",
            "3157 [ D loss: 0.250591, acc.: 93%] [G loss: 3.292991]\n",
            "3158 [ D loss: 0.200916, acc.: 95%] [G loss: 4.540472]\n",
            "3159 [ D loss: 0.227924, acc.: 96%] [G loss: 4.163046]\n",
            "3160 [ D loss: 0.246304, acc.: 94%] [G loss: 4.344739]\n",
            "3161 [ D loss: 0.229312, acc.: 90%] [G loss: 6.424821]\n",
            "3162 [ D loss: 0.170698, acc.: 97%] [G loss: 6.342986]\n",
            "3163 [ D loss: 0.308529, acc.: 84%] [G loss: 4.589110]\n",
            "3164 [ D loss: 0.159355, acc.: 99%] [G loss: 6.536636]\n",
            "3165 [ D loss: 0.223270, acc.: 94%] [G loss: 3.552924]\n",
            "3166 [ D loss: 0.227958, acc.: 92%] [G loss: 6.607273]\n",
            "3167 [ D loss: 0.276910, acc.: 91%] [G loss: 4.162282]\n",
            "3168 [ D loss: 0.226574, acc.: 93%] [G loss: 3.698088]\n",
            "3169 [ D loss: 0.322055, acc.: 90%] [G loss: 4.034173]\n",
            "3170 [ D loss: 0.399156, acc.: 88%] [G loss: 2.329120]\n",
            "3171 [ D loss: 0.280368, acc.: 93%] [G loss: 4.347216]\n",
            "3172 [ D loss: 0.250087, acc.: 94%] [G loss: 6.296329]\n",
            "3173 [ D loss: 0.249201, acc.: 93%] [G loss: 7.376161]\n",
            "3174 [ D loss: 0.136994, acc.: 98%] [G loss: 4.501489]\n",
            "3175 [ D loss: 0.096726, acc.: 98%] [G loss: 4.651596]\n",
            "3176 [ D loss: 0.136664, acc.: 96%] [G loss: 6.112553]\n",
            "3177 [ D loss: 0.151123, acc.: 97%] [G loss: 4.465610]\n",
            "3178 [ D loss: 0.191002, acc.: 95%] [G loss: 4.817505]\n",
            "3179 [ D loss: 0.215660, acc.: 89%] [G loss: 7.931583]\n",
            "3180 [ D loss: 0.324585, acc.: 89%] [G loss: 5.253925]\n",
            "3181 [ D loss: 0.178505, acc.: 96%] [G loss: 5.062522]\n",
            "3182 [ D loss: 0.203273, acc.: 93%] [G loss: 3.389102]\n",
            "3183 [ D loss: 0.227899, acc.: 92%] [G loss: 4.106175]\n",
            "3184 [ D loss: 0.173459, acc.: 95%] [G loss: 3.418485]\n",
            "3185 [ D loss: 0.376825, acc.: 83%] [G loss: 3.864301]\n",
            "3186 [ D loss: 0.184134, acc.: 92%] [G loss: 5.751972]\n",
            "3187 [ D loss: 0.268810, acc.: 92%] [G loss: 4.044359]\n",
            "3188 [ D loss: 0.180489, acc.: 100%] [G loss: 4.611909]\n",
            "3189 [ D loss: 0.198453, acc.: 95%] [G loss: 4.015467]\n",
            "3190 [ D loss: 0.183572, acc.: 97%] [G loss: 6.610798]\n",
            "3191 [ D loss: 0.118782, acc.: 96%] [G loss: 6.518788]\n",
            "3192 [ D loss: 0.280213, acc.: 86%] [G loss: 4.499840]\n",
            "3193 [ D loss: 0.172557, acc.: 95%] [G loss: 3.881696]\n",
            "3194 [ D loss: 0.178871, acc.: 92%] [G loss: 7.802115]\n",
            "3195 [ D loss: 0.241888, acc.: 94%] [G loss: 3.183936]\n",
            "3196 [ D loss: 0.142633, acc.: 96%] [G loss: 4.292169]\n",
            "3197 [ D loss: 0.168299, acc.: 95%] [G loss: 3.913376]\n",
            "3198 [ D loss: 0.168551, acc.: 97%] [G loss: 4.193539]\n",
            "3199 [ D loss: 0.186781, acc.: 93%] [G loss: 10.790900]\n",
            "3200 [ D loss: 0.156005, acc.: 95%] [G loss: 6.665820]\n",
            "3201 [ D loss: 0.176233, acc.: 94%] [G loss: 4.968788]\n",
            "3202 [ D loss: 0.114052, acc.: 98%] [G loss: 7.396425]\n",
            "3203 [ D loss: 0.188506, acc.: 94%] [G loss: 5.905870]\n",
            "3204 [ D loss: 0.139217, acc.: 96%] [G loss: 5.379775]\n",
            "3205 [ D loss: 0.282153, acc.: 90%] [G loss: 3.831967]\n",
            "3206 [ D loss: 0.208583, acc.: 91%] [G loss: 3.450503]\n",
            "3207 [ D loss: 0.291580, acc.: 93%] [G loss: 3.516058]\n",
            "3208 [ D loss: 0.254749, acc.: 92%] [G loss: 3.651936]\n",
            "3209 [ D loss: 0.261046, acc.: 92%] [G loss: 3.003778]\n",
            "3210 [ D loss: 0.270690, acc.: 92%] [G loss: 3.946468]\n",
            "3211 [ D loss: 0.279538, acc.: 92%] [G loss: 3.934938]\n",
            "3212 [ D loss: 0.188743, acc.: 95%] [G loss: 4.230384]\n",
            "3213 [ D loss: 0.258396, acc.: 95%] [G loss: 3.763451]\n",
            "3214 [ D loss: 0.228454, acc.: 95%] [G loss: 4.349134]\n",
            "3215 [ D loss: 0.194664, acc.: 96%] [G loss: 3.938600]\n",
            "3216 [ D loss: 0.252867, acc.: 92%] [G loss: 4.145003]\n",
            "3217 [ D loss: 0.234305, acc.: 93%] [G loss: 3.210495]\n",
            "3218 [ D loss: 0.252484, acc.: 95%] [G loss: 3.349360]\n",
            "3219 [ D loss: 0.124223, acc.: 98%] [G loss: 3.877708]\n",
            "3220 [ D loss: 0.292512, acc.: 90%] [G loss: 4.218823]\n",
            "3221 [ D loss: 0.176945, acc.: 95%] [G loss: 5.876284]\n",
            "3222 [ D loss: 0.225484, acc.: 91%] [G loss: 6.118247]\n",
            "3223 [ D loss: 0.248908, acc.: 95%] [G loss: 5.422153]\n",
            "3224 [ D loss: 0.140900, acc.: 97%] [G loss: 6.636586]\n",
            "3225 [ D loss: 0.244207, acc.: 91%] [G loss: 3.358608]\n",
            "3226 [ D loss: 0.145730, acc.: 97%] [G loss: 4.402063]\n",
            "3227 [ D loss: 0.185398, acc.: 93%] [G loss: 6.037886]\n",
            "3228 [ D loss: 0.224676, acc.: 93%] [G loss: 5.185246]\n",
            "3229 [ D loss: 0.149254, acc.: 98%] [G loss: 7.773850]\n",
            "3230 [ D loss: 0.164836, acc.: 100%] [G loss: 4.445480]\n",
            "3231 [ D loss: 0.123317, acc.: 98%] [G loss: 4.067020]\n",
            "3232 [ D loss: 0.115445, acc.: 97%] [G loss: 7.811022]\n",
            "3233 [ D loss: 0.172967, acc.: 93%] [G loss: 5.599805]\n",
            "3234 [ D loss: 0.187037, acc.: 95%] [G loss: 6.746746]\n",
            "3235 [ D loss: 0.215587, acc.: 94%] [G loss: 5.507863]\n",
            "3236 [ D loss: 0.167532, acc.: 98%] [G loss: 4.990729]\n",
            "3237 [ D loss: 0.278548, acc.: 92%] [G loss: 3.544872]\n",
            "3238 [ D loss: 0.165445, acc.: 98%] [G loss: 3.776666]\n",
            "3239 [ D loss: 0.230651, acc.: 96%] [G loss: 3.434643]\n",
            "3240 [ D loss: 0.238981, acc.: 93%] [G loss: 3.478446]\n",
            "3241 [ D loss: 0.249149, acc.: 94%] [G loss: 3.761744]\n",
            "3242 [ D loss: 0.288018, acc.: 91%] [G loss: 3.887122]\n",
            "3243 [ D loss: 0.214718, acc.: 95%] [G loss: 4.669470]\n",
            "3244 [ D loss: 0.230272, acc.: 92%] [G loss: 3.975636]\n",
            "3245 [ D loss: 0.185623, acc.: 97%] [G loss: 6.445871]\n",
            "3246 [ D loss: 0.181187, acc.: 91%] [G loss: 5.046041]\n",
            "3247 [ D loss: 0.256200, acc.: 91%] [G loss: 3.955324]\n",
            "3248 [ D loss: 0.149310, acc.: 97%] [G loss: 4.371162]\n",
            "3249 [ D loss: 0.150663, acc.: 96%] [G loss: 5.168060]\n",
            "3250 [ D loss: 0.213005, acc.: 94%] [G loss: 4.180377]\n",
            "3251 [ D loss: 0.190815, acc.: 95%] [G loss: 3.956820]\n",
            "3252 [ D loss: 0.267971, acc.: 88%] [G loss: 4.356562]\n",
            "3253 [ D loss: 0.176062, acc.: 96%] [G loss: 4.093321]\n",
            "3254 [ D loss: 0.260830, acc.: 91%] [G loss: 3.574095]\n",
            "3255 [ D loss: 0.284213, acc.: 91%] [G loss: 3.470078]\n",
            "3256 [ D loss: 0.202382, acc.: 93%] [G loss: 4.540026]\n",
            "3257 [ D loss: 0.200665, acc.: 95%] [G loss: 4.201664]\n",
            "3258 [ D loss: 0.200806, acc.: 95%] [G loss: 5.863051]\n",
            "3259 [ D loss: 0.162446, acc.: 98%] [G loss: 3.971432]\n",
            "3260 [ D loss: 0.157132, acc.: 98%] [G loss: 4.909698]\n",
            "3261 [ D loss: 0.203485, acc.: 95%] [G loss: 4.813253]\n",
            "3262 [ D loss: 0.225316, acc.: 95%] [G loss: 4.321497]\n",
            "3263 [ D loss: 0.134028, acc.: 98%] [G loss: 4.435368]\n",
            "3264 [ D loss: 0.178578, acc.: 95%] [G loss: 7.551384]\n",
            "3265 [ D loss: 0.161354, acc.: 95%] [G loss: 4.238033]\n",
            "3266 [ D loss: 0.092774, acc.: 98%] [G loss: 6.612071]\n",
            "3267 [ D loss: 0.195339, acc.: 95%] [G loss: 4.198203]\n",
            "3268 [ D loss: 0.136630, acc.: 96%] [G loss: 3.394348]\n",
            "3269 [ D loss: 0.108093, acc.: 98%] [G loss: 4.727263]\n",
            "3270 [ D loss: 0.169564, acc.: 96%] [G loss: 4.429688]\n",
            "3271 [ D loss: 0.261005, acc.: 88%] [G loss: 6.541049]\n",
            "3272 [ D loss: 0.224939, acc.: 95%] [G loss: 4.917009]\n",
            "3273 [ D loss: 0.211270, acc.: 91%] [G loss: 4.589972]\n",
            "3274 [ D loss: 0.373340, acc.: 85%] [G loss: 4.146831]\n",
            "3275 [ D loss: 0.147877, acc.: 98%] [G loss: 4.470053]\n",
            "3276 [ D loss: 0.274969, acc.: 90%] [G loss: 5.169540]\n",
            "3277 [ D loss: 0.144705, acc.: 98%] [G loss: 5.895205]\n",
            "3278 [ D loss: 0.141026, acc.: 98%] [G loss: 6.656054]\n",
            "3279 [ D loss: 0.182137, acc.: 94%] [G loss: 5.152762]\n",
            "3280 [ D loss: 0.189308, acc.: 95%] [G loss: 4.864183]\n",
            "3281 [ D loss: 0.202898, acc.: 95%] [G loss: 5.441329]\n",
            "3282 [ D loss: 0.258490, acc.: 91%] [G loss: 3.264633]\n",
            "3283 [ D loss: 0.319559, acc.: 88%] [G loss: 4.603002]\n",
            "3284 [ D loss: 0.190145, acc.: 95%] [G loss: 4.487739]\n",
            "3285 [ D loss: 0.270510, acc.: 91%] [G loss: 3.788232]\n",
            "3286 [ D loss: 0.210125, acc.: 93%] [G loss: 3.564377]\n",
            "3287 [ D loss: 0.183841, acc.: 97%] [G loss: 5.796415]\n",
            "3288 [ D loss: 0.145607, acc.: 98%] [G loss: 4.607575]\n",
            "3289 [ D loss: 0.239436, acc.: 94%] [G loss: 4.283453]\n",
            "3290 [ D loss: 0.172536, acc.: 96%] [G loss: 4.647047]\n",
            "3291 [ D loss: 0.180157, acc.: 97%] [G loss: 2.897780]\n",
            "3292 [ D loss: 0.185856, acc.: 94%] [G loss: 4.466784]\n",
            "3293 [ D loss: 0.172901, acc.: 99%] [G loss: 3.841539]\n",
            "3294 [ D loss: 0.171229, acc.: 98%] [G loss: 4.474729]\n",
            "3295 [ D loss: 0.104808, acc.: 97%] [G loss: 6.042357]\n",
            "3296 [ D loss: 0.159226, acc.: 96%] [G loss: 3.780574]\n",
            "3297 [ D loss: 0.163209, acc.: 95%] [G loss: 5.647289]\n",
            "3298 [ D loss: 0.133304, acc.: 95%] [G loss: 5.494177]\n",
            "3299 [ D loss: 0.179643, acc.: 95%] [G loss: 6.727238]\n",
            "3300 [ D loss: 0.096704, acc.: 98%] [G loss: 4.334874]\n",
            "3301 [ D loss: 0.208113, acc.: 95%] [G loss: 4.701403]\n",
            "3302 [ D loss: 0.122866, acc.: 98%] [G loss: 6.027646]\n",
            "3303 [ D loss: 0.170898, acc.: 95%] [G loss: 5.293491]\n",
            "3304 [ D loss: 0.199955, acc.: 96%] [G loss: 3.771075]\n",
            "3305 [ D loss: 0.255188, acc.: 91%] [G loss: 3.620532]\n",
            "3306 [ D loss: 0.221856, acc.: 93%] [G loss: 4.912258]\n",
            "3307 [ D loss: 0.153506, acc.: 96%] [G loss: 4.784678]\n",
            "3308 [ D loss: 0.201607, acc.: 95%] [G loss: 3.840571]\n",
            "3309 [ D loss: 0.195051, acc.: 95%] [G loss: 4.000915]\n",
            "3310 [ D loss: 0.244544, acc.: 94%] [G loss: 6.980650]\n",
            "3311 [ D loss: 0.171486, acc.: 96%] [G loss: 4.132545]\n",
            "3312 [ D loss: 0.230086, acc.: 92%] [G loss: 6.418169]\n",
            "3313 [ D loss: 0.121071, acc.: 96%] [G loss: 6.538117]\n",
            "3314 [ D loss: 0.270004, acc.: 88%] [G loss: 4.849420]\n",
            "3315 [ D loss: 0.197906, acc.: 91%] [G loss: 4.428042]\n",
            "3316 [ D loss: 0.225686, acc.: 93%] [G loss: 6.612508]\n",
            "3317 [ D loss: 0.332095, acc.: 86%] [G loss: 3.019226]\n",
            "3318 [ D loss: 0.148886, acc.: 98%] [G loss: 5.534758]\n",
            "3319 [ D loss: 0.221920, acc.: 92%] [G loss: 5.236885]\n",
            "3320 [ D loss: 0.249252, acc.: 95%] [G loss: 4.220710]\n",
            "3321 [ D loss: 0.214870, acc.: 91%] [G loss: 5.764668]\n",
            "3322 [ D loss: 0.098519, acc.: 98%] [G loss: 6.461245]\n",
            "3323 [ D loss: 0.085590, acc.: 99%] [G loss: 10.965993]\n",
            "3324 [ D loss: 0.127060, acc.: 97%] [G loss: 8.170933]\n",
            "3325 [ D loss: 0.121059, acc.: 97%] [G loss: 6.732773]\n",
            "3326 [ D loss: 0.185071, acc.: 95%] [G loss: 4.410649]\n",
            "3327 [ D loss: 0.189239, acc.: 92%] [G loss: 5.230556]\n",
            "3328 [ D loss: 0.174903, acc.: 97%] [G loss: 4.835110]\n",
            "3329 [ D loss: 0.208751, acc.: 91%] [G loss: 5.043032]\n",
            "3330 [ D loss: 0.233818, acc.: 90%] [G loss: 3.899784]\n",
            "3331 [ D loss: 0.262448, acc.: 90%] [G loss: 3.624261]\n",
            "3332 [ D loss: 0.338400, acc.: 91%] [G loss: 4.672143]\n",
            "3333 [ D loss: 0.207883, acc.: 92%] [G loss: 4.905797]\n",
            "3334 [ D loss: 0.279467, acc.: 91%] [G loss: 4.760873]\n",
            "3335 [ D loss: 0.195440, acc.: 94%] [G loss: 5.469135]\n",
            "3336 [ D loss: 0.146402, acc.: 95%] [G loss: 4.940836]\n",
            "3337 [ D loss: 0.169177, acc.: 99%] [G loss: 5.744455]\n",
            "3338 [ D loss: 0.173553, acc.: 93%] [G loss: 4.146979]\n",
            "3339 [ D loss: 0.144263, acc.: 95%] [G loss: 4.178580]\n",
            "3340 [ D loss: 0.167872, acc.: 97%] [G loss: 3.688735]\n",
            "3341 [ D loss: 0.171136, acc.: 95%] [G loss: 4.223512]\n",
            "3342 [ D loss: 0.173242, acc.: 95%] [G loss: 4.266892]\n",
            "3343 [ D loss: 0.175776, acc.: 98%] [G loss: 3.966002]\n",
            "3344 [ D loss: 0.184603, acc.: 96%] [G loss: 4.348068]\n",
            "3345 [ D loss: 0.333587, acc.: 86%] [G loss: 3.386674]\n",
            "3346 [ D loss: 0.298177, acc.: 85%] [G loss: 3.658774]\n",
            "3347 [ D loss: 0.268238, acc.: 89%] [G loss: 3.307451]\n",
            "3348 [ D loss: 0.107035, acc.: 100%] [G loss: 4.147380]\n",
            "3349 [ D loss: 0.208933, acc.: 95%] [G loss: 4.557005]\n",
            "3350 [ D loss: 0.209333, acc.: 91%] [G loss: 3.999287]\n",
            "3351 [ D loss: 0.157663, acc.: 98%] [G loss: 3.488044]\n",
            "3352 [ D loss: 0.140988, acc.: 97%] [G loss: 4.389928]\n",
            "3353 [ D loss: 0.120149, acc.: 98%] [G loss: 4.022012]\n",
            "3354 [ D loss: 0.309414, acc.: 88%] [G loss: 4.417991]\n",
            "3355 [ D loss: 0.188358, acc.: 93%] [G loss: 3.990160]\n",
            "3356 [ D loss: 0.340920, acc.: 87%] [G loss: 3.461139]\n",
            "3357 [ D loss: 0.189299, acc.: 95%] [G loss: 4.438279]\n",
            "3358 [ D loss: 0.151701, acc.: 96%] [G loss: 3.719351]\n",
            "3359 [ D loss: 0.128531, acc.: 95%] [G loss: 9.308420]\n",
            "3360 [ D loss: 0.176487, acc.: 96%] [G loss: 3.385140]\n",
            "3361 [ D loss: 0.167704, acc.: 94%] [G loss: 4.178116]\n",
            "3362 [ D loss: 0.149247, acc.: 97%] [G loss: 3.923029]\n",
            "3363 [ D loss: 0.217591, acc.: 91%] [G loss: 3.516434]\n",
            "3364 [ D loss: 0.234216, acc.: 91%] [G loss: 5.199810]\n",
            "3365 [ D loss: 0.205071, acc.: 95%] [G loss: 5.189074]\n",
            "3366 [ D loss: 0.151422, acc.: 98%] [G loss: 4.395478]\n",
            "3367 [ D loss: 0.188192, acc.: 96%] [G loss: 3.835429]\n",
            "3368 [ D loss: 0.235674, acc.: 96%] [G loss: 3.050421]\n",
            "3369 [ D loss: 0.120037, acc.: 98%] [G loss: 4.709006]\n",
            "3370 [ D loss: 0.270944, acc.: 89%] [G loss: 4.050646]\n",
            "3371 [ D loss: 0.305975, acc.: 88%] [G loss: 3.990267]\n",
            "3372 [ D loss: 0.237127, acc.: 92%] [G loss: 3.483421]\n",
            "3373 [ D loss: 0.214595, acc.: 95%] [G loss: 3.172381]\n",
            "3374 [ D loss: 0.186317, acc.: 95%] [G loss: 5.868927]\n",
            "3375 [ D loss: 0.161753, acc.: 96%] [G loss: 4.359785]\n",
            "3376 [ D loss: 0.121525, acc.: 97%] [G loss: 9.197623]\n",
            "3377 [ D loss: 0.201134, acc.: 95%] [G loss: 4.780114]\n",
            "3378 [ D loss: 0.166582, acc.: 96%] [G loss: 3.482594]\n",
            "3379 [ D loss: 0.186075, acc.: 95%] [G loss: 5.082559]\n",
            "3380 [ D loss: 0.234924, acc.: 91%] [G loss: 5.482565]\n",
            "3381 [ D loss: 0.304485, acc.: 89%] [G loss: 4.993810]\n",
            "3382 [ D loss: 0.171785, acc.: 95%] [G loss: 5.609912]\n",
            "3383 [ D loss: 0.316397, acc.: 86%] [G loss: 3.407870]\n",
            "3384 [ D loss: 0.177187, acc.: 95%] [G loss: 5.895652]\n",
            "3385 [ D loss: 0.187055, acc.: 95%] [G loss: 5.480244]\n",
            "3386 [ D loss: 0.122452, acc.: 97%] [G loss: 9.489425]\n",
            "3387 [ D loss: 0.145571, acc.: 94%] [G loss: 5.140558]\n",
            "3388 [ D loss: 0.100520, acc.: 98%] [G loss: 4.250409]\n",
            "3389 [ D loss: 0.204544, acc.: 91%] [G loss: 3.832905]\n",
            "3390 [ D loss: 0.153665, acc.: 94%] [G loss: 5.162796]\n",
            "3391 [ D loss: 0.183251, acc.: 96%] [G loss: 3.955566]\n",
            "3392 [ D loss: 0.241912, acc.: 91%] [G loss: 2.944563]\n",
            "3393 [ D loss: 0.200154, acc.: 94%] [G loss: 3.903491]\n",
            "3394 [ D loss: 0.142330, acc.: 99%] [G loss: 6.155523]\n",
            "3395 [ D loss: 0.133733, acc.: 95%] [G loss: 7.526896]\n",
            "3396 [ D loss: 0.162121, acc.: 96%] [G loss: 4.663312]\n",
            "3397 [ D loss: 0.211776, acc.: 93%] [G loss: 3.251338]\n",
            "3398 [ D loss: 0.202898, acc.: 93%] [G loss: 5.948471]\n",
            "3399 [ D loss: 0.189971, acc.: 92%] [G loss: 3.752043]\n",
            "3400 [ D loss: 0.222889, acc.: 94%] [G loss: 3.408611]\n",
            "3401 [ D loss: 0.304426, acc.: 90%] [G loss: 4.205306]\n",
            "3402 [ D loss: 0.280101, acc.: 89%] [G loss: 5.940553]\n",
            "3403 [ D loss: 0.249409, acc.: 91%] [G loss: 5.099540]\n",
            "3404 [ D loss: 0.171332, acc.: 95%] [G loss: 5.032228]\n",
            "3405 [ D loss: 0.200901, acc.: 95%] [G loss: 3.530832]\n",
            "3406 [ D loss: 0.382854, acc.: 83%] [G loss: 3.253866]\n",
            "3407 [ D loss: 0.193966, acc.: 95%] [G loss: 3.835701]\n",
            "3408 [ D loss: 0.316041, acc.: 90%] [G loss: 3.944678]\n",
            "3409 [ D loss: 0.175501, acc.: 94%] [G loss: 3.591323]\n",
            "3410 [ D loss: 0.258088, acc.: 91%] [G loss: 4.830616]\n",
            "3411 [ D loss: 0.176348, acc.: 95%] [G loss: 9.813261]\n",
            "3412 [ D loss: 0.171258, acc.: 93%] [G loss: 4.306988]\n",
            "3413 [ D loss: 0.171991, acc.: 94%] [G loss: 6.023605]\n",
            "3414 [ D loss: 0.224285, acc.: 95%] [G loss: 3.671898]\n",
            "3415 [ D loss: 0.131453, acc.: 99%] [G loss: 4.180241]\n",
            "3416 [ D loss: 0.269688, acc.: 92%] [G loss: 3.237650]\n",
            "3417 [ D loss: 0.193903, acc.: 94%] [G loss: 4.072095]\n",
            "3418 [ D loss: 0.214594, acc.: 96%] [G loss: 4.506302]\n",
            "3419 [ D loss: 0.197193, acc.: 95%] [G loss: 3.633449]\n",
            "3420 [ D loss: 0.196776, acc.: 94%] [G loss: 5.448987]\n",
            "3421 [ D loss: 0.163333, acc.: 92%] [G loss: 6.781564]\n",
            "3422 [ D loss: 0.152933, acc.: 94%] [G loss: 6.706153]\n",
            "3423 [ D loss: 0.136700, acc.: 95%] [G loss: 6.473186]\n",
            "3424 [ D loss: 0.198558, acc.: 92%] [G loss: 10.285979]\n",
            "3425 [ D loss: 0.247862, acc.: 91%] [G loss: 6.338503]\n",
            "3426 [ D loss: 0.114175, acc.: 98%] [G loss: 4.307199]\n",
            "3427 [ D loss: 0.134121, acc.: 95%] [G loss: 5.666451]\n",
            "3428 [ D loss: 0.233118, acc.: 90%] [G loss: 4.938327]\n",
            "3429 [ D loss: 0.178286, acc.: 95%] [G loss: 6.944248]\n",
            "3430 [ D loss: 0.176558, acc.: 96%] [G loss: 4.072033]\n",
            "3431 [ D loss: 0.175842, acc.: 95%] [G loss: 4.566691]\n",
            "3432 [ D loss: 0.265233, acc.: 91%] [G loss: 3.525566]\n",
            "3433 [ D loss: 0.215594, acc.: 94%] [G loss: 3.775372]\n",
            "3434 [ D loss: 0.252447, acc.: 91%] [G loss: 3.118099]\n",
            "3435 [ D loss: 0.223125, acc.: 92%] [G loss: 4.034004]\n",
            "3436 [ D loss: 0.186573, acc.: 96%] [G loss: 4.706039]\n",
            "3437 [ D loss: 0.156470, acc.: 97%] [G loss: 4.705766]\n",
            "3438 [ D loss: 0.221560, acc.: 93%] [G loss: 4.539605]\n",
            "3439 [ D loss: 0.210619, acc.: 92%] [G loss: 5.343366]\n",
            "3440 [ D loss: 0.156218, acc.: 96%] [G loss: 5.920268]\n",
            "3441 [ D loss: 0.158422, acc.: 95%] [G loss: 4.862233]\n",
            "3442 [ D loss: 0.318176, acc.: 87%] [G loss: 3.228326]\n",
            "3443 [ D loss: 0.209818, acc.: 93%] [G loss: 3.631203]\n",
            "3444 [ D loss: 0.216439, acc.: 95%] [G loss: 4.528222]\n",
            "3445 [ D loss: 0.219725, acc.: 94%] [G loss: 7.020955]\n",
            "3446 [ D loss: 0.152019, acc.: 95%] [G loss: 6.566900]\n",
            "3447 [ D loss: 0.165435, acc.: 96%] [G loss: 4.093649]\n",
            "3448 [ D loss: 0.148288, acc.: 97%] [G loss: 4.485516]\n",
            "3449 [ D loss: 0.237150, acc.: 93%] [G loss: 5.906132]\n",
            "3450 [ D loss: 0.245791, acc.: 88%] [G loss: 4.216300]\n",
            "3451 [ D loss: 0.248266, acc.: 91%] [G loss: 9.622953]\n",
            "3452 [ D loss: 0.074612, acc.: 98%] [G loss: 5.541920]\n",
            "3453 [ D loss: 0.124374, acc.: 99%] [G loss: 7.783889]\n",
            "3454 [ D loss: 0.195741, acc.: 93%] [G loss: 5.767233]\n",
            "3455 [ D loss: 0.170221, acc.: 96%] [G loss: 6.014577]\n",
            "3456 [ D loss: 0.138755, acc.: 97%] [G loss: 6.075650]\n",
            "3457 [ D loss: 0.193311, acc.: 93%] [G loss: 5.556452]\n",
            "3458 [ D loss: 0.173856, acc.: 95%] [G loss: 7.124858]\n",
            "3459 [ D loss: 0.131570, acc.: 98%] [G loss: 3.990609]\n",
            "3460 [ D loss: 0.178032, acc.: 95%] [G loss: 3.731642]\n",
            "3461 [ D loss: 0.236645, acc.: 94%] [G loss: 3.833061]\n",
            "3462 [ D loss: 0.230436, acc.: 90%] [G loss: 3.322392]\n",
            "3463 [ D loss: 0.241045, acc.: 91%] [G loss: 3.306617]\n",
            "3464 [ D loss: 0.194089, acc.: 92%] [G loss: 4.473278]\n",
            "3465 [ D loss: 0.233753, acc.: 92%] [G loss: 2.893161]\n",
            "3466 [ D loss: 0.177900, acc.: 97%] [G loss: 3.054941]\n",
            "3467 [ D loss: 0.216941, acc.: 95%] [G loss: 3.417902]\n",
            "3468 [ D loss: 0.285888, acc.: 86%] [G loss: 4.464691]\n",
            "3469 [ D loss: 0.208058, acc.: 95%] [G loss: 4.107783]\n",
            "3470 [ D loss: 0.214566, acc.: 95%] [G loss: 3.788115]\n",
            "3471 [ D loss: 0.217187, acc.: 95%] [G loss: 2.600168]\n",
            "3472 [ D loss: 0.218171, acc.: 92%] [G loss: 3.647869]\n",
            "3473 [ D loss: 0.181889, acc.: 95%] [G loss: 3.829091]\n",
            "3474 [ D loss: 0.226649, acc.: 94%] [G loss: 3.621023]\n",
            "3475 [ D loss: 0.145460, acc.: 95%] [G loss: 4.600876]\n",
            "3476 [ D loss: 0.234811, acc.: 91%] [G loss: 5.124902]\n",
            "3477 [ D loss: 0.203881, acc.: 94%] [G loss: 6.679661]\n",
            "3478 [ D loss: 0.193313, acc.: 95%] [G loss: 3.476574]\n",
            "3479 [ D loss: 0.275315, acc.: 92%] [G loss: 5.640058]\n",
            "3480 [ D loss: 0.220277, acc.: 91%] [G loss: 5.228470]\n",
            "3481 [ D loss: 0.230237, acc.: 94%] [G loss: 4.162369]\n",
            "3482 [ D loss: 0.141062, acc.: 99%] [G loss: 4.000382]\n",
            "3483 [ D loss: 0.171758, acc.: 94%] [G loss: 4.275303]\n",
            "3484 [ D loss: 0.257363, acc.: 93%] [G loss: 3.417586]\n",
            "3485 [ D loss: 0.217064, acc.: 95%] [G loss: 3.775980]\n",
            "3486 [ D loss: 0.267237, acc.: 93%] [G loss: 4.003205]\n",
            "3487 [ D loss: 0.133895, acc.: 97%] [G loss: 4.309631]\n",
            "3488 [ D loss: 0.196092, acc.: 94%] [G loss: 3.653370]\n",
            "3489 [ D loss: 0.181665, acc.: 96%] [G loss: 4.223311]\n",
            "3490 [ D loss: 0.209937, acc.: 92%] [G loss: 4.165395]\n",
            "3491 [ D loss: 0.222357, acc.: 93%] [G loss: 4.011953]\n",
            "3492 [ D loss: 0.184424, acc.: 94%] [G loss: 4.526681]\n",
            "3493 [ D loss: 0.135927, acc.: 95%] [G loss: 5.238079]\n",
            "3494 [ D loss: 0.169798, acc.: 96%] [G loss: 3.760785]\n",
            "3495 [ D loss: 0.209575, acc.: 95%] [G loss: 3.878084]\n",
            "3496 [ D loss: 0.182413, acc.: 93%] [G loss: 4.535611]\n",
            "3497 [ D loss: 0.315083, acc.: 87%] [G loss: 3.918806]\n",
            "3498 [ D loss: 0.224826, acc.: 92%] [G loss: 4.211649]\n",
            "3499 [ D loss: 0.243870, acc.: 92%] [G loss: 4.148235]\n",
            "3500 [ D loss: 0.152495, acc.: 98%] [G loss: 5.593665]\n",
            "3501 [ D loss: 0.214216, acc.: 93%] [G loss: 4.992170]\n",
            "3502 [ D loss: 0.198968, acc.: 95%] [G loss: 4.938368]\n",
            "3503 [ D loss: 0.175427, acc.: 98%] [G loss: 3.624422]\n",
            "3504 [ D loss: 0.184427, acc.: 95%] [G loss: 4.072168]\n",
            "3505 [ D loss: 0.281701, acc.: 89%] [G loss: 4.023502]\n",
            "3506 [ D loss: 0.178614, acc.: 97%] [G loss: 3.899207]\n",
            "3507 [ D loss: 0.114293, acc.: 99%] [G loss: 3.650560]\n",
            "3508 [ D loss: 0.224267, acc.: 91%] [G loss: 3.665984]\n",
            "3509 [ D loss: 0.256588, acc.: 93%] [G loss: 3.214149]\n",
            "3510 [ D loss: 0.155721, acc.: 97%] [G loss: 4.559426]\n",
            "3511 [ D loss: 0.164521, acc.: 95%] [G loss: 4.152108]\n",
            "3512 [ D loss: 0.180492, acc.: 96%] [G loss: 3.748826]\n",
            "3513 [ D loss: 0.258514, acc.: 91%] [G loss: 4.250663]\n",
            "3514 [ D loss: 0.172307, acc.: 95%] [G loss: 3.660559]\n",
            "3515 [ D loss: 0.154812, acc.: 98%] [G loss: 3.822233]\n",
            "3516 [ D loss: 0.170485, acc.: 95%] [G loss: 3.401841]\n",
            "3517 [ D loss: 0.220540, acc.: 93%] [G loss: 4.850828]\n",
            "3518 [ D loss: 0.205618, acc.: 95%] [G loss: 4.860193]\n",
            "3519 [ D loss: 0.178331, acc.: 96%] [G loss: 4.528788]\n",
            "3520 [ D loss: 0.230017, acc.: 94%] [G loss: 5.618895]\n",
            "3521 [ D loss: 0.141473, acc.: 98%] [G loss: 3.970714]\n",
            "3522 [ D loss: 0.237709, acc.: 88%] [G loss: 4.696400]\n",
            "3523 [ D loss: 0.229704, acc.: 91%] [G loss: 8.174620]\n",
            "3524 [ D loss: 0.149898, acc.: 95%] [G loss: 6.156484]\n",
            "3525 [ D loss: 0.171631, acc.: 94%] [G loss: 10.325454]\n",
            "3526 [ D loss: 0.139718, acc.: 95%] [G loss: 10.515344]\n",
            "3527 [ D loss: 0.166236, acc.: 95%] [G loss: 7.504529]\n",
            "3528 [ D loss: 0.100014, acc.: 97%] [G loss: 6.168281]\n",
            "3529 [ D loss: 0.137201, acc.: 95%] [G loss: 5.123428]\n",
            "3530 [ D loss: 0.167632, acc.: 98%] [G loss: 4.043056]\n",
            "3531 [ D loss: 0.208935, acc.: 92%] [G loss: 4.351348]\n",
            "3532 [ D loss: 0.194839, acc.: 95%] [G loss: 4.667409]\n",
            "3533 [ D loss: 0.208978, acc.: 94%] [G loss: 4.451497]\n",
            "3534 [ D loss: 0.119913, acc.: 96%] [G loss: 10.734701]\n",
            "3535 [ D loss: 0.221360, acc.: 91%] [G loss: 4.198927]\n",
            "3536 [ D loss: 0.086431, acc.: 98%] [G loss: 7.344159]\n",
            "3537 [ D loss: 0.189797, acc.: 95%] [G loss: 4.554469]\n",
            "3538 [ D loss: 0.244253, acc.: 93%] [G loss: 5.612843]\n",
            "3539 [ D loss: 0.165627, acc.: 97%] [G loss: 4.647492]\n",
            "3540 [ D loss: 0.263699, acc.: 91%] [G loss: 4.036146]\n",
            "3541 [ D loss: 0.162717, acc.: 98%] [G loss: 4.217316]\n",
            "3542 [ D loss: 0.222975, acc.: 95%] [G loss: 3.126153]\n",
            "3543 [ D loss: 0.213600, acc.: 94%] [G loss: 3.381811]\n",
            "3544 [ D loss: 0.176377, acc.: 98%] [G loss: 4.145865]\n",
            "3545 [ D loss: 0.190592, acc.: 95%] [G loss: 4.377621]\n",
            "3546 [ D loss: 0.228344, acc.: 95%] [G loss: 5.163644]\n",
            "3547 [ D loss: 0.156466, acc.: 94%] [G loss: 6.865699]\n",
            "3548 [ D loss: 0.175719, acc.: 91%] [G loss: 5.671560]\n",
            "3549 [ D loss: 0.148277, acc.: 97%] [G loss: 4.362164]\n",
            "3550 [ D loss: 0.231450, acc.: 92%] [G loss: 4.603784]\n",
            "3551 [ D loss: 0.138764, acc.: 97%] [G loss: 5.363170]\n",
            "3552 [ D loss: 0.152543, acc.: 94%] [G loss: 4.672408]\n",
            "3553 [ D loss: 0.132044, acc.: 97%] [G loss: 5.765139]\n",
            "3554 [ D loss: 0.099003, acc.: 98%] [G loss: 4.999671]\n",
            "3555 [ D loss: 0.212355, acc.: 94%] [G loss: 3.897061]\n",
            "3556 [ D loss: 0.169897, acc.: 96%] [G loss: 3.672198]\n",
            "3557 [ D loss: 0.193912, acc.: 94%] [G loss: 3.920714]\n",
            "3558 [ D loss: 0.212021, acc.: 93%] [G loss: 4.339450]\n",
            "3559 [ D loss: 0.214594, acc.: 93%] [G loss: 4.081346]\n",
            "3560 [ D loss: 0.279400, acc.: 89%] [G loss: 3.094378]\n",
            "3561 [ D loss: 0.236198, acc.: 94%] [G loss: 3.682417]\n",
            "3562 [ D loss: 0.224699, acc.: 94%] [G loss: 3.698073]\n",
            "3563 [ D loss: 0.226456, acc.: 95%] [G loss: 4.984222]\n",
            "3564 [ D loss: 0.235704, acc.: 95%] [G loss: 6.735791]\n",
            "3565 [ D loss: 0.155880, acc.: 93%] [G loss: 5.091368]\n",
            "3566 [ D loss: 0.185884, acc.: 95%] [G loss: 4.103314]\n",
            "3567 [ D loss: 0.158111, acc.: 95%] [G loss: 3.975029]\n",
            "3568 [ D loss: 0.220018, acc.: 93%] [G loss: 4.106413]\n",
            "3569 [ D loss: 0.234538, acc.: 94%] [G loss: 4.220144]\n",
            "3570 [ D loss: 0.173200, acc.: 96%] [G loss: 4.982247]\n",
            "3571 [ D loss: 0.235861, acc.: 93%] [G loss: 3.033112]\n",
            "3572 [ D loss: 0.191052, acc.: 97%] [G loss: 3.602898]\n",
            "3573 [ D loss: 0.164687, acc.: 97%] [G loss: 3.767938]\n",
            "3574 [ D loss: 0.292919, acc.: 90%] [G loss: 3.377632]\n",
            "3575 [ D loss: 0.231802, acc.: 90%] [G loss: 6.391822]\n",
            "3576 [ D loss: 0.287200, acc.: 86%] [G loss: 4.406707]\n",
            "3577 [ D loss: 0.109551, acc.: 96%] [G loss: 5.781822]\n",
            "3578 [ D loss: 0.194495, acc.: 93%] [G loss: 5.096225]\n",
            "3579 [ D loss: 0.147085, acc.: 96%] [G loss: 5.966645]\n",
            "3580 [ D loss: 0.190675, acc.: 92%] [G loss: 6.653174]\n",
            "3581 [ D loss: 0.108623, acc.: 96%] [G loss: 9.653641]\n",
            "3582 [ D loss: 0.171146, acc.: 96%] [G loss: 5.869760]\n",
            "3583 [ D loss: 0.239649, acc.: 90%] [G loss: 4.383535]\n",
            "3584 [ D loss: 0.207195, acc.: 95%] [G loss: 3.882273]\n",
            "3585 [ D loss: 0.265765, acc.: 90%] [G loss: 3.898709]\n",
            "3586 [ D loss: 0.148628, acc.: 98%] [G loss: 3.981727]\n",
            "3587 [ D loss: 0.159291, acc.: 96%] [G loss: 3.607015]\n",
            "3588 [ D loss: 0.165521, acc.: 95%] [G loss: 4.006327]\n",
            "3589 [ D loss: 0.250249, acc.: 93%] [G loss: 3.897451]\n",
            "3590 [ D loss: 0.234869, acc.: 91%] [G loss: 5.378368]\n",
            "3591 [ D loss: 0.200053, acc.: 95%] [G loss: 3.931662]\n",
            "3592 [ D loss: 0.258146, acc.: 89%] [G loss: 3.941857]\n",
            "3593 [ D loss: 0.153893, acc.: 95%] [G loss: 4.836386]\n",
            "3594 [ D loss: 0.201521, acc.: 93%] [G loss: 4.265810]\n",
            "3595 [ D loss: 0.235800, acc.: 92%] [G loss: 5.341080]\n",
            "3596 [ D loss: 0.223380, acc.: 93%] [G loss: 3.275987]\n",
            "3597 [ D loss: 0.113134, acc.: 98%] [G loss: 3.853920]\n",
            "3598 [ D loss: 0.254598, acc.: 92%] [G loss: 4.083725]\n",
            "3599 [ D loss: 0.125258, acc.: 100%] [G loss: 3.612832]\n",
            "3600 [ D loss: 0.188783, acc.: 95%] [G loss: 4.807217]\n",
            "3601 [ D loss: 0.250628, acc.: 92%] [G loss: 3.943189]\n",
            "3602 [ D loss: 0.214092, acc.: 96%] [G loss: 10.394081]\n",
            "3603 [ D loss: 0.213280, acc.: 93%] [G loss: 6.431020]\n",
            "3604 [ D loss: 0.135205, acc.: 96%] [G loss: 4.457214]\n",
            "3605 [ D loss: 0.081289, acc.: 97%] [G loss: 12.833536]\n",
            "3606 [ D loss: 0.052042, acc.: 98%] [G loss: 12.830198]\n",
            "3607 [ D loss: 0.084250, acc.: 97%] [G loss: 10.612551]\n",
            "3608 [ D loss: 0.091710, acc.: 97%] [G loss: 9.036107]\n",
            "3609 [ D loss: 0.094200, acc.: 98%] [G loss: 4.818480]\n",
            "3610 [ D loss: 0.134945, acc.: 95%] [G loss: 5.203373]\n",
            "3611 [ D loss: 0.098890, acc.: 97%] [G loss: 4.943405]\n",
            "3612 [ D loss: 0.181512, acc.: 95%] [G loss: 3.562636]\n",
            "3613 [ D loss: 0.200187, acc.: 94%] [G loss: 3.692222]\n",
            "3614 [ D loss: 0.201573, acc.: 95%] [G loss: 3.422588]\n",
            "3615 [ D loss: 0.178751, acc.: 98%] [G loss: 3.046332]\n",
            "3616 [ D loss: 0.186300, acc.: 97%] [G loss: 4.424870]\n",
            "3617 [ D loss: 0.284035, acc.: 90%] [G loss: 4.551410]\n",
            "3618 [ D loss: 0.198143, acc.: 94%] [G loss: 7.974565]\n",
            "3619 [ D loss: 0.260826, acc.: 88%] [G loss: 4.967296]\n",
            "3620 [ D loss: 0.167003, acc.: 95%] [G loss: 4.715501]\n",
            "3621 [ D loss: 0.152402, acc.: 96%] [G loss: 4.111069]\n",
            "3622 [ D loss: 0.177009, acc.: 97%] [G loss: 4.182951]\n",
            "3623 [ D loss: 0.273578, acc.: 87%] [G loss: 4.090963]\n",
            "3624 [ D loss: 0.171595, acc.: 92%] [G loss: 6.902517]\n",
            "3625 [ D loss: 0.175327, acc.: 96%] [G loss: 6.282468]\n",
            "3626 [ D loss: 0.144504, acc.: 97%] [G loss: 4.052900]\n",
            "3627 [ D loss: 0.200843, acc.: 95%] [G loss: 5.546725]\n",
            "3628 [ D loss: 0.128104, acc.: 94%] [G loss: 5.143718]\n",
            "3629 [ D loss: 0.210581, acc.: 94%] [G loss: 3.301133]\n",
            "3630 [ D loss: 0.259843, acc.: 88%] [G loss: 5.300419]\n",
            "3631 [ D loss: 0.147838, acc.: 94%] [G loss: 4.741549]\n",
            "3632 [ D loss: 0.169661, acc.: 95%] [G loss: 5.229296]\n",
            "3633 [ D loss: 0.191295, acc.: 95%] [G loss: 4.995239]\n",
            "3634 [ D loss: 0.186177, acc.: 94%] [G loss: 4.786561]\n",
            "3635 [ D loss: 0.244729, acc.: 92%] [G loss: 5.178744]\n",
            "3636 [ D loss: 0.161968, acc.: 95%] [G loss: 4.401870]\n",
            "3637 [ D loss: 0.171732, acc.: 98%] [G loss: 3.925058]\n",
            "3638 [ D loss: 0.173326, acc.: 95%] [G loss: 4.106426]\n",
            "3639 [ D loss: 0.208665, acc.: 92%] [G loss: 4.109637]\n",
            "3640 [ D loss: 0.221621, acc.: 94%] [G loss: 3.290485]\n",
            "3641 [ D loss: 0.184926, acc.: 95%] [G loss: 3.850334]\n",
            "3642 [ D loss: 0.320322, acc.: 91%] [G loss: 3.851525]\n",
            "3643 [ D loss: 0.393556, acc.: 83%] [G loss: 3.743866]\n",
            "3644 [ D loss: 0.169755, acc.: 95%] [G loss: 3.814877]\n",
            "3645 [ D loss: 0.278816, acc.: 85%] [G loss: 9.703953]\n",
            "3646 [ D loss: 0.184378, acc.: 94%] [G loss: 8.258259]\n",
            "3647 [ D loss: 0.166997, acc.: 95%] [G loss: 8.156102]\n",
            "3648 [ D loss: 0.126975, acc.: 95%] [G loss: 4.857216]\n",
            "3649 [ D loss: 0.128550, acc.: 98%] [G loss: 6.148736]\n",
            "3650 [ D loss: 0.172103, acc.: 96%] [G loss: 3.515307]\n",
            "3651 [ D loss: 0.143198, acc.: 98%] [G loss: 4.991862]\n",
            "3652 [ D loss: 0.168919, acc.: 95%] [G loss: 4.552797]\n",
            "3653 [ D loss: 0.233266, acc.: 91%] [G loss: 3.856997]\n",
            "3654 [ D loss: 0.140433, acc.: 96%] [G loss: 4.214738]\n",
            "3655 [ D loss: 0.211725, acc.: 95%] [G loss: 4.271891]\n",
            "3656 [ D loss: 0.173679, acc.: 97%] [G loss: 4.298111]\n",
            "3657 [ D loss: 0.274104, acc.: 89%] [G loss: 3.558544]\n",
            "3658 [ D loss: 0.155025, acc.: 96%] [G loss: 5.430118]\n",
            "3659 [ D loss: 0.218961, acc.: 92%] [G loss: 4.169968]\n",
            "3660 [ D loss: 0.322419, acc.: 87%] [G loss: 3.994518]\n",
            "3661 [ D loss: 0.240412, acc.: 93%] [G loss: 4.683479]\n",
            "3662 [ D loss: 0.251362, acc.: 90%] [G loss: 4.459764]\n",
            "3663 [ D loss: 0.355135, acc.: 86%] [G loss: 4.160989]\n",
            "3664 [ D loss: 0.172750, acc.: 95%] [G loss: 4.860848]\n",
            "3665 [ D loss: 0.279261, acc.: 88%] [G loss: 3.769431]\n",
            "3666 [ D loss: 0.253117, acc.: 91%] [G loss: 3.829938]\n",
            "3667 [ D loss: 0.291052, acc.: 91%] [G loss: 3.680826]\n",
            "3668 [ D loss: 0.332475, acc.: 86%] [G loss: 2.982388]\n",
            "3669 [ D loss: 0.338223, acc.: 88%] [G loss: 4.057111]\n",
            "3670 [ D loss: 0.186508, acc.: 95%] [G loss: 4.724957]\n",
            "3671 [ D loss: 0.213805, acc.: 95%] [G loss: 3.973150]\n",
            "3672 [ D loss: 0.179074, acc.: 93%] [G loss: 4.356894]\n",
            "3673 [ D loss: 0.166794, acc.: 96%] [G loss: 4.377856]\n",
            "3674 [ D loss: 0.144774, acc.: 95%] [G loss: 5.793119]\n",
            "3675 [ D loss: 0.182239, acc.: 98%] [G loss: 9.041090]\n",
            "3676 [ D loss: 0.137312, acc.: 96%] [G loss: 7.470929]\n",
            "3677 [ D loss: 0.140024, acc.: 96%] [G loss: 10.204324]\n",
            "3678 [ D loss: 0.073289, acc.: 98%] [G loss: 10.032213]\n",
            "3679 [ D loss: 0.068985, acc.: 98%] [G loss: 9.562353]\n",
            "3680 [ D loss: 0.154025, acc.: 92%] [G loss: 10.196118]\n",
            "3681 [ D loss: 0.172456, acc.: 95%] [G loss: 4.882451]\n",
            "3682 [ D loss: 0.156436, acc.: 95%] [G loss: 5.280868]\n",
            "3683 [ D loss: 0.158762, acc.: 96%] [G loss: 5.175315]\n",
            "3684 [ D loss: 0.185420, acc.: 94%] [G loss: 4.483946]\n",
            "3685 [ D loss: 0.173295, acc.: 98%] [G loss: 3.901495]\n",
            "3686 [ D loss: 0.221794, acc.: 94%] [G loss: 4.272067]\n",
            "3687 [ D loss: 0.249130, acc.: 94%] [G loss: 3.875180]\n",
            "3688 [ D loss: 0.226960, acc.: 92%] [G loss: 4.281783]\n",
            "3689 [ D loss: 0.145963, acc.: 98%] [G loss: 4.309236]\n",
            "3690 [ D loss: 0.155520, acc.: 95%] [G loss: 3.117408]\n",
            "3691 [ D loss: 0.172579, acc.: 95%] [G loss: 6.492204]\n",
            "3692 [ D loss: 0.174588, acc.: 95%] [G loss: 6.940891]\n",
            "3693 [ D loss: 0.175320, acc.: 95%] [G loss: 5.742233]\n",
            "3694 [ D loss: 0.157969, acc.: 97%] [G loss: 6.760874]\n",
            "3695 [ D loss: 0.225871, acc.: 94%] [G loss: 4.120280]\n",
            "3696 [ D loss: 0.228455, acc.: 92%] [G loss: 3.794169]\n",
            "3697 [ D loss: 0.289872, acc.: 89%] [G loss: 3.570577]\n",
            "3698 [ D loss: 0.206275, acc.: 92%] [G loss: 4.626051]\n",
            "3699 [ D loss: 0.136019, acc.: 97%] [G loss: 6.896709]\n",
            "3700 [ D loss: 0.164305, acc.: 95%] [G loss: 4.642249]\n",
            "3701 [ D loss: 0.281996, acc.: 87%] [G loss: 4.061194]\n",
            "3702 [ D loss: 0.228764, acc.: 94%] [G loss: 3.651230]\n",
            "3703 [ D loss: 0.178407, acc.: 94%] [G loss: 4.729650]\n",
            "3704 [ D loss: 0.245175, acc.: 94%] [G loss: 4.319107]\n",
            "3705 [ D loss: 0.119078, acc.: 99%] [G loss: 5.596847]\n",
            "3706 [ D loss: 0.178523, acc.: 94%] [G loss: 6.810954]\n",
            "3707 [ D loss: 0.209198, acc.: 93%] [G loss: 5.883807]\n",
            "3708 [ D loss: 0.156261, acc.: 94%] [G loss: 5.057040]\n",
            "3709 [ D loss: 0.149152, acc.: 97%] [G loss: 4.604756]\n",
            "3710 [ D loss: 0.151331, acc.: 95%] [G loss: 4.851355]\n",
            "3711 [ D loss: 0.207810, acc.: 93%] [G loss: 4.858943]\n",
            "3712 [ D loss: 0.128153, acc.: 98%] [G loss: 5.381092]\n",
            "3713 [ D loss: 0.194010, acc.: 96%] [G loss: 4.603737]\n",
            "3714 [ D loss: 0.209423, acc.: 93%] [G loss: 4.667360]\n",
            "3715 [ D loss: 0.164834, acc.: 98%] [G loss: 3.591904]\n",
            "3716 [ D loss: 0.191636, acc.: 95%] [G loss: 3.912674]\n",
            "3717 [ D loss: 0.258634, acc.: 89%] [G loss: 4.629395]\n",
            "3718 [ D loss: 0.272234, acc.: 91%] [G loss: 4.350369]\n",
            "3719 [ D loss: 0.345793, acc.: 84%] [G loss: 4.991623]\n",
            "3720 [ D loss: 0.336262, acc.: 88%] [G loss: 4.315277]\n",
            "3721 [ D loss: 0.169643, acc.: 95%] [G loss: 4.309710]\n",
            "3722 [ D loss: 0.182669, acc.: 95%] [G loss: 4.726140]\n",
            "3723 [ D loss: 0.198023, acc.: 93%] [G loss: 4.325183]\n",
            "3724 [ D loss: 0.170939, acc.: 97%] [G loss: 4.395721]\n",
            "3725 [ D loss: 0.195374, acc.: 95%] [G loss: 4.311415]\n",
            "3726 [ D loss: 0.194097, acc.: 95%] [G loss: 3.589424]\n",
            "3727 [ D loss: 0.199133, acc.: 93%] [G loss: 3.640460]\n",
            "3728 [ D loss: 0.181672, acc.: 96%] [G loss: 3.633107]\n",
            "3729 [ D loss: 0.228676, acc.: 95%] [G loss: 3.547281]\n",
            "3730 [ D loss: 0.215130, acc.: 93%] [G loss: 4.115471]\n",
            "3731 [ D loss: 0.226016, acc.: 92%] [G loss: 3.366958]\n",
            "3732 [ D loss: 0.139896, acc.: 97%] [G loss: 5.075508]\n",
            "3733 [ D loss: 0.175509, acc.: 95%] [G loss: 5.985342]\n",
            "3734 [ D loss: 0.138894, acc.: 98%] [G loss: 3.996699]\n",
            "3735 [ D loss: 0.146150, acc.: 95%] [G loss: 3.844784]\n",
            "3736 [ D loss: 0.107862, acc.: 98%] [G loss: 5.329529]\n",
            "3737 [ D loss: 0.162874, acc.: 96%] [G loss: 5.284406]\n",
            "3738 [ D loss: 0.147217, acc.: 94%] [G loss: 6.796892]\n",
            "3739 [ D loss: 0.162658, acc.: 96%] [G loss: 5.052190]\n",
            "3740 [ D loss: 0.162722, acc.: 95%] [G loss: 3.896696]\n",
            "3741 [ D loss: 0.181350, acc.: 94%] [G loss: 4.128646]\n",
            "3742 [ D loss: 0.112813, acc.: 98%] [G loss: 9.942034]\n",
            "3743 [ D loss: 0.219741, acc.: 91%] [G loss: 3.903641]\n",
            "3744 [ D loss: 0.172118, acc.: 94%] [G loss: 5.262246]\n",
            "3745 [ D loss: 0.351001, acc.: 84%] [G loss: 3.692611]\n",
            "3746 [ D loss: 0.272596, acc.: 91%] [G loss: 5.160536]\n",
            "3747 [ D loss: 0.148062, acc.: 95%] [G loss: 4.997299]\n",
            "3748 [ D loss: 0.224088, acc.: 95%] [G loss: 3.833932]\n",
            "3749 [ D loss: 0.130447, acc.: 98%] [G loss: 4.944299]\n",
            "3750 [ D loss: 0.255192, acc.: 91%] [G loss: 3.951308]\n",
            "3751 [ D loss: 0.108949, acc.: 98%] [G loss: 4.005657]\n",
            "3752 [ D loss: 0.256383, acc.: 91%] [G loss: 3.492529]\n",
            "3753 [ D loss: 0.105243, acc.: 98%] [G loss: 7.265903]\n",
            "3754 [ D loss: 0.128695, acc.: 95%] [G loss: 5.361325]\n",
            "3755 [ D loss: 0.225088, acc.: 91%] [G loss: 5.155348]\n",
            "3756 [ D loss: 0.216118, acc.: 97%] [G loss: 5.819396]\n",
            "3757 [ D loss: 0.292512, acc.: 87%] [G loss: 4.456906]\n",
            "3758 [ D loss: 0.133431, acc.: 98%] [G loss: 3.849204]\n",
            "3759 [ D loss: 0.171161, acc.: 96%] [G loss: 4.424672]\n",
            "3760 [ D loss: 0.182608, acc.: 95%] [G loss: 5.725772]\n",
            "3761 [ D loss: 0.196190, acc.: 95%] [G loss: 4.294432]\n",
            "3762 [ D loss: 0.264998, acc.: 93%] [G loss: 4.243289]\n",
            "3763 [ D loss: 0.155492, acc.: 97%] [G loss: 3.969448]\n",
            "3764 [ D loss: 0.220304, acc.: 94%] [G loss: 4.962359]\n",
            "3765 [ D loss: 0.169493, acc.: 93%] [G loss: 7.156417]\n",
            "3766 [ D loss: 0.169933, acc.: 98%] [G loss: 4.130198]\n",
            "3767 [ D loss: 0.179323, acc.: 93%] [G loss: 5.113526]\n",
            "3768 [ D loss: 0.260902, acc.: 89%] [G loss: 4.908599]\n",
            "3769 [ D loss: 0.147047, acc.: 97%] [G loss: 4.339052]\n",
            "3770 [ D loss: 0.181650, acc.: 94%] [G loss: 7.615474]\n",
            "3771 [ D loss: 0.147242, acc.: 96%] [G loss: 4.856520]\n",
            "3772 [ D loss: 0.135090, acc.: 99%] [G loss: 4.766331]\n",
            "3773 [ D loss: 0.183264, acc.: 95%] [G loss: 5.300461]\n",
            "3774 [ D loss: 0.131023, acc.: 96%] [G loss: 6.876008]\n",
            "3775 [ D loss: 0.227682, acc.: 90%] [G loss: 6.888977]\n",
            "3776 [ D loss: 0.117799, acc.: 97%] [G loss: 8.308680]\n",
            "3777 [ D loss: 0.078281, acc.: 99%] [G loss: 8.882051]\n",
            "3778 [ D loss: 0.149977, acc.: 95%] [G loss: 6.200378]\n",
            "3779 [ D loss: 0.130756, acc.: 95%] [G loss: 5.689501]\n",
            "3780 [ D loss: 0.166726, acc.: 95%] [G loss: 5.380744]\n",
            "3781 [ D loss: 0.214821, acc.: 93%] [G loss: 7.536830]\n",
            "3782 [ D loss: 0.228094, acc.: 91%] [G loss: 5.105347]\n",
            "3783 [ D loss: 0.122544, acc.: 97%] [G loss: 8.599959]\n",
            "3784 [ D loss: 0.176925, acc.: 96%] [G loss: 3.641341]\n",
            "3785 [ D loss: 0.162305, acc.: 95%] [G loss: 5.274547]\n",
            "3786 [ D loss: 0.098353, acc.: 98%] [G loss: 5.991543]\n",
            "3787 [ D loss: 0.185223, acc.: 94%] [G loss: 5.101054]\n",
            "3788 [ D loss: 0.125895, acc.: 97%] [G loss: 4.360296]\n",
            "3789 [ D loss: 0.223545, acc.: 92%] [G loss: 4.155045]\n",
            "3790 [ D loss: 0.201564, acc.: 92%] [G loss: 4.930861]\n",
            "3791 [ D loss: 0.182273, acc.: 93%] [G loss: 5.383967]\n",
            "3792 [ D loss: 0.264120, acc.: 90%] [G loss: 4.747097]\n",
            "3793 [ D loss: 0.278041, acc.: 87%] [G loss: 4.045376]\n",
            "3794 [ D loss: 0.144412, acc.: 98%] [G loss: 4.805225]\n",
            "3795 [ D loss: 0.166668, acc.: 96%] [G loss: 4.406254]\n",
            "3796 [ D loss: 0.206082, acc.: 95%] [G loss: 4.426217]\n",
            "3797 [ D loss: 0.138930, acc.: 95%] [G loss: 4.954079]\n",
            "3798 [ D loss: 0.175729, acc.: 95%] [G loss: 4.873966]\n",
            "3799 [ D loss: 0.209617, acc.: 95%] [G loss: 5.453976]\n",
            "3800 [ D loss: 0.177425, acc.: 95%] [G loss: 3.979457]\n",
            "3801 [ D loss: 0.219696, acc.: 94%] [G loss: 4.208503]\n",
            "3802 [ D loss: 0.143889, acc.: 97%] [G loss: 4.715692]\n",
            "3803 [ D loss: 0.351057, acc.: 84%] [G loss: 6.165630]\n",
            "3804 [ D loss: 0.182199, acc.: 93%] [G loss: 13.302418]\n",
            "3805 [ D loss: 0.193233, acc.: 91%] [G loss: 5.902856]\n",
            "3806 [ D loss: 0.113190, acc.: 98%] [G loss: 4.179002]\n",
            "3807 [ D loss: 0.178024, acc.: 96%] [G loss: 4.845225]\n",
            "3808 [ D loss: 0.132103, acc.: 97%] [G loss: 5.978180]\n",
            "3809 [ D loss: 0.192043, acc.: 95%] [G loss: 4.435431]\n",
            "3810 [ D loss: 0.142404, acc.: 96%] [G loss: 4.660129]\n",
            "3811 [ D loss: 0.240795, acc.: 93%] [G loss: 3.768664]\n",
            "3812 [ D loss: 0.174023, acc.: 91%] [G loss: 5.014451]\n",
            "3813 [ D loss: 0.242772, acc.: 88%] [G loss: 4.139472]\n",
            "3814 [ D loss: 0.194508, acc.: 94%] [G loss: 6.792598]\n",
            "3815 [ D loss: 0.148267, acc.: 95%] [G loss: 5.470961]\n",
            "3816 [ D loss: 0.294389, acc.: 89%] [G loss: 4.072689]\n",
            "3817 [ D loss: 0.231563, acc.: 92%] [G loss: 4.566556]\n",
            "3818 [ D loss: 0.319938, acc.: 86%] [G loss: 3.469598]\n",
            "3819 [ D loss: 0.194030, acc.: 95%] [G loss: 4.299527]\n",
            "3820 [ D loss: 0.182706, acc.: 93%] [G loss: 3.958591]\n",
            "3821 [ D loss: 0.210651, acc.: 93%] [G loss: 4.284783]\n",
            "3822 [ D loss: 0.146845, acc.: 97%] [G loss: 4.350887]\n",
            "3823 [ D loss: 0.138071, acc.: 98%] [G loss: 4.254831]\n",
            "3824 [ D loss: 0.167019, acc.: 95%] [G loss: 4.818298]\n",
            "3825 [ D loss: 0.148202, acc.: 97%] [G loss: 4.178559]\n",
            "3826 [ D loss: 0.128417, acc.: 98%] [G loss: 5.683521]\n",
            "3827 [ D loss: 0.147688, acc.: 99%] [G loss: 4.364088]\n",
            "3828 [ D loss: 0.283039, acc.: 84%] [G loss: 3.984371]\n",
            "3829 [ D loss: 0.259109, acc.: 91%] [G loss: 4.372053]\n",
            "3830 [ D loss: 0.299351, acc.: 87%] [G loss: 6.360662]\n",
            "3831 [ D loss: 0.582021, acc.: 71%] [G loss: 11.953552]\n",
            "3832 [ D loss: 0.491302, acc.: 77%] [G loss: 4.100404]\n",
            "3833 [ D loss: 0.175448, acc.: 94%] [G loss: 3.639266]\n",
            "3834 [ D loss: 0.137775, acc.: 98%] [G loss: 4.926275]\n",
            "3835 [ D loss: 0.206137, acc.: 93%] [G loss: 4.131890]\n",
            "3836 [ D loss: 0.150348, acc.: 97%] [G loss: 6.445737]\n",
            "3837 [ D loss: 0.235081, acc.: 90%] [G loss: 4.670792]\n",
            "3838 [ D loss: 0.221771, acc.: 92%] [G loss: 10.407494]\n",
            "3839 [ D loss: 0.151617, acc.: 94%] [G loss: 4.981014]\n",
            "3840 [ D loss: 0.133894, acc.: 95%] [G loss: 4.953004]\n",
            "3841 [ D loss: 0.127283, acc.: 98%] [G loss: 8.855635]\n",
            "3842 [ D loss: 0.115057, acc.: 97%] [G loss: 5.268614]\n",
            "3843 [ D loss: 0.080520, acc.: 98%] [G loss: 7.890702]\n",
            "3844 [ D loss: 0.152470, acc.: 94%] [G loss: 4.523247]\n",
            "3845 [ D loss: 0.133284, acc.: 95%] [G loss: 5.753338]\n",
            "3846 [ D loss: 0.244429, acc.: 91%] [G loss: 5.459260]\n",
            "3847 [ D loss: 0.250220, acc.: 89%] [G loss: 6.086822]\n",
            "3848 [ D loss: 0.197663, acc.: 91%] [G loss: 4.217538]\n",
            "3849 [ D loss: 0.147068, acc.: 97%] [G loss: 4.534185]\n",
            "3850 [ D loss: 0.242037, acc.: 91%] [G loss: 3.884008]\n",
            "3851 [ D loss: 0.222500, acc.: 92%] [G loss: 3.849689]\n",
            "3852 [ D loss: 0.232383, acc.: 93%] [G loss: 3.629318]\n",
            "3853 [ D loss: 0.235140, acc.: 94%] [G loss: 4.377964]\n",
            "3854 [ D loss: 0.265747, acc.: 90%] [G loss: 3.107723]\n",
            "3855 [ D loss: 0.174034, acc.: 95%] [G loss: 3.719707]\n",
            "3856 [ D loss: 0.267720, acc.: 91%] [G loss: 4.445463]\n",
            "3857 [ D loss: 0.239127, acc.: 91%] [G loss: 4.328472]\n",
            "3858 [ D loss: 0.261223, acc.: 89%] [G loss: 4.445173]\n",
            "3859 [ D loss: 0.100379, acc.: 98%] [G loss: 4.192806]\n",
            "3860 [ D loss: 0.268857, acc.: 88%] [G loss: 5.139327]\n",
            "3861 [ D loss: 0.147755, acc.: 95%] [G loss: 6.751125]\n",
            "3862 [ D loss: 0.179889, acc.: 96%] [G loss: 5.721762]\n",
            "3863 [ D loss: 0.315640, acc.: 84%] [G loss: 4.146556]\n",
            "3864 [ D loss: 0.115218, acc.: 97%] [G loss: 5.527054]\n",
            "3865 [ D loss: 0.177772, acc.: 95%] [G loss: 3.566018]\n",
            "3866 [ D loss: 0.167976, acc.: 94%] [G loss: 3.628721]\n",
            "3867 [ D loss: 0.144343, acc.: 96%] [G loss: 4.351021]\n",
            "3868 [ D loss: 0.226692, acc.: 93%] [G loss: 3.728124]\n",
            "3869 [ D loss: 0.173735, acc.: 96%] [G loss: 3.436221]\n",
            "3870 [ D loss: 0.251678, acc.: 94%] [G loss: 4.314363]\n",
            "3871 [ D loss: 0.232373, acc.: 93%] [G loss: 4.295172]\n",
            "3872 [ D loss: 0.237360, acc.: 90%] [G loss: 5.536535]\n",
            "3873 [ D loss: 0.114300, acc.: 98%] [G loss: 7.802032]\n",
            "3874 [ D loss: 0.135736, acc.: 96%] [G loss: 4.395854]\n",
            "3875 [ D loss: 0.235086, acc.: 92%] [G loss: 4.357286]\n",
            "3876 [ D loss: 0.110204, acc.: 98%] [G loss: 7.456352]\n",
            "3877 [ D loss: 0.193323, acc.: 94%] [G loss: 4.491093]\n",
            "3878 [ D loss: 0.157652, acc.: 96%] [G loss: 5.404085]\n",
            "3879 [ D loss: 0.189284, acc.: 95%] [G loss: 3.820943]\n",
            "3880 [ D loss: 0.235685, acc.: 90%] [G loss: 5.456760]\n",
            "3881 [ D loss: 0.342845, acc.: 84%] [G loss: 3.798909]\n",
            "3882 [ D loss: 0.172165, acc.: 94%] [G loss: 5.142782]\n",
            "3883 [ D loss: 0.209521, acc.: 91%] [G loss: 4.325261]\n",
            "3884 [ D loss: 0.177422, acc.: 95%] [G loss: 6.256993]\n",
            "3885 [ D loss: 0.076924, acc.: 99%] [G loss: 6.323486]\n",
            "3886 [ D loss: 0.152341, acc.: 94%] [G loss: 5.952980]\n",
            "3887 [ D loss: 0.208287, acc.: 90%] [G loss: 5.591164]\n",
            "3888 [ D loss: 0.099474, acc.: 95%] [G loss: 6.318847]\n",
            "3889 [ D loss: 0.171698, acc.: 94%] [G loss: 5.493350]\n",
            "3890 [ D loss: 0.175040, acc.: 94%] [G loss: 4.408459]\n",
            "3891 [ D loss: 0.191460, acc.: 94%] [G loss: 5.606170]\n",
            "3892 [ D loss: 0.194835, acc.: 92%] [G loss: 6.521043]\n",
            "3893 [ D loss: 0.237582, acc.: 89%] [G loss: 4.160767]\n",
            "3894 [ D loss: 0.177034, acc.: 95%] [G loss: 6.529238]\n",
            "3895 [ D loss: 0.202697, acc.: 94%] [G loss: 6.103503]\n",
            "3896 [ D loss: 0.160866, acc.: 97%] [G loss: 3.707157]\n",
            "3897 [ D loss: 0.128577, acc.: 98%] [G loss: 4.290975]\n",
            "3898 [ D loss: 0.320502, acc.: 88%] [G loss: 4.092977]\n",
            "3899 [ D loss: 0.191866, acc.: 95%] [G loss: 4.438934]\n",
            "3900 [ D loss: 0.225244, acc.: 93%] [G loss: 4.158627]\n",
            "3901 [ D loss: 0.220461, acc.: 93%] [G loss: 5.293863]\n",
            "3902 [ D loss: 0.147146, acc.: 96%] [G loss: 6.241031]\n",
            "3903 [ D loss: 0.075227, acc.: 99%] [G loss: 5.868823]\n",
            "3904 [ D loss: 0.157838, acc.: 94%] [G loss: 4.708694]\n",
            "3905 [ D loss: 0.189717, acc.: 94%] [G loss: 5.322742]\n",
            "3906 [ D loss: 0.283547, acc.: 91%] [G loss: 4.329139]\n",
            "3907 [ D loss: 0.199175, acc.: 91%] [G loss: 4.283517]\n",
            "3908 [ D loss: 0.196162, acc.: 94%] [G loss: 3.976509]\n",
            "3909 [ D loss: 0.197358, acc.: 95%] [G loss: 4.461128]\n",
            "3910 [ D loss: 0.268157, acc.: 91%] [G loss: 3.765064]\n",
            "3911 [ D loss: 0.237440, acc.: 91%] [G loss: 3.170557]\n",
            "3912 [ D loss: 0.238592, acc.: 93%] [G loss: 4.328125]\n",
            "3913 [ D loss: 0.246462, acc.: 90%] [G loss: 4.306811]\n",
            "3914 [ D loss: 0.359101, acc.: 86%] [G loss: 3.730175]\n",
            "3915 [ D loss: 0.257099, acc.: 88%] [G loss: 4.380161]\n",
            "3916 [ D loss: 0.207271, acc.: 92%] [G loss: 4.688910]\n",
            "3917 [ D loss: 0.136086, acc.: 96%] [G loss: 3.969552]\n",
            "3918 [ D loss: 0.203532, acc.: 94%] [G loss: 5.470475]\n",
            "3919 [ D loss: 0.138841, acc.: 98%] [G loss: 6.390074]\n",
            "3920 [ D loss: 0.209554, acc.: 89%] [G loss: 8.675859]\n",
            "3921 [ D loss: 0.163413, acc.: 95%] [G loss: 4.680974]\n",
            "3922 [ D loss: 0.244638, acc.: 91%] [G loss: 3.143316]\n",
            "3923 [ D loss: 0.153485, acc.: 97%] [G loss: 3.572390]\n",
            "3924 [ D loss: 0.215571, acc.: 96%] [G loss: 4.559637]\n",
            "3925 [ D loss: 0.207108, acc.: 95%] [G loss: 4.694929]\n",
            "3926 [ D loss: 0.302802, acc.: 88%] [G loss: 4.933180]\n",
            "3927 [ D loss: 0.258190, acc.: 89%] [G loss: 4.588123]\n",
            "3928 [ D loss: 0.199767, acc.: 95%] [G loss: 4.221498]\n",
            "3929 [ D loss: 0.301686, acc.: 88%] [G loss: 4.521457]\n",
            "3930 [ D loss: 0.233875, acc.: 92%] [G loss: 6.387712]\n",
            "3931 [ D loss: 0.244178, acc.: 87%] [G loss: 5.236474]\n",
            "3932 [ D loss: 0.184455, acc.: 92%] [G loss: 5.159822]\n",
            "3933 [ D loss: 0.193737, acc.: 93%] [G loss: 5.889094]\n",
            "3934 [ D loss: 0.163101, acc.: 97%] [G loss: 7.095243]\n",
            "3935 [ D loss: 0.176308, acc.: 93%] [G loss: 7.388495]\n",
            "3936 [ D loss: 0.187093, acc.: 92%] [G loss: 4.587542]\n",
            "3937 [ D loss: 0.191095, acc.: 91%] [G loss: 6.281917]\n",
            "3938 [ D loss: 0.176104, acc.: 93%] [G loss: 4.560483]\n",
            "3939 [ D loss: 0.143494, acc.: 96%] [G loss: 5.158037]\n",
            "3940 [ D loss: 0.308955, acc.: 90%] [G loss: 3.778688]\n",
            "3941 [ D loss: 0.158989, acc.: 95%] [G loss: 4.298618]\n",
            "3942 [ D loss: 0.160851, acc.: 94%] [G loss: 5.112362]\n",
            "3943 [ D loss: 0.158590, acc.: 96%] [G loss: 5.000600]\n",
            "3944 [ D loss: 0.186831, acc.: 94%] [G loss: 4.896436]\n",
            "3945 [ D loss: 0.155299, acc.: 95%] [G loss: 3.457809]\n",
            "3946 [ D loss: 0.220245, acc.: 94%] [G loss: 4.665661]\n",
            "3947 [ D loss: 0.264227, acc.: 92%] [G loss: 7.461905]\n",
            "3948 [ D loss: 0.146100, acc.: 95%] [G loss: 5.276888]\n",
            "3949 [ D loss: 0.115260, acc.: 97%] [G loss: 6.384260]\n",
            "3950 [ D loss: 0.116467, acc.: 97%] [G loss: 6.196299]\n",
            "3951 [ D loss: 0.191840, acc.: 95%] [G loss: 7.608168]\n",
            "3952 [ D loss: 0.166348, acc.: 91%] [G loss: 9.899337]\n",
            "3953 [ D loss: 0.080408, acc.: 98%] [G loss: 8.272421]\n",
            "3954 [ D loss: 0.160687, acc.: 95%] [G loss: 7.187376]\n",
            "3955 [ D loss: 0.242851, acc.: 91%] [G loss: 5.612098]\n",
            "3956 [ D loss: 0.133020, acc.: 95%] [G loss: 8.337081]\n",
            "3957 [ D loss: 0.122971, acc.: 97%] [G loss: 8.302099]\n",
            "3958 [ D loss: 0.137319, acc.: 95%] [G loss: 5.176289]\n",
            "3959 [ D loss: 0.101404, acc.: 99%] [G loss: 5.528697]\n",
            "3960 [ D loss: 0.211657, acc.: 91%] [G loss: 3.429969]\n",
            "3961 [ D loss: 0.188060, acc.: 94%] [G loss: 5.636764]\n",
            "3962 [ D loss: 0.227344, acc.: 91%] [G loss: 4.978890]\n",
            "3963 [ D loss: 0.142765, acc.: 95%] [G loss: 5.697381]\n",
            "3964 [ D loss: 0.171641, acc.: 92%] [G loss: 7.341248]\n",
            "3965 [ D loss: 0.155231, acc.: 95%] [G loss: 4.975584]\n",
            "3966 [ D loss: 0.110108, acc.: 97%] [G loss: 10.447870]\n",
            "3967 [ D loss: 0.147224, acc.: 96%] [G loss: 8.495125]\n",
            "3968 [ D loss: 0.171929, acc.: 94%] [G loss: 4.957341]\n",
            "3969 [ D loss: 0.156661, acc.: 95%] [G loss: 6.087377]\n",
            "3970 [ D loss: 0.206683, acc.: 95%] [G loss: 3.959627]\n",
            "3971 [ D loss: 0.225236, acc.: 93%] [G loss: 4.073809]\n",
            "3972 [ D loss: 0.262638, acc.: 88%] [G loss: 3.537324]\n",
            "3973 [ D loss: 0.144319, acc.: 97%] [G loss: 3.771707]\n",
            "3974 [ D loss: 0.186710, acc.: 95%] [G loss: 4.804506]\n",
            "3975 [ D loss: 0.201115, acc.: 91%] [G loss: 3.842216]\n",
            "3976 [ D loss: 0.186903, acc.: 94%] [G loss: 4.682303]\n",
            "3977 [ D loss: 0.226507, acc.: 93%] [G loss: 3.972821]\n",
            "3978 [ D loss: 0.329572, acc.: 87%] [G loss: 3.757283]\n",
            "3979 [ D loss: 0.247292, acc.: 91%] [G loss: 4.304324]\n",
            "3980 [ D loss: 0.307672, acc.: 88%] [G loss: 3.421496]\n",
            "3981 [ D loss: 0.146984, acc.: 95%] [G loss: 4.380605]\n",
            "3982 [ D loss: 0.142405, acc.: 98%] [G loss: 4.691716]\n",
            "3983 [ D loss: 0.216010, acc.: 93%] [G loss: 3.876109]\n",
            "3984 [ D loss: 0.181936, acc.: 95%] [G loss: 3.856846]\n",
            "3985 [ D loss: 0.263354, acc.: 91%] [G loss: 3.687300]\n",
            "3986 [ D loss: 0.223222, acc.: 93%] [G loss: 4.098360]\n",
            "3987 [ D loss: 0.205761, acc.: 93%] [G loss: 3.481082]\n",
            "3988 [ D loss: 0.220982, acc.: 95%] [G loss: 3.902442]\n",
            "3989 [ D loss: 0.102862, acc.: 98%] [G loss: 4.273696]\n",
            "3990 [ D loss: 0.216997, acc.: 94%] [G loss: 3.490052]\n",
            "3991 [ D loss: 0.296574, acc.: 86%] [G loss: 3.939722]\n",
            "3992 [ D loss: 0.247754, acc.: 93%] [G loss: 4.569457]\n",
            "3993 [ D loss: 0.321390, acc.: 84%] [G loss: 3.269889]\n",
            "3994 [ D loss: 0.208109, acc.: 95%] [G loss: 3.826542]\n",
            "3995 [ D loss: 0.213549, acc.: 92%] [G loss: 4.105242]\n",
            "3996 [ D loss: 0.155759, acc.: 97%] [G loss: 4.686036]\n",
            "3997 [ D loss: 0.188468, acc.: 92%] [G loss: 3.776960]\n",
            "3998 [ D loss: 0.271722, acc.: 88%] [G loss: 4.850718]\n",
            "3999 [ D loss: 0.226226, acc.: 90%] [G loss: 4.703880]\n",
            "4000 [ D loss: 0.247023, acc.: 92%] [G loss: 4.335651]\n",
            "4001 [ D loss: 0.183535, acc.: 95%] [G loss: 3.870476]\n",
            "4002 [ D loss: 0.114152, acc.: 95%] [G loss: 4.680132]\n",
            "4003 [ D loss: 0.266601, acc.: 90%] [G loss: 5.712086]\n",
            "4004 [ D loss: 0.102609, acc.: 98%] [G loss: 8.940041]\n",
            "4005 [ D loss: 0.215570, acc.: 91%] [G loss: 6.038976]\n",
            "4006 [ D loss: 0.194967, acc.: 95%] [G loss: 6.852890]\n",
            "4007 [ D loss: 0.180317, acc.: 93%] [G loss: 4.952173]\n",
            "4008 [ D loss: 0.110450, acc.: 98%] [G loss: 4.859914]\n",
            "4009 [ D loss: 0.251449, acc.: 90%] [G loss: 5.083732]\n",
            "4010 [ D loss: 0.166490, acc.: 96%] [G loss: 6.735057]\n",
            "4011 [ D loss: 0.262149, acc.: 91%] [G loss: 4.143908]\n",
            "4012 [ D loss: 0.173854, acc.: 97%] [G loss: 4.357879]\n",
            "4013 [ D loss: 0.272455, acc.: 88%] [G loss: 7.666893]\n",
            "4014 [ D loss: 0.207853, acc.: 90%] [G loss: 7.617806]\n",
            "4015 [ D loss: 0.134964, acc.: 96%] [G loss: 4.473175]\n",
            "4016 [ D loss: 0.224649, acc.: 89%] [G loss: 6.091161]\n",
            "4017 [ D loss: 0.147374, acc.: 95%] [G loss: 5.364985]\n",
            "4018 [ D loss: 0.105745, acc.: 98%] [G loss: 7.850897]\n",
            "4019 [ D loss: 0.192960, acc.: 92%] [G loss: 5.279089]\n",
            "4020 [ D loss: 0.128193, acc.: 95%] [G loss: 4.376154]\n",
            "4021 [ D loss: 0.167056, acc.: 95%] [G loss: 3.022007]\n",
            "4022 [ D loss: 0.133781, acc.: 98%] [G loss: 4.377079]\n",
            "4023 [ D loss: 0.283501, acc.: 90%] [G loss: 3.732002]\n",
            "4024 [ D loss: 0.272985, acc.: 92%] [G loss: 3.492462]\n",
            "4025 [ D loss: 0.223396, acc.: 95%] [G loss: 4.284175]\n",
            "4026 [ D loss: 0.190969, acc.: 94%] [G loss: 4.067707]\n",
            "4027 [ D loss: 0.252497, acc.: 93%] [G loss: 3.686528]\n",
            "4028 [ D loss: 0.260920, acc.: 93%] [G loss: 4.658938]\n",
            "4029 [ D loss: 0.248753, acc.: 94%] [G loss: 4.207969]\n",
            "4030 [ D loss: 0.163754, acc.: 97%] [G loss: 3.793065]\n",
            "4031 [ D loss: 0.206357, acc.: 95%] [G loss: 4.801779]\n",
            "4032 [ D loss: 0.238845, acc.: 91%] [G loss: 4.466691]\n",
            "4033 [ D loss: 0.123097, acc.: 98%] [G loss: 6.936373]\n",
            "4034 [ D loss: 0.235972, acc.: 91%] [G loss: 4.267619]\n",
            "4035 [ D loss: 0.188601, acc.: 95%] [G loss: 3.519761]\n",
            "4036 [ D loss: 0.275167, acc.: 88%] [G loss: 3.356751]\n",
            "4037 [ D loss: 0.189035, acc.: 95%] [G loss: 5.787697]\n",
            "4038 [ D loss: 0.106666, acc.: 97%] [G loss: 4.836528]\n",
            "4039 [ D loss: 0.175118, acc.: 95%] [G loss: 3.304977]\n",
            "4040 [ D loss: 0.095112, acc.: 99%] [G loss: 5.552014]\n",
            "4041 [ D loss: 0.196791, acc.: 92%] [G loss: 5.563739]\n",
            "4042 [ D loss: 0.138080, acc.: 95%] [G loss: 6.234457]\n",
            "4043 [ D loss: 0.222971, acc.: 90%] [G loss: 4.615922]\n",
            "4044 [ D loss: 0.187257, acc.: 97%] [G loss: 6.170328]\n",
            "4045 [ D loss: 0.119146, acc.: 95%] [G loss: 5.830987]\n",
            "4046 [ D loss: 0.178400, acc.: 95%] [G loss: 4.185368]\n",
            "4047 [ D loss: 0.179435, acc.: 91%] [G loss: 4.756927]\n",
            "4048 [ D loss: 0.195598, acc.: 94%] [G loss: 4.558771]\n",
            "4049 [ D loss: 0.182317, acc.: 95%] [G loss: 3.681786]\n",
            "4050 [ D loss: 0.160697, acc.: 93%] [G loss: 5.487769]\n",
            "4051 [ D loss: 0.168359, acc.: 96%] [G loss: 5.434703]\n",
            "4052 [ D loss: 0.161343, acc.: 95%] [G loss: 4.960577]\n",
            "4053 [ D loss: 0.192012, acc.: 95%] [G loss: 4.754034]\n",
            "4054 [ D loss: 0.142121, acc.: 95%] [G loss: 4.424791]\n",
            "4055 [ D loss: 0.398390, acc.: 85%] [G loss: 3.850278]\n",
            "4056 [ D loss: 0.139075, acc.: 96%] [G loss: 4.420828]\n",
            "4057 [ D loss: 0.216833, acc.: 93%] [G loss: 4.280251]\n",
            "4058 [ D loss: 0.277744, acc.: 88%] [G loss: 5.540360]\n",
            "4059 [ D loss: 0.260815, acc.: 88%] [G loss: 3.520155]\n",
            "4060 [ D loss: 0.199625, acc.: 92%] [G loss: 4.013639]\n",
            "4061 [ D loss: 0.237594, acc.: 92%] [G loss: 4.182182]\n",
            "4062 [ D loss: 0.165782, acc.: 95%] [G loss: 4.718891]\n",
            "4063 [ D loss: 0.144876, acc.: 96%] [G loss: 6.406191]\n",
            "4064 [ D loss: 0.173595, acc.: 93%] [G loss: 3.469375]\n",
            "4065 [ D loss: 0.220183, acc.: 91%] [G loss: 6.307153]\n",
            "4066 [ D loss: 0.102898, acc.: 97%] [G loss: 5.924829]\n",
            "4067 [ D loss: 0.208388, acc.: 94%] [G loss: 5.236197]\n",
            "4068 [ D loss: 0.174257, acc.: 92%] [G loss: 7.769886]\n",
            "4069 [ D loss: 0.152829, acc.: 95%] [G loss: 5.375115]\n",
            "4070 [ D loss: 0.141336, acc.: 97%] [G loss: 6.339327]\n",
            "4071 [ D loss: 0.154506, acc.: 97%] [G loss: 4.792297]\n",
            "4072 [ D loss: 0.138764, acc.: 97%] [G loss: 8.892938]\n",
            "4073 [ D loss: 0.129106, acc.: 97%] [G loss: 7.532835]\n",
            "4074 [ D loss: 0.197009, acc.: 94%] [G loss: 4.637688]\n",
            "4075 [ D loss: 0.148600, acc.: 94%] [G loss: 7.008808]\n",
            "4076 [ D loss: 0.194407, acc.: 95%] [G loss: 4.577423]\n",
            "4077 [ D loss: 0.226262, acc.: 90%] [G loss: 3.326017]\n",
            "4078 [ D loss: 0.181338, acc.: 95%] [G loss: 9.140855]\n",
            "4079 [ D loss: 0.158705, acc.: 95%] [G loss: 4.728580]\n",
            "4080 [ D loss: 0.106025, acc.: 99%] [G loss: 5.286255]\n",
            "4081 [ D loss: 0.197481, acc.: 93%] [G loss: 5.879838]\n",
            "4082 [ D loss: 0.167390, acc.: 94%] [G loss: 3.976317]\n",
            "4083 [ D loss: 0.178803, acc.: 94%] [G loss: 6.274799]\n",
            "4084 [ D loss: 0.272265, acc.: 91%] [G loss: 4.423683]\n",
            "4085 [ D loss: 0.145507, acc.: 95%] [G loss: 4.543139]\n",
            "4086 [ D loss: 0.202806, acc.: 93%] [G loss: 4.473374]\n",
            "4087 [ D loss: 0.199478, acc.: 95%] [G loss: 3.760926]\n",
            "4088 [ D loss: 0.179387, acc.: 95%] [G loss: 4.896155]\n",
            "4089 [ D loss: 0.109930, acc.: 98%] [G loss: 4.531314]\n",
            "4090 [ D loss: 0.251345, acc.: 91%] [G loss: 3.977210]\n",
            "4091 [ D loss: 0.131766, acc.: 97%] [G loss: 4.267192]\n",
            "4092 [ D loss: 0.167477, acc.: 95%] [G loss: 4.758515]\n",
            "4093 [ D loss: 0.167792, acc.: 96%] [G loss: 5.497869]\n",
            "4094 [ D loss: 0.117747, acc.: 96%] [G loss: 4.364862]\n",
            "4095 [ D loss: 0.261891, acc.: 90%] [G loss: 3.842558]\n",
            "4096 [ D loss: 0.259000, acc.: 92%] [G loss: 3.715832]\n",
            "4097 [ D loss: 0.212564, acc.: 94%] [G loss: 3.242227]\n",
            "4098 [ D loss: 0.181288, acc.: 96%] [G loss: 4.032128]\n",
            "4099 [ D loss: 0.114313, acc.: 97%] [G loss: 5.810443]\n",
            "4100 [ D loss: 0.171372, acc.: 95%] [G loss: 6.985597]\n",
            "4101 [ D loss: 0.184142, acc.: 94%] [G loss: 5.409850]\n",
            "4102 [ D loss: 0.117266, acc.: 97%] [G loss: 7.611123]\n",
            "4103 [ D loss: 0.151224, acc.: 93%] [G loss: 4.058712]\n",
            "4104 [ D loss: 0.237820, acc.: 91%] [G loss: 5.046758]\n",
            "4105 [ D loss: 0.234891, acc.: 91%] [G loss: 4.445175]\n",
            "4106 [ D loss: 0.247986, acc.: 95%] [G loss: 4.880657]\n",
            "4107 [ D loss: 0.126759, acc.: 98%] [G loss: 4.259084]\n",
            "4108 [ D loss: 0.204129, acc.: 93%] [G loss: 4.333185]\n",
            "4109 [ D loss: 0.205956, acc.: 89%] [G loss: 4.509845]\n",
            "4110 [ D loss: 0.262738, acc.: 88%] [G loss: 5.241771]\n",
            "4111 [ D loss: 0.155905, acc.: 91%] [G loss: 4.188847]\n",
            "4112 [ D loss: 0.228657, acc.: 89%] [G loss: 11.356663]\n",
            "4113 [ D loss: 0.203808, acc.: 91%] [G loss: 4.656441]\n",
            "4114 [ D loss: 0.251550, acc.: 91%] [G loss: 5.397602]\n",
            "4115 [ D loss: 0.146855, acc.: 95%] [G loss: 8.742436]\n",
            "4116 [ D loss: 0.259488, acc.: 92%] [G loss: 4.952187]\n",
            "4117 [ D loss: 0.241103, acc.: 91%] [G loss: 6.170209]\n",
            "4118 [ D loss: 0.126687, acc.: 95%] [G loss: 5.448053]\n",
            "4119 [ D loss: 0.218625, acc.: 93%] [G loss: 4.881593]\n",
            "4120 [ D loss: 0.193484, acc.: 94%] [G loss: 5.598086]\n",
            "4121 [ D loss: 0.095060, acc.: 98%] [G loss: 8.395180]\n",
            "4122 [ D loss: 0.269516, acc.: 90%] [G loss: 4.811092]\n",
            "4123 [ D loss: 0.123473, acc.: 96%] [G loss: 5.811985]\n",
            "4124 [ D loss: 0.224232, acc.: 89%] [G loss: 5.740375]\n",
            "4125 [ D loss: 0.346390, acc.: 84%] [G loss: 4.128398]\n",
            "4126 [ D loss: 0.193001, acc.: 92%] [G loss: 4.324943]\n",
            "4127 [ D loss: 0.281766, acc.: 93%] [G loss: 4.368270]\n",
            "4128 [ D loss: 0.161007, acc.: 97%] [G loss: 3.406948]\n",
            "4129 [ D loss: 0.238420, acc.: 92%] [G loss: 4.502724]\n",
            "4130 [ D loss: 0.206513, acc.: 93%] [G loss: 4.492497]\n",
            "4131 [ D loss: 0.137297, acc.: 97%] [G loss: 4.009916]\n",
            "4132 [ D loss: 0.174047, acc.: 94%] [G loss: 4.595203]\n",
            "4133 [ D loss: 0.221162, acc.: 91%] [G loss: 6.080663]\n",
            "4134 [ D loss: 0.175772, acc.: 93%] [G loss: 8.596746]\n",
            "4135 [ D loss: 0.165215, acc.: 95%] [G loss: 4.423101]\n",
            "4136 [ D loss: 0.231853, acc.: 89%] [G loss: 4.232059]\n",
            "4137 [ D loss: 0.189652, acc.: 91%] [G loss: 5.096166]\n",
            "4138 [ D loss: 0.208162, acc.: 92%] [G loss: 4.389523]\n",
            "4139 [ D loss: 0.227509, acc.: 91%] [G loss: 4.247185]\n",
            "4140 [ D loss: 0.317901, acc.: 84%] [G loss: 4.114115]\n",
            "4141 [ D loss: 0.160634, acc.: 95%] [G loss: 4.655029]\n",
            "4142 [ D loss: 0.179810, acc.: 95%] [G loss: 3.573461]\n",
            "4143 [ D loss: 0.187388, acc.: 96%] [G loss: 5.405180]\n",
            "4144 [ D loss: 0.173628, acc.: 92%] [G loss: 7.271303]\n",
            "4145 [ D loss: 0.241010, acc.: 89%] [G loss: 5.088483]\n",
            "4146 [ D loss: 0.150480, acc.: 95%] [G loss: 5.206781]\n",
            "4147 [ D loss: 0.145983, acc.: 96%] [G loss: 4.806680]\n",
            "4148 [ D loss: 0.150421, acc.: 92%] [G loss: 5.564047]\n",
            "4149 [ D loss: 0.129335, acc.: 97%] [G loss: 3.984586]\n",
            "4150 [ D loss: 0.240200, acc.: 90%] [G loss: 3.909667]\n",
            "4151 [ D loss: 0.259748, acc.: 91%] [G loss: 3.764418]\n",
            "4152 [ D loss: 0.138799, acc.: 99%] [G loss: 3.680310]\n",
            "4153 [ D loss: 0.272167, acc.: 91%] [G loss: 4.198946]\n",
            "4154 [ D loss: 0.225822, acc.: 92%] [G loss: 4.051271]\n",
            "4155 [ D loss: 0.195944, acc.: 95%] [G loss: 4.744627]\n",
            "4156 [ D loss: 0.250834, acc.: 93%] [G loss: 4.945889]\n",
            "4157 [ D loss: 0.171178, acc.: 95%] [G loss: 4.948481]\n",
            "4158 [ D loss: 0.270302, acc.: 93%] [G loss: 4.423679]\n",
            "4159 [ D loss: 0.197399, acc.: 93%] [G loss: 5.822785]\n",
            "4160 [ D loss: 0.147912, acc.: 97%] [G loss: 4.962382]\n",
            "4161 [ D loss: 0.131806, acc.: 97%] [G loss: 5.220627]\n",
            "4162 [ D loss: 0.231888, acc.: 92%] [G loss: 4.312159]\n",
            "4163 [ D loss: 0.245150, acc.: 91%] [G loss: 4.560019]\n",
            "4164 [ D loss: 0.193048, acc.: 94%] [G loss: 5.316911]\n",
            "4165 [ D loss: 0.240894, acc.: 92%] [G loss: 3.738308]\n",
            "4166 [ D loss: 0.199644, acc.: 93%] [G loss: 3.863326]\n",
            "4167 [ D loss: 0.163510, acc.: 96%] [G loss: 6.456576]\n",
            "4168 [ D loss: 0.100653, acc.: 97%] [G loss: 5.488577]\n",
            "4169 [ D loss: 0.212218, acc.: 93%] [G loss: 4.634149]\n",
            "4170 [ D loss: 0.194983, acc.: 95%] [G loss: 4.377860]\n",
            "4171 [ D loss: 0.271888, acc.: 87%] [G loss: 4.090798]\n",
            "4172 [ D loss: 0.172134, acc.: 94%] [G loss: 5.530675]\n",
            "4173 [ D loss: 0.238747, acc.: 88%] [G loss: 7.136069]\n",
            "4174 [ D loss: 0.165618, acc.: 95%] [G loss: 4.996089]\n",
            "4175 [ D loss: 0.284987, acc.: 87%] [G loss: 4.794178]\n",
            "4176 [ D loss: 0.176886, acc.: 95%] [G loss: 7.410604]\n",
            "4177 [ D loss: 0.177109, acc.: 91%] [G loss: 6.485297]\n",
            "4178 [ D loss: 0.135213, acc.: 98%] [G loss: 5.799226]\n",
            "4179 [ D loss: 0.133456, acc.: 96%] [G loss: 4.684939]\n",
            "4180 [ D loss: 0.196788, acc.: 95%] [G loss: 5.531296]\n",
            "4181 [ D loss: 0.207439, acc.: 94%] [G loss: 4.882178]\n",
            "4182 [ D loss: 0.185958, acc.: 95%] [G loss: 3.459518]\n",
            "4183 [ D loss: 0.239087, acc.: 92%] [G loss: 4.414444]\n",
            "4184 [ D loss: 0.319251, acc.: 86%] [G loss: 4.049654]\n",
            "4185 [ D loss: 0.177786, acc.: 95%] [G loss: 4.682499]\n",
            "4186 [ D loss: 0.299577, acc.: 87%] [G loss: 4.970771]\n",
            "4187 [ D loss: 0.192158, acc.: 94%] [G loss: 5.316695]\n",
            "4188 [ D loss: 0.328581, acc.: 84%] [G loss: 3.717490]\n",
            "4189 [ D loss: 0.204188, acc.: 92%] [G loss: 4.518766]\n",
            "4190 [ D loss: 0.477938, acc.: 76%] [G loss: 3.301779]\n",
            "4191 [ D loss: 0.113454, acc.: 96%] [G loss: 6.795461]\n",
            "4192 [ D loss: 0.389718, acc.: 85%] [G loss: 6.683189]\n",
            "4193 [ D loss: 0.245453, acc.: 91%] [G loss: 4.097623]\n",
            "4194 [ D loss: 0.140475, acc.: 97%] [G loss: 4.493605]\n",
            "4195 [ D loss: 0.140112, acc.: 97%] [G loss: 6.340999]\n",
            "4196 [ D loss: 0.168855, acc.: 96%] [G loss: 6.770901]\n",
            "4197 [ D loss: 0.167967, acc.: 94%] [G loss: 5.197725]\n",
            "4198 [ D loss: 0.129080, acc.: 96%] [G loss: 5.778006]\n",
            "4199 [ D loss: 0.099927, acc.: 98%] [G loss: 3.476020]\n",
            "4200 [ D loss: 0.089779, acc.: 99%] [G loss: 7.865919]\n",
            "4201 [ D loss: 0.164510, acc.: 97%] [G loss: 4.603391]\n",
            "4202 [ D loss: 0.154456, acc.: 94%] [G loss: 5.901943]\n",
            "4203 [ D loss: 0.179068, acc.: 91%] [G loss: 6.720518]\n",
            "4204 [ D loss: 0.210540, acc.: 95%] [G loss: 4.919666]\n",
            "4205 [ D loss: 0.116221, acc.: 97%] [G loss: 5.116954]\n",
            "4206 [ D loss: 0.267299, acc.: 91%] [G loss: 4.703117]\n",
            "4207 [ D loss: 0.249267, acc.: 90%] [G loss: 4.740120]\n",
            "4208 [ D loss: 0.133056, acc.: 95%] [G loss: 4.650162]\n",
            "4209 [ D loss: 0.171471, acc.: 93%] [G loss: 9.554230]\n",
            "4210 [ D loss: 0.205572, acc.: 92%] [G loss: 6.115759]\n",
            "4211 [ D loss: 0.135370, acc.: 96%] [G loss: 6.896882]\n",
            "4212 [ D loss: 0.158476, acc.: 93%] [G loss: 6.522369]\n",
            "4213 [ D loss: 0.105069, acc.: 98%] [G loss: 6.615139]\n",
            "4214 [ D loss: 0.139721, acc.: 95%] [G loss: 5.066461]\n",
            "4215 [ D loss: 0.174513, acc.: 93%] [G loss: 6.071993]\n",
            "4216 [ D loss: 0.191202, acc.: 93%] [G loss: 4.099194]\n",
            "4217 [ D loss: 0.213139, acc.: 92%] [G loss: 3.932556]\n",
            "4218 [ D loss: 0.234466, acc.: 91%] [G loss: 4.769047]\n",
            "4219 [ D loss: 0.109699, acc.: 98%] [G loss: 5.447687]\n",
            "4220 [ D loss: 0.163495, acc.: 96%] [G loss: 3.931473]\n",
            "4221 [ D loss: 0.130856, acc.: 98%] [G loss: 4.722405]\n",
            "4222 [ D loss: 0.201811, acc.: 95%] [G loss: 5.378142]\n",
            "4223 [ D loss: 0.165171, acc.: 95%] [G loss: 4.347082]\n",
            "4224 [ D loss: 0.125375, acc.: 97%] [G loss: 5.312646]\n",
            "4225 [ D loss: 0.145792, acc.: 95%] [G loss: 4.273377]\n",
            "4226 [ D loss: 0.280798, acc.: 92%] [G loss: 3.529524]\n",
            "4227 [ D loss: 0.208589, acc.: 93%] [G loss: 4.082668]\n",
            "4228 [ D loss: 0.160842, acc.: 95%] [G loss: 4.270102]\n",
            "4229 [ D loss: 0.180459, acc.: 95%] [G loss: 4.249071]\n",
            "4230 [ D loss: 0.150590, acc.: 98%] [G loss: 4.455046]\n",
            "4231 [ D loss: 0.142620, acc.: 95%] [G loss: 6.039785]\n",
            "4232 [ D loss: 0.096439, acc.: 98%] [G loss: 7.001853]\n",
            "4233 [ D loss: 0.167762, acc.: 95%] [G loss: 5.964575]\n",
            "4234 [ D loss: 0.199636, acc.: 94%] [G loss: 4.318634]\n",
            "4235 [ D loss: 0.181358, acc.: 94%] [G loss: 8.074914]\n",
            "4236 [ D loss: 0.267829, acc.: 87%] [G loss: 4.391787]\n",
            "4237 [ D loss: 0.189456, acc.: 92%] [G loss: 4.138611]\n",
            "4238 [ D loss: 0.052786, acc.: 100%] [G loss: 8.764666]\n",
            "4239 [ D loss: 0.118860, acc.: 96%] [G loss: 5.532541]\n",
            "4240 [ D loss: 0.140129, acc.: 97%] [G loss: 7.970107]\n",
            "4241 [ D loss: 0.078612, acc.: 98%] [G loss: 11.949114]\n",
            "4242 [ D loss: 0.071644, acc.: 97%] [G loss: 8.524244]\n",
            "4243 [ D loss: 0.168089, acc.: 93%] [G loss: 6.186194]\n",
            "4244 [ D loss: 0.185365, acc.: 95%] [G loss: 7.763582]\n",
            "4245 [ D loss: 0.159797, acc.: 95%] [G loss: 3.950159]\n",
            "4246 [ D loss: 0.161187, acc.: 95%] [G loss: 4.461574]\n",
            "4247 [ D loss: 0.121909, acc.: 98%] [G loss: 4.391362]\n",
            "4248 [ D loss: 0.117937, acc.: 98%] [G loss: 5.381142]\n",
            "4249 [ D loss: 0.283829, acc.: 88%] [G loss: 3.645557]\n",
            "4250 [ D loss: 0.263722, acc.: 88%] [G loss: 4.954076]\n",
            "4251 [ D loss: 0.305030, acc.: 88%] [G loss: 4.438717]\n",
            "4252 [ D loss: 0.325244, acc.: 86%] [G loss: 5.025892]\n",
            "4253 [ D loss: 0.155829, acc.: 95%] [G loss: 4.372304]\n",
            "4254 [ D loss: 0.122549, acc.: 98%] [G loss: 4.201899]\n",
            "4255 [ D loss: 0.130782, acc.: 97%] [G loss: 5.347780]\n",
            "4256 [ D loss: 0.159841, acc.: 96%] [G loss: 4.232886]\n",
            "4257 [ D loss: 0.169641, acc.: 93%] [G loss: 3.951736]\n",
            "4258 [ D loss: 0.161741, acc.: 95%] [G loss: 3.693435]\n",
            "4259 [ D loss: 0.197170, acc.: 94%] [G loss: 5.993182]\n",
            "4260 [ D loss: 0.134916, acc.: 95%] [G loss: 5.400808]\n",
            "4261 [ D loss: 0.141665, acc.: 95%] [G loss: 4.824685]\n",
            "4262 [ D loss: 0.180878, acc.: 92%] [G loss: 6.385970]\n",
            "4263 [ D loss: 0.215458, acc.: 92%] [G loss: 4.239274]\n",
            "4264 [ D loss: 0.232587, acc.: 91%] [G loss: 5.234342]\n",
            "4265 [ D loss: 0.105195, acc.: 97%] [G loss: 5.927834]\n",
            "4266 [ D loss: 0.173846, acc.: 95%] [G loss: 5.404362]\n",
            "4267 [ D loss: 0.246192, acc.: 91%] [G loss: 4.808702]\n",
            "4268 [ D loss: 0.257923, acc.: 91%] [G loss: 3.404633]\n",
            "4269 [ D loss: 0.281664, acc.: 90%] [G loss: 3.677486]\n",
            "4270 [ D loss: 0.203072, acc.: 94%] [G loss: 3.907720]\n",
            "4271 [ D loss: 0.187895, acc.: 95%] [G loss: 3.875041]\n",
            "4272 [ D loss: 0.218461, acc.: 94%] [G loss: 3.657109]\n",
            "4273 [ D loss: 0.109002, acc.: 97%] [G loss: 4.307405]\n",
            "4274 [ D loss: 0.157857, acc.: 97%] [G loss: 3.992184]\n",
            "4275 [ D loss: 0.184050, acc.: 95%] [G loss: 3.726346]\n",
            "4276 [ D loss: 0.180950, acc.: 95%] [G loss: 3.443602]\n",
            "4277 [ D loss: 0.229483, acc.: 91%] [G loss: 4.126554]\n",
            "4278 [ D loss: 0.166961, acc.: 95%] [G loss: 5.372429]\n",
            "4279 [ D loss: 0.149543, acc.: 97%] [G loss: 4.288805]\n",
            "4280 [ D loss: 0.192928, acc.: 95%] [G loss: 4.050412]\n",
            "4281 [ D loss: 0.196005, acc.: 93%] [G loss: 3.945098]\n",
            "4282 [ D loss: 0.208191, acc.: 95%] [G loss: 3.677857]\n",
            "4283 [ D loss: 0.184181, acc.: 97%] [G loss: 4.070504]\n",
            "4284 [ D loss: 0.378295, acc.: 80%] [G loss: 4.048979]\n",
            "4285 [ D loss: 0.323409, acc.: 87%] [G loss: 6.034019]\n",
            "4286 [ D loss: 0.155031, acc.: 97%] [G loss: 6.619859]\n",
            "4287 [ D loss: 0.172166, acc.: 94%] [G loss: 5.973047]\n",
            "4288 [ D loss: 0.093703, acc.: 98%] [G loss: 3.951243]\n",
            "4289 [ D loss: 0.087926, acc.: 98%] [G loss: 7.645691]\n",
            "4290 [ D loss: 0.187350, acc.: 90%] [G loss: 8.195775]\n",
            "4291 [ D loss: 0.114604, acc.: 98%] [G loss: 7.009254]\n",
            "4292 [ D loss: 0.196733, acc.: 95%] [G loss: 4.849005]\n",
            "4293 [ D loss: 0.133798, acc.: 97%] [G loss: 6.308182]\n",
            "4294 [ D loss: 0.172809, acc.: 95%] [G loss: 3.852040]\n",
            "4295 [ D loss: 0.216087, acc.: 94%] [G loss: 3.307343]\n",
            "4296 [ D loss: 0.290525, acc.: 90%] [G loss: 4.562665]\n",
            "4297 [ D loss: 0.259034, acc.: 91%] [G loss: 5.103148]\n",
            "4298 [ D loss: 0.228950, acc.: 88%] [G loss: 5.826102]\n",
            "4299 [ D loss: 0.197408, acc.: 93%] [G loss: 3.665915]\n",
            "4300 [ D loss: 0.228053, acc.: 94%] [G loss: 3.811561]\n",
            "4301 [ D loss: 0.189280, acc.: 96%] [G loss: 5.414193]\n",
            "4302 [ D loss: 0.153672, acc.: 93%] [G loss: 5.224195]\n",
            "4303 [ D loss: 0.090926, acc.: 97%] [G loss: 4.581600]\n",
            "4304 [ D loss: 0.128536, acc.: 97%] [G loss: 5.041926]\n",
            "4305 [ D loss: 0.140167, acc.: 98%] [G loss: 5.194532]\n",
            "4306 [ D loss: 0.284648, acc.: 85%] [G loss: 5.599113]\n",
            "4307 [ D loss: 0.172867, acc.: 95%] [G loss: 5.456185]\n",
            "4308 [ D loss: 0.161400, acc.: 95%] [G loss: 4.916220]\n",
            "4309 [ D loss: 0.111328, acc.: 97%] [G loss: 5.536588]\n",
            "4310 [ D loss: 0.230768, acc.: 91%] [G loss: 4.130373]\n",
            "4311 [ D loss: 0.207059, acc.: 92%] [G loss: 6.368506]\n",
            "4312 [ D loss: 0.186183, acc.: 94%] [G loss: 4.397037]\n",
            "4313 [ D loss: 0.198726, acc.: 95%] [G loss: 3.957639]\n",
            "4314 [ D loss: 0.235724, acc.: 91%] [G loss: 6.722381]\n",
            "4315 [ D loss: 0.155390, acc.: 95%] [G loss: 6.492512]\n",
            "4316 [ D loss: 0.278532, acc.: 88%] [G loss: 5.555873]\n",
            "4317 [ D loss: 0.155686, acc.: 94%] [G loss: 4.898485]\n",
            "4318 [ D loss: 0.228653, acc.: 91%] [G loss: 5.984676]\n",
            "4319 [ D loss: 0.195219, acc.: 93%] [G loss: 4.694619]\n",
            "4320 [ D loss: 0.198461, acc.: 93%] [G loss: 4.594111]\n",
            "4321 [ D loss: 0.193145, acc.: 93%] [G loss: 4.008743]\n",
            "4322 [ D loss: 0.172609, acc.: 97%] [G loss: 4.252587]\n",
            "4323 [ D loss: 0.182324, acc.: 95%] [G loss: 5.453056]\n",
            "4324 [ D loss: 0.127445, acc.: 96%] [G loss: 5.664939]\n",
            "4325 [ D loss: 0.251692, acc.: 88%] [G loss: 4.488687]\n",
            "4326 [ D loss: 0.367040, acc.: 84%] [G loss: 6.140481]\n",
            "4327 [ D loss: 0.228356, acc.: 91%] [G loss: 4.550101]\n",
            "4328 [ D loss: 0.225688, acc.: 88%] [G loss: 5.659074]\n",
            "4329 [ D loss: 0.194034, acc.: 93%] [G loss: 5.171843]\n",
            "4330 [ D loss: 0.169401, acc.: 95%] [G loss: 5.845119]\n",
            "4331 [ D loss: 0.157464, acc.: 97%] [G loss: 5.385555]\n",
            "4332 [ D loss: 0.141317, acc.: 98%] [G loss: 3.808721]\n",
            "4333 [ D loss: 0.181516, acc.: 94%] [G loss: 4.020062]\n",
            "4334 [ D loss: 0.230500, acc.: 92%] [G loss: 6.606125]\n",
            "4335 [ D loss: 0.304446, acc.: 88%] [G loss: 6.108961]\n",
            "4336 [ D loss: 0.090621, acc.: 97%] [G loss: 9.591497]\n",
            "4337 [ D loss: 0.088711, acc.: 97%] [G loss: 6.191014]\n",
            "4338 [ D loss: 0.159381, acc.: 95%] [G loss: 6.245753]\n",
            "4339 [ D loss: 0.069024, acc.: 99%] [G loss: 6.808533]\n",
            "4340 [ D loss: 0.149704, acc.: 95%] [G loss: 7.746002]\n",
            "4341 [ D loss: 0.141368, acc.: 98%] [G loss: 3.292486]\n",
            "4342 [ D loss: 0.178635, acc.: 94%] [G loss: 3.998231]\n",
            "4343 [ D loss: 0.146074, acc.: 95%] [G loss: 5.291358]\n",
            "4344 [ D loss: 0.167314, acc.: 96%] [G loss: 4.266349]\n",
            "4345 [ D loss: 0.124088, acc.: 97%] [G loss: 4.252405]\n",
            "4346 [ D loss: 0.262481, acc.: 91%] [G loss: 4.109204]\n",
            "4347 [ D loss: 0.225884, acc.: 94%] [G loss: 3.276962]\n",
            "4348 [ D loss: 0.162344, acc.: 95%] [G loss: 3.593361]\n",
            "4349 [ D loss: 0.278328, acc.: 88%] [G loss: 4.495715]\n",
            "4350 [ D loss: 0.213681, acc.: 92%] [G loss: 3.883999]\n",
            "4351 [ D loss: 0.131184, acc.: 97%] [G loss: 3.975855]\n",
            "4352 [ D loss: 0.275847, acc.: 90%] [G loss: 3.725216]\n",
            "4353 [ D loss: 0.247005, acc.: 92%] [G loss: 4.053421]\n",
            "4354 [ D loss: 0.265493, acc.: 94%] [G loss: 4.213130]\n",
            "4355 [ D loss: 0.172522, acc.: 91%] [G loss: 3.861935]\n",
            "4356 [ D loss: 0.132322, acc.: 97%] [G loss: 4.784718]\n",
            "4357 [ D loss: 0.131971, acc.: 95%] [G loss: 5.901207]\n",
            "4358 [ D loss: 0.198252, acc.: 91%] [G loss: 4.377588]\n",
            "4359 [ D loss: 0.209115, acc.: 92%] [G loss: 9.943855]\n",
            "4360 [ D loss: 0.175109, acc.: 95%] [G loss: 4.260205]\n",
            "4361 [ D loss: 0.094304, acc.: 98%] [G loss: 6.270081]\n",
            "4362 [ D loss: 0.211516, acc.: 92%] [G loss: 4.718233]\n",
            "4363 [ D loss: 0.094338, acc.: 99%] [G loss: 4.531110]\n",
            "4364 [ D loss: 0.149321, acc.: 96%] [G loss: 4.787907]\n",
            "4365 [ D loss: 0.152448, acc.: 95%] [G loss: 4.121793]\n",
            "4366 [ D loss: 0.163754, acc.: 95%] [G loss: 4.618165]\n",
            "4367 [ D loss: 0.139734, acc.: 95%] [G loss: 5.713188]\n",
            "4368 [ D loss: 0.186048, acc.: 95%] [G loss: 4.825072]\n",
            "4369 [ D loss: 0.224533, acc.: 94%] [G loss: 3.905702]\n",
            "4370 [ D loss: 0.254703, acc.: 91%] [G loss: 3.806874]\n",
            "4371 [ D loss: 0.135310, acc.: 96%] [G loss: 4.368979]\n",
            "4372 [ D loss: 0.231838, acc.: 94%] [G loss: 5.114276]\n",
            "4373 [ D loss: 0.116051, acc.: 97%] [G loss: 5.773969]\n",
            "4374 [ D loss: 0.208328, acc.: 92%] [G loss: 5.050189]\n",
            "4375 [ D loss: 0.146859, acc.: 96%] [G loss: 4.045867]\n",
            "4376 [ D loss: 0.191108, acc.: 94%] [G loss: 4.531100]\n",
            "4377 [ D loss: 0.144069, acc.: 98%] [G loss: 4.732890]\n",
            "4378 [ D loss: 0.153599, acc.: 97%] [G loss: 4.234564]\n",
            "4379 [ D loss: 0.253727, acc.: 89%] [G loss: 4.414571]\n",
            "4380 [ D loss: 0.185172, acc.: 96%] [G loss: 4.046401]\n",
            "4381 [ D loss: 0.335484, acc.: 84%] [G loss: 4.219034]\n",
            "4382 [ D loss: 0.203466, acc.: 91%] [G loss: 4.716145]\n",
            "4383 [ D loss: 0.142716, acc.: 97%] [G loss: 4.972083]\n",
            "4384 [ D loss: 0.156714, acc.: 96%] [G loss: 7.215350]\n",
            "4385 [ D loss: 0.299056, acc.: 92%] [G loss: 3.554176]\n",
            "4386 [ D loss: 0.175257, acc.: 96%] [G loss: 5.285981]\n",
            "4387 [ D loss: 0.145611, acc.: 95%] [G loss: 7.123801]\n",
            "4388 [ D loss: 0.114338, acc.: 95%] [G loss: 5.528655]\n",
            "4389 [ D loss: 0.179211, acc.: 93%] [G loss: 5.639725]\n",
            "4390 [ D loss: 0.200757, acc.: 92%] [G loss: 4.930520]\n",
            "4391 [ D loss: 0.088401, acc.: 98%] [G loss: 4.861976]\n",
            "4392 [ D loss: 0.146103, acc.: 94%] [G loss: 4.900030]\n",
            "4393 [ D loss: 0.247987, acc.: 92%] [G loss: 4.173831]\n",
            "4394 [ D loss: 0.207089, acc.: 92%] [G loss: 4.507303]\n",
            "4395 [ D loss: 0.217953, acc.: 95%] [G loss: 4.146157]\n",
            "4396 [ D loss: 0.212789, acc.: 92%] [G loss: 4.425906]\n",
            "4397 [ D loss: 0.170787, acc.: 95%] [G loss: 4.652124]\n",
            "4398 [ D loss: 0.257497, acc.: 90%] [G loss: 4.269843]\n",
            "4399 [ D loss: 0.241963, acc.: 93%] [G loss: 4.730341]\n",
            "4400 [ D loss: 0.180025, acc.: 93%] [G loss: 3.884904]\n",
            "4401 [ D loss: 0.182395, acc.: 95%] [G loss: 5.541475]\n",
            "4402 [ D loss: 0.140338, acc.: 96%] [G loss: 4.239340]\n",
            "4403 [ D loss: 0.166665, acc.: 94%] [G loss: 5.369986]\n",
            "4404 [ D loss: 0.096189, acc.: 98%] [G loss: 4.736263]\n",
            "4405 [ D loss: 0.237056, acc.: 88%] [G loss: 5.089894]\n",
            "4406 [ D loss: 0.177821, acc.: 95%] [G loss: 3.616013]\n",
            "4407 [ D loss: 0.211729, acc.: 92%] [G loss: 3.536958]\n",
            "4408 [ D loss: 0.234733, acc.: 95%] [G loss: 4.570251]\n",
            "4409 [ D loss: 0.152521, acc.: 95%] [G loss: 5.479737]\n",
            "4410 [ D loss: 0.220756, acc.: 93%] [G loss: 3.968436]\n",
            "4411 [ D loss: 0.179540, acc.: 92%] [G loss: 3.963178]\n",
            "4412 [ D loss: 0.141878, acc.: 95%] [G loss: 3.722963]\n",
            "4413 [ D loss: 0.162611, acc.: 95%] [G loss: 4.580889]\n",
            "4414 [ D loss: 0.283766, acc.: 91%] [G loss: 3.770097]\n",
            "4415 [ D loss: 0.414293, acc.: 78%] [G loss: 7.617729]\n",
            "4416 [ D loss: 0.213280, acc.: 92%] [G loss: 6.408542]\n",
            "4417 [ D loss: 0.274546, acc.: 87%] [G loss: 3.944173]\n",
            "4418 [ D loss: 0.166709, acc.: 95%] [G loss: 4.935739]\n",
            "4419 [ D loss: 0.267854, acc.: 89%] [G loss: 5.062332]\n",
            "4420 [ D loss: 0.253257, acc.: 93%] [G loss: 4.041662]\n",
            "4421 [ D loss: 0.190191, acc.: 95%] [G loss: 4.840257]\n",
            "4422 [ D loss: 0.096072, acc.: 98%] [G loss: 6.397935]\n",
            "4423 [ D loss: 0.148448, acc.: 95%] [G loss: 4.840334]\n",
            "4424 [ D loss: 0.216108, acc.: 95%] [G loss: 4.939860]\n",
            "4425 [ D loss: 0.133430, acc.: 96%] [G loss: 5.103764]\n",
            "4426 [ D loss: 0.212952, acc.: 92%] [G loss: 5.722770]\n",
            "4427 [ D loss: 0.188527, acc.: 93%] [G loss: 4.591613]\n",
            "4428 [ D loss: 0.129053, acc.: 97%] [G loss: 4.091577]\n",
            "4429 [ D loss: 0.213613, acc.: 93%] [G loss: 4.332332]\n",
            "4430 [ D loss: 0.239411, acc.: 89%] [G loss: 4.621475]\n",
            "4431 [ D loss: 0.102132, acc.: 98%] [G loss: 4.918001]\n",
            "4432 [ D loss: 0.134171, acc.: 96%] [G loss: 4.885629]\n",
            "4433 [ D loss: 0.196766, acc.: 91%] [G loss: 4.548182]\n",
            "4434 [ D loss: 0.229214, acc.: 92%] [G loss: 4.144735]\n",
            "4435 [ D loss: 0.226137, acc.: 96%] [G loss: 3.868969]\n",
            "4436 [ D loss: 0.160345, acc.: 96%] [G loss: 4.095302]\n",
            "4437 [ D loss: 0.240773, acc.: 92%] [G loss: 6.007412]\n",
            "4438 [ D loss: 0.176435, acc.: 94%] [G loss: 4.088445]\n",
            "4439 [ D loss: 0.179520, acc.: 94%] [G loss: 4.878492]\n",
            "4440 [ D loss: 0.143424, acc.: 96%] [G loss: 5.942714]\n",
            "4441 [ D loss: 0.311480, acc.: 86%] [G loss: 4.179504]\n",
            "4442 [ D loss: 0.234965, acc.: 92%] [G loss: 4.615794]\n",
            "4443 [ D loss: 0.168432, acc.: 96%] [G loss: 3.995829]\n",
            "4444 [ D loss: 0.184916, acc.: 95%] [G loss: 3.889513]\n",
            "4445 [ D loss: 0.128716, acc.: 98%] [G loss: 4.789034]\n",
            "4446 [ D loss: 0.218240, acc.: 92%] [G loss: 4.102382]\n",
            "4447 [ D loss: 0.173473, acc.: 95%] [G loss: 4.647499]\n",
            "4448 [ D loss: 0.294296, acc.: 84%] [G loss: 4.481781]\n",
            "4449 [ D loss: 0.231041, acc.: 93%] [G loss: 4.511940]\n",
            "4450 [ D loss: 0.212904, acc.: 92%] [G loss: 4.610267]\n",
            "4451 [ D loss: 0.157674, acc.: 96%] [G loss: 9.074386]\n",
            "4452 [ D loss: 0.134309, acc.: 95%] [G loss: 5.549648]\n",
            "4453 [ D loss: 0.288900, acc.: 87%] [G loss: 4.570285]\n",
            "4454 [ D loss: 0.163924, acc.: 95%] [G loss: 6.573714]\n",
            "4455 [ D loss: 0.154894, acc.: 94%] [G loss: 4.616164]\n",
            "4456 [ D loss: 0.142050, acc.: 95%] [G loss: 6.660878]\n",
            "4457 [ D loss: 0.103175, acc.: 97%] [G loss: 6.163836]\n",
            "4458 [ D loss: 0.223834, acc.: 95%] [G loss: 4.300071]\n",
            "4459 [ D loss: 0.171799, acc.: 95%] [G loss: 4.852567]\n",
            "4460 [ D loss: 0.196840, acc.: 92%] [G loss: 4.218095]\n",
            "4461 [ D loss: 0.188409, acc.: 93%] [G loss: 4.622893]\n",
            "4462 [ D loss: 0.134528, acc.: 98%] [G loss: 3.708677]\n",
            "4463 [ D loss: 0.162023, acc.: 95%] [G loss: 3.839535]\n",
            "4464 [ D loss: 0.158861, acc.: 96%] [G loss: 5.251733]\n",
            "4465 [ D loss: 0.252941, acc.: 93%] [G loss: 4.292225]\n",
            "4466 [ D loss: 0.160585, acc.: 98%] [G loss: 4.520017]\n",
            "4467 [ D loss: 0.226489, acc.: 92%] [G loss: 5.016066]\n",
            "4468 [ D loss: 0.114925, acc.: 95%] [G loss: 4.760697]\n",
            "4469 [ D loss: 0.169288, acc.: 92%] [G loss: 6.604329]\n",
            "4470 [ D loss: 0.127492, acc.: 96%] [G loss: 7.129013]\n",
            "4471 [ D loss: 0.155235, acc.: 94%] [G loss: 5.221889]\n",
            "4472 [ D loss: 0.232041, acc.: 89%] [G loss: 7.616397]\n",
            "4473 [ D loss: 0.215756, acc.: 94%] [G loss: 3.943603]\n",
            "4474 [ D loss: 0.104079, acc.: 98%] [G loss: 3.886152]\n",
            "4475 [ D loss: 0.174423, acc.: 94%] [G loss: 5.629786]\n",
            "4476 [ D loss: 0.261483, acc.: 90%] [G loss: 4.176393]\n",
            "4477 [ D loss: 0.178471, acc.: 91%] [G loss: 4.403461]\n",
            "4478 [ D loss: 0.177224, acc.: 95%] [G loss: 4.045395]\n",
            "4479 [ D loss: 0.264274, acc.: 91%] [G loss: 4.298025]\n",
            "4480 [ D loss: 0.218416, acc.: 94%] [G loss: 4.898030]\n",
            "4481 [ D loss: 0.210753, acc.: 93%] [G loss: 4.198735]\n",
            "4482 [ D loss: 0.116361, acc.: 97%] [G loss: 4.825007]\n",
            "4483 [ D loss: 0.223949, acc.: 91%] [G loss: 4.392865]\n",
            "4484 [ D loss: 0.182601, acc.: 95%] [G loss: 4.441558]\n",
            "4485 [ D loss: 0.174117, acc.: 93%] [G loss: 5.090581]\n",
            "4486 [ D loss: 0.182715, acc.: 93%] [G loss: 6.810052]\n",
            "4487 [ D loss: 0.171218, acc.: 97%] [G loss: 3.881070]\n",
            "4488 [ D loss: 0.148985, acc.: 92%] [G loss: 8.717061]\n",
            "4489 [ D loss: 0.192977, acc.: 95%] [G loss: 4.363378]\n",
            "4490 [ D loss: 0.172715, acc.: 95%] [G loss: 5.657547]\n",
            "4491 [ D loss: 0.220621, acc.: 91%] [G loss: 4.088011]\n",
            "4492 [ D loss: 0.172348, acc.: 94%] [G loss: 3.742972]\n",
            "4493 [ D loss: 0.195409, acc.: 94%] [G loss: 3.497211]\n",
            "4494 [ D loss: 0.207832, acc.: 93%] [G loss: 4.538480]\n",
            "4495 [ D loss: 0.158174, acc.: 97%] [G loss: 4.834124]\n",
            "4496 [ D loss: 0.361191, acc.: 84%] [G loss: 4.072741]\n",
            "4497 [ D loss: 0.225062, acc.: 91%] [G loss: 5.908866]\n",
            "4498 [ D loss: 0.155048, acc.: 96%] [G loss: 4.578502]\n",
            "4499 [ D loss: 0.150396, acc.: 95%] [G loss: 4.745350]\n",
            "4500 [ D loss: 0.207063, acc.: 92%] [G loss: 5.018426]\n",
            "4501 [ D loss: 0.196494, acc.: 93%] [G loss: 5.968009]\n",
            "4502 [ D loss: 0.099798, acc.: 99%] [G loss: 8.262443]\n",
            "4503 [ D loss: 0.195712, acc.: 91%] [G loss: 5.084257]\n",
            "4504 [ D loss: 0.170017, acc.: 95%] [G loss: 4.559941]\n",
            "4505 [ D loss: 0.133176, acc.: 96%] [G loss: 5.594925]\n",
            "4506 [ D loss: 0.130772, acc.: 94%] [G loss: 4.049475]\n",
            "4507 [ D loss: 0.145066, acc.: 94%] [G loss: 5.431116]\n",
            "4508 [ D loss: 0.183100, acc.: 93%] [G loss: 6.282768]\n",
            "4509 [ D loss: 0.248719, acc.: 91%] [G loss: 4.030598]\n",
            "4510 [ D loss: 0.158075, acc.: 95%] [G loss: 4.344911]\n",
            "4511 [ D loss: 0.198193, acc.: 95%] [G loss: 4.288036]\n",
            "4512 [ D loss: 0.170200, acc.: 92%] [G loss: 5.099597]\n",
            "4513 [ D loss: 0.172300, acc.: 94%] [G loss: 5.818779]\n",
            "4514 [ D loss: 0.117592, acc.: 98%] [G loss: 3.773141]\n",
            "4515 [ D loss: 0.241303, acc.: 93%] [G loss: 4.619088]\n",
            "4516 [ D loss: 0.122949, acc.: 98%] [G loss: 4.002582]\n",
            "4517 [ D loss: 0.197087, acc.: 93%] [G loss: 3.599878]\n",
            "4518 [ D loss: 0.167529, acc.: 95%] [G loss: 3.896909]\n",
            "4519 [ D loss: 0.142659, acc.: 97%] [G loss: 5.805819]\n",
            "4520 [ D loss: 0.142769, acc.: 96%] [G loss: 5.075148]\n",
            "4521 [ D loss: 0.305392, acc.: 89%] [G loss: 5.181386]\n",
            "4522 [ D loss: 0.196549, acc.: 91%] [G loss: 6.951737]\n",
            "4523 [ D loss: 0.146075, acc.: 95%] [G loss: 3.438537]\n",
            "4524 [ D loss: 0.145300, acc.: 97%] [G loss: 3.400710]\n",
            "4525 [ D loss: 0.261478, acc.: 91%] [G loss: 6.178886]\n",
            "4526 [ D loss: 0.311859, acc.: 85%] [G loss: 4.541628]\n",
            "4527 [ D loss: 0.241567, acc.: 91%] [G loss: 6.631160]\n",
            "4528 [ D loss: 0.136694, acc.: 95%] [G loss: 5.611920]\n",
            "4529 [ D loss: 0.134409, acc.: 95%] [G loss: 6.545384]\n",
            "4530 [ D loss: 0.261477, acc.: 88%] [G loss: 6.634867]\n",
            "4531 [ D loss: 0.168375, acc.: 94%] [G loss: 4.682408]\n",
            "4532 [ D loss: 0.139142, acc.: 95%] [G loss: 7.321871]\n",
            "4533 [ D loss: 0.165829, acc.: 95%] [G loss: 6.038644]\n",
            "4534 [ D loss: 0.136858, acc.: 97%] [G loss: 6.434037]\n",
            "4535 [ D loss: 0.174017, acc.: 93%] [G loss: 7.320992]\n",
            "4536 [ D loss: 0.164345, acc.: 94%] [G loss: 6.435095]\n",
            "4537 [ D loss: 0.185429, acc.: 95%] [G loss: 6.000347]\n",
            "4538 [ D loss: 0.273000, acc.: 86%] [G loss: 8.356316]\n",
            "4539 [ D loss: 0.114071, acc.: 94%] [G loss: 7.890137]\n",
            "4540 [ D loss: 0.210063, acc.: 90%] [G loss: 4.614839]\n",
            "4541 [ D loss: 0.130292, acc.: 95%] [G loss: 4.886731]\n",
            "4542 [ D loss: 0.217897, acc.: 93%] [G loss: 4.246869]\n",
            "4543 [ D loss: 0.150935, acc.: 96%] [G loss: 4.345298]\n",
            "4544 [ D loss: 0.223585, acc.: 93%] [G loss: 3.992463]\n",
            "4545 [ D loss: 0.216196, acc.: 91%] [G loss: 4.274216]\n",
            "4546 [ D loss: 0.245333, acc.: 90%] [G loss: 3.830234]\n",
            "4547 [ D loss: 0.224583, acc.: 93%] [G loss: 4.896832]\n",
            "4548 [ D loss: 0.179462, acc.: 95%] [G loss: 5.569735]\n",
            "4549 [ D loss: 0.213714, acc.: 92%] [G loss: 4.182187]\n",
            "4550 [ D loss: 0.128955, acc.: 98%] [G loss: 4.712766]\n",
            "4551 [ D loss: 0.216947, acc.: 92%] [G loss: 4.825406]\n",
            "4552 [ D loss: 0.193457, acc.: 93%] [G loss: 3.104721]\n",
            "4553 [ D loss: 0.205796, acc.: 95%] [G loss: 4.978247]\n",
            "4554 [ D loss: 0.165717, acc.: 94%] [G loss: 6.543154]\n",
            "4555 [ D loss: 0.152131, acc.: 95%] [G loss: 4.570333]\n",
            "4556 [ D loss: 0.187557, acc.: 91%] [G loss: 4.299081]\n",
            "4557 [ D loss: 0.162094, acc.: 95%] [G loss: 4.615016]\n",
            "4558 [ D loss: 0.195738, acc.: 92%] [G loss: 3.948602]\n",
            "4559 [ D loss: 0.328223, acc.: 86%] [G loss: 3.599415]\n",
            "4560 [ D loss: 0.224848, acc.: 95%] [G loss: 4.180683]\n",
            "4561 [ D loss: 0.184417, acc.: 95%] [G loss: 5.520825]\n",
            "4562 [ D loss: 0.146556, acc.: 95%] [G loss: 9.003147]\n",
            "4563 [ D loss: 0.109600, acc.: 95%] [G loss: 4.365160]\n",
            "4564 [ D loss: 0.147131, acc.: 97%] [G loss: 4.744761]\n",
            "4565 [ D loss: 0.271281, acc.: 88%] [G loss: 4.442667]\n",
            "4566 [ D loss: 0.233877, acc.: 88%] [G loss: 4.137540]\n",
            "4567 [ D loss: 0.205808, acc.: 94%] [G loss: 4.524607]\n",
            "4568 [ D loss: 0.157401, acc.: 95%] [G loss: 4.836243]\n",
            "4569 [ D loss: 0.220013, acc.: 91%] [G loss: 3.710525]\n",
            "4570 [ D loss: 0.197035, acc.: 91%] [G loss: 5.525230]\n",
            "4571 [ D loss: 0.133915, acc.: 97%] [G loss: 6.969454]\n",
            "4572 [ D loss: 0.143688, acc.: 96%] [G loss: 5.708964]\n",
            "4573 [ D loss: 0.093086, acc.: 97%] [G loss: 8.738405]\n",
            "4574 [ D loss: 0.149151, acc.: 95%] [G loss: 6.848751]\n",
            "4575 [ D loss: 0.129469, acc.: 98%] [G loss: 7.519841]\n",
            "4576 [ D loss: 0.198279, acc.: 95%] [G loss: 5.487767]\n",
            "4577 [ D loss: 0.112629, acc.: 98%] [G loss: 5.619296]\n",
            "4578 [ D loss: 0.149054, acc.: 95%] [G loss: 5.563916]\n",
            "4579 [ D loss: 0.174192, acc.: 94%] [G loss: 4.131152]\n",
            "4580 [ D loss: 0.166604, acc.: 97%] [G loss: 5.067305]\n",
            "4581 [ D loss: 0.117394, acc.: 96%] [G loss: 5.178641]\n",
            "4582 [ D loss: 0.230794, acc.: 89%] [G loss: 4.378623]\n",
            "4583 [ D loss: 0.128183, acc.: 97%] [G loss: 4.795809]\n",
            "4584 [ D loss: 0.189793, acc.: 95%] [G loss: 4.514508]\n",
            "4585 [ D loss: 0.244288, acc.: 91%] [G loss: 3.614825]\n",
            "4586 [ D loss: 0.196603, acc.: 91%] [G loss: 5.398450]\n",
            "4587 [ D loss: 0.166278, acc.: 93%] [G loss: 5.320822]\n",
            "4588 [ D loss: 0.191317, acc.: 93%] [G loss: 4.569148]\n",
            "4589 [ D loss: 0.140364, acc.: 97%] [G loss: 4.142436]\n",
            "4590 [ D loss: 0.111518, acc.: 98%] [G loss: 5.826334]\n",
            "4591 [ D loss: 0.206782, acc.: 94%] [G loss: 5.498428]\n",
            "4592 [ D loss: 0.115556, acc.: 97%] [G loss: 4.846763]\n",
            "4593 [ D loss: 0.152468, acc.: 95%] [G loss: 4.088387]\n",
            "4594 [ D loss: 0.144372, acc.: 96%] [G loss: 4.612371]\n",
            "4595 [ D loss: 0.139022, acc.: 96%] [G loss: 5.169432]\n",
            "4596 [ D loss: 0.125174, acc.: 97%] [G loss: 6.064904]\n",
            "4597 [ D loss: 0.191327, acc.: 92%] [G loss: 7.142399]\n",
            "4598 [ D loss: 0.126997, acc.: 95%] [G loss: 5.861938]\n",
            "4599 [ D loss: 0.127000, acc.: 95%] [G loss: 7.707080]\n",
            "4600 [ D loss: 0.096279, acc.: 98%] [G loss: 7.682123]\n",
            "4601 [ D loss: 0.130931, acc.: 96%] [G loss: 5.448411]\n",
            "4602 [ D loss: 0.270051, acc.: 88%] [G loss: 4.638060]\n",
            "4603 [ D loss: 0.170473, acc.: 96%] [G loss: 4.066686]\n",
            "4604 [ D loss: 0.310819, acc.: 86%] [G loss: 4.289263]\n",
            "4605 [ D loss: 0.261559, acc.: 92%] [G loss: 3.737298]\n",
            "4606 [ D loss: 0.301365, acc.: 87%] [G loss: 5.931252]\n",
            "4607 [ D loss: 0.190909, acc.: 92%] [G loss: 5.726767]\n",
            "4608 [ D loss: 0.284352, acc.: 91%] [G loss: 4.939031]\n",
            "4609 [ D loss: 0.201435, acc.: 91%] [G loss: 4.980552]\n",
            "4610 [ D loss: 0.150328, acc.: 95%] [G loss: 3.903244]\n",
            "4611 [ D loss: 0.198254, acc.: 93%] [G loss: 5.004801]\n",
            "4612 [ D loss: 0.188299, acc.: 93%] [G loss: 3.927674]\n",
            "4613 [ D loss: 0.184538, acc.: 92%] [G loss: 5.425220]\n",
            "4614 [ D loss: 0.189406, acc.: 92%] [G loss: 3.979848]\n",
            "4615 [ D loss: 0.128608, acc.: 95%] [G loss: 5.048496]\n",
            "4616 [ D loss: 0.260643, acc.: 88%] [G loss: 5.134409]\n",
            "4617 [ D loss: 0.218880, acc.: 89%] [G loss: 4.508731]\n",
            "4618 [ D loss: 0.157481, acc.: 95%] [G loss: 3.943683]\n",
            "4619 [ D loss: 0.184678, acc.: 95%] [G loss: 5.129973]\n",
            "4620 [ D loss: 0.213887, acc.: 95%] [G loss: 7.023281]\n",
            "4621 [ D loss: 0.151259, acc.: 96%] [G loss: 5.517578]\n",
            "4622 [ D loss: 0.214302, acc.: 91%] [G loss: 4.276846]\n",
            "4623 [ D loss: 0.158775, acc.: 96%] [G loss: 3.454201]\n",
            "4624 [ D loss: 0.179543, acc.: 95%] [G loss: 4.977973]\n",
            "4625 [ D loss: 0.094904, acc.: 98%] [G loss: 9.216047]\n",
            "4626 [ D loss: 0.143717, acc.: 97%] [G loss: 7.243647]\n",
            "4627 [ D loss: 0.140176, acc.: 95%] [G loss: 6.351057]\n",
            "4628 [ D loss: 0.119509, acc.: 95%] [G loss: 5.509357]\n",
            "4629 [ D loss: 0.147131, acc.: 95%] [G loss: 7.141071]\n",
            "4630 [ D loss: 0.114959, acc.: 96%] [G loss: 6.411014]\n",
            "4631 [ D loss: 0.165789, acc.: 94%] [G loss: 7.397882]\n",
            "4632 [ D loss: 0.172945, acc.: 93%] [G loss: 4.971670]\n",
            "4633 [ D loss: 0.200323, acc.: 91%] [G loss: 5.720682]\n",
            "4634 [ D loss: 0.126809, acc.: 97%] [G loss: 6.046035]\n",
            "4635 [ D loss: 0.264495, acc.: 89%] [G loss: 3.791908]\n",
            "4636 [ D loss: 0.201732, acc.: 91%] [G loss: 4.487375]\n",
            "4637 [ D loss: 0.239728, acc.: 92%] [G loss: 3.582767]\n",
            "4638 [ D loss: 0.295937, acc.: 88%] [G loss: 3.879113]\n",
            "4639 [ D loss: 0.117485, acc.: 97%] [G loss: 4.699690]\n",
            "4640 [ D loss: 0.231994, acc.: 91%] [G loss: 4.726951]\n",
            "4641 [ D loss: 0.203874, acc.: 92%] [G loss: 3.776851]\n",
            "4642 [ D loss: 0.201751, acc.: 91%] [G loss: 3.166193]\n",
            "4643 [ D loss: 0.138557, acc.: 96%] [G loss: 4.680343]\n",
            "4644 [ D loss: 0.209475, acc.: 96%] [G loss: 5.120339]\n",
            "4645 [ D loss: 0.120755, acc.: 97%] [G loss: 4.920091]\n",
            "4646 [ D loss: 0.205309, acc.: 91%] [G loss: 4.990839]\n",
            "4647 [ D loss: 0.083740, acc.: 98%] [G loss: 3.656075]\n",
            "4648 [ D loss: 0.239595, acc.: 91%] [G loss: 3.926857]\n",
            "4649 [ D loss: 0.159103, acc.: 95%] [G loss: 5.451411]\n",
            "4650 [ D loss: 0.219706, acc.: 91%] [G loss: 7.151595]\n",
            "4651 [ D loss: 0.335055, acc.: 86%] [G loss: 3.625131]\n",
            "4652 [ D loss: 0.142104, acc.: 98%] [G loss: 4.301904]\n",
            "4653 [ D loss: 0.124116, acc.: 95%] [G loss: 5.205946]\n",
            "4654 [ D loss: 0.304204, acc.: 88%] [G loss: 4.455752]\n",
            "4655 [ D loss: 0.187867, acc.: 94%] [G loss: 4.802960]\n",
            "4656 [ D loss: 0.282450, acc.: 88%] [G loss: 5.527993]\n",
            "4657 [ D loss: 0.148734, acc.: 95%] [G loss: 5.835423]\n",
            "4658 [ D loss: 0.120913, acc.: 96%] [G loss: 4.810415]\n",
            "4659 [ D loss: 0.118402, acc.: 98%] [G loss: 7.300293]\n",
            "4660 [ D loss: 0.074229, acc.: 98%] [G loss: 5.899986]\n",
            "4661 [ D loss: 0.061627, acc.: 98%] [G loss: 10.680210]\n",
            "4662 [ D loss: 0.133175, acc.: 95%] [G loss: 10.860405]\n",
            "4663 [ D loss: 0.108075, acc.: 97%] [G loss: 7.508261]\n",
            "4664 [ D loss: 0.183094, acc.: 91%] [G loss: 4.536937]\n",
            "4665 [ D loss: 0.087068, acc.: 98%] [G loss: 9.999771]\n",
            "4666 [ D loss: 0.117531, acc.: 98%] [G loss: 5.882249]\n",
            "4667 [ D loss: 0.171633, acc.: 92%] [G loss: 4.192248]\n",
            "4668 [ D loss: 0.383917, acc.: 88%] [G loss: 5.283930]\n",
            "4669 [ D loss: 0.072408, acc.: 99%] [G loss: 7.191608]\n",
            "4670 [ D loss: 0.156933, acc.: 95%] [G loss: 3.675354]\n",
            "4671 [ D loss: 0.221504, acc.: 91%] [G loss: 4.690692]\n",
            "4672 [ D loss: 0.195624, acc.: 95%] [G loss: 5.414822]\n",
            "4673 [ D loss: 0.155910, acc.: 95%] [G loss: 4.084789]\n",
            "4674 [ D loss: 0.187822, acc.: 94%] [G loss: 7.057678]\n",
            "4675 [ D loss: 0.157817, acc.: 91%] [G loss: 4.739220]\n",
            "4676 [ D loss: 0.220300, acc.: 92%] [G loss: 5.404693]\n",
            "4677 [ D loss: 0.190146, acc.: 92%] [G loss: 4.739585]\n",
            "4678 [ D loss: 0.126512, acc.: 96%] [G loss: 4.185239]\n",
            "4679 [ D loss: 0.197993, acc.: 95%] [G loss: 4.685738]\n",
            "4680 [ D loss: 0.103169, acc.: 97%] [G loss: 4.328613]\n",
            "4681 [ D loss: 0.280042, acc.: 92%] [G loss: 5.032545]\n",
            "4682 [ D loss: 0.161644, acc.: 94%] [G loss: 7.923414]\n",
            "4683 [ D loss: 0.092041, acc.: 97%] [G loss: 7.644832]\n",
            "4684 [ D loss: 0.138356, acc.: 96%] [G loss: 5.645879]\n",
            "4685 [ D loss: 0.106301, acc.: 98%] [G loss: 6.131224]\n",
            "4686 [ D loss: 0.262120, acc.: 93%] [G loss: 6.599813]\n",
            "4687 [ D loss: 0.107557, acc.: 96%] [G loss: 7.656573]\n",
            "4688 [ D loss: 0.159708, acc.: 92%] [G loss: 5.969556]\n",
            "4689 [ D loss: 0.079837, acc.: 98%] [G loss: 4.514526]\n",
            "4690 [ D loss: 0.178247, acc.: 94%] [G loss: 5.272024]\n",
            "4691 [ D loss: 0.149158, acc.: 98%] [G loss: 7.810664]\n",
            "4692 [ D loss: 0.150293, acc.: 92%] [G loss: 5.087469]\n",
            "4693 [ D loss: 0.154384, acc.: 95%] [G loss: 5.541568]\n",
            "4694 [ D loss: 0.165315, acc.: 93%] [G loss: 5.491705]\n",
            "4695 [ D loss: 0.196598, acc.: 95%] [G loss: 5.945659]\n",
            "4696 [ D loss: 0.195488, acc.: 92%] [G loss: 5.282696]\n",
            "4697 [ D loss: 0.162322, acc.: 95%] [G loss: 5.335761]\n",
            "4698 [ D loss: 0.162157, acc.: 95%] [G loss: 7.069189]\n",
            "4699 [ D loss: 0.148842, acc.: 97%] [G loss: 3.664475]\n",
            "4700 [ D loss: 0.166405, acc.: 94%] [G loss: 5.262712]\n",
            "4701 [ D loss: 0.170168, acc.: 95%] [G loss: 4.410119]\n",
            "4702 [ D loss: 0.202961, acc.: 94%] [G loss: 3.425588]\n",
            "4703 [ D loss: 0.243490, acc.: 91%] [G loss: 4.103277]\n",
            "4704 [ D loss: 0.205373, acc.: 93%] [G loss: 4.930197]\n",
            "4705 [ D loss: 0.130532, acc.: 96%] [G loss: 5.445630]\n",
            "4706 [ D loss: 0.204899, acc.: 91%] [G loss: 3.931394]\n",
            "4707 [ D loss: 0.110241, acc.: 95%] [G loss: 7.455799]\n",
            "4708 [ D loss: 0.139372, acc.: 96%] [G loss: 5.035326]\n",
            "4709 [ D loss: 0.247154, acc.: 87%] [G loss: 4.339812]\n",
            "4710 [ D loss: 0.161007, acc.: 95%] [G loss: 4.945254]\n",
            "4711 [ D loss: 0.384864, acc.: 82%] [G loss: 3.460497]\n",
            "4712 [ D loss: 0.118889, acc.: 97%] [G loss: 4.759378]\n",
            "4713 [ D loss: 0.261728, acc.: 91%] [G loss: 4.325911]\n",
            "4714 [ D loss: 0.142188, acc.: 97%] [G loss: 4.476129]\n",
            "4715 [ D loss: 0.077596, acc.: 98%] [G loss: 5.785865]\n",
            "4716 [ D loss: 0.241946, acc.: 90%] [G loss: 4.575127]\n",
            "4717 [ D loss: 0.228309, acc.: 89%] [G loss: 3.888716]\n",
            "4718 [ D loss: 0.140338, acc.: 97%] [G loss: 6.263335]\n",
            "4719 [ D loss: 0.150284, acc.: 94%] [G loss: 4.293632]\n",
            "4720 [ D loss: 0.226959, acc.: 91%] [G loss: 7.965971]\n",
            "4721 [ D loss: 0.272969, acc.: 88%] [G loss: 4.553098]\n",
            "4722 [ D loss: 0.252973, acc.: 88%] [G loss: 3.424148]\n",
            "4723 [ D loss: 0.190199, acc.: 93%] [G loss: 8.131119]\n",
            "4724 [ D loss: 0.150194, acc.: 95%] [G loss: 5.323889]\n",
            "4725 [ D loss: 0.144687, acc.: 95%] [G loss: 6.390520]\n",
            "4726 [ D loss: 0.189430, acc.: 93%] [G loss: 4.618637]\n",
            "4727 [ D loss: 0.081088, acc.: 98%] [G loss: 5.804019]\n",
            "4728 [ D loss: 0.188844, acc.: 95%] [G loss: 3.298626]\n",
            "4729 [ D loss: 0.159873, acc.: 93%] [G loss: 5.564131]\n",
            "4730 [ D loss: 0.167054, acc.: 92%] [G loss: 4.536562]\n",
            "4731 [ D loss: 0.160587, acc.: 96%] [G loss: 3.118166]\n",
            "4732 [ D loss: 0.168867, acc.: 95%] [G loss: 3.655758]\n",
            "4733 [ D loss: 0.267461, acc.: 91%] [G loss: 4.150678]\n",
            "4734 [ D loss: 0.151638, acc.: 97%] [G loss: 3.758729]\n",
            "4735 [ D loss: 0.223329, acc.: 91%] [G loss: 4.649496]\n",
            "4736 [ D loss: 0.348983, acc.: 83%] [G loss: 4.059961]\n",
            "4737 [ D loss: 0.147270, acc.: 94%] [G loss: 4.437572]\n",
            "4738 [ D loss: 0.258587, acc.: 91%] [G loss: 3.375727]\n",
            "4739 [ D loss: 0.122267, acc.: 97%] [G loss: 4.493618]\n",
            "4740 [ D loss: 0.318135, acc.: 88%] [G loss: 4.224796]\n",
            "4741 [ D loss: 0.249885, acc.: 91%] [G loss: 3.374480]\n",
            "4742 [ D loss: 0.245987, acc.: 91%] [G loss: 4.385101]\n",
            "4743 [ D loss: 0.253039, acc.: 91%] [G loss: 3.574069]\n",
            "4744 [ D loss: 0.227118, acc.: 94%] [G loss: 3.775163]\n",
            "4745 [ D loss: 0.131305, acc.: 97%] [G loss: 4.650820]\n",
            "4746 [ D loss: 0.201001, acc.: 95%] [G loss: 3.825337]\n",
            "4747 [ D loss: 0.277864, acc.: 89%] [G loss: 3.663553]\n",
            "4748 [ D loss: 0.203277, acc.: 94%] [G loss: 3.535576]\n",
            "4749 [ D loss: 0.173245, acc.: 95%] [G loss: 3.628661]\n",
            "4750 [ D loss: 0.244988, acc.: 89%] [G loss: 3.726050]\n",
            "4751 [ D loss: 0.242328, acc.: 90%] [G loss: 4.403447]\n",
            "4752 [ D loss: 0.214869, acc.: 91%] [G loss: 4.600972]\n",
            "4753 [ D loss: 0.101656, acc.: 97%] [G loss: 3.734328]\n",
            "4754 [ D loss: 0.142094, acc.: 95%] [G loss: 4.817636]\n",
            "4755 [ D loss: 0.183256, acc.: 95%] [G loss: 4.447253]\n",
            "4756 [ D loss: 0.166542, acc.: 95%] [G loss: 7.671866]\n",
            "4757 [ D loss: 0.300976, acc.: 89%] [G loss: 4.302810]\n",
            "4758 [ D loss: 0.250508, acc.: 90%] [G loss: 10.111381]\n",
            "4759 [ D loss: 0.289963, acc.: 85%] [G loss: 6.715310]\n",
            "4760 [ D loss: 0.097560, acc.: 97%] [G loss: 6.690839]\n",
            "4761 [ D loss: 0.145375, acc.: 92%] [G loss: 6.166286]\n",
            "4762 [ D loss: 0.113629, acc.: 96%] [G loss: 5.411033]\n",
            "4763 [ D loss: 0.090738, acc.: 98%] [G loss: 6.617530]\n",
            "4764 [ D loss: 0.143784, acc.: 94%] [G loss: 7.184619]\n",
            "4765 [ D loss: 0.170395, acc.: 95%] [G loss: 4.609992]\n",
            "4766 [ D loss: 0.058474, acc.: 100%] [G loss: 5.069481]\n",
            "4767 [ D loss: 0.136514, acc.: 94%] [G loss: 5.610825]\n",
            "4768 [ D loss: 0.195996, acc.: 94%] [G loss: 4.027318]\n",
            "4769 [ D loss: 0.189690, acc.: 94%] [G loss: 4.342393]\n",
            "4770 [ D loss: 0.117996, acc.: 96%] [G loss: 5.509461]\n",
            "4771 [ D loss: 0.196149, acc.: 91%] [G loss: 4.449833]\n",
            "4772 [ D loss: 0.156463, acc.: 95%] [G loss: 4.442217]\n",
            "4773 [ D loss: 0.235921, acc.: 89%] [G loss: 3.975152]\n",
            "4774 [ D loss: 0.189831, acc.: 95%] [G loss: 3.961313]\n",
            "4775 [ D loss: 0.260856, acc.: 88%] [G loss: 3.296152]\n",
            "4776 [ D loss: 0.137735, acc.: 96%] [G loss: 5.035887]\n",
            "4777 [ D loss: 0.189172, acc.: 93%] [G loss: 4.105518]\n",
            "4778 [ D loss: 0.115454, acc.: 98%] [G loss: 4.506991]\n",
            "4779 [ D loss: 0.163905, acc.: 92%] [G loss: 3.998451]\n",
            "4780 [ D loss: 0.236428, acc.: 88%] [G loss: 6.503067]\n",
            "4781 [ D loss: 0.155699, acc.: 95%] [G loss: 6.134623]\n",
            "4782 [ D loss: 0.136435, acc.: 95%] [G loss: 9.003695]\n",
            "4783 [ D loss: 0.113981, acc.: 96%] [G loss: 5.211735]\n",
            "4784 [ D loss: 0.227223, acc.: 88%] [G loss: 4.875247]\n",
            "4785 [ D loss: 0.131726, acc.: 98%] [G loss: 6.882369]\n",
            "4786 [ D loss: 0.216318, acc.: 90%] [G loss: 5.618387]\n",
            "4787 [ D loss: 0.120257, acc.: 98%] [G loss: 4.346848]\n",
            "4788 [ D loss: 0.195991, acc.: 94%] [G loss: 3.763548]\n",
            "4789 [ D loss: 0.166333, acc.: 96%] [G loss: 3.703698]\n",
            "4790 [ D loss: 0.235308, acc.: 92%] [G loss: 4.373600]\n",
            "4791 [ D loss: 0.129109, acc.: 96%] [G loss: 5.056005]\n",
            "4792 [ D loss: 0.180771, acc.: 95%] [G loss: 5.553126]\n",
            "4793 [ D loss: 0.237071, acc.: 91%] [G loss: 3.753285]\n",
            "4794 [ D loss: 0.114019, acc.: 98%] [G loss: 3.952397]\n",
            "4795 [ D loss: 0.292684, acc.: 87%] [G loss: 4.253576]\n",
            "4796 [ D loss: 0.198104, acc.: 92%] [G loss: 3.853368]\n",
            "4797 [ D loss: 0.172650, acc.: 95%] [G loss: 4.222298]\n",
            "4798 [ D loss: 0.139627, acc.: 98%] [G loss: 4.831917]\n",
            "4799 [ D loss: 0.150983, acc.: 94%] [G loss: 3.777994]\n",
            "4800 [ D loss: 0.140085, acc.: 97%] [G loss: 4.742281]\n",
            "4801 [ D loss: 0.274825, acc.: 88%] [G loss: 3.580622]\n",
            "4802 [ D loss: 0.207530, acc.: 94%] [G loss: 4.035620]\n",
            "4803 [ D loss: 0.227148, acc.: 91%] [G loss: 4.615997]\n",
            "4804 [ D loss: 0.123457, acc.: 98%] [G loss: 4.826530]\n",
            "4805 [ D loss: 0.231428, acc.: 90%] [G loss: 5.996458]\n",
            "4806 [ D loss: 0.252778, acc.: 88%] [G loss: 4.588643]\n",
            "4807 [ D loss: 0.218604, acc.: 91%] [G loss: 4.668015]\n",
            "4808 [ D loss: 0.251647, acc.: 90%] [G loss: 3.876482]\n",
            "4809 [ D loss: 0.182184, acc.: 94%] [G loss: 5.686722]\n",
            "4810 [ D loss: 0.124349, acc.: 96%] [G loss: 4.291662]\n",
            "4811 [ D loss: 0.227612, acc.: 91%] [G loss: 5.026206]\n",
            "4812 [ D loss: 0.168797, acc.: 92%] [G loss: 5.916656]\n",
            "4813 [ D loss: 0.086652, acc.: 97%] [G loss: 4.716963]\n",
            "4814 [ D loss: 0.145991, acc.: 95%] [G loss: 3.948425]\n",
            "4815 [ D loss: 0.195842, acc.: 95%] [G loss: 4.679477]\n",
            "4816 [ D loss: 0.244611, acc.: 90%] [G loss: 4.155288]\n",
            "4817 [ D loss: 0.187479, acc.: 95%] [G loss: 3.678315]\n",
            "4818 [ D loss: 0.235902, acc.: 91%] [G loss: 4.524378]\n",
            "4819 [ D loss: 0.209901, acc.: 89%] [G loss: 3.524287]\n",
            "4820 [ D loss: 0.295327, acc.: 88%] [G loss: 4.392496]\n",
            "4821 [ D loss: 0.122348, acc.: 98%] [G loss: 4.414466]\n",
            "4822 [ D loss: 0.212892, acc.: 91%] [G loss: 4.230611]\n",
            "4823 [ D loss: 0.252077, acc.: 88%] [G loss: 4.750009]\n",
            "4824 [ D loss: 0.217943, acc.: 93%] [G loss: 4.959726]\n",
            "4825 [ D loss: 0.300395, acc.: 89%] [G loss: 3.626396]\n",
            "4826 [ D loss: 0.115189, acc.: 97%] [G loss: 4.538203]\n",
            "4827 [ D loss: 0.143950, acc.: 95%] [G loss: 3.484491]\n",
            "4828 [ D loss: 0.122857, acc.: 97%] [G loss: 4.602543]\n",
            "4829 [ D loss: 0.248047, acc.: 90%] [G loss: 5.211670]\n",
            "4830 [ D loss: 0.089000, acc.: 97%] [G loss: 7.488173]\n",
            "4831 [ D loss: 0.111769, acc.: 96%] [G loss: 5.008912]\n",
            "4832 [ D loss: 0.114842, acc.: 96%] [G loss: 11.813559]\n",
            "4833 [ D loss: 0.153759, acc.: 94%] [G loss: 5.805785]\n",
            "4834 [ D loss: 0.178484, acc.: 92%] [G loss: 4.687207]\n",
            "4835 [ D loss: 0.237468, acc.: 91%] [G loss: 5.514720]\n",
            "4836 [ D loss: 0.246545, acc.: 91%] [G loss: 7.406672]\n",
            "4837 [ D loss: 0.144924, acc.: 92%] [G loss: 3.717095]\n",
            "4838 [ D loss: 0.259587, acc.: 85%] [G loss: 5.749347]\n",
            "4839 [ D loss: 0.211210, acc.: 91%] [G loss: 6.031984]\n",
            "4840 [ D loss: 0.149890, acc.: 94%] [G loss: 6.841842]\n",
            "4841 [ D loss: 0.144098, acc.: 94%] [G loss: 5.142744]\n",
            "4842 [ D loss: 0.268039, acc.: 90%] [G loss: 4.404441]\n",
            "4843 [ D loss: 0.184383, acc.: 94%] [G loss: 4.900037]\n",
            "4844 [ D loss: 0.241461, acc.: 91%] [G loss: 5.775599]\n",
            "4845 [ D loss: 0.171936, acc.: 93%] [G loss: 5.745811]\n",
            "4846 [ D loss: 0.141572, acc.: 95%] [G loss: 5.897420]\n",
            "4847 [ D loss: 0.160713, acc.: 95%] [G loss: 5.800982]\n",
            "4848 [ D loss: 0.273422, acc.: 88%] [G loss: 4.057148]\n",
            "4849 [ D loss: 0.256461, acc.: 91%] [G loss: 4.805913]\n",
            "4850 [ D loss: 0.231348, acc.: 92%] [G loss: 4.712757]\n",
            "4851 [ D loss: 0.165797, acc.: 96%] [G loss: 4.495463]\n",
            "4852 [ D loss: 0.115116, acc.: 96%] [G loss: 6.566725]\n",
            "4853 [ D loss: 0.199948, acc.: 92%] [G loss: 13.726572]\n",
            "4854 [ D loss: 0.078681, acc.: 99%] [G loss: 6.223533]\n",
            "4855 [ D loss: 0.112162, acc.: 98%] [G loss: 5.803262]\n",
            "4856 [ D loss: 0.190624, acc.: 93%] [G loss: 7.019124]\n",
            "4857 [ D loss: 0.117550, acc.: 95%] [G loss: 5.336204]\n",
            "4858 [ D loss: 0.246098, acc.: 89%] [G loss: 6.102427]\n",
            "4859 [ D loss: 0.155131, acc.: 96%] [G loss: 5.087659]\n",
            "4860 [ D loss: 0.136840, acc.: 95%] [G loss: 4.090937]\n",
            "4861 [ D loss: 0.139845, acc.: 95%] [G loss: 4.741238]\n",
            "4862 [ D loss: 0.120097, acc.: 98%] [G loss: 5.539396]\n",
            "4863 [ D loss: 0.269841, acc.: 88%] [G loss: 5.788736]\n",
            "4864 [ D loss: 0.272227, acc.: 91%] [G loss: 4.752286]\n",
            "4865 [ D loss: 0.122050, acc.: 95%] [G loss: 5.807518]\n",
            "4866 [ D loss: 0.273318, acc.: 90%] [G loss: 4.008973]\n",
            "4867 [ D loss: 0.188782, acc.: 95%] [G loss: 4.703059]\n",
            "4868 [ D loss: 0.253939, acc.: 88%] [G loss: 4.300132]\n",
            "4869 [ D loss: 0.190017, acc.: 92%] [G loss: 4.398202]\n",
            "4870 [ D loss: 0.254040, acc.: 91%] [G loss: 3.972534]\n",
            "4871 [ D loss: 0.284625, acc.: 88%] [G loss: 5.648381]\n",
            "4872 [ D loss: 0.258648, acc.: 90%] [G loss: 4.390327]\n",
            "4873 [ D loss: 0.133097, acc.: 95%] [G loss: 4.619613]\n",
            "4874 [ D loss: 0.193861, acc.: 91%] [G loss: 6.107237]\n",
            "4875 [ D loss: 0.254845, acc.: 91%] [G loss: 4.310347]\n",
            "4876 [ D loss: 0.225675, acc.: 91%] [G loss: 5.157989]\n",
            "4877 [ D loss: 0.299489, acc.: 88%] [G loss: 6.765997]\n",
            "4878 [ D loss: 0.226850, acc.: 90%] [G loss: 4.184758]\n",
            "4879 [ D loss: 0.099009, acc.: 98%] [G loss: 7.972418]\n",
            "4880 [ D loss: 0.149312, acc.: 98%] [G loss: 4.507016]\n",
            "4881 [ D loss: 0.206286, acc.: 94%] [G loss: 3.619887]\n",
            "4882 [ D loss: 0.139498, acc.: 95%] [G loss: 5.462855]\n",
            "4883 [ D loss: 0.219378, acc.: 91%] [G loss: 4.714958]\n",
            "4884 [ D loss: 0.186281, acc.: 93%] [G loss: 5.773351]\n",
            "4885 [ D loss: 0.135164, acc.: 93%] [G loss: 6.249395]\n",
            "4886 [ D loss: 0.123885, acc.: 96%] [G loss: 5.229104]\n",
            "4887 [ D loss: 0.184311, acc.: 95%] [G loss: 4.044664]\n",
            "4888 [ D loss: 0.203130, acc.: 96%] [G loss: 4.359749]\n",
            "4889 [ D loss: 0.261848, acc.: 91%] [G loss: 4.173731]\n",
            "4890 [ D loss: 0.281178, acc.: 90%] [G loss: 4.471790]\n",
            "4891 [ D loss: 0.204388, acc.: 93%] [G loss: 4.170003]\n",
            "4892 [ D loss: 0.251511, acc.: 89%] [G loss: 4.362650]\n",
            "4893 [ D loss: 0.174944, acc.: 93%] [G loss: 4.706831]\n",
            "4894 [ D loss: 0.338616, acc.: 84%] [G loss: 4.331587]\n",
            "4895 [ D loss: 0.139989, acc.: 95%] [G loss: 4.579743]\n",
            "4896 [ D loss: 0.223968, acc.: 95%] [G loss: 4.335680]\n",
            "4897 [ D loss: 0.230075, acc.: 89%] [G loss: 3.755751]\n",
            "4898 [ D loss: 0.280071, acc.: 89%] [G loss: 4.389548]\n",
            "4899 [ D loss: 0.070192, acc.: 99%] [G loss: 4.382370]\n",
            "4900 [ D loss: 0.218359, acc.: 92%] [G loss: 3.971830]\n",
            "4901 [ D loss: 0.197131, acc.: 95%] [G loss: 5.436837]\n",
            "4902 [ D loss: 0.197276, acc.: 93%] [G loss: 4.574163]\n",
            "4903 [ D loss: 0.176055, acc.: 94%] [G loss: 4.357731]\n",
            "4904 [ D loss: 0.243498, acc.: 92%] [G loss: 4.601115]\n",
            "4905 [ D loss: 0.129593, acc.: 97%] [G loss: 5.404992]\n",
            "4906 [ D loss: 0.173264, acc.: 94%] [G loss: 4.616879]\n",
            "4907 [ D loss: 0.151420, acc.: 94%] [G loss: 8.752594]\n",
            "4908 [ D loss: 0.175413, acc.: 95%] [G loss: 6.711520]\n",
            "4909 [ D loss: 0.185822, acc.: 92%] [G loss: 5.822715]\n",
            "4910 [ D loss: 0.091451, acc.: 96%] [G loss: 12.150566]\n",
            "4911 [ D loss: 0.139874, acc.: 92%] [G loss: 7.597837]\n",
            "4912 [ D loss: 0.141674, acc.: 95%] [G loss: 4.540128]\n",
            "4913 [ D loss: 0.143703, acc.: 94%] [G loss: 4.299038]\n",
            "4914 [ D loss: 0.182708, acc.: 92%] [G loss: 4.568063]\n",
            "4915 [ D loss: 0.216477, acc.: 92%] [G loss: 4.302925]\n",
            "4916 [ D loss: 0.188713, acc.: 93%] [G loss: 4.103804]\n",
            "4917 [ D loss: 0.066734, acc.: 98%] [G loss: 6.152861]\n",
            "4918 [ D loss: 0.221028, acc.: 92%] [G loss: 3.889726]\n",
            "4919 [ D loss: 0.222373, acc.: 91%] [G loss: 3.822483]\n",
            "4920 [ D loss: 0.233282, acc.: 92%] [G loss: 5.815620]\n",
            "4921 [ D loss: 0.155929, acc.: 97%] [G loss: 4.099155]\n",
            "4922 [ D loss: 0.136087, acc.: 96%] [G loss: 7.561557]\n",
            "4923 [ D loss: 0.224971, acc.: 91%] [G loss: 4.150394]\n",
            "4924 [ D loss: 0.156240, acc.: 95%] [G loss: 5.820445]\n",
            "4925 [ D loss: 0.206759, acc.: 92%] [G loss: 5.072671]\n",
            "4926 [ D loss: 0.137892, acc.: 96%] [G loss: 3.860506]\n",
            "4927 [ D loss: 0.154441, acc.: 95%] [G loss: 6.297252]\n",
            "4928 [ D loss: 0.107004, acc.: 98%] [G loss: 5.152649]\n",
            "4929 [ D loss: 0.127479, acc.: 97%] [G loss: 6.937061]\n",
            "4930 [ D loss: 0.186656, acc.: 92%] [G loss: 6.542967]\n",
            "4931 [ D loss: 0.175554, acc.: 97%] [G loss: 5.023992]\n",
            "4932 [ D loss: 0.172853, acc.: 93%] [G loss: 7.151176]\n",
            "4933 [ D loss: 0.104215, acc.: 96%] [G loss: 5.661864]\n",
            "4934 [ D loss: 0.174769, acc.: 96%] [G loss: 4.701939]\n",
            "4935 [ D loss: 0.263076, acc.: 87%] [G loss: 5.260581]\n",
            "4936 [ D loss: 0.168107, acc.: 95%] [G loss: 5.887317]\n",
            "4937 [ D loss: 0.093633, acc.: 98%] [G loss: 5.250010]\n",
            "4938 [ D loss: 0.192374, acc.: 95%] [G loss: 4.275026]\n",
            "4939 [ D loss: 0.132549, acc.: 96%] [G loss: 4.738022]\n",
            "4940 [ D loss: 0.158427, acc.: 95%] [G loss: 5.199829]\n",
            "4941 [ D loss: 0.171919, acc.: 94%] [G loss: 5.739915]\n",
            "4942 [ D loss: 0.160710, acc.: 94%] [G loss: 4.778516]\n",
            "4943 [ D loss: 0.280434, acc.: 86%] [G loss: 3.876450]\n",
            "4944 [ D loss: 0.148158, acc.: 95%] [G loss: 5.335402]\n",
            "4945 [ D loss: 0.121805, acc.: 95%] [G loss: 4.553634]\n",
            "4946 [ D loss: 0.214075, acc.: 91%] [G loss: 4.531910]\n",
            "4947 [ D loss: 0.166305, acc.: 95%] [G loss: 7.294190]\n",
            "4948 [ D loss: 0.158236, acc.: 94%] [G loss: 8.178372]\n",
            "4949 [ D loss: 0.148220, acc.: 97%] [G loss: 5.165053]\n",
            "4950 [ D loss: 0.123093, acc.: 97%] [G loss: 5.431321]\n",
            "4951 [ D loss: 0.232056, acc.: 92%] [G loss: 6.872134]\n",
            "4952 [ D loss: 0.117399, acc.: 96%] [G loss: 7.194672]\n",
            "4953 [ D loss: 0.111122, acc.: 98%] [G loss: 7.191546]\n",
            "4954 [ D loss: 0.228073, acc.: 93%] [G loss: 7.982000]\n",
            "4955 [ D loss: 0.151555, acc.: 95%] [G loss: 5.877866]\n",
            "4956 [ D loss: 0.111530, acc.: 97%] [G loss: 5.584567]\n",
            "4957 [ D loss: 0.090747, acc.: 97%] [G loss: 5.853353]\n",
            "4958 [ D loss: 0.160544, acc.: 91%] [G loss: 6.644999]\n",
            "4959 [ D loss: 0.197194, acc.: 95%] [G loss: 5.656865]\n",
            "4960 [ D loss: 0.184543, acc.: 94%] [G loss: 4.208433]\n",
            "4961 [ D loss: 0.185529, acc.: 94%] [G loss: 5.326586]\n",
            "4962 [ D loss: 0.146045, acc.: 95%] [G loss: 3.759391]\n",
            "4963 [ D loss: 0.135244, acc.: 98%] [G loss: 6.114634]\n",
            "4964 [ D loss: 0.091916, acc.: 97%] [G loss: 6.131406]\n",
            "4965 [ D loss: 0.140892, acc.: 95%] [G loss: 6.420467]\n",
            "4966 [ D loss: 0.229212, acc.: 90%] [G loss: 6.787190]\n",
            "4967 [ D loss: 0.095023, acc.: 97%] [G loss: 9.342207]\n",
            "4968 [ D loss: 0.281081, acc.: 89%] [G loss: 4.913040]\n",
            "4969 [ D loss: 0.155404, acc.: 95%] [G loss: 5.127142]\n",
            "4970 [ D loss: 0.231749, acc.: 91%] [G loss: 5.599346]\n",
            "4971 [ D loss: 0.112935, acc.: 95%] [G loss: 5.234245]\n",
            "4972 [ D loss: 0.238144, acc.: 91%] [G loss: 5.166884]\n",
            "4973 [ D loss: 0.215127, acc.: 93%] [G loss: 4.562108]\n",
            "4974 [ D loss: 0.289298, acc.: 88%] [G loss: 4.909223]\n",
            "4975 [ D loss: 0.189204, acc.: 96%] [G loss: 4.600442]\n",
            "4976 [ D loss: 0.215895, acc.: 95%] [G loss: 6.947461]\n",
            "4977 [ D loss: 0.156791, acc.: 93%] [G loss: 6.241011]\n",
            "4978 [ D loss: 0.219534, acc.: 91%] [G loss: 4.765514]\n",
            "4979 [ D loss: 0.176475, acc.: 92%] [G loss: 6.446605]\n",
            "4980 [ D loss: 0.081700, acc.: 98%] [G loss: 4.551339]\n",
            "4981 [ D loss: 0.171216, acc.: 93%] [G loss: 5.019036]\n",
            "4982 [ D loss: 0.158017, acc.: 97%] [G loss: 5.012882]\n",
            "4983 [ D loss: 0.160798, acc.: 95%] [G loss: 6.713211]\n",
            "4984 [ D loss: 0.188916, acc.: 92%] [G loss: 5.561542]\n",
            "4985 [ D loss: 0.145122, acc.: 96%] [G loss: 4.215647]\n",
            "4986 [ D loss: 0.144227, acc.: 98%] [G loss: 5.892702]\n",
            "4987 [ D loss: 0.133805, acc.: 96%] [G loss: 4.575607]\n",
            "4988 [ D loss: 0.203519, acc.: 89%] [G loss: 5.296503]\n",
            "4989 [ D loss: 0.202480, acc.: 90%] [G loss: 4.345023]\n",
            "4990 [ D loss: 0.086349, acc.: 99%] [G loss: 4.372252]\n",
            "4991 [ D loss: 0.178138, acc.: 96%] [G loss: 4.410848]\n",
            "4992 [ D loss: 0.187135, acc.: 96%] [G loss: 3.605568]\n",
            "4993 [ D loss: 0.115068, acc.: 96%] [G loss: 4.430910]\n",
            "4994 [ D loss: 0.144227, acc.: 95%] [G loss: 4.742642]\n",
            "4995 [ D loss: 0.242098, acc.: 92%] [G loss: 5.180969]\n",
            "4996 [ D loss: 0.208949, acc.: 92%] [G loss: 4.461411]\n",
            "4997 [ D loss: 0.160256, acc.: 98%] [G loss: 5.024476]\n",
            "4998 [ D loss: 0.138913, acc.: 97%] [G loss: 4.531438]\n",
            "4999 [ D loss: 0.223142, acc.: 89%] [G loss: 5.427886]\n",
            "5000 [ D loss: 0.239948, acc.: 88%] [G loss: 5.071418]\n",
            "5001 [ D loss: 0.145079, acc.: 95%] [G loss: 4.584356]\n",
            "5002 [ D loss: 0.127446, acc.: 96%] [G loss: 3.924407]\n",
            "5003 [ D loss: 0.192348, acc.: 94%] [G loss: 5.350563]\n",
            "5004 [ D loss: 0.106008, acc.: 98%] [G loss: 4.817918]\n",
            "5005 [ D loss: 0.267287, acc.: 93%] [G loss: 5.136122]\n",
            "5006 [ D loss: 0.290766, acc.: 90%] [G loss: 5.250892]\n",
            "5007 [ D loss: 0.135289, acc.: 95%] [G loss: 3.854762]\n",
            "5008 [ D loss: 0.146933, acc.: 95%] [G loss: 3.731609]\n",
            "5009 [ D loss: 0.175594, acc.: 95%] [G loss: 4.310584]\n",
            "5010 [ D loss: 0.165177, acc.: 94%] [G loss: 5.414136]\n",
            "5011 [ D loss: 0.212290, acc.: 92%] [G loss: 4.484920]\n",
            "5012 [ D loss: 0.144677, acc.: 95%] [G loss: 4.201369]\n",
            "5013 [ D loss: 0.204289, acc.: 92%] [G loss: 6.348680]\n",
            "5014 [ D loss: 0.189355, acc.: 91%] [G loss: 7.145285]\n",
            "5015 [ D loss: 0.098835, acc.: 98%] [G loss: 4.166386]\n",
            "5016 [ D loss: 0.220701, acc.: 89%] [G loss: 4.476539]\n",
            "5017 [ D loss: 0.131235, acc.: 95%] [G loss: 3.558810]\n",
            "5018 [ D loss: 0.106826, acc.: 97%] [G loss: 4.795349]\n",
            "5019 [ D loss: 0.163656, acc.: 95%] [G loss: 6.118439]\n",
            "5020 [ D loss: 0.303048, acc.: 87%] [G loss: 6.434489]\n",
            "5021 [ D loss: 0.143709, acc.: 92%] [G loss: 4.839477]\n",
            "5022 [ D loss: 0.110894, acc.: 97%] [G loss: 7.970517]\n",
            "5023 [ D loss: 0.280620, acc.: 87%] [G loss: 3.664948]\n",
            "5024 [ D loss: 0.154816, acc.: 96%] [G loss: 6.369925]\n",
            "5025 [ D loss: 0.206284, acc.: 91%] [G loss: 4.103545]\n",
            "5026 [ D loss: 0.085600, acc.: 98%] [G loss: 3.885925]\n",
            "5027 [ D loss: 0.145862, acc.: 95%] [G loss: 7.567694]\n",
            "5028 [ D loss: 0.153593, acc.: 95%] [G loss: 4.852833]\n",
            "5029 [ D loss: 0.122181, acc.: 97%] [G loss: 6.167301]\n",
            "5030 [ D loss: 0.196787, acc.: 91%] [G loss: 5.432152]\n",
            "5031 [ D loss: 0.130186, acc.: 98%] [G loss: 6.590668]\n",
            "5032 [ D loss: 0.158818, acc.: 95%] [G loss: 4.791836]\n",
            "5033 [ D loss: 0.157769, acc.: 95%] [G loss: 5.280298]\n",
            "5034 [ D loss: 0.229692, acc.: 89%] [G loss: 4.465564]\n",
            "5035 [ D loss: 0.145888, acc.: 96%] [G loss: 5.724163]\n",
            "5036 [ D loss: 0.156719, acc.: 94%] [G loss: 6.213481]\n",
            "5037 [ D loss: 0.167196, acc.: 95%] [G loss: 6.046866]\n",
            "5038 [ D loss: 0.138867, acc.: 95%] [G loss: 4.537000]\n",
            "5039 [ D loss: 0.180755, acc.: 95%] [G loss: 4.842121]\n",
            "5040 [ D loss: 0.189280, acc.: 93%] [G loss: 5.629117]\n",
            "5041 [ D loss: 0.134814, acc.: 97%] [G loss: 5.610291]\n",
            "5042 [ D loss: 0.117817, acc.: 97%] [G loss: 4.607465]\n",
            "5043 [ D loss: 0.159623, acc.: 95%] [G loss: 5.647568]\n",
            "5044 [ D loss: 0.152922, acc.: 93%] [G loss: 5.592957]\n",
            "5045 [ D loss: 0.162763, acc.: 95%] [G loss: 6.583247]\n",
            "5046 [ D loss: 0.106947, acc.: 98%] [G loss: 5.232879]\n",
            "5047 [ D loss: 0.175270, acc.: 94%] [G loss: 4.898287]\n",
            "5048 [ D loss: 0.134597, acc.: 96%] [G loss: 5.446332]\n",
            "5049 [ D loss: 0.097785, acc.: 97%] [G loss: 7.939723]\n",
            "5050 [ D loss: 0.219570, acc.: 92%] [G loss: 9.114723]\n",
            "5051 [ D loss: 0.100060, acc.: 98%] [G loss: 7.070339]\n",
            "5052 [ D loss: 0.095901, acc.: 98%] [G loss: 4.466743]\n",
            "5053 [ D loss: 0.108903, acc.: 98%] [G loss: 5.788871]\n",
            "5054 [ D loss: 0.140329, acc.: 94%] [G loss: 7.517807]\n",
            "5055 [ D loss: 0.182361, acc.: 92%] [G loss: 5.028129]\n",
            "5056 [ D loss: 0.104825, acc.: 95%] [G loss: 5.486902]\n",
            "5057 [ D loss: 0.227284, acc.: 91%] [G loss: 4.089010]\n",
            "5058 [ D loss: 0.167684, acc.: 94%] [G loss: 4.821729]\n",
            "5059 [ D loss: 0.220842, acc.: 91%] [G loss: 4.134911]\n",
            "5060 [ D loss: 0.209694, acc.: 94%] [G loss: 3.740511]\n",
            "5061 [ D loss: 0.121302, acc.: 97%] [G loss: 3.976885]\n",
            "5062 [ D loss: 0.168468, acc.: 93%] [G loss: 4.781666]\n",
            "5063 [ D loss: 0.183982, acc.: 94%] [G loss: 3.315684]\n",
            "5064 [ D loss: 0.255970, acc.: 94%] [G loss: 4.699535]\n",
            "5065 [ D loss: 0.246415, acc.: 91%] [G loss: 4.737314]\n",
            "5066 [ D loss: 0.167262, acc.: 94%] [G loss: 6.131616]\n",
            "5067 [ D loss: 0.202906, acc.: 94%] [G loss: 5.990937]\n",
            "5068 [ D loss: 0.162399, acc.: 98%] [G loss: 5.674437]\n",
            "5069 [ D loss: 0.128838, acc.: 94%] [G loss: 7.163522]\n",
            "5070 [ D loss: 0.132522, acc.: 92%] [G loss: 5.495603]\n",
            "5071 [ D loss: 0.170063, acc.: 93%] [G loss: 6.962873]\n",
            "5072 [ D loss: 0.115081, acc.: 95%] [G loss: 5.778920]\n",
            "5073 [ D loss: 0.236493, acc.: 87%] [G loss: 5.023834]\n",
            "5074 [ D loss: 0.117858, acc.: 96%] [G loss: 6.779120]\n",
            "5075 [ D loss: 0.068057, acc.: 98%] [G loss: 5.125265]\n",
            "5076 [ D loss: 0.210236, acc.: 93%] [G loss: 5.741666]\n",
            "5077 [ D loss: 0.134081, acc.: 95%] [G loss: 4.554672]\n",
            "5078 [ D loss: 0.126956, acc.: 95%] [G loss: 5.135921]\n",
            "5079 [ D loss: 0.251873, acc.: 88%] [G loss: 5.248283]\n",
            "5080 [ D loss: 0.133731, acc.: 95%] [G loss: 4.567445]\n",
            "5081 [ D loss: 0.159322, acc.: 96%] [G loss: 4.573033]\n",
            "5082 [ D loss: 0.105781, acc.: 96%] [G loss: 4.565828]\n",
            "5083 [ D loss: 0.157530, acc.: 94%] [G loss: 4.039803]\n",
            "5084 [ D loss: 0.201537, acc.: 91%] [G loss: 4.390851]\n",
            "5085 [ D loss: 0.187297, acc.: 94%] [G loss: 3.988706]\n",
            "5086 [ D loss: 0.133992, acc.: 93%] [G loss: 5.490396]\n",
            "5087 [ D loss: 0.143528, acc.: 94%] [G loss: 7.576908]\n",
            "5088 [ D loss: 0.093044, acc.: 96%] [G loss: 6.354903]\n",
            "5089 [ D loss: 0.125831, acc.: 95%] [G loss: 7.649933]\n",
            "5090 [ D loss: 0.108249, acc.: 97%] [G loss: 6.228003]\n",
            "5091 [ D loss: 0.171847, acc.: 94%] [G loss: 4.779912]\n",
            "5092 [ D loss: 0.104725, acc.: 98%] [G loss: 5.255538]\n",
            "5093 [ D loss: 0.204677, acc.: 90%] [G loss: 5.052165]\n",
            "5094 [ D loss: 0.122319, acc.: 96%] [G loss: 6.732485]\n",
            "5095 [ D loss: 0.069547, acc.: 98%] [G loss: 4.963252]\n",
            "5096 [ D loss: 0.129729, acc.: 96%] [G loss: 5.783301]\n",
            "5097 [ D loss: 0.113362, acc.: 98%] [G loss: 4.853878]\n",
            "5098 [ D loss: 0.156351, acc.: 95%] [G loss: 5.813126]\n",
            "5099 [ D loss: 0.145374, acc.: 96%] [G loss: 9.981867]\n",
            "5100 [ D loss: 0.117920, acc.: 97%] [G loss: 6.120039]\n",
            "5101 [ D loss: 0.091074, acc.: 98%] [G loss: 4.689499]\n",
            "5102 [ D loss: 0.175593, acc.: 95%] [G loss: 3.944307]\n",
            "5103 [ D loss: 0.244756, acc.: 91%] [G loss: 3.392571]\n",
            "5104 [ D loss: 0.130847, acc.: 94%] [G loss: 3.379427]\n",
            "5105 [ D loss: 0.261103, acc.: 89%] [G loss: 5.150143]\n",
            "5106 [ D loss: 0.182162, acc.: 94%] [G loss: 4.142236]\n",
            "5107 [ D loss: 0.149591, acc.: 98%] [G loss: 3.860556]\n",
            "5108 [ D loss: 0.132607, acc.: 97%] [G loss: 3.846804]\n",
            "5109 [ D loss: 0.176679, acc.: 95%] [G loss: 3.441250]\n",
            "5110 [ D loss: 0.197014, acc.: 93%] [G loss: 3.803148]\n",
            "5111 [ D loss: 0.189313, acc.: 94%] [G loss: 4.090801]\n",
            "5112 [ D loss: 0.175722, acc.: 95%] [G loss: 5.326684]\n",
            "5113 [ D loss: 0.292180, acc.: 87%] [G loss: 3.498934]\n",
            "5114 [ D loss: 0.114741, acc.: 96%] [G loss: 4.576125]\n",
            "5115 [ D loss: 0.193111, acc.: 92%] [G loss: 3.814451]\n",
            "5116 [ D loss: 0.259419, acc.: 89%] [G loss: 4.357133]\n",
            "5117 [ D loss: 0.182261, acc.: 95%] [G loss: 4.530193]\n",
            "5118 [ D loss: 0.200099, acc.: 92%] [G loss: 3.998281]\n",
            "5119 [ D loss: 0.153403, acc.: 95%] [G loss: 4.177409]\n",
            "5120 [ D loss: 0.151947, acc.: 95%] [G loss: 4.892998]\n",
            "5121 [ D loss: 0.155265, acc.: 95%] [G loss: 4.013651]\n",
            "5122 [ D loss: 0.146605, acc.: 95%] [G loss: 6.106418]\n",
            "5123 [ D loss: 0.176297, acc.: 91%] [G loss: 4.365969]\n",
            "5124 [ D loss: 0.162013, acc.: 92%] [G loss: 4.049651]\n",
            "5125 [ D loss: 0.247455, acc.: 94%] [G loss: 4.116860]\n",
            "5126 [ D loss: 0.104592, acc.: 96%] [G loss: 5.079301]\n",
            "5127 [ D loss: 0.123201, acc.: 95%] [G loss: 7.293432]\n",
            "5128 [ D loss: 0.122057, acc.: 94%] [G loss: 6.618322]\n",
            "5129 [ D loss: 0.121184, acc.: 94%] [G loss: 5.676350]\n",
            "5130 [ D loss: 0.117793, acc.: 96%] [G loss: 4.948769]\n",
            "5131 [ D loss: 0.216586, acc.: 91%] [G loss: 6.202506]\n",
            "5132 [ D loss: 0.151707, acc.: 92%] [G loss: 6.524387]\n",
            "5133 [ D loss: 0.151902, acc.: 95%] [G loss: 5.333665]\n",
            "5134 [ D loss: 0.182732, acc.: 93%] [G loss: 4.906696]\n",
            "5135 [ D loss: 0.078823, acc.: 97%] [G loss: 5.546263]\n",
            "5136 [ D loss: 0.150457, acc.: 94%] [G loss: 6.049048]\n",
            "5137 [ D loss: 0.137096, acc.: 95%] [G loss: 5.045110]\n",
            "5138 [ D loss: 0.148369, acc.: 95%] [G loss: 4.792915]\n",
            "5139 [ D loss: 0.145834, acc.: 96%] [G loss: 5.061938]\n",
            "5140 [ D loss: 0.144546, acc.: 98%] [G loss: 4.201920]\n",
            "5141 [ D loss: 0.194661, acc.: 93%] [G loss: 4.654925]\n",
            "5142 [ D loss: 0.146693, acc.: 94%] [G loss: 4.692965]\n",
            "5143 [ D loss: 0.150040, acc.: 96%] [G loss: 4.041808]\n",
            "5144 [ D loss: 0.207315, acc.: 91%] [G loss: 3.763527]\n",
            "5145 [ D loss: 0.199758, acc.: 93%] [G loss: 6.291934]\n",
            "5146 [ D loss: 0.201224, acc.: 90%] [G loss: 4.400411]\n",
            "5147 [ D loss: 0.222754, acc.: 91%] [G loss: 6.616510]\n",
            "5148 [ D loss: 0.246249, acc.: 92%] [G loss: 8.070559]\n",
            "5149 [ D loss: 0.093153, acc.: 97%] [G loss: 5.333697]\n",
            "5150 [ D loss: 0.127318, acc.: 95%] [G loss: 7.777864]\n",
            "5151 [ D loss: 0.073031, acc.: 97%] [G loss: 7.115577]\n",
            "5152 [ D loss: 0.057180, acc.: 99%] [G loss: 7.455523]\n",
            "5153 [ D loss: 0.160962, acc.: 95%] [G loss: 12.139486]\n",
            "5154 [ D loss: 0.095125, acc.: 98%] [G loss: 9.410929]\n",
            "5155 [ D loss: 0.126588, acc.: 95%] [G loss: 10.486672]\n",
            "5156 [ D loss: 0.182327, acc.: 91%] [G loss: 5.441854]\n",
            "5157 [ D loss: 0.109170, acc.: 95%] [G loss: 5.537322]\n",
            "5158 [ D loss: 0.139160, acc.: 94%] [G loss: 4.896173]\n",
            "5159 [ D loss: 0.108757, acc.: 96%] [G loss: 7.395224]\n",
            "5160 [ D loss: 0.124647, acc.: 96%] [G loss: 6.055760]\n",
            "5161 [ D loss: 0.117142, acc.: 95%] [G loss: 6.193411]\n",
            "5162 [ D loss: 0.194016, acc.: 91%] [G loss: 5.990847]\n",
            "5163 [ D loss: 0.121340, acc.: 96%] [G loss: 6.023690]\n",
            "5164 [ D loss: 0.159864, acc.: 95%] [G loss: 4.492471]\n",
            "5165 [ D loss: 0.336686, acc.: 88%] [G loss: 4.051850]\n",
            "5166 [ D loss: 0.110561, acc.: 96%] [G loss: 4.606183]\n",
            "5167 [ D loss: 0.162820, acc.: 95%] [G loss: 4.432714]\n",
            "5168 [ D loss: 0.140589, acc.: 95%] [G loss: 4.697659]\n",
            "5169 [ D loss: 0.218798, acc.: 91%] [G loss: 7.258532]\n",
            "5170 [ D loss: 0.089904, acc.: 97%] [G loss: 5.425826]\n",
            "5171 [ D loss: 0.127934, acc.: 95%] [G loss: 10.556766]\n",
            "5172 [ D loss: 0.131586, acc.: 96%] [G loss: 6.265532]\n",
            "5173 [ D loss: 0.229594, acc.: 92%] [G loss: 6.202138]\n",
            "5174 [ D loss: 0.212743, acc.: 91%] [G loss: 7.056719]\n",
            "5175 [ D loss: 0.146673, acc.: 94%] [G loss: 10.663950]\n",
            "5176 [ D loss: 0.108496, acc.: 96%] [G loss: 4.777246]\n",
            "5177 [ D loss: 0.162080, acc.: 93%] [G loss: 5.718602]\n",
            "5178 [ D loss: 0.150458, acc.: 96%] [G loss: 5.460657]\n",
            "5179 [ D loss: 0.115457, acc.: 98%] [G loss: 3.981022]\n",
            "5180 [ D loss: 0.105547, acc.: 98%] [G loss: 4.101634]\n",
            "5181 [ D loss: 0.162120, acc.: 94%] [G loss: 4.737051]\n",
            "5182 [ D loss: 0.216338, acc.: 94%] [G loss: 4.038766]\n",
            "5183 [ D loss: 0.166747, acc.: 95%] [G loss: 4.184318]\n",
            "5184 [ D loss: 0.196851, acc.: 95%] [G loss: 4.191000]\n",
            "5185 [ D loss: 0.118843, acc.: 98%] [G loss: 4.383722]\n",
            "5186 [ D loss: 0.220874, acc.: 91%] [G loss: 5.914652]\n",
            "5187 [ D loss: 0.107503, acc.: 98%] [G loss: 4.410928]\n",
            "5188 [ D loss: 0.157846, acc.: 95%] [G loss: 6.768109]\n",
            "5189 [ D loss: 0.116466, acc.: 95%] [G loss: 4.928399]\n",
            "5190 [ D loss: 0.110120, acc.: 97%] [G loss: 5.197924]\n",
            "5191 [ D loss: 0.233621, acc.: 93%] [G loss: 4.102704]\n",
            "5192 [ D loss: 0.203914, acc.: 91%] [G loss: 4.776343]\n",
            "5193 [ D loss: 0.147135, acc.: 95%] [G loss: 4.457441]\n",
            "5194 [ D loss: 0.209324, acc.: 94%] [G loss: 5.793782]\n",
            "5195 [ D loss: 0.211258, acc.: 90%] [G loss: 4.441312]\n",
            "5196 [ D loss: 0.074252, acc.: 99%] [G loss: 5.601979]\n",
            "5197 [ D loss: 0.145213, acc.: 96%] [G loss: 8.335546]\n",
            "5198 [ D loss: 0.075250, acc.: 98%] [G loss: 7.380343]\n",
            "5199 [ D loss: 0.194607, acc.: 91%] [G loss: 6.103393]\n",
            "5200 [ D loss: 0.152590, acc.: 95%] [G loss: 6.620466]\n",
            "5201 [ D loss: 0.054000, acc.: 100%] [G loss: 9.383325]\n",
            "5202 [ D loss: 0.050152, acc.: 100%] [G loss: 9.318640]\n",
            "5203 [ D loss: 0.065469, acc.: 98%] [G loss: 13.049837]\n",
            "5204 [ D loss: 0.124612, acc.: 94%] [G loss: 10.131752]\n",
            "5205 [ D loss: 0.085491, acc.: 99%] [G loss: 7.372075]\n",
            "5206 [ D loss: 0.099086, acc.: 96%] [G loss: 3.643930]\n",
            "5207 [ D loss: 0.129384, acc.: 95%] [G loss: 3.839439]\n",
            "5208 [ D loss: 0.181834, acc.: 92%] [G loss: 4.830501]\n",
            "5209 [ D loss: 0.152123, acc.: 96%] [G loss: 4.297253]\n",
            "5210 [ D loss: 0.293893, acc.: 87%] [G loss: 4.162122]\n",
            "5211 [ D loss: 0.242170, acc.: 91%] [G loss: 4.260867]\n",
            "5212 [ D loss: 0.157853, acc.: 94%] [G loss: 5.310935]\n",
            "5213 [ D loss: 0.153612, acc.: 96%] [G loss: 4.036373]\n",
            "5214 [ D loss: 0.279382, acc.: 88%] [G loss: 4.510425]\n",
            "5215 [ D loss: 0.118756, acc.: 98%] [G loss: 4.955399]\n",
            "5216 [ D loss: 0.119192, acc.: 96%] [G loss: 3.077286]\n",
            "5217 [ D loss: 0.156890, acc.: 97%] [G loss: 5.317248]\n",
            "5218 [ D loss: 0.124357, acc.: 96%] [G loss: 5.132659]\n",
            "5219 [ D loss: 0.168614, acc.: 95%] [G loss: 4.576432]\n",
            "5220 [ D loss: 0.178771, acc.: 97%] [G loss: 5.485332]\n",
            "5221 [ D loss: 0.119165, acc.: 97%] [G loss: 3.836424]\n",
            "5222 [ D loss: 0.164094, acc.: 94%] [G loss: 6.932560]\n",
            "5223 [ D loss: 0.124299, acc.: 94%] [G loss: 7.426410]\n",
            "5224 [ D loss: 0.151261, acc.: 95%] [G loss: 5.930905]\n",
            "5225 [ D loss: 0.218315, acc.: 92%] [G loss: 5.965977]\n",
            "5226 [ D loss: 0.197640, acc.: 93%] [G loss: 4.406301]\n",
            "5227 [ D loss: 0.160767, acc.: 94%] [G loss: 5.454362]\n",
            "5228 [ D loss: 0.091376, acc.: 98%] [G loss: 5.560317]\n",
            "5229 [ D loss: 0.216717, acc.: 91%] [G loss: 5.517366]\n",
            "5230 [ D loss: 0.143117, acc.: 94%] [G loss: 5.812037]\n",
            "5231 [ D loss: 0.159673, acc.: 95%] [G loss: 6.967437]\n",
            "5232 [ D loss: 0.132887, acc.: 95%] [G loss: 6.554431]\n",
            "5233 [ D loss: 0.093276, acc.: 98%] [G loss: 4.970372]\n",
            "5234 [ D loss: 0.238508, acc.: 89%] [G loss: 3.879261]\n",
            "5235 [ D loss: 0.160204, acc.: 95%] [G loss: 5.396732]\n",
            "5236 [ D loss: 0.254572, acc.: 91%] [G loss: 4.527422]\n",
            "5237 [ D loss: 0.238884, acc.: 91%] [G loss: 5.046824]\n",
            "5238 [ D loss: 0.155256, acc.: 95%] [G loss: 4.584731]\n",
            "5239 [ D loss: 0.192761, acc.: 91%] [G loss: 4.910303]\n",
            "5240 [ D loss: 0.164141, acc.: 95%] [G loss: 6.045634]\n",
            "5241 [ D loss: 0.213421, acc.: 89%] [G loss: 5.470293]\n",
            "5242 [ D loss: 0.093199, acc.: 98%] [G loss: 4.307736]\n",
            "5243 [ D loss: 0.172150, acc.: 93%] [G loss: 4.869283]\n",
            "5244 [ D loss: 0.142441, acc.: 96%] [G loss: 5.821384]\n",
            "5245 [ D loss: 0.150190, acc.: 95%] [G loss: 4.363775]\n",
            "5246 [ D loss: 0.239753, acc.: 90%] [G loss: 4.417052]\n",
            "5247 [ D loss: 0.184339, acc.: 95%] [G loss: 4.866377]\n",
            "5248 [ D loss: 0.146452, acc.: 95%] [G loss: 8.683958]\n",
            "5249 [ D loss: 0.181727, acc.: 91%] [G loss: 6.346795]\n",
            "5250 [ D loss: 0.111498, acc.: 97%] [G loss: 6.186576]\n",
            "5251 [ D loss: 0.107657, acc.: 97%] [G loss: 5.001415]\n",
            "5252 [ D loss: 0.182437, acc.: 95%] [G loss: 4.903385]\n",
            "5253 [ D loss: 0.150870, acc.: 95%] [G loss: 4.517164]\n",
            "5254 [ D loss: 0.096078, acc.: 98%] [G loss: 4.119392]\n",
            "5255 [ D loss: 0.234792, acc.: 92%] [G loss: 5.918679]\n",
            "5256 [ D loss: 0.141444, acc.: 94%] [G loss: 4.091734]\n",
            "5257 [ D loss: 0.140463, acc.: 95%] [G loss: 4.086561]\n",
            "5258 [ D loss: 0.110755, acc.: 97%] [G loss: 4.845515]\n",
            "5259 [ D loss: 0.270084, acc.: 86%] [G loss: 6.286733]\n",
            "5260 [ D loss: 0.151551, acc.: 94%] [G loss: 5.891721]\n",
            "5261 [ D loss: 0.173944, acc.: 92%] [G loss: 7.169345]\n",
            "5262 [ D loss: 0.161848, acc.: 91%] [G loss: 5.846580]\n",
            "5263 [ D loss: 0.122656, acc.: 95%] [G loss: 6.320501]\n",
            "5264 [ D loss: 0.173597, acc.: 95%] [G loss: 8.736811]\n",
            "5265 [ D loss: 0.096396, acc.: 98%] [G loss: 7.869713]\n",
            "5266 [ D loss: 0.088247, acc.: 99%] [G loss: 10.282592]\n",
            "5267 [ D loss: 0.098914, acc.: 96%] [G loss: 10.096620]\n",
            "5268 [ D loss: 0.176790, acc.: 94%] [G loss: 4.597362]\n",
            "5269 [ D loss: 0.313730, acc.: 87%] [G loss: 4.843094]\n",
            "5270 [ D loss: 0.196206, acc.: 93%] [G loss: 5.543214]\n",
            "5271 [ D loss: 0.127517, acc.: 96%] [G loss: 7.077252]\n",
            "5272 [ D loss: 0.135492, acc.: 95%] [G loss: 10.812165]\n",
            "5273 [ D loss: 0.106959, acc.: 95%] [G loss: 6.643086]\n",
            "5274 [ D loss: 0.096533, acc.: 96%] [G loss: 6.198007]\n",
            "5275 [ D loss: 0.142175, acc.: 95%] [G loss: 7.301166]\n",
            "5276 [ D loss: 0.141506, acc.: 96%] [G loss: 5.565268]\n",
            "5277 [ D loss: 0.174191, acc.: 93%] [G loss: 4.016657]\n",
            "5278 [ D loss: 0.132819, acc.: 95%] [G loss: 5.339020]\n",
            "5279 [ D loss: 0.170939, acc.: 97%] [G loss: 5.679815]\n",
            "5280 [ D loss: 0.081504, acc.: 97%] [G loss: 5.712500]\n",
            "5281 [ D loss: 0.132958, acc.: 96%] [G loss: 5.356932]\n",
            "5282 [ D loss: 0.161906, acc.: 95%] [G loss: 4.101239]\n",
            "5283 [ D loss: 0.263536, acc.: 94%] [G loss: 5.147282]\n",
            "5284 [ D loss: 0.166143, acc.: 93%] [G loss: 4.325502]\n",
            "5285 [ D loss: 0.218914, acc.: 93%] [G loss: 3.810766]\n",
            "5286 [ D loss: 0.208770, acc.: 93%] [G loss: 4.912103]\n",
            "5287 [ D loss: 0.194296, acc.: 91%] [G loss: 5.066519]\n",
            "5288 [ D loss: 0.190231, acc.: 92%] [G loss: 4.803479]\n",
            "5289 [ D loss: 0.308924, acc.: 83%] [G loss: 5.019923]\n",
            "5290 [ D loss: 0.275411, acc.: 89%] [G loss: 5.137572]\n",
            "5291 [ D loss: 0.259812, acc.: 91%] [G loss: 4.200480]\n",
            "5292 [ D loss: 0.144234, acc.: 97%] [G loss: 5.204815]\n",
            "5293 [ D loss: 0.164133, acc.: 91%] [G loss: 7.293056]\n",
            "5294 [ D loss: 0.127585, acc.: 95%] [G loss: 9.683599]\n",
            "5295 [ D loss: 0.136427, acc.: 96%] [G loss: 5.548998]\n",
            "5296 [ D loss: 0.180733, acc.: 93%] [G loss: 4.455906]\n",
            "5297 [ D loss: 0.102518, acc.: 97%] [G loss: 5.470016]\n",
            "5298 [ D loss: 0.141818, acc.: 96%] [G loss: 4.515892]\n",
            "5299 [ D loss: 0.156135, acc.: 94%] [G loss: 5.549819]\n",
            "5300 [ D loss: 0.208904, acc.: 91%] [G loss: 4.757591]\n",
            "5301 [ D loss: 0.222869, acc.: 92%] [G loss: 5.870481]\n",
            "5302 [ D loss: 0.243960, acc.: 90%] [G loss: 4.486961]\n",
            "5303 [ D loss: 0.165654, acc.: 94%] [G loss: 8.881827]\n",
            "5304 [ D loss: 0.158302, acc.: 97%] [G loss: 5.512671]\n",
            "5305 [ D loss: 0.287448, acc.: 88%] [G loss: 6.691686]\n",
            "5306 [ D loss: 0.139641, acc.: 95%] [G loss: 7.119462]\n",
            "5307 [ D loss: 0.168787, acc.: 95%] [G loss: 5.259422]\n",
            "5308 [ D loss: 0.139831, acc.: 96%] [G loss: 8.202948]\n",
            "5309 [ D loss: 0.132527, acc.: 97%] [G loss: 7.400787]\n",
            "5310 [ D loss: 0.198021, acc.: 91%] [G loss: 3.632607]\n",
            "5311 [ D loss: 0.152172, acc.: 95%] [G loss: 4.906549]\n",
            "5312 [ D loss: 0.120754, acc.: 98%] [G loss: 5.055232]\n",
            "5313 [ D loss: 0.205797, acc.: 93%] [G loss: 4.418241]\n",
            "5314 [ D loss: 0.228186, acc.: 93%] [G loss: 4.617841]\n",
            "5315 [ D loss: 0.171809, acc.: 95%] [G loss: 4.099779]\n",
            "5316 [ D loss: 0.243015, acc.: 91%] [G loss: 4.490035]\n",
            "5317 [ D loss: 0.229175, acc.: 90%] [G loss: 4.027209]\n",
            "5318 [ D loss: 0.167019, acc.: 95%] [G loss: 4.399900]\n",
            "5319 [ D loss: 0.194406, acc.: 95%] [G loss: 4.355593]\n",
            "5320 [ D loss: 0.232909, acc.: 93%] [G loss: 4.820796]\n",
            "5321 [ D loss: 0.197189, acc.: 93%] [G loss: 4.628067]\n",
            "5322 [ D loss: 0.223336, acc.: 90%] [G loss: 3.721348]\n",
            "5323 [ D loss: 0.242644, acc.: 88%] [G loss: 6.377607]\n",
            "5324 [ D loss: 0.182438, acc.: 92%] [G loss: 4.968607]\n",
            "5325 [ D loss: 0.093406, acc.: 96%] [G loss: 6.288498]\n",
            "5326 [ D loss: 0.087354, acc.: 97%] [G loss: 5.871605]\n",
            "5327 [ D loss: 0.114403, acc.: 97%] [G loss: 8.351019]\n",
            "5328 [ D loss: 0.222662, acc.: 89%] [G loss: 5.986372]\n",
            "5329 [ D loss: 0.161880, acc.: 96%] [G loss: 7.630803]\n",
            "5330 [ D loss: 0.144226, acc.: 94%] [G loss: 5.546313]\n",
            "5331 [ D loss: 0.157444, acc.: 94%] [G loss: 11.907264]\n",
            "5332 [ D loss: 0.130829, acc.: 97%] [G loss: 11.751972]\n",
            "5333 [ D loss: 0.113785, acc.: 96%] [G loss: 8.973347]\n",
            "5334 [ D loss: 0.119045, acc.: 95%] [G loss: 8.808708]\n",
            "5335 [ D loss: 0.060044, acc.: 99%] [G loss: 7.774796]\n",
            "5336 [ D loss: 0.250692, acc.: 87%] [G loss: 5.043428]\n",
            "5337 [ D loss: 0.191229, acc.: 93%] [G loss: 4.940669]\n",
            "5338 [ D loss: 0.177553, acc.: 93%] [G loss: 7.538540]\n",
            "5339 [ D loss: 0.105708, acc.: 97%] [G loss: 8.703300]\n",
            "5340 [ D loss: 0.155198, acc.: 95%] [G loss: 5.317750]\n",
            "5341 [ D loss: 0.155871, acc.: 93%] [G loss: 10.317711]\n",
            "5342 [ D loss: 0.181318, acc.: 92%] [G loss: 6.101114]\n",
            "5343 [ D loss: 0.098317, acc.: 98%] [G loss: 4.315379]\n",
            "5344 [ D loss: 0.130362, acc.: 96%] [G loss: 5.805462]\n",
            "5345 [ D loss: 0.157481, acc.: 94%] [G loss: 6.107335]\n",
            "5346 [ D loss: 0.210996, acc.: 91%] [G loss: 4.602557]\n",
            "5347 [ D loss: 0.136282, acc.: 95%] [G loss: 9.678853]\n",
            "5348 [ D loss: 0.190146, acc.: 92%] [G loss: 5.275791]\n",
            "5349 [ D loss: 0.088603, acc.: 98%] [G loss: 5.994387]\n",
            "5350 [ D loss: 0.083665, acc.: 96%] [G loss: 6.341551]\n",
            "5351 [ D loss: 0.108055, acc.: 98%] [G loss: 4.637897]\n",
            "5352 [ D loss: 0.149801, acc.: 95%] [G loss: 4.673956]\n",
            "5353 [ D loss: 0.178791, acc.: 94%] [G loss: 4.819736]\n",
            "5354 [ D loss: 0.346444, acc.: 82%] [G loss: 5.840148]\n",
            "5355 [ D loss: 0.265647, acc.: 87%] [G loss: 4.584725]\n",
            "5356 [ D loss: 0.167482, acc.: 92%] [G loss: 5.815945]\n",
            "5357 [ D loss: 0.245411, acc.: 90%] [G loss: 3.908766]\n",
            "5358 [ D loss: 0.254107, acc.: 89%] [G loss: 4.712636]\n",
            "5359 [ D loss: 0.206719, acc.: 91%] [G loss: 4.463074]\n",
            "5360 [ D loss: 0.131873, acc.: 96%] [G loss: 5.451359]\n",
            "5361 [ D loss: 0.254951, acc.: 88%] [G loss: 4.363021]\n",
            "5362 [ D loss: 0.161040, acc.: 95%] [G loss: 5.414523]\n",
            "5363 [ D loss: 0.230532, acc.: 90%] [G loss: 5.120850]\n",
            "5364 [ D loss: 0.162684, acc.: 95%] [G loss: 3.906590]\n",
            "5365 [ D loss: 0.228546, acc.: 92%] [G loss: 4.735967]\n",
            "5366 [ D loss: 0.158597, acc.: 94%] [G loss: 5.428331]\n",
            "5367 [ D loss: 0.173224, acc.: 93%] [G loss: 5.835250]\n",
            "5368 [ D loss: 0.103910, acc.: 97%] [G loss: 7.617100]\n",
            "5369 [ D loss: 0.150449, acc.: 95%] [G loss: 7.467002]\n",
            "5370 [ D loss: 0.151469, acc.: 95%] [G loss: 4.987203]\n",
            "5371 [ D loss: 0.122798, acc.: 98%] [G loss: 4.569112]\n",
            "5372 [ D loss: 0.272322, acc.: 88%] [G loss: 4.001596]\n",
            "5373 [ D loss: 0.195734, acc.: 92%] [G loss: 4.938882]\n",
            "5374 [ D loss: 0.134839, acc.: 95%] [G loss: 5.112632]\n",
            "5375 [ D loss: 0.139966, acc.: 95%] [G loss: 5.370180]\n",
            "5376 [ D loss: 0.119138, acc.: 95%] [G loss: 7.382754]\n",
            "5377 [ D loss: 0.144605, acc.: 95%] [G loss: 6.307973]\n",
            "5378 [ D loss: 0.211254, acc.: 93%] [G loss: 4.819661]\n",
            "5379 [ D loss: 0.237706, acc.: 91%] [G loss: 9.384961]\n",
            "5380 [ D loss: 0.112173, acc.: 96%] [G loss: 9.354980]\n",
            "5381 [ D loss: 0.121090, acc.: 96%] [G loss: 7.419143]\n",
            "5382 [ D loss: 0.118640, acc.: 95%] [G loss: 14.207484]\n",
            "5383 [ D loss: 0.151224, acc.: 95%] [G loss: 6.554124]\n",
            "5384 [ D loss: 0.113322, acc.: 98%] [G loss: 11.168302]\n",
            "5385 [ D loss: 0.110600, acc.: 97%] [G loss: 7.133465]\n",
            "5386 [ D loss: 0.189367, acc.: 90%] [G loss: 7.987404]\n",
            "5387 [ D loss: 0.263961, acc.: 91%] [G loss: 4.229963]\n",
            "5388 [ D loss: 0.186475, acc.: 93%] [G loss: 5.097117]\n",
            "5389 [ D loss: 0.142085, acc.: 97%] [G loss: 4.850851]\n",
            "5390 [ D loss: 0.115911, acc.: 98%] [G loss: 5.427454]\n",
            "5391 [ D loss: 0.185142, acc.: 95%] [G loss: 4.668154]\n",
            "5392 [ D loss: 0.113186, acc.: 96%] [G loss: 6.021543]\n",
            "5393 [ D loss: 0.110694, acc.: 98%] [G loss: 4.737058]\n",
            "5394 [ D loss: 0.078755, acc.: 98%] [G loss: 6.774378]\n",
            "5395 [ D loss: 0.164208, acc.: 95%] [G loss: 5.927220]\n",
            "5396 [ D loss: 0.126852, acc.: 95%] [G loss: 5.490840]\n",
            "5397 [ D loss: 0.150408, acc.: 95%] [G loss: 6.090109]\n",
            "5398 [ D loss: 0.181020, acc.: 90%] [G loss: 6.115571]\n",
            "5399 [ D loss: 0.146725, acc.: 92%] [G loss: 5.093530]\n",
            "5400 [ D loss: 0.122953, acc.: 97%] [G loss: 6.634964]\n",
            "5401 [ D loss: 0.157366, acc.: 95%] [G loss: 7.450233]\n",
            "5402 [ D loss: 0.159514, acc.: 92%] [G loss: 5.687173]\n",
            "5403 [ D loss: 0.260431, acc.: 88%] [G loss: 5.003174]\n",
            "5404 [ D loss: 0.103361, acc.: 98%] [G loss: 6.134816]\n",
            "5405 [ D loss: 0.236226, acc.: 88%] [G loss: 5.449747]\n",
            "5406 [ D loss: 0.159969, acc.: 95%] [G loss: 5.731969]\n",
            "5407 [ D loss: 0.202958, acc.: 93%] [G loss: 4.118714]\n",
            "5408 [ D loss: 0.108808, acc.: 97%] [G loss: 6.098263]\n",
            "5409 [ D loss: 0.193848, acc.: 91%] [G loss: 5.054189]\n",
            "5410 [ D loss: 0.132945, acc.: 96%] [G loss: 4.999674]\n",
            "5411 [ D loss: 0.106711, acc.: 97%] [G loss: 4.182582]\n",
            "5412 [ D loss: 0.105049, acc.: 98%] [G loss: 5.064484]\n",
            "5413 [ D loss: 0.189720, acc.: 89%] [G loss: 5.100795]\n",
            "5414 [ D loss: 0.159941, acc.: 93%] [G loss: 5.870924]\n",
            "5415 [ D loss: 0.127145, acc.: 98%] [G loss: 4.963155]\n",
            "5416 [ D loss: 0.175374, acc.: 94%] [G loss: 4.536059]\n",
            "5417 [ D loss: 0.161421, acc.: 95%] [G loss: 4.184102]\n",
            "5418 [ D loss: 0.158817, acc.: 94%] [G loss: 3.882709]\n",
            "5419 [ D loss: 0.177475, acc.: 95%] [G loss: 5.277055]\n",
            "5420 [ D loss: 0.189027, acc.: 94%] [G loss: 4.687394]\n",
            "5421 [ D loss: 0.120605, acc.: 98%] [G loss: 8.169622]\n",
            "5422 [ D loss: 0.098379, acc.: 97%] [G loss: 5.318692]\n",
            "5423 [ D loss: 0.125556, acc.: 95%] [G loss: 7.572581]\n",
            "5424 [ D loss: 0.144735, acc.: 92%] [G loss: 4.390790]\n",
            "5425 [ D loss: 0.142895, acc.: 95%] [G loss: 4.487773]\n",
            "5426 [ D loss: 0.266487, acc.: 87%] [G loss: 5.009877]\n",
            "5427 [ D loss: 0.210919, acc.: 93%] [G loss: 5.350516]\n",
            "5428 [ D loss: 0.118156, acc.: 97%] [G loss: 4.141292]\n",
            "5429 [ D loss: 0.153185, acc.: 97%] [G loss: 10.676270]\n",
            "5430 [ D loss: 0.217144, acc.: 92%] [G loss: 6.899887]\n",
            "5431 [ D loss: 0.230038, acc.: 91%] [G loss: 4.496780]\n",
            "5432 [ D loss: 0.198155, acc.: 95%] [G loss: 4.212316]\n",
            "5433 [ D loss: 0.179970, acc.: 95%] [G loss: 5.165470]\n",
            "5434 [ D loss: 0.260291, acc.: 91%] [G loss: 3.973412]\n",
            "5435 [ D loss: 0.095687, acc.: 98%] [G loss: 6.277400]\n",
            "5436 [ D loss: 0.282039, acc.: 90%] [G loss: 5.082186]\n",
            "5437 [ D loss: 0.154410, acc.: 93%] [G loss: 12.017550]\n",
            "5438 [ D loss: 0.229339, acc.: 92%] [G loss: 8.158058]\n",
            "5439 [ D loss: 0.082068, acc.: 96%] [G loss: 6.205411]\n",
            "5440 [ D loss: 0.185392, acc.: 95%] [G loss: 6.355871]\n",
            "5441 [ D loss: 0.267124, acc.: 91%] [G loss: 6.064747]\n",
            "5442 [ D loss: 0.183490, acc.: 92%] [G loss: 5.841656]\n",
            "5443 [ D loss: 0.090944, acc.: 97%] [G loss: 4.752502]\n",
            "5444 [ D loss: 0.152922, acc.: 94%] [G loss: 5.149294]\n",
            "5445 [ D loss: 0.138828, acc.: 94%] [G loss: 5.942959]\n",
            "5446 [ D loss: 0.113422, acc.: 97%] [G loss: 6.763346]\n",
            "5447 [ D loss: 0.166965, acc.: 94%] [G loss: 7.299673]\n",
            "5448 [ D loss: 0.098677, acc.: 98%] [G loss: 3.680659]\n",
            "5449 [ D loss: 0.226274, acc.: 92%] [G loss: 3.733453]\n",
            "5450 [ D loss: 0.153415, acc.: 95%] [G loss: 4.388917]\n",
            "5451 [ D loss: 0.159574, acc.: 95%] [G loss: 6.758995]\n",
            "5452 [ D loss: 0.144145, acc.: 95%] [G loss: 3.960588]\n",
            "5453 [ D loss: 0.159143, acc.: 95%] [G loss: 6.204092]\n",
            "5454 [ D loss: 0.216415, acc.: 95%] [G loss: 4.333733]\n",
            "5455 [ D loss: 0.216048, acc.: 90%] [G loss: 5.030881]\n",
            "5456 [ D loss: 0.175597, acc.: 95%] [G loss: 5.002825]\n",
            "5457 [ D loss: 0.148163, acc.: 96%] [G loss: 4.328750]\n",
            "5458 [ D loss: 0.197644, acc.: 91%] [G loss: 4.852714]\n",
            "5459 [ D loss: 0.161002, acc.: 92%] [G loss: 3.811181]\n",
            "5460 [ D loss: 0.276288, acc.: 88%] [G loss: 5.856954]\n",
            "5461 [ D loss: 0.154945, acc.: 93%] [G loss: 3.754209]\n",
            "5462 [ D loss: 0.194941, acc.: 91%] [G loss: 5.144003]\n",
            "5463 [ D loss: 0.119593, acc.: 98%] [G loss: 6.045100]\n",
            "5464 [ D loss: 0.081431, acc.: 98%] [G loss: 5.046032]\n",
            "5465 [ D loss: 0.194700, acc.: 95%] [G loss: 7.414800]\n",
            "5466 [ D loss: 0.157068, acc.: 94%] [G loss: 6.680436]\n",
            "5467 [ D loss: 0.055085, acc.: 97%] [G loss: 8.164802]\n",
            "5468 [ D loss: 0.092049, acc.: 98%] [G loss: 4.779828]\n",
            "5469 [ D loss: 0.132061, acc.: 95%] [G loss: 6.377295]\n",
            "5470 [ D loss: 0.160144, acc.: 96%] [G loss: 9.211222]\n",
            "5471 [ D loss: 0.169900, acc.: 95%] [G loss: 5.858252]\n",
            "5472 [ D loss: 0.110673, acc.: 97%] [G loss: 8.572537]\n",
            "5473 [ D loss: 0.163977, acc.: 94%] [G loss: 4.167374]\n",
            "5474 [ D loss: 0.133798, acc.: 95%] [G loss: 4.373302]\n",
            "5475 [ D loss: 0.167711, acc.: 96%] [G loss: 4.146042]\n",
            "5476 [ D loss: 0.222986, acc.: 91%] [G loss: 3.508694]\n",
            "5477 [ D loss: 0.146506, acc.: 97%] [G loss: 3.757424]\n",
            "5478 [ D loss: 0.197139, acc.: 93%] [G loss: 4.511731]\n",
            "5479 [ D loss: 0.261099, acc.: 91%] [G loss: 4.492661]\n",
            "5480 [ D loss: 0.147003, acc.: 94%] [G loss: 4.545386]\n",
            "5481 [ D loss: 0.185592, acc.: 95%] [G loss: 4.984523]\n",
            "5482 [ D loss: 0.222761, acc.: 91%] [G loss: 4.202342]\n",
            "5483 [ D loss: 0.102979, acc.: 98%] [G loss: 6.468962]\n",
            "5484 [ D loss: 0.137748, acc.: 94%] [G loss: 4.566136]\n",
            "5485 [ D loss: 0.190223, acc.: 91%] [G loss: 5.058448]\n",
            "5486 [ D loss: 0.067022, acc.: 98%] [G loss: 8.893644]\n",
            "5487 [ D loss: 0.194610, acc.: 91%] [G loss: 5.207115]\n",
            "5488 [ D loss: 0.173711, acc.: 92%] [G loss: 6.159826]\n",
            "5489 [ D loss: 0.116295, acc.: 98%] [G loss: 5.773129]\n",
            "5490 [ D loss: 0.136093, acc.: 96%] [G loss: 10.092933]\n",
            "5491 [ D loss: 0.184625, acc.: 93%] [G loss: 6.470969]\n",
            "5492 [ D loss: 0.152675, acc.: 95%] [G loss: 6.184378]\n",
            "5493 [ D loss: 0.102473, acc.: 97%] [G loss: 6.315873]\n",
            "5494 [ D loss: 0.184127, acc.: 92%] [G loss: 8.080465]\n",
            "5495 [ D loss: 0.132406, acc.: 96%] [G loss: 4.865242]\n",
            "5496 [ D loss: 0.105987, acc.: 96%] [G loss: 4.970906]\n",
            "5497 [ D loss: 0.152721, acc.: 95%] [G loss: 5.246154]\n",
            "5498 [ D loss: 0.153060, acc.: 92%] [G loss: 4.651148]\n",
            "5499 [ D loss: 0.231967, acc.: 91%] [G loss: 5.949445]\n",
            "5500 [ D loss: 0.256773, acc.: 88%] [G loss: 4.355480]\n",
            "5501 [ D loss: 0.184737, acc.: 92%] [G loss: 5.382048]\n",
            "5502 [ D loss: 0.162501, acc.: 93%] [G loss: 5.172561]\n",
            "5503 [ D loss: 0.159361, acc.: 95%] [G loss: 5.267907]\n",
            "5504 [ D loss: 0.113924, acc.: 95%] [G loss: 4.751870]\n",
            "5505 [ D loss: 0.177544, acc.: 96%] [G loss: 3.195099]\n",
            "5506 [ D loss: 0.224845, acc.: 92%] [G loss: 5.899460]\n",
            "5507 [ D loss: 0.200866, acc.: 93%] [G loss: 4.457635]\n",
            "5508 [ D loss: 0.231891, acc.: 92%] [G loss: 3.952043]\n",
            "5509 [ D loss: 0.239917, acc.: 95%] [G loss: 5.000675]\n",
            "5510 [ D loss: 0.130197, acc.: 95%] [G loss: 5.195485]\n",
            "5511 [ D loss: 0.210248, acc.: 89%] [G loss: 4.602295]\n",
            "5512 [ D loss: 0.147374, acc.: 95%] [G loss: 4.355965]\n",
            "5513 [ D loss: 0.140580, acc.: 95%] [G loss: 7.721806]\n",
            "5514 [ D loss: 0.147629, acc.: 95%] [G loss: 5.794827]\n",
            "5515 [ D loss: 0.116741, acc.: 96%] [G loss: 3.674433]\n",
            "5516 [ D loss: 0.161723, acc.: 95%] [G loss: 4.282516]\n",
            "5517 [ D loss: 0.105392, acc.: 99%] [G loss: 5.275904]\n",
            "5518 [ D loss: 0.324219, acc.: 84%] [G loss: 4.215120]\n",
            "5519 [ D loss: 0.224411, acc.: 91%] [G loss: 4.664613]\n",
            "5520 [ D loss: 0.150265, acc.: 93%] [G loss: 5.935668]\n",
            "5521 [ D loss: 0.194761, acc.: 93%] [G loss: 6.126740]\n",
            "5522 [ D loss: 0.090938, acc.: 98%] [G loss: 4.825161]\n",
            "5523 [ D loss: 0.086515, acc.: 97%] [G loss: 4.885884]\n",
            "5524 [ D loss: 0.257578, acc.: 89%] [G loss: 4.961673]\n",
            "5525 [ D loss: 0.083524, acc.: 97%] [G loss: 5.494707]\n",
            "5526 [ D loss: 0.234054, acc.: 91%] [G loss: 4.176772]\n",
            "5527 [ D loss: 0.192947, acc.: 95%] [G loss: 4.366755]\n",
            "5528 [ D loss: 0.143377, acc.: 95%] [G loss: 4.701540]\n",
            "5529 [ D loss: 0.167876, acc.: 93%] [G loss: 4.003383]\n",
            "5530 [ D loss: 0.335234, acc.: 80%] [G loss: 5.455981]\n",
            "5531 [ D loss: 0.144579, acc.: 95%] [G loss: 4.888149]\n",
            "5532 [ D loss: 0.270749, acc.: 89%] [G loss: 4.275486]\n",
            "5533 [ D loss: 0.210007, acc.: 92%] [G loss: 5.268266]\n",
            "5534 [ D loss: 0.149059, acc.: 95%] [G loss: 4.712872]\n",
            "5535 [ D loss: 0.194261, acc.: 91%] [G loss: 4.568576]\n",
            "5536 [ D loss: 0.094156, acc.: 97%] [G loss: 5.052511]\n",
            "5537 [ D loss: 0.178538, acc.: 91%] [G loss: 5.680585]\n",
            "5538 [ D loss: 0.129067, acc.: 95%] [G loss: 6.639925]\n",
            "5539 [ D loss: 0.188778, acc.: 92%] [G loss: 6.767349]\n",
            "5540 [ D loss: 0.112792, acc.: 95%] [G loss: 6.117115]\n",
            "5541 [ D loss: 0.096913, acc.: 98%] [G loss: 5.119492]\n",
            "5542 [ D loss: 0.115287, acc.: 98%] [G loss: 4.698350]\n",
            "5543 [ D loss: 0.141125, acc.: 95%] [G loss: 8.157408]\n",
            "5544 [ D loss: 0.163928, acc.: 94%] [G loss: 6.582955]\n",
            "5545 [ D loss: 0.106877, acc.: 96%] [G loss: 8.980259]\n",
            "5546 [ D loss: 0.169345, acc.: 93%] [G loss: 5.922468]\n",
            "5547 [ D loss: 0.045808, acc.: 99%] [G loss: 6.592883]\n",
            "5548 [ D loss: 0.079883, acc.: 97%] [G loss: 5.339828]\n",
            "5549 [ D loss: 0.144773, acc.: 95%] [G loss: 9.600664]\n",
            "5550 [ D loss: 0.077762, acc.: 98%] [G loss: 9.843001]\n",
            "5551 [ D loss: 0.098656, acc.: 96%] [G loss: 10.500820]\n",
            "5552 [ D loss: 0.077650, acc.: 98%] [G loss: 6.195361]\n",
            "5553 [ D loss: 0.186381, acc.: 91%] [G loss: 7.750607]\n",
            "5554 [ D loss: 0.084379, acc.: 98%] [G loss: 8.861938]\n",
            "5555 [ D loss: 0.192227, acc.: 92%] [G loss: 5.738502]\n",
            "5556 [ D loss: 0.180496, acc.: 92%] [G loss: 5.988923]\n",
            "5557 [ D loss: 0.128358, acc.: 96%] [G loss: 4.890889]\n",
            "5558 [ D loss: 0.180286, acc.: 92%] [G loss: 5.242970]\n",
            "5559 [ D loss: 0.133299, acc.: 96%] [G loss: 4.494860]\n",
            "5560 [ D loss: 0.162648, acc.: 95%] [G loss: 4.753068]\n",
            "5561 [ D loss: 0.184004, acc.: 91%] [G loss: 3.612522]\n",
            "5562 [ D loss: 0.322552, acc.: 88%] [G loss: 4.399559]\n",
            "5563 [ D loss: 0.188209, acc.: 91%] [G loss: 4.405988]\n",
            "5564 [ D loss: 0.155762, acc.: 93%] [G loss: 4.415653]\n",
            "5565 [ D loss: 0.159060, acc.: 95%] [G loss: 5.112919]\n",
            "5566 [ D loss: 0.284566, acc.: 88%] [G loss: 5.061650]\n",
            "5567 [ D loss: 0.180466, acc.: 92%] [G loss: 5.285846]\n",
            "5568 [ D loss: 0.191726, acc.: 91%] [G loss: 3.925254]\n",
            "5569 [ D loss: 0.142679, acc.: 95%] [G loss: 5.010288]\n",
            "5570 [ D loss: 0.271421, acc.: 88%] [G loss: 4.662688]\n",
            "5571 [ D loss: 0.167729, acc.: 93%] [G loss: 7.056403]\n",
            "5572 [ D loss: 0.208848, acc.: 91%] [G loss: 5.792894]\n",
            "5573 [ D loss: 0.103330, acc.: 95%] [G loss: 3.662193]\n",
            "5574 [ D loss: 0.131550, acc.: 98%] [G loss: 4.800135]\n",
            "5575 [ D loss: 0.182634, acc.: 93%] [G loss: 4.950111]\n",
            "5576 [ D loss: 0.224899, acc.: 89%] [G loss: 5.491811]\n",
            "5577 [ D loss: 0.099776, acc.: 97%] [G loss: 6.747876]\n",
            "5578 [ D loss: 0.137153, acc.: 95%] [G loss: 4.678362]\n",
            "5579 [ D loss: 0.161935, acc.: 95%] [G loss: 5.249712]\n",
            "5580 [ D loss: 0.157289, acc.: 95%] [G loss: 5.148821]\n",
            "5581 [ D loss: 0.123731, acc.: 97%] [G loss: 5.333523]\n",
            "5582 [ D loss: 0.198331, acc.: 91%] [G loss: 10.865572]\n",
            "5583 [ D loss: 0.167086, acc.: 94%] [G loss: 5.958194]\n",
            "5584 [ D loss: 0.204994, acc.: 91%] [G loss: 4.869438]\n",
            "5585 [ D loss: 0.139380, acc.: 96%] [G loss: 4.716695]\n",
            "5586 [ D loss: 0.170130, acc.: 94%] [G loss: 4.799485]\n",
            "5587 [ D loss: 0.171045, acc.: 93%] [G loss: 7.395354]\n",
            "5588 [ D loss: 0.195807, acc.: 92%] [G loss: 5.401170]\n",
            "5589 [ D loss: 0.098141, acc.: 98%] [G loss: 5.372315]\n",
            "5590 [ D loss: 0.149787, acc.: 95%] [G loss: 7.300019]\n",
            "5591 [ D loss: 0.182711, acc.: 91%] [G loss: 5.993627]\n",
            "5592 [ D loss: 0.111215, acc.: 96%] [G loss: 4.721251]\n",
            "5593 [ D loss: 0.169570, acc.: 95%] [G loss: 5.023940]\n",
            "5594 [ D loss: 0.201785, acc.: 95%] [G loss: 4.816874]\n",
            "5595 [ D loss: 0.153479, acc.: 92%] [G loss: 5.176235]\n",
            "5596 [ D loss: 0.230858, acc.: 91%] [G loss: 6.525027]\n",
            "5597 [ D loss: 0.174231, acc.: 95%] [G loss: 5.182181]\n",
            "5598 [ D loss: 0.262030, acc.: 88%] [G loss: 6.833470]\n",
            "5599 [ D loss: 0.170620, acc.: 98%] [G loss: 7.301184]\n",
            "5600 [ D loss: 0.155868, acc.: 95%] [G loss: 4.565458]\n",
            "5601 [ D loss: 0.169037, acc.: 95%] [G loss: 5.025740]\n",
            "5602 [ D loss: 0.130889, acc.: 96%] [G loss: 6.086326]\n",
            "5603 [ D loss: 0.172096, acc.: 95%] [G loss: 4.635461]\n",
            "5604 [ D loss: 0.207151, acc.: 92%] [G loss: 9.964893]\n",
            "5605 [ D loss: 0.104417, acc.: 97%] [G loss: 6.706099]\n",
            "5606 [ D loss: 0.095313, acc.: 96%] [G loss: 6.383957]\n",
            "5607 [ D loss: 0.143542, acc.: 95%] [G loss: 6.148724]\n",
            "5608 [ D loss: 0.211728, acc.: 91%] [G loss: 4.964408]\n",
            "5609 [ D loss: 0.142390, acc.: 95%] [G loss: 4.890458]\n",
            "5610 [ D loss: 0.167329, acc.: 96%] [G loss: 4.692967]\n",
            "5611 [ D loss: 0.292494, acc.: 90%] [G loss: 5.242541]\n",
            "5612 [ D loss: 0.115701, acc.: 95%] [G loss: 4.734236]\n",
            "5613 [ D loss: 0.239130, acc.: 89%] [G loss: 5.267561]\n",
            "5614 [ D loss: 0.044176, acc.: 98%] [G loss: 6.354023]\n",
            "5615 [ D loss: 0.159880, acc.: 95%] [G loss: 6.293246]\n",
            "5616 [ D loss: 0.197130, acc.: 93%] [G loss: 4.730253]\n",
            "5617 [ D loss: 0.131077, acc.: 94%] [G loss: 11.412138]\n",
            "5618 [ D loss: 0.089503, acc.: 97%] [G loss: 6.956676]\n",
            "5619 [ D loss: 0.278463, acc.: 88%] [G loss: 10.254023]\n",
            "5620 [ D loss: 0.154586, acc.: 94%] [G loss: 6.402008]\n",
            "5621 [ D loss: 0.111448, acc.: 98%] [G loss: 6.523199]\n",
            "5622 [ D loss: 0.143275, acc.: 94%] [G loss: 9.813827]\n",
            "5623 [ D loss: 0.097891, acc.: 98%] [G loss: 5.098785]\n",
            "5624 [ D loss: 0.145675, acc.: 95%] [G loss: 5.419470]\n",
            "5625 [ D loss: 0.102209, acc.: 95%] [G loss: 5.381819]\n",
            "5626 [ D loss: 0.120825, acc.: 95%] [G loss: 11.322458]\n",
            "5627 [ D loss: 0.152759, acc.: 92%] [G loss: 6.623131]\n",
            "5628 [ D loss: 0.261535, acc.: 91%] [G loss: 5.003913]\n",
            "5629 [ D loss: 0.461108, acc.: 80%] [G loss: 7.322546]\n",
            "5630 [ D loss: 0.636988, acc.: 74%] [G loss: 6.082182]\n",
            "5631 [ D loss: 0.161462, acc.: 93%] [G loss: 7.692410]\n",
            "5632 [ D loss: 0.283747, acc.: 89%] [G loss: 5.957091]\n",
            "5633 [ D loss: 0.204601, acc.: 92%] [G loss: 8.654991]\n",
            "5634 [ D loss: 0.249936, acc.: 91%] [G loss: 5.759057]\n",
            "5635 [ D loss: 0.179331, acc.: 95%] [G loss: 5.778402]\n",
            "5636 [ D loss: 0.124145, acc.: 96%] [G loss: 5.597422]\n",
            "5637 [ D loss: 0.113703, acc.: 98%] [G loss: 4.860789]\n",
            "5638 [ D loss: 0.147233, acc.: 95%] [G loss: 5.940483]\n",
            "5639 [ D loss: 0.178342, acc.: 94%] [G loss: 5.304128]\n",
            "5640 [ D loss: 0.175205, acc.: 93%] [G loss: 5.278273]\n",
            "5641 [ D loss: 0.175310, acc.: 92%] [G loss: 6.185031]\n",
            "5642 [ D loss: 0.168467, acc.: 96%] [G loss: 5.394429]\n",
            "5643 [ D loss: 0.200543, acc.: 92%] [G loss: 6.140119]\n",
            "5644 [ D loss: 0.135090, acc.: 96%] [G loss: 4.831513]\n",
            "5645 [ D loss: 0.149013, acc.: 95%] [G loss: 8.018796]\n",
            "5646 [ D loss: 0.094438, acc.: 97%] [G loss: 4.638244]\n",
            "5647 [ D loss: 0.246539, acc.: 90%] [G loss: 5.356042]\n",
            "5648 [ D loss: 0.217143, acc.: 90%] [G loss: 5.919209]\n",
            "5649 [ D loss: 0.199755, acc.: 91%] [G loss: 7.610836]\n",
            "5650 [ D loss: 0.109321, acc.: 97%] [G loss: 5.433944]\n",
            "5651 [ D loss: 0.269613, acc.: 90%] [G loss: 7.623832]\n",
            "5652 [ D loss: 0.133520, acc.: 96%] [G loss: 7.008360]\n",
            "5653 [ D loss: 0.151149, acc.: 95%] [G loss: 4.714532]\n",
            "5654 [ D loss: 0.253438, acc.: 90%] [G loss: 5.819142]\n",
            "5655 [ D loss: 0.265914, acc.: 91%] [G loss: 4.284169]\n",
            "5656 [ D loss: 0.238793, acc.: 89%] [G loss: 5.133038]\n",
            "5657 [ D loss: 0.101571, acc.: 97%] [G loss: 6.438920]\n",
            "5658 [ D loss: 0.243119, acc.: 93%] [G loss: 3.873206]\n",
            "5659 [ D loss: 0.161621, acc.: 94%] [G loss: 3.923593]\n",
            "5660 [ D loss: 0.170442, acc.: 92%] [G loss: 4.484701]\n",
            "5661 [ D loss: 0.260209, acc.: 91%] [G loss: 4.156317]\n",
            "5662 [ D loss: 0.232271, acc.: 91%] [G loss: 4.767712]\n",
            "5663 [ D loss: 0.241685, acc.: 92%] [G loss: 4.367828]\n",
            "5664 [ D loss: 0.192220, acc.: 93%] [G loss: 4.622087]\n",
            "5665 [ D loss: 0.243442, acc.: 93%] [G loss: 4.305947]\n",
            "5666 [ D loss: 0.235984, acc.: 90%] [G loss: 6.389025]\n",
            "5667 [ D loss: 0.237024, acc.: 90%] [G loss: 5.168901]\n",
            "5668 [ D loss: 0.123705, acc.: 96%] [G loss: 8.644054]\n",
            "5669 [ D loss: 0.215350, acc.: 91%] [G loss: 5.096154]\n",
            "5670 [ D loss: 0.231082, acc.: 91%] [G loss: 5.562171]\n",
            "5671 [ D loss: 0.176234, acc.: 92%] [G loss: 5.850867]\n",
            "5672 [ D loss: 0.207999, acc.: 92%] [G loss: 4.430649]\n",
            "5673 [ D loss: 0.294849, acc.: 87%] [G loss: 6.469159]\n",
            "5674 [ D loss: 0.257150, acc.: 90%] [G loss: 4.753365]\n",
            "5675 [ D loss: 0.118418, acc.: 96%] [G loss: 10.817887]\n",
            "5676 [ D loss: 0.124865, acc.: 98%] [G loss: 4.807225]\n",
            "5677 [ D loss: 0.079211, acc.: 98%] [G loss: 6.613302]\n",
            "5678 [ D loss: 0.116720, acc.: 95%] [G loss: 9.245180]\n",
            "5679 [ D loss: 0.114638, acc.: 97%] [G loss: 8.800886]\n",
            "5680 [ D loss: 0.134562, acc.: 95%] [G loss: 8.399621]\n",
            "5681 [ D loss: 0.103573, acc.: 97%] [G loss: 8.515942]\n",
            "5682 [ D loss: 0.119588, acc.: 96%] [G loss: 8.435257]\n",
            "5683 [ D loss: 0.136069, acc.: 93%] [G loss: 5.798074]\n",
            "5684 [ D loss: 0.156226, acc.: 96%] [G loss: 4.808113]\n",
            "5685 [ D loss: 0.189292, acc.: 94%] [G loss: 4.244677]\n",
            "5686 [ D loss: 0.225699, acc.: 88%] [G loss: 3.955164]\n",
            "5687 [ D loss: 0.256783, acc.: 90%] [G loss: 5.335310]\n",
            "5688 [ D loss: 0.132323, acc.: 95%] [G loss: 7.873775]\n",
            "5689 [ D loss: 0.216789, acc.: 90%] [G loss: 4.473884]\n",
            "5690 [ D loss: 0.234079, acc.: 91%] [G loss: 4.925862]\n",
            "5691 [ D loss: 0.098418, acc.: 98%] [G loss: 6.104909]\n",
            "5692 [ D loss: 0.095115, acc.: 98%] [G loss: 9.021628]\n",
            "5693 [ D loss: 0.186732, acc.: 91%] [G loss: 5.667865]\n",
            "5694 [ D loss: 0.148875, acc.: 96%] [G loss: 6.277864]\n",
            "5695 [ D loss: 0.099532, acc.: 98%] [G loss: 4.769429]\n",
            "5696 [ D loss: 0.147866, acc.: 95%] [G loss: 4.761036]\n",
            "5697 [ D loss: 0.161332, acc.: 95%] [G loss: 6.890049]\n",
            "5698 [ D loss: 0.220824, acc.: 91%] [G loss: 4.155860]\n",
            "5699 [ D loss: 0.258891, acc.: 88%] [G loss: 4.965275]\n",
            "5700 [ D loss: 0.110629, acc.: 98%] [G loss: 6.056618]\n",
            "5701 [ D loss: 0.236209, acc.: 93%] [G loss: 4.498562]\n",
            "5702 [ D loss: 0.147713, acc.: 94%] [G loss: 7.157041]\n",
            "5703 [ D loss: 0.251346, acc.: 90%] [G loss: 6.673644]\n",
            "5704 [ D loss: 0.147647, acc.: 96%] [G loss: 5.972198]\n",
            "5705 [ D loss: 0.166947, acc.: 95%] [G loss: 4.419497]\n",
            "5706 [ D loss: 0.153003, acc.: 94%] [G loss: 5.492630]\n",
            "5707 [ D loss: 0.214601, acc.: 93%] [G loss: 3.955195]\n",
            "5708 [ D loss: 0.187383, acc.: 94%] [G loss: 4.565909]\n",
            "5709 [ D loss: 0.270097, acc.: 91%] [G loss: 4.712389]\n",
            "5710 [ D loss: 0.162322, acc.: 93%] [G loss: 4.830800]\n",
            "5711 [ D loss: 0.181339, acc.: 95%] [G loss: 4.969830]\n",
            "5712 [ D loss: 0.302389, acc.: 88%] [G loss: 3.939595]\n",
            "5713 [ D loss: 0.186064, acc.: 93%] [G loss: 5.189000]\n",
            "5714 [ D loss: 0.283786, acc.: 91%] [G loss: 4.840862]\n",
            "5715 [ D loss: 0.267406, acc.: 90%] [G loss: 5.234843]\n",
            "5716 [ D loss: 0.372861, acc.: 81%] [G loss: 6.303210]\n",
            "5717 [ D loss: 0.176984, acc.: 95%] [G loss: 5.589570]\n",
            "5718 [ D loss: 0.351905, acc.: 86%] [G loss: 5.164183]\n",
            "5719 [ D loss: 0.194656, acc.: 92%] [G loss: 5.259181]\n",
            "5720 [ D loss: 0.118756, acc.: 95%] [G loss: 5.240748]\n",
            "5721 [ D loss: 0.171341, acc.: 95%] [G loss: 5.351139]\n",
            "5722 [ D loss: 0.194779, acc.: 92%] [G loss: 4.764968]\n",
            "5723 [ D loss: 0.085545, acc.: 98%] [G loss: 6.580610]\n",
            "5724 [ D loss: 0.185569, acc.: 93%] [G loss: 7.425611]\n",
            "5725 [ D loss: 0.094377, acc.: 98%] [G loss: 5.278633]\n",
            "5726 [ D loss: 0.174450, acc.: 92%] [G loss: 6.635946]\n",
            "5727 [ D loss: 0.123842, acc.: 97%] [G loss: 6.835444]\n",
            "5728 [ D loss: 0.204388, acc.: 91%] [G loss: 6.676595]\n",
            "5729 [ D loss: 0.066852, acc.: 98%] [G loss: 8.359926]\n",
            "5730 [ D loss: 0.089716, acc.: 96%] [G loss: 7.517953]\n",
            "5731 [ D loss: 0.106518, acc.: 97%] [G loss: 3.901883]\n",
            "5732 [ D loss: 0.271361, acc.: 85%] [G loss: 4.015351]\n",
            "5733 [ D loss: 0.196950, acc.: 92%] [G loss: 7.149859]\n",
            "5734 [ D loss: 0.106781, acc.: 96%] [G loss: 5.197375]\n",
            "5735 [ D loss: 0.124703, acc.: 95%] [G loss: 8.350941]\n",
            "5736 [ D loss: 0.117762, acc.: 96%] [G loss: 8.781463]\n",
            "5737 [ D loss: 0.224154, acc.: 92%] [G loss: 4.804783]\n",
            "5738 [ D loss: 0.141770, acc.: 95%] [G loss: 5.267301]\n",
            "5739 [ D loss: 0.192772, acc.: 95%] [G loss: 6.735433]\n",
            "5740 [ D loss: 0.124119, acc.: 95%] [G loss: 7.282032]\n",
            "5741 [ D loss: 0.176934, acc.: 95%] [G loss: 9.467961]\n",
            "5742 [ D loss: 0.092882, acc.: 95%] [G loss: 6.283521]\n",
            "5743 [ D loss: 0.144647, acc.: 92%] [G loss: 8.610458]\n",
            "5744 [ D loss: 0.106359, acc.: 97%] [G loss: 4.723072]\n",
            "5745 [ D loss: 0.146632, acc.: 95%] [G loss: 5.563698]\n",
            "5746 [ D loss: 0.086729, acc.: 98%] [G loss: 7.279578]\n",
            "5747 [ D loss: 0.140049, acc.: 97%] [G loss: 9.761932]\n",
            "5748 [ D loss: 0.152073, acc.: 94%] [G loss: 4.708700]\n",
            "5749 [ D loss: 0.102569, acc.: 98%] [G loss: 4.528295]\n",
            "5750 [ D loss: 0.088919, acc.: 98%] [G loss: 6.809249]\n",
            "5751 [ D loss: 0.169573, acc.: 94%] [G loss: 3.814485]\n",
            "5752 [ D loss: 0.145977, acc.: 96%] [G loss: 5.730778]\n",
            "5753 [ D loss: 0.125911, acc.: 94%] [G loss: 4.988072]\n",
            "5754 [ D loss: 0.160996, acc.: 95%] [G loss: 5.273750]\n",
            "5755 [ D loss: 0.147249, acc.: 95%] [G loss: 5.109440]\n",
            "5756 [ D loss: 0.226456, acc.: 91%] [G loss: 6.595608]\n",
            "5757 [ D loss: 0.222805, acc.: 89%] [G loss: 5.814535]\n",
            "5758 [ D loss: 0.126201, acc.: 96%] [G loss: 5.762045]\n",
            "5759 [ D loss: 0.170458, acc.: 95%] [G loss: 4.747659]\n",
            "5760 [ D loss: 0.103474, acc.: 97%] [G loss: 5.787901]\n",
            "5761 [ D loss: 0.095790, acc.: 98%] [G loss: 4.282879]\n",
            "5762 [ D loss: 0.169985, acc.: 97%] [G loss: 5.276263]\n",
            "5763 [ D loss: 0.097458, acc.: 98%] [G loss: 5.213202]\n",
            "5764 [ D loss: 0.197683, acc.: 91%] [G loss: 4.396358]\n",
            "5765 [ D loss: 0.161266, acc.: 95%] [G loss: 4.389794]\n",
            "5766 [ D loss: 0.120952, acc.: 96%] [G loss: 6.881915]\n",
            "5767 [ D loss: 0.124399, acc.: 96%] [G loss: 5.275233]\n",
            "5768 [ D loss: 0.071443, acc.: 98%] [G loss: 4.721118]\n",
            "5769 [ D loss: 0.195298, acc.: 91%] [G loss: 4.243217]\n",
            "5770 [ D loss: 0.168577, acc.: 95%] [G loss: 4.380177]\n",
            "5771 [ D loss: 0.184945, acc.: 95%] [G loss: 4.320781]\n",
            "5772 [ D loss: 0.111270, acc.: 98%] [G loss: 3.811718]\n",
            "5773 [ D loss: 0.175370, acc.: 93%] [G loss: 4.206583]\n",
            "5774 [ D loss: 0.167555, acc.: 95%] [G loss: 4.789722]\n",
            "5775 [ D loss: 0.250029, acc.: 89%] [G loss: 4.784524]\n",
            "5776 [ D loss: 0.158688, acc.: 95%] [G loss: 4.350080]\n",
            "5777 [ D loss: 0.139865, acc.: 94%] [G loss: 5.083872]\n",
            "5778 [ D loss: 0.134180, acc.: 93%] [G loss: 5.716196]\n",
            "5779 [ D loss: 0.093222, acc.: 97%] [G loss: 6.016960]\n",
            "5780 [ D loss: 0.126703, acc.: 95%] [G loss: 7.940460]\n",
            "5781 [ D loss: 0.082063, acc.: 97%] [G loss: 4.703078]\n",
            "5782 [ D loss: 0.078950, acc.: 98%] [G loss: 5.492974]\n",
            "5783 [ D loss: 0.211632, acc.: 88%] [G loss: 5.849201]\n",
            "5784 [ D loss: 0.140840, acc.: 95%] [G loss: 4.130751]\n",
            "5785 [ D loss: 0.213637, acc.: 93%] [G loss: 4.479439]\n",
            "5786 [ D loss: 0.223938, acc.: 91%] [G loss: 4.536887]\n",
            "5787 [ D loss: 0.132408, acc.: 98%] [G loss: 4.927781]\n",
            "5788 [ D loss: 0.209869, acc.: 91%] [G loss: 5.917579]\n",
            "5789 [ D loss: 0.237277, acc.: 93%] [G loss: 5.096844]\n",
            "5790 [ D loss: 0.183604, acc.: 92%] [G loss: 5.030750]\n",
            "5791 [ D loss: 0.184625, acc.: 92%] [G loss: 5.056067]\n",
            "5792 [ D loss: 0.192325, acc.: 94%] [G loss: 4.265723]\n",
            "5793 [ D loss: 0.110384, acc.: 98%] [G loss: 5.596429]\n",
            "5794 [ D loss: 0.164912, acc.: 95%] [G loss: 4.835511]\n",
            "5795 [ D loss: 0.153375, acc.: 91%] [G loss: 6.548766]\n",
            "5796 [ D loss: 0.136433, acc.: 95%] [G loss: 5.511837]\n",
            "5797 [ D loss: 0.124501, acc.: 95%] [G loss: 3.855454]\n",
            "5798 [ D loss: 0.181557, acc.: 95%] [G loss: 7.517869]\n",
            "5799 [ D loss: 0.083055, acc.: 98%] [G loss: 5.709530]\n",
            "5800 [ D loss: 0.174790, acc.: 95%] [G loss: 4.707181]\n",
            "5801 [ D loss: 0.143747, acc.: 95%] [G loss: 4.244815]\n",
            "5802 [ D loss: 0.163252, acc.: 95%] [G loss: 4.907555]\n",
            "5803 [ D loss: 0.178204, acc.: 95%] [G loss: 4.434099]\n",
            "5804 [ D loss: 0.246448, acc.: 89%] [G loss: 4.391380]\n",
            "5805 [ D loss: 0.223211, acc.: 92%] [G loss: 5.427782]\n",
            "5806 [ D loss: 0.232496, acc.: 90%] [G loss: 5.778866]\n",
            "5807 [ D loss: 0.125760, acc.: 95%] [G loss: 5.934836]\n",
            "5808 [ D loss: 0.153297, acc.: 95%] [G loss: 5.316141]\n",
            "5809 [ D loss: 0.172962, acc.: 97%] [G loss: 6.120826]\n",
            "5810 [ D loss: 0.205988, acc.: 93%] [G loss: 4.826840]\n",
            "5811 [ D loss: 0.133716, acc.: 98%] [G loss: 5.011072]\n",
            "5812 [ D loss: 0.254004, acc.: 94%] [G loss: 4.934444]\n",
            "5813 [ D loss: 0.245326, acc.: 91%] [G loss: 5.865320]\n",
            "5814 [ D loss: 0.233106, acc.: 90%] [G loss: 4.502317]\n",
            "5815 [ D loss: 0.153437, acc.: 96%] [G loss: 4.675394]\n",
            "5816 [ D loss: 0.153795, acc.: 95%] [G loss: 5.684796]\n",
            "5817 [ D loss: 0.216182, acc.: 89%] [G loss: 5.210387]\n",
            "5818 [ D loss: 0.137808, acc.: 95%] [G loss: 4.799339]\n",
            "5819 [ D loss: 0.228000, acc.: 94%] [G loss: 5.476139]\n",
            "5820 [ D loss: 0.196228, acc.: 91%] [G loss: 3.652002]\n",
            "5821 [ D loss: 0.105323, acc.: 97%] [G loss: 4.592268]\n",
            "5822 [ D loss: 0.220932, acc.: 91%] [G loss: 5.284312]\n",
            "5823 [ D loss: 0.188982, acc.: 92%] [G loss: 3.983036]\n",
            "5824 [ D loss: 0.249474, acc.: 90%] [G loss: 5.258093]\n",
            "5825 [ D loss: 0.157240, acc.: 94%] [G loss: 4.814809]\n",
            "5826 [ D loss: 0.199742, acc.: 94%] [G loss: 4.265444]\n",
            "5827 [ D loss: 0.148598, acc.: 95%] [G loss: 4.861843]\n",
            "5828 [ D loss: 0.170738, acc.: 95%] [G loss: 4.918004]\n",
            "5829 [ D loss: 0.142102, acc.: 94%] [G loss: 5.253373]\n",
            "5830 [ D loss: 0.194426, acc.: 91%] [G loss: 7.737477]\n",
            "5831 [ D loss: 0.127752, acc.: 95%] [G loss: 7.054105]\n",
            "5832 [ D loss: 0.169100, acc.: 95%] [G loss: 5.064111]\n",
            "5833 [ D loss: 0.108585, acc.: 97%] [G loss: 6.083313]\n",
            "5834 [ D loss: 0.179518, acc.: 95%] [G loss: 4.558522]\n",
            "5835 [ D loss: 0.074613, acc.: 98%] [G loss: 4.795381]\n",
            "5836 [ D loss: 0.173398, acc.: 95%] [G loss: 9.117463]\n",
            "5837 [ D loss: 0.132645, acc.: 95%] [G loss: 5.669148]\n",
            "5838 [ D loss: 0.153741, acc.: 93%] [G loss: 6.642227]\n",
            "5839 [ D loss: 0.103625, acc.: 97%] [G loss: 5.338953]\n",
            "5840 [ D loss: 0.100691, acc.: 98%] [G loss: 10.407038]\n",
            "5841 [ D loss: 0.106919, acc.: 96%] [G loss: 7.304917]\n",
            "5842 [ D loss: 0.139904, acc.: 95%] [G loss: 5.957111]\n",
            "5843 [ D loss: 0.119573, acc.: 96%] [G loss: 7.910936]\n",
            "5844 [ D loss: 0.192454, acc.: 90%] [G loss: 4.451506]\n",
            "5845 [ D loss: 0.224408, acc.: 92%] [G loss: 4.523706]\n",
            "5846 [ D loss: 0.210727, acc.: 91%] [G loss: 4.985035]\n",
            "5847 [ D loss: 0.140170, acc.: 93%] [G loss: 5.407646]\n",
            "5848 [ D loss: 0.119608, acc.: 96%] [G loss: 4.444418]\n",
            "5849 [ D loss: 0.128954, acc.: 97%] [G loss: 4.910068]\n",
            "5850 [ D loss: 0.189080, acc.: 91%] [G loss: 4.335678]\n",
            "5851 [ D loss: 0.260601, acc.: 88%] [G loss: 4.692989]\n",
            "5852 [ D loss: 0.152402, acc.: 95%] [G loss: 5.768629]\n",
            "5853 [ D loss: 0.148087, acc.: 94%] [G loss: 5.201416]\n",
            "5854 [ D loss: 0.218623, acc.: 91%] [G loss: 5.780878]\n",
            "5855 [ D loss: 0.198993, acc.: 95%] [G loss: 4.744133]\n",
            "5856 [ D loss: 0.214550, acc.: 91%] [G loss: 4.374939]\n",
            "5857 [ D loss: 0.155310, acc.: 95%] [G loss: 5.328601]\n",
            "5858 [ D loss: 0.091424, acc.: 96%] [G loss: 7.265779]\n",
            "5859 [ D loss: 0.105551, acc.: 97%] [G loss: 6.504390]\n",
            "5860 [ D loss: 0.151451, acc.: 94%] [G loss: 6.227312]\n",
            "5861 [ D loss: 0.104308, acc.: 98%] [G loss: 4.872871]\n",
            "5862 [ D loss: 0.127973, acc.: 95%] [G loss: 5.280865]\n",
            "5863 [ D loss: 0.081274, acc.: 99%] [G loss: 5.536612]\n",
            "5864 [ D loss: 0.168506, acc.: 94%] [G loss: 5.145880]\n",
            "5865 [ D loss: 0.141956, acc.: 95%] [G loss: 4.657222]\n",
            "5866 [ D loss: 0.129288, acc.: 95%] [G loss: 6.443457]\n",
            "5867 [ D loss: 0.195014, acc.: 94%] [G loss: 4.946295]\n",
            "5868 [ D loss: 0.124352, acc.: 96%] [G loss: 5.971863]\n",
            "5869 [ D loss: 0.155351, acc.: 95%] [G loss: 4.739153]\n",
            "5870 [ D loss: 0.134370, acc.: 95%] [G loss: 5.168581]\n",
            "5871 [ D loss: 0.169627, acc.: 91%] [G loss: 10.142665]\n",
            "5872 [ D loss: 0.122704, acc.: 96%] [G loss: 6.748250]\n",
            "5873 [ D loss: 0.155501, acc.: 92%] [G loss: 4.733885]\n",
            "5874 [ D loss: 0.186597, acc.: 91%] [G loss: 4.690153]\n",
            "5875 [ D loss: 0.188734, acc.: 96%] [G loss: 5.143940]\n",
            "5876 [ D loss: 0.062520, acc.: 98%] [G loss: 4.971550]\n",
            "5877 [ D loss: 0.149132, acc.: 97%] [G loss: 6.150812]\n",
            "5878 [ D loss: 0.202865, acc.: 95%] [G loss: 5.091135]\n",
            "5879 [ D loss: 0.055160, acc.: 98%] [G loss: 10.778502]\n",
            "5880 [ D loss: 0.230048, acc.: 91%] [G loss: 13.356948]\n",
            "5881 [ D loss: 0.084250, acc.: 99%] [G loss: 7.278593]\n",
            "5882 [ D loss: 0.096193, acc.: 95%] [G loss: 6.394644]\n",
            "5883 [ D loss: 0.059374, acc.: 99%] [G loss: 11.180073]\n",
            "5884 [ D loss: 0.128317, acc.: 96%] [G loss: 6.948958]\n",
            "5885 [ D loss: 0.145427, acc.: 97%] [G loss: 6.992302]\n",
            "5886 [ D loss: 0.149791, acc.: 95%] [G loss: 11.397651]\n",
            "5887 [ D loss: 0.120219, acc.: 98%] [G loss: 6.399920]\n",
            "5888 [ D loss: 0.126859, acc.: 98%] [G loss: 3.886227]\n",
            "5889 [ D loss: 0.078312, acc.: 99%] [G loss: 5.083766]\n",
            "5890 [ D loss: 0.145063, acc.: 97%] [G loss: 4.354080]\n",
            "5891 [ D loss: 0.161626, acc.: 94%] [G loss: 4.759550]\n",
            "5892 [ D loss: 0.090784, acc.: 98%] [G loss: 4.294528]\n",
            "5893 [ D loss: 0.170295, acc.: 95%] [G loss: 4.747215]\n",
            "5894 [ D loss: 0.129263, acc.: 95%] [G loss: 4.777213]\n",
            "5895 [ D loss: 0.177283, acc.: 95%] [G loss: 8.959142]\n",
            "5896 [ D loss: 0.101654, acc.: 97%] [G loss: 6.414206]\n",
            "5897 [ D loss: 0.129919, acc.: 97%] [G loss: 7.151426]\n",
            "5898 [ D loss: 0.106228, acc.: 95%] [G loss: 7.227525]\n",
            "5899 [ D loss: 0.104402, acc.: 97%] [G loss: 4.611631]\n",
            "5900 [ D loss: 0.224363, acc.: 89%] [G loss: 6.956921]\n",
            "5901 [ D loss: 0.214896, acc.: 91%] [G loss: 5.727823]\n",
            "5902 [ D loss: 0.135593, acc.: 98%] [G loss: 5.784088]\n",
            "5903 [ D loss: 0.124213, acc.: 98%] [G loss: 4.655015]\n",
            "5904 [ D loss: 0.178638, acc.: 93%] [G loss: 7.223050]\n",
            "5905 [ D loss: 0.096968, acc.: 97%] [G loss: 5.890720]\n",
            "5906 [ D loss: 0.181266, acc.: 95%] [G loss: 4.779813]\n",
            "5907 [ D loss: 0.085269, acc.: 98%] [G loss: 8.070539]\n",
            "5908 [ D loss: 0.116540, acc.: 95%] [G loss: 5.613993]\n",
            "5909 [ D loss: 0.157344, acc.: 95%] [G loss: 4.657490]\n",
            "5910 [ D loss: 0.143125, acc.: 97%] [G loss: 5.000705]\n",
            "5911 [ D loss: 0.150134, acc.: 94%] [G loss: 4.690587]\n",
            "5912 [ D loss: 0.190702, acc.: 91%] [G loss: 6.680096]\n",
            "5913 [ D loss: 0.209989, acc.: 91%] [G loss: 4.169307]\n",
            "5914 [ D loss: 0.217085, acc.: 93%] [G loss: 5.287274]\n",
            "5915 [ D loss: 0.333709, acc.: 84%] [G loss: 4.921790]\n",
            "5916 [ D loss: 0.282420, acc.: 84%] [G loss: 5.244931]\n",
            "5917 [ D loss: 0.298212, acc.: 89%] [G loss: 5.278669]\n",
            "5918 [ D loss: 0.194613, acc.: 93%] [G loss: 5.483071]\n",
            "5919 [ D loss: 0.301345, acc.: 88%] [G loss: 5.711765]\n",
            "5920 [ D loss: 0.325943, acc.: 86%] [G loss: 4.954781]\n",
            "5921 [ D loss: 0.183325, acc.: 93%] [G loss: 7.783952]\n",
            "5922 [ D loss: 0.058491, acc.: 100%] [G loss: 6.358024]\n",
            "5923 [ D loss: 0.131438, acc.: 96%] [G loss: 4.388251]\n",
            "5924 [ D loss: 0.150647, acc.: 95%] [G loss: 5.774591]\n",
            "5925 [ D loss: 0.083752, acc.: 98%] [G loss: 8.223156]\n",
            "5926 [ D loss: 0.091414, acc.: 98%] [G loss: 6.299662]\n",
            "5927 [ D loss: 0.115453, acc.: 95%] [G loss: 4.980282]\n",
            "5928 [ D loss: 0.109635, acc.: 95%] [G loss: 6.371217]\n",
            "5929 [ D loss: 0.206053, acc.: 91%] [G loss: 5.569544]\n",
            "5930 [ D loss: 0.104848, acc.: 97%] [G loss: 7.046945]\n",
            "5931 [ D loss: 0.129054, acc.: 95%] [G loss: 5.140067]\n",
            "5932 [ D loss: 0.251464, acc.: 89%] [G loss: 4.984407]\n",
            "5933 [ D loss: 0.213082, acc.: 88%] [G loss: 7.646966]\n",
            "5934 [ D loss: 0.131882, acc.: 95%] [G loss: 4.001560]\n",
            "5935 [ D loss: 0.117189, acc.: 96%] [G loss: 3.966402]\n",
            "5936 [ D loss: 0.132014, acc.: 95%] [G loss: 4.346011]\n",
            "5937 [ D loss: 0.135477, acc.: 93%] [G loss: 6.456925]\n",
            "5938 [ D loss: 0.171148, acc.: 95%] [G loss: 5.481553]\n",
            "5939 [ D loss: 0.147695, acc.: 96%] [G loss: 5.280386]\n",
            "5940 [ D loss: 0.103698, acc.: 98%] [G loss: 5.410426]\n",
            "5941 [ D loss: 0.174075, acc.: 92%] [G loss: 4.392989]\n",
            "5942 [ D loss: 0.139223, acc.: 95%] [G loss: 5.148699]\n",
            "5943 [ D loss: 0.211979, acc.: 93%] [G loss: 4.979240]\n",
            "5944 [ D loss: 0.173465, acc.: 94%] [G loss: 7.703412]\n",
            "5945 [ D loss: 0.106946, acc.: 98%] [G loss: 6.621791]\n",
            "5946 [ D loss: 0.213185, acc.: 90%] [G loss: 8.201099]\n",
            "5947 [ D loss: 0.120080, acc.: 95%] [G loss: 6.767313]\n",
            "5948 [ D loss: 0.138200, acc.: 94%] [G loss: 4.914279]\n",
            "5949 [ D loss: 0.152445, acc.: 95%] [G loss: 9.906922]\n",
            "5950 [ D loss: 0.139816, acc.: 93%] [G loss: 5.784808]\n",
            "5951 [ D loss: 0.214545, acc.: 91%] [G loss: 6.932051]\n",
            "5952 [ D loss: 0.165446, acc.: 94%] [G loss: 5.946792]\n",
            "5953 [ D loss: 0.130626, acc.: 97%] [G loss: 4.426832]\n",
            "5954 [ D loss: 0.114108, acc.: 96%] [G loss: 4.997200]\n",
            "5955 [ D loss: 0.196690, acc.: 94%] [G loss: 5.553445]\n",
            "5956 [ D loss: 0.254020, acc.: 91%] [G loss: 3.972564]\n",
            "5957 [ D loss: 0.140681, acc.: 97%] [G loss: 4.566668]\n",
            "5958 [ D loss: 0.171925, acc.: 93%] [G loss: 5.253117]\n",
            "5959 [ D loss: 0.162383, acc.: 95%] [G loss: 4.482630]\n",
            "5960 [ D loss: 0.191419, acc.: 91%] [G loss: 5.838521]\n",
            "5961 [ D loss: 0.238421, acc.: 90%] [G loss: 3.759182]\n",
            "5962 [ D loss: 0.167617, acc.: 93%] [G loss: 5.286029]\n",
            "5963 [ D loss: 0.136866, acc.: 96%] [G loss: 12.482672]\n",
            "5964 [ D loss: 0.242897, acc.: 88%] [G loss: 5.039833]\n",
            "5965 [ D loss: 0.183927, acc.: 92%] [G loss: 8.354393]\n",
            "5966 [ D loss: 0.083439, acc.: 99%] [G loss: 5.691270]\n",
            "5967 [ D loss: 0.181486, acc.: 95%] [G loss: 6.384021]\n",
            "5968 [ D loss: 0.141092, acc.: 97%] [G loss: 4.867152]\n",
            "5969 [ D loss: 0.198751, acc.: 93%] [G loss: 5.328825]\n",
            "5970 [ D loss: 0.217613, acc.: 92%] [G loss: 6.080173]\n",
            "5971 [ D loss: 0.075689, acc.: 98%] [G loss: 6.190438]\n",
            "5972 [ D loss: 0.121203, acc.: 97%] [G loss: 8.639726]\n",
            "5973 [ D loss: 0.137196, acc.: 95%] [G loss: 5.156727]\n",
            "5974 [ D loss: 0.131007, acc.: 96%] [G loss: 4.955211]\n",
            "5975 [ D loss: 0.137608, acc.: 95%] [G loss: 5.029696]\n",
            "5976 [ D loss: 0.262948, acc.: 87%] [G loss: 6.072246]\n",
            "5977 [ D loss: 0.229720, acc.: 88%] [G loss: 6.199376]\n",
            "5978 [ D loss: 0.291411, acc.: 86%] [G loss: 6.518774]\n",
            "5979 [ D loss: 0.148006, acc.: 94%] [G loss: 5.077971]\n",
            "5980 [ D loss: 0.067124, acc.: 98%] [G loss: 12.785930]\n",
            "5981 [ D loss: 0.125602, acc.: 96%] [G loss: 7.125443]\n",
            "5982 [ D loss: 0.135349, acc.: 94%] [G loss: 6.546567]\n",
            "5983 [ D loss: 0.169491, acc.: 93%] [G loss: 5.704310]\n",
            "5984 [ D loss: 0.176443, acc.: 92%] [G loss: 5.454765]\n",
            "5985 [ D loss: 0.113255, acc.: 96%] [G loss: 5.873476]\n",
            "5986 [ D loss: 0.131338, acc.: 95%] [G loss: 12.067830]\n",
            "5987 [ D loss: 0.208934, acc.: 93%] [G loss: 7.025577]\n",
            "5988 [ D loss: 0.180132, acc.: 95%] [G loss: 4.799759]\n",
            "5989 [ D loss: 0.104699, acc.: 96%] [G loss: 4.813890]\n",
            "5990 [ D loss: 0.201344, acc.: 91%] [G loss: 4.677777]\n",
            "5991 [ D loss: 0.215276, acc.: 92%] [G loss: 5.210673]\n",
            "5992 [ D loss: 0.149775, acc.: 95%] [G loss: 4.302928]\n",
            "5993 [ D loss: 0.130024, acc.: 95%] [G loss: 4.396662]\n",
            "5994 [ D loss: 0.159318, acc.: 93%] [G loss: 5.291371]\n",
            "5995 [ D loss: 0.135305, acc.: 96%] [G loss: 5.140451]\n",
            "5996 [ D loss: 0.130346, acc.: 98%] [G loss: 4.825016]\n",
            "5997 [ D loss: 0.116367, acc.: 96%] [G loss: 5.014867]\n",
            "5998 [ D loss: 0.173863, acc.: 93%] [G loss: 4.237044]\n",
            "5999 [ D loss: 0.169665, acc.: 93%] [G loss: 4.814646]\n",
            "6000 [ D loss: 0.245259, acc.: 93%] [G loss: 4.881189]\n",
            "6001 [ D loss: 0.122981, acc.: 97%] [G loss: 5.566806]\n",
            "6002 [ D loss: 0.183859, acc.: 95%] [G loss: 5.267806]\n",
            "6003 [ D loss: 0.133682, acc.: 95%] [G loss: 4.681365]\n",
            "6004 [ D loss: 0.158258, acc.: 95%] [G loss: 4.639431]\n",
            "6005 [ D loss: 0.193482, acc.: 92%] [G loss: 3.265595]\n",
            "6006 [ D loss: 0.088257, acc.: 97%] [G loss: 6.412644]\n",
            "6007 [ D loss: 0.146856, acc.: 95%] [G loss: 5.957170]\n",
            "6008 [ D loss: 0.138379, acc.: 95%] [G loss: 4.910721]\n",
            "6009 [ D loss: 0.119132, acc.: 95%] [G loss: 5.394629]\n",
            "6010 [ D loss: 0.150646, acc.: 96%] [G loss: 4.470989]\n",
            "6011 [ D loss: 0.196771, acc.: 95%] [G loss: 5.522746]\n",
            "6012 [ D loss: 0.214142, acc.: 94%] [G loss: 3.964207]\n",
            "6013 [ D loss: 0.079429, acc.: 98%] [G loss: 4.725981]\n",
            "6014 [ D loss: 0.207736, acc.: 92%] [G loss: 3.915540]\n",
            "6015 [ D loss: 0.201060, acc.: 92%] [G loss: 4.841848]\n",
            "6016 [ D loss: 0.262362, acc.: 89%] [G loss: 8.183236]\n",
            "6017 [ D loss: 0.152860, acc.: 95%] [G loss: 6.609910]\n",
            "6018 [ D loss: 0.181537, acc.: 91%] [G loss: 4.872321]\n",
            "6019 [ D loss: 0.164945, acc.: 92%] [G loss: 5.650748]\n",
            "6020 [ D loss: 0.204129, acc.: 92%] [G loss: 5.208849]\n",
            "6021 [ D loss: 0.154987, acc.: 95%] [G loss: 5.061494]\n",
            "6022 [ D loss: 0.258809, acc.: 88%] [G loss: 3.983640]\n",
            "6023 [ D loss: 0.212196, acc.: 93%] [G loss: 4.035639]\n",
            "6024 [ D loss: 0.190066, acc.: 91%] [G loss: 5.536942]\n",
            "6025 [ D loss: 0.101776, acc.: 95%] [G loss: 7.307718]\n",
            "6026 [ D loss: 0.121010, acc.: 95%] [G loss: 6.273637]\n",
            "6027 [ D loss: 0.128148, acc.: 94%] [G loss: 4.972626]\n",
            "6028 [ D loss: 0.128136, acc.: 95%] [G loss: 3.544606]\n",
            "6029 [ D loss: 0.227500, acc.: 89%] [G loss: 4.521146]\n",
            "6030 [ D loss: 0.299658, acc.: 88%] [G loss: 4.281015]\n",
            "6031 [ D loss: 0.208878, acc.: 91%] [G loss: 4.751365]\n",
            "6032 [ D loss: 0.160386, acc.: 95%] [G loss: 4.796182]\n",
            "6033 [ D loss: 0.206202, acc.: 92%] [G loss: 4.515915]\n",
            "6034 [ D loss: 0.154369, acc.: 95%] [G loss: 4.797810]\n",
            "6035 [ D loss: 0.184100, acc.: 95%] [G loss: 4.631058]\n",
            "6036 [ D loss: 0.102570, acc.: 98%] [G loss: 5.622944]\n",
            "6037 [ D loss: 0.246801, acc.: 89%] [G loss: 4.962234]\n",
            "6038 [ D loss: 0.170080, acc.: 92%] [G loss: 4.279399]\n",
            "6039 [ D loss: 0.373069, acc.: 82%] [G loss: 6.137785]\n",
            "6040 [ D loss: 0.299600, acc.: 89%] [G loss: 4.521106]\n",
            "6041 [ D loss: 0.063898, acc.: 98%] [G loss: 3.976240]\n",
            "6042 [ D loss: 0.112065, acc.: 97%] [G loss: 8.965906]\n",
            "6043 [ D loss: 0.140040, acc.: 96%] [G loss: 5.546813]\n",
            "6044 [ D loss: 0.162968, acc.: 95%] [G loss: 6.281843]\n",
            "6045 [ D loss: 0.127699, acc.: 97%] [G loss: 7.940976]\n",
            "6046 [ D loss: 0.124614, acc.: 97%] [G loss: 5.281889]\n",
            "6047 [ D loss: 0.224145, acc.: 89%] [G loss: 4.940448]\n",
            "6048 [ D loss: 0.216457, acc.: 93%] [G loss: 4.675999]\n",
            "6049 [ D loss: 0.218256, acc.: 94%] [G loss: 4.443207]\n",
            "6050 [ D loss: 0.161268, acc.: 94%] [G loss: 5.969686]\n",
            "6051 [ D loss: 0.183515, acc.: 93%] [G loss: 3.759897]\n",
            "6052 [ D loss: 0.191402, acc.: 91%] [G loss: 5.157954]\n",
            "6053 [ D loss: 0.205153, acc.: 92%] [G loss: 5.699452]\n",
            "6054 [ D loss: 0.209864, acc.: 92%] [G loss: 6.257506]\n",
            "6055 [ D loss: 0.109920, acc.: 96%] [G loss: 9.398735]\n",
            "6056 [ D loss: 0.161575, acc.: 94%] [G loss: 12.174593]\n",
            "6057 [ D loss: 0.069438, acc.: 99%] [G loss: 9.475243]\n",
            "6058 [ D loss: 0.106322, acc.: 96%] [G loss: 5.441290]\n",
            "6059 [ D loss: 0.102632, acc.: 97%] [G loss: 9.376938]\n",
            "6060 [ D loss: 0.123013, acc.: 95%] [G loss: 10.389887]\n",
            "6061 [ D loss: 0.122620, acc.: 97%] [G loss: 6.024384]\n",
            "6062 [ D loss: 0.125085, acc.: 96%] [G loss: 3.668057]\n",
            "6063 [ D loss: 0.139298, acc.: 95%] [G loss: 6.446594]\n",
            "6064 [ D loss: 0.173783, acc.: 91%] [G loss: 6.678909]\n",
            "6065 [ D loss: 0.199137, acc.: 92%] [G loss: 4.510232]\n",
            "6066 [ D loss: 0.142168, acc.: 93%] [G loss: 7.257866]\n",
            "6067 [ D loss: 0.206137, acc.: 92%] [G loss: 7.867695]\n",
            "6068 [ D loss: 0.129083, acc.: 96%] [G loss: 5.474710]\n",
            "6069 [ D loss: 0.151010, acc.: 96%] [G loss: 5.848292]\n",
            "6070 [ D loss: 0.157927, acc.: 93%] [G loss: 5.341214]\n",
            "6071 [ D loss: 0.157896, acc.: 95%] [G loss: 4.722016]\n",
            "6072 [ D loss: 0.129926, acc.: 96%] [G loss: 4.385632]\n",
            "6073 [ D loss: 0.167052, acc.: 94%] [G loss: 4.408416]\n",
            "6074 [ D loss: 0.156696, acc.: 95%] [G loss: 4.611383]\n",
            "6075 [ D loss: 0.294097, acc.: 89%] [G loss: 2.991025]\n",
            "6076 [ D loss: 0.088562, acc.: 98%] [G loss: 5.622929]\n",
            "6077 [ D loss: 0.207542, acc.: 91%] [G loss: 8.435509]\n",
            "6078 [ D loss: 0.129589, acc.: 95%] [G loss: 5.163598]\n",
            "6079 [ D loss: 0.083912, acc.: 99%] [G loss: 6.281395]\n",
            "6080 [ D loss: 0.238002, acc.: 91%] [G loss: 5.942686]\n",
            "6081 [ D loss: 0.114253, acc.: 95%] [G loss: 5.432580]\n",
            "6082 [ D loss: 0.266779, acc.: 91%] [G loss: 3.474438]\n",
            "6083 [ D loss: 0.091934, acc.: 98%] [G loss: 4.789771]\n",
            "6084 [ D loss: 0.150164, acc.: 95%] [G loss: 5.806962]\n",
            "6085 [ D loss: 0.073854, acc.: 98%] [G loss: 5.794288]\n",
            "6086 [ D loss: 0.118855, acc.: 96%] [G loss: 4.985244]\n",
            "6087 [ D loss: 0.107362, acc.: 96%] [G loss: 8.369827]\n",
            "6088 [ D loss: 0.155197, acc.: 92%] [G loss: 6.494116]\n",
            "6089 [ D loss: 0.202299, acc.: 93%] [G loss: 7.206429]\n",
            "6090 [ D loss: 0.148267, acc.: 94%] [G loss: 7.315594]\n",
            "6091 [ D loss: 0.161012, acc.: 92%] [G loss: 4.790291]\n",
            "6092 [ D loss: 0.149770, acc.: 97%] [G loss: 6.869623]\n",
            "6093 [ D loss: 0.172123, acc.: 94%] [G loss: 4.489371]\n",
            "6094 [ D loss: 0.076044, acc.: 99%] [G loss: 4.836111]\n",
            "6095 [ D loss: 0.156571, acc.: 95%] [G loss: 3.794832]\n",
            "6096 [ D loss: 0.119993, acc.: 94%] [G loss: 6.573671]\n",
            "6097 [ D loss: 0.173515, acc.: 94%] [G loss: 5.435654]\n",
            "6098 [ D loss: 0.164917, acc.: 94%] [G loss: 4.388498]\n",
            "6099 [ D loss: 0.086412, acc.: 98%] [G loss: 8.255482]\n",
            "6100 [ D loss: 0.189942, acc.: 93%] [G loss: 6.350074]\n",
            "6101 [ D loss: 0.185193, acc.: 93%] [G loss: 4.512040]\n",
            "6102 [ D loss: 0.174903, acc.: 93%] [G loss: 4.044043]\n",
            "6103 [ D loss: 0.112352, acc.: 97%] [G loss: 4.600877]\n",
            "6104 [ D loss: 0.201204, acc.: 93%] [G loss: 4.023412]\n",
            "6105 [ D loss: 0.144639, acc.: 96%] [G loss: 5.630504]\n",
            "6106 [ D loss: 0.261234, acc.: 89%] [G loss: 4.675878]\n",
            "6107 [ D loss: 0.098835, acc.: 98%] [G loss: 5.102919]\n",
            "6108 [ D loss: 0.252336, acc.: 91%] [G loss: 4.553320]\n",
            "6109 [ D loss: 0.123503, acc.: 95%] [G loss: 5.194169]\n",
            "6110 [ D loss: 0.125976, acc.: 95%] [G loss: 5.372324]\n",
            "6111 [ D loss: 0.218663, acc.: 91%] [G loss: 5.932062]\n",
            "6112 [ D loss: 0.135664, acc.: 95%] [G loss: 6.283135]\n",
            "6113 [ D loss: 0.090267, acc.: 98%] [G loss: 5.300634]\n",
            "6114 [ D loss: 0.339872, acc.: 85%] [G loss: 4.235767]\n",
            "6115 [ D loss: 0.224102, acc.: 91%] [G loss: 4.889268]\n",
            "6116 [ D loss: 0.100184, acc.: 98%] [G loss: 5.011742]\n",
            "6117 [ D loss: 0.280107, acc.: 88%] [G loss: 6.781644]\n",
            "6118 [ D loss: 0.170740, acc.: 94%] [G loss: 5.159976]\n",
            "6119 [ D loss: 0.094797, acc.: 97%] [G loss: 7.573386]\n",
            "6120 [ D loss: 0.090308, acc.: 99%] [G loss: 5.386962]\n",
            "6121 [ D loss: 0.157602, acc.: 93%] [G loss: 5.122987]\n",
            "6122 [ D loss: 0.120522, acc.: 95%] [G loss: 6.122662]\n",
            "6123 [ D loss: 0.196403, acc.: 91%] [G loss: 5.233661]\n",
            "6124 [ D loss: 0.132791, acc.: 96%] [G loss: 8.382542]\n",
            "6125 [ D loss: 0.153900, acc.: 94%] [G loss: 5.051156]\n",
            "6126 [ D loss: 0.073818, acc.: 98%] [G loss: 5.716353]\n",
            "6127 [ D loss: 0.057567, acc.: 98%] [G loss: 10.795774]\n",
            "6128 [ D loss: 0.093960, acc.: 97%] [G loss: 8.730670]\n",
            "6129 [ D loss: 0.075068, acc.: 98%] [G loss: 5.919840]\n",
            "6130 [ D loss: 0.100310, acc.: 97%] [G loss: 6.910583]\n",
            "6131 [ D loss: 0.117711, acc.: 97%] [G loss: 8.608854]\n",
            "6132 [ D loss: 0.264296, acc.: 88%] [G loss: 5.122381]\n",
            "6133 [ D loss: 0.156845, acc.: 95%] [G loss: 5.484625]\n",
            "6134 [ D loss: 0.129015, acc.: 96%] [G loss: 5.381963]\n",
            "6135 [ D loss: 0.194575, acc.: 94%] [G loss: 5.278636]\n",
            "6136 [ D loss: 0.124717, acc.: 95%] [G loss: 9.144341]\n",
            "6137 [ D loss: 0.139160, acc.: 95%] [G loss: 5.183647]\n",
            "6138 [ D loss: 0.178684, acc.: 94%] [G loss: 5.158904]\n",
            "6139 [ D loss: 0.073152, acc.: 100%] [G loss: 5.504606]\n",
            "6140 [ D loss: 0.139159, acc.: 95%] [G loss: 4.935441]\n",
            "6141 [ D loss: 0.127520, acc.: 96%] [G loss: 7.760425]\n",
            "6142 [ D loss: 0.102770, acc.: 96%] [G loss: 6.061222]\n",
            "6143 [ D loss: 0.101157, acc.: 98%] [G loss: 13.911945]\n",
            "6144 [ D loss: 0.091872, acc.: 97%] [G loss: 10.958177]\n",
            "6145 [ D loss: 0.076158, acc.: 98%] [G loss: 7.041496]\n",
            "6146 [ D loss: 0.138189, acc.: 94%] [G loss: 6.209950]\n",
            "6147 [ D loss: 0.137711, acc.: 96%] [G loss: 5.609583]\n",
            "6148 [ D loss: 0.193642, acc.: 92%] [G loss: 4.751967]\n",
            "6149 [ D loss: 0.217612, acc.: 95%] [G loss: 4.977654]\n",
            "6150 [ D loss: 0.202840, acc.: 91%] [G loss: 4.420291]\n",
            "6151 [ D loss: 0.205183, acc.: 92%] [G loss: 4.386732]\n",
            "6152 [ D loss: 0.154287, acc.: 94%] [G loss: 4.114288]\n",
            "6153 [ D loss: 0.273478, acc.: 83%] [G loss: 6.518129]\n",
            "6154 [ D loss: 0.115676, acc.: 96%] [G loss: 9.470058]\n",
            "6155 [ D loss: 0.129828, acc.: 95%] [G loss: 6.604400]\n",
            "6156 [ D loss: 0.113815, acc.: 97%] [G loss: 7.565331]\n",
            "6157 [ D loss: 0.120278, acc.: 95%] [G loss: 6.059900]\n",
            "6158 [ D loss: 0.144104, acc.: 93%] [G loss: 4.532702]\n",
            "6159 [ D loss: 0.079966, acc.: 97%] [G loss: 5.950766]\n",
            "6160 [ D loss: 0.336314, acc.: 80%] [G loss: 7.670825]\n",
            "6161 [ D loss: 0.281690, acc.: 91%] [G loss: 6.354073]\n",
            "6162 [ D loss: 0.153219, acc.: 92%] [G loss: 9.761025]\n",
            "6163 [ D loss: 0.157194, acc.: 94%] [G loss: 8.218691]\n",
            "6164 [ D loss: 0.106962, acc.: 95%] [G loss: 5.263967]\n",
            "6165 [ D loss: 0.062749, acc.: 98%] [G loss: 5.649307]\n",
            "6166 [ D loss: 0.146492, acc.: 95%] [G loss: 4.762656]\n",
            "6167 [ D loss: 0.237920, acc.: 91%] [G loss: 10.752117]\n",
            "6168 [ D loss: 0.255360, acc.: 89%] [G loss: 7.361319]\n",
            "6169 [ D loss: 0.105526, acc.: 95%] [G loss: 5.726035]\n",
            "6170 [ D loss: 0.164457, acc.: 94%] [G loss: 4.625615]\n",
            "6171 [ D loss: 0.224678, acc.: 90%] [G loss: 4.109031]\n",
            "6172 [ D loss: 0.187242, acc.: 95%] [G loss: 5.518738]\n",
            "6173 [ D loss: 0.163074, acc.: 95%] [G loss: 5.210885]\n",
            "6174 [ D loss: 0.193310, acc.: 93%] [G loss: 5.557881]\n",
            "6175 [ D loss: 0.206617, acc.: 91%] [G loss: 4.855282]\n",
            "6176 [ D loss: 0.131334, acc.: 96%] [G loss: 6.151562]\n",
            "6177 [ D loss: 0.247886, acc.: 89%] [G loss: 5.909364]\n",
            "6178 [ D loss: 0.173165, acc.: 92%] [G loss: 5.257649]\n",
            "6179 [ D loss: 0.056878, acc.: 99%] [G loss: 6.638943]\n",
            "6180 [ D loss: 0.124318, acc.: 95%] [G loss: 5.375919]\n",
            "6181 [ D loss: 0.100563, acc.: 96%] [G loss: 9.332331]\n",
            "6182 [ D loss: 0.082387, acc.: 98%] [G loss: 6.490956]\n",
            "6183 [ D loss: 0.069065, acc.: 99%] [G loss: 5.540812]\n",
            "6184 [ D loss: 0.136826, acc.: 95%] [G loss: 5.225196]\n",
            "6185 [ D loss: 0.137369, acc.: 95%] [G loss: 4.432046]\n",
            "6186 [ D loss: 0.152203, acc.: 95%] [G loss: 5.098867]\n",
            "6187 [ D loss: 0.135264, acc.: 95%] [G loss: 6.277830]\n",
            "6188 [ D loss: 0.136388, acc.: 94%] [G loss: 5.692299]\n",
            "6189 [ D loss: 0.198069, acc.: 91%] [G loss: 3.979274]\n",
            "6190 [ D loss: 0.131720, acc.: 97%] [G loss: 5.287032]\n",
            "6191 [ D loss: 0.163552, acc.: 95%] [G loss: 6.546330]\n",
            "6192 [ D loss: 0.218545, acc.: 89%] [G loss: 5.900828]\n",
            "6193 [ D loss: 0.153355, acc.: 93%] [G loss: 5.201897]\n",
            "6194 [ D loss: 0.166896, acc.: 94%] [G loss: 6.575613]\n",
            "6195 [ D loss: 0.110495, acc.: 98%] [G loss: 7.819016]\n",
            "6196 [ D loss: 0.143969, acc.: 95%] [G loss: 7.653675]\n",
            "6197 [ D loss: 0.089092, acc.: 98%] [G loss: 7.986214]\n",
            "6198 [ D loss: 0.133914, acc.: 95%] [G loss: 6.308832]\n",
            "6199 [ D loss: 0.242952, acc.: 91%] [G loss: 5.356570]\n",
            "6200 [ D loss: 0.108098, acc.: 96%] [G loss: 5.623919]\n",
            "6201 [ D loss: 0.163862, acc.: 95%] [G loss: 6.592247]\n",
            "6202 [ D loss: 0.180298, acc.: 93%] [G loss: 4.424875]\n",
            "6203 [ D loss: 0.078709, acc.: 98%] [G loss: 5.514243]\n",
            "6204 [ D loss: 0.194661, acc.: 94%] [G loss: 3.917730]\n",
            "6205 [ D loss: 0.298113, acc.: 88%] [G loss: 6.285983]\n",
            "6206 [ D loss: 0.159096, acc.: 94%] [G loss: 6.436130]\n",
            "6207 [ D loss: 0.284514, acc.: 85%] [G loss: 5.136299]\n",
            "6208 [ D loss: 0.127201, acc.: 95%] [G loss: 4.847838]\n",
            "6209 [ D loss: 0.288399, acc.: 87%] [G loss: 5.489242]\n",
            "6210 [ D loss: 0.112157, acc.: 95%] [G loss: 6.222808]\n",
            "6211 [ D loss: 0.179987, acc.: 95%] [G loss: 5.499934]\n",
            "6212 [ D loss: 0.108196, acc.: 98%] [G loss: 7.880546]\n",
            "6213 [ D loss: 0.128910, acc.: 97%] [G loss: 5.577691]\n",
            "6214 [ D loss: 0.139917, acc.: 95%] [G loss: 4.259042]\n",
            "6215 [ D loss: 0.139847, acc.: 95%] [G loss: 6.736166]\n",
            "6216 [ D loss: 0.122813, acc.: 95%] [G loss: 4.650413]\n",
            "6217 [ D loss: 0.201526, acc.: 94%] [G loss: 5.517936]\n",
            "6218 [ D loss: 0.190501, acc.: 93%] [G loss: 5.223284]\n",
            "6219 [ D loss: 0.191219, acc.: 91%] [G loss: 7.316421]\n",
            "6220 [ D loss: 0.096849, acc.: 95%] [G loss: 4.648878]\n",
            "6221 [ D loss: 0.276031, acc.: 85%] [G loss: 9.319617]\n",
            "6222 [ D loss: 0.094339, acc.: 98%] [G loss: 10.758907]\n",
            "6223 [ D loss: 0.100268, acc.: 96%] [G loss: 8.733492]\n",
            "6224 [ D loss: 0.143900, acc.: 93%] [G loss: 4.233098]\n",
            "6225 [ D loss: 0.161061, acc.: 92%] [G loss: 5.587850]\n",
            "6226 [ D loss: 0.182668, acc.: 97%] [G loss: 3.845197]\n",
            "6227 [ D loss: 0.195697, acc.: 91%] [G loss: 5.796245]\n",
            "6228 [ D loss: 0.087738, acc.: 98%] [G loss: 6.259840]\n",
            "6229 [ D loss: 0.188036, acc.: 94%] [G loss: 4.842712]\n",
            "6230 [ D loss: 0.115703, acc.: 97%] [G loss: 5.408382]\n",
            "6231 [ D loss: 0.177304, acc.: 95%] [G loss: 6.095107]\n",
            "6232 [ D loss: 0.140160, acc.: 95%] [G loss: 5.074266]\n",
            "6233 [ D loss: 0.166744, acc.: 95%] [G loss: 4.852177]\n",
            "6234 [ D loss: 0.188812, acc.: 93%] [G loss: 4.721038]\n",
            "6235 [ D loss: 0.168578, acc.: 95%] [G loss: 4.689929]\n",
            "6236 [ D loss: 0.242703, acc.: 90%] [G loss: 3.779972]\n",
            "6237 [ D loss: 0.160918, acc.: 95%] [G loss: 5.303593]\n",
            "6238 [ D loss: 0.263221, acc.: 88%] [G loss: 4.651783]\n",
            "6239 [ D loss: 0.134967, acc.: 96%] [G loss: 5.152940]\n",
            "6240 [ D loss: 0.142184, acc.: 95%] [G loss: 7.298150]\n",
            "6241 [ D loss: 0.127756, acc.: 95%] [G loss: 4.308076]\n",
            "6242 [ D loss: 0.129947, acc.: 96%] [G loss: 7.649957]\n",
            "6243 [ D loss: 0.188176, acc.: 93%] [G loss: 4.607981]\n",
            "6244 [ D loss: 0.151878, acc.: 95%] [G loss: 5.052637]\n",
            "6245 [ D loss: 0.272547, acc.: 87%] [G loss: 7.507235]\n",
            "6246 [ D loss: 0.136806, acc.: 96%] [G loss: 4.753344]\n",
            "6247 [ D loss: 0.149018, acc.: 95%] [G loss: 4.388329]\n",
            "6248 [ D loss: 0.259942, acc.: 88%] [G loss: 5.720232]\n",
            "6249 [ D loss: 0.085116, acc.: 96%] [G loss: 6.586855]\n",
            "6250 [ D loss: 0.203804, acc.: 94%] [G loss: 4.764811]\n",
            "6251 [ D loss: 0.138607, acc.: 95%] [G loss: 4.535112]\n",
            "6252 [ D loss: 0.117640, acc.: 95%] [G loss: 5.961982]\n",
            "6253 [ D loss: 0.143505, acc.: 95%] [G loss: 4.104895]\n",
            "6254 [ D loss: 0.178952, acc.: 93%] [G loss: 4.597497]\n",
            "6255 [ D loss: 0.255329, acc.: 90%] [G loss: 4.381699]\n",
            "6256 [ D loss: 0.188080, acc.: 94%] [G loss: 9.915577]\n",
            "6257 [ D loss: 0.112563, acc.: 97%] [G loss: 11.817829]\n",
            "6258 [ D loss: 0.077273, acc.: 98%] [G loss: 9.412326]\n",
            "6259 [ D loss: 0.072134, acc.: 98%] [G loss: 10.827690]\n",
            "6260 [ D loss: 0.070112, acc.: 98%] [G loss: 9.742626]\n",
            "6261 [ D loss: 0.124440, acc.: 95%] [G loss: 7.082263]\n",
            "6262 [ D loss: 0.069095, acc.: 98%] [G loss: 6.374039]\n",
            "6263 [ D loss: 0.074138, acc.: 99%] [G loss: 8.110291]\n",
            "6264 [ D loss: 0.072699, acc.: 99%] [G loss: 6.480227]\n",
            "6265 [ D loss: 0.134738, acc.: 96%] [G loss: 5.881354]\n",
            "6266 [ D loss: 0.145959, acc.: 95%] [G loss: 5.055478]\n",
            "6267 [ D loss: 0.166644, acc.: 94%] [G loss: 5.615762]\n",
            "6268 [ D loss: 0.121651, acc.: 95%] [G loss: 7.019750]\n",
            "6269 [ D loss: 0.147404, acc.: 97%] [G loss: 4.111475]\n",
            "6270 [ D loss: 0.103724, acc.: 97%] [G loss: 4.930882]\n",
            "6271 [ D loss: 0.241340, acc.: 90%] [G loss: 7.029745]\n",
            "6272 [ D loss: 0.218790, acc.: 91%] [G loss: 6.600617]\n",
            "6273 [ D loss: 0.135662, acc.: 97%] [G loss: 6.306683]\n",
            "6274 [ D loss: 0.302148, acc.: 89%] [G loss: 4.397314]\n",
            "6275 [ D loss: 0.119591, acc.: 97%] [G loss: 5.402634]\n",
            "6276 [ D loss: 0.116027, acc.: 96%] [G loss: 5.360287]\n",
            "6277 [ D loss: 0.191996, acc.: 90%] [G loss: 4.413032]\n",
            "6278 [ D loss: 0.173842, acc.: 95%] [G loss: 4.884355]\n",
            "6279 [ D loss: 0.272161, acc.: 90%] [G loss: 4.792356]\n",
            "6280 [ D loss: 0.183629, acc.: 94%] [G loss: 3.935108]\n",
            "6281 [ D loss: 0.175280, acc.: 92%] [G loss: 5.040201]\n",
            "6282 [ D loss: 0.269395, acc.: 92%] [G loss: 3.882037]\n",
            "6283 [ D loss: 0.137434, acc.: 98%] [G loss: 4.703790]\n",
            "6284 [ D loss: 0.181427, acc.: 93%] [G loss: 6.459991]\n",
            "6285 [ D loss: 0.164704, acc.: 94%] [G loss: 12.724106]\n",
            "6286 [ D loss: 0.130884, acc.: 93%] [G loss: 6.151176]\n",
            "6287 [ D loss: 0.107511, acc.: 98%] [G loss: 6.339229]\n",
            "6288 [ D loss: 0.093597, acc.: 98%] [G loss: 9.561070]\n",
            "6289 [ D loss: 0.075411, acc.: 99%] [G loss: 11.071377]\n",
            "6290 [ D loss: 0.121858, acc.: 95%] [G loss: 8.231969]\n",
            "6291 [ D loss: 0.087701, acc.: 96%] [G loss: 7.535251]\n",
            "6292 [ D loss: 0.122165, acc.: 95%] [G loss: 6.400871]\n",
            "6293 [ D loss: 0.104863, acc.: 96%] [G loss: 6.051667]\n",
            "6294 [ D loss: 0.235571, acc.: 92%] [G loss: 5.264969]\n",
            "6295 [ D loss: 0.201640, acc.: 92%] [G loss: 4.441798]\n",
            "6296 [ D loss: 0.145678, acc.: 94%] [G loss: 4.805338]\n",
            "6297 [ D loss: 0.232667, acc.: 93%] [G loss: 4.010405]\n",
            "6298 [ D loss: 0.096393, acc.: 97%] [G loss: 4.980820]\n",
            "6299 [ D loss: 0.289570, acc.: 86%] [G loss: 4.141477]\n",
            "6300 [ D loss: 0.152993, acc.: 95%] [G loss: 4.502189]\n",
            "6301 [ D loss: 0.136010, acc.: 94%] [G loss: 5.860388]\n",
            "6302 [ D loss: 0.110833, acc.: 98%] [G loss: 6.477925]\n",
            "6303 [ D loss: 0.119746, acc.: 97%] [G loss: 4.985571]\n",
            "6304 [ D loss: 0.081634, acc.: 98%] [G loss: 8.258427]\n",
            "6305 [ D loss: 0.191076, acc.: 93%] [G loss: 8.197920]\n",
            "6306 [ D loss: 0.200462, acc.: 92%] [G loss: 7.645847]\n",
            "6307 [ D loss: 0.073051, acc.: 99%] [G loss: 5.429116]\n",
            "6308 [ D loss: 0.118522, acc.: 95%] [G loss: 3.753276]\n",
            "6309 [ D loss: 0.173403, acc.: 94%] [G loss: 4.309665]\n",
            "6310 [ D loss: 0.187037, acc.: 91%] [G loss: 5.562695]\n",
            "6311 [ D loss: 0.163199, acc.: 94%] [G loss: 5.044349]\n",
            "6312 [ D loss: 0.182844, acc.: 94%] [G loss: 4.461968]\n",
            "6313 [ D loss: 0.223961, acc.: 88%] [G loss: 4.469255]\n",
            "6314 [ D loss: 0.120407, acc.: 98%] [G loss: 4.368592]\n",
            "6315 [ D loss: 0.216635, acc.: 92%] [G loss: 5.473177]\n",
            "6316 [ D loss: 0.177339, acc.: 94%] [G loss: 8.661818]\n",
            "6317 [ D loss: 0.158287, acc.: 95%] [G loss: 11.241686]\n",
            "6318 [ D loss: 0.165929, acc.: 94%] [G loss: 4.974742]\n",
            "6319 [ D loss: 0.154890, acc.: 95%] [G loss: 5.386265]\n",
            "6320 [ D loss: 0.094084, acc.: 98%] [G loss: 4.893394]\n",
            "6321 [ D loss: 0.187665, acc.: 92%] [G loss: 8.412782]\n",
            "6322 [ D loss: 0.096095, acc.: 98%] [G loss: 7.052944]\n",
            "6323 [ D loss: 0.157841, acc.: 93%] [G loss: 4.404339]\n",
            "6324 [ D loss: 0.098504, acc.: 97%] [G loss: 6.270604]\n",
            "6325 [ D loss: 0.075861, acc.: 98%] [G loss: 6.580505]\n",
            "6326 [ D loss: 0.096535, acc.: 99%] [G loss: 4.296773]\n",
            "6327 [ D loss: 0.119919, acc.: 95%] [G loss: 5.416446]\n",
            "6328 [ D loss: 0.109415, acc.: 96%] [G loss: 5.299614]\n",
            "6329 [ D loss: 0.145083, acc.: 94%] [G loss: 3.384375]\n",
            "6330 [ D loss: 0.125800, acc.: 96%] [G loss: 6.870283]\n",
            "6331 [ D loss: 0.130913, acc.: 97%] [G loss: 6.345784]\n",
            "6332 [ D loss: 0.146294, acc.: 96%] [G loss: 4.420454]\n",
            "6333 [ D loss: 0.289022, acc.: 91%] [G loss: 5.826623]\n",
            "6334 [ D loss: 0.224672, acc.: 92%] [G loss: 4.944573]\n",
            "6335 [ D loss: 0.171632, acc.: 94%] [G loss: 4.892023]\n",
            "6336 [ D loss: 0.188431, acc.: 92%] [G loss: 5.267708]\n",
            "6337 [ D loss: 0.158989, acc.: 92%] [G loss: 8.089124]\n",
            "6338 [ D loss: 0.098458, acc.: 97%] [G loss: 9.350349]\n",
            "6339 [ D loss: 0.096334, acc.: 95%] [G loss: 8.988447]\n",
            "6340 [ D loss: 0.123422, acc.: 95%] [G loss: 12.106064]\n",
            "6341 [ D loss: 0.059874, acc.: 98%] [G loss: 8.978302]\n",
            "6342 [ D loss: 0.078512, acc.: 98%] [G loss: 10.503242]\n",
            "6343 [ D loss: 0.118408, acc.: 95%] [G loss: 7.329109]\n",
            "6344 [ D loss: 0.184340, acc.: 95%] [G loss: 5.260002]\n",
            "6345 [ D loss: 0.299790, acc.: 86%] [G loss: 5.422700]\n",
            "6346 [ D loss: 0.106405, acc.: 98%] [G loss: 4.902360]\n",
            "6347 [ D loss: 0.274096, acc.: 89%] [G loss: 3.484432]\n",
            "6348 [ D loss: 0.162093, acc.: 95%] [G loss: 4.195143]\n",
            "6349 [ D loss: 0.209128, acc.: 91%] [G loss: 3.982533]\n",
            "6350 [ D loss: 0.117415, acc.: 97%] [G loss: 4.666769]\n",
            "6351 [ D loss: 0.145130, acc.: 96%] [G loss: 5.430398]\n",
            "6352 [ D loss: 0.191103, acc.: 93%] [G loss: 4.611381]\n",
            "6353 [ D loss: 0.172285, acc.: 96%] [G loss: 6.416488]\n",
            "6354 [ D loss: 0.221720, acc.: 91%] [G loss: 2.463535]\n",
            "6355 [ D loss: 0.100566, acc.: 96%] [G loss: 8.298085]\n",
            "6356 [ D loss: 0.332588, acc.: 84%] [G loss: 6.921968]\n",
            "6357 [ D loss: 0.177689, acc.: 92%] [G loss: 5.891809]\n",
            "6358 [ D loss: 0.172599, acc.: 93%] [G loss: 6.333179]\n",
            "6359 [ D loss: 0.110357, acc.: 95%] [G loss: 10.314857]\n",
            "6360 [ D loss: 0.130354, acc.: 95%] [G loss: 5.912745]\n",
            "6361 [ D loss: 0.057841, acc.: 98%] [G loss: 5.303090]\n",
            "6362 [ D loss: 0.121838, acc.: 95%] [G loss: 7.995677]\n",
            "6363 [ D loss: 0.112536, acc.: 97%] [G loss: 5.791852]\n",
            "6364 [ D loss: 0.238895, acc.: 91%] [G loss: 4.458705]\n",
            "6365 [ D loss: 0.189953, acc.: 93%] [G loss: 5.329461]\n",
            "6366 [ D loss: 0.181468, acc.: 94%] [G loss: 6.096599]\n",
            "6367 [ D loss: 0.400065, acc.: 83%] [G loss: 4.531896]\n",
            "6368 [ D loss: 0.144220, acc.: 97%] [G loss: 5.451810]\n",
            "6369 [ D loss: 0.104578, acc.: 96%] [G loss: 7.745896]\n",
            "6370 [ D loss: 0.163666, acc.: 91%] [G loss: 4.895277]\n",
            "6371 [ D loss: 0.079363, acc.: 98%] [G loss: 8.761512]\n",
            "6372 [ D loss: 0.192017, acc.: 92%] [G loss: 5.263049]\n",
            "6373 [ D loss: 0.187916, acc.: 92%] [G loss: 7.346160]\n",
            "6374 [ D loss: 0.179414, acc.: 94%] [G loss: 8.070429]\n",
            "6375 [ D loss: 0.228613, acc.: 92%] [G loss: 6.784541]\n",
            "6376 [ D loss: 0.133564, acc.: 93%] [G loss: 4.694601]\n",
            "6377 [ D loss: 0.083356, acc.: 97%] [G loss: 8.553843]\n",
            "6378 [ D loss: 0.096856, acc.: 95%] [G loss: 11.535658]\n",
            "6379 [ D loss: 0.085883, acc.: 96%] [G loss: 12.964603]\n",
            "6380 [ D loss: 0.102918, acc.: 97%] [G loss: 9.302389]\n",
            "6381 [ D loss: 0.101302, acc.: 96%] [G loss: 8.173804]\n",
            "6382 [ D loss: 0.128520, acc.: 97%] [G loss: 4.820251]\n",
            "6383 [ D loss: 0.098224, acc.: 97%] [G loss: 5.555671]\n",
            "6384 [ D loss: 0.177368, acc.: 93%] [G loss: 4.500545]\n",
            "6385 [ D loss: 0.148874, acc.: 95%] [G loss: 5.056297]\n",
            "6386 [ D loss: 0.110169, acc.: 98%] [G loss: 4.620543]\n",
            "6387 [ D loss: 0.159702, acc.: 95%] [G loss: 5.236785]\n",
            "6388 [ D loss: 0.135178, acc.: 95%] [G loss: 6.112252]\n",
            "6389 [ D loss: 0.096897, acc.: 96%] [G loss: 7.152357]\n",
            "6390 [ D loss: 0.196760, acc.: 93%] [G loss: 6.840010]\n",
            "6391 [ D loss: 0.068167, acc.: 99%] [G loss: 7.214957]\n",
            "6392 [ D loss: 0.190767, acc.: 91%] [G loss: 5.720296]\n",
            "6393 [ D loss: 0.320375, acc.: 88%] [G loss: 5.420185]\n",
            "6394 [ D loss: 0.185374, acc.: 91%] [G loss: 4.385289]\n",
            "6395 [ D loss: 0.203903, acc.: 92%] [G loss: 4.332333]\n",
            "6396 [ D loss: 0.130737, acc.: 96%] [G loss: 4.481169]\n",
            "6397 [ D loss: 0.114349, acc.: 95%] [G loss: 4.879072]\n",
            "6398 [ D loss: 0.151153, acc.: 94%] [G loss: 4.645422]\n",
            "6399 [ D loss: 0.248987, acc.: 91%] [G loss: 5.251626]\n",
            "6400 [ D loss: 0.122812, acc.: 95%] [G loss: 5.245414]\n",
            "6401 [ D loss: 0.132037, acc.: 95%] [G loss: 5.734473]\n",
            "6402 [ D loss: 0.311021, acc.: 85%] [G loss: 4.383834]\n",
            "6403 [ D loss: 0.205465, acc.: 91%] [G loss: 5.713867]\n",
            "6404 [ D loss: 0.210737, acc.: 91%] [G loss: 6.712050]\n",
            "6405 [ D loss: 0.098405, acc.: 98%] [G loss: 5.188217]\n",
            "6406 [ D loss: 0.268501, acc.: 90%] [G loss: 5.112505]\n",
            "6407 [ D loss: 0.149941, acc.: 93%] [G loss: 4.618580]\n",
            "6408 [ D loss: 0.191528, acc.: 92%] [G loss: 5.307936]\n",
            "6409 [ D loss: 0.196891, acc.: 94%] [G loss: 4.245464]\n",
            "6410 [ D loss: 0.272778, acc.: 90%] [G loss: 8.126766]\n",
            "6411 [ D loss: 0.084007, acc.: 97%] [G loss: 7.489254]\n",
            "6412 [ D loss: 0.117262, acc.: 95%] [G loss: 12.113379]\n",
            "6413 [ D loss: 0.180444, acc.: 96%] [G loss: 10.760363]\n",
            "6414 [ D loss: 0.102570, acc.: 95%] [G loss: 13.583310]\n",
            "6415 [ D loss: 0.097567, acc.: 97%] [G loss: 9.164382]\n",
            "6416 [ D loss: 0.100800, acc.: 97%] [G loss: 9.281824]\n",
            "6417 [ D loss: 0.164519, acc.: 94%] [G loss: 5.448355]\n",
            "6418 [ D loss: 0.107974, acc.: 96%] [G loss: 6.421585]\n",
            "6419 [ D loss: 0.160855, acc.: 94%] [G loss: 3.767760]\n",
            "6420 [ D loss: 0.161708, acc.: 93%] [G loss: 5.513756]\n",
            "6421 [ D loss: 0.150935, acc.: 95%] [G loss: 4.297799]\n",
            "6422 [ D loss: 0.108962, acc.: 98%] [G loss: 4.528806]\n",
            "6423 [ D loss: 0.133205, acc.: 95%] [G loss: 5.061587]\n",
            "6424 [ D loss: 0.203572, acc.: 92%] [G loss: 4.484789]\n",
            "6425 [ D loss: 0.130508, acc.: 97%] [G loss: 5.051243]\n",
            "6426 [ D loss: 0.208897, acc.: 92%] [G loss: 4.296116]\n",
            "6427 [ D loss: 0.191504, acc.: 94%] [G loss: 4.671903]\n",
            "6428 [ D loss: 0.255200, acc.: 88%] [G loss: 4.716353]\n",
            "6429 [ D loss: 0.104557, acc.: 96%] [G loss: 5.292291]\n",
            "6430 [ D loss: 0.182400, acc.: 93%] [G loss: 4.682010]\n",
            "6431 [ D loss: 0.118006, acc.: 97%] [G loss: 4.386819]\n",
            "6432 [ D loss: 0.169788, acc.: 93%] [G loss: 4.612139]\n",
            "6433 [ D loss: 0.222006, acc.: 92%] [G loss: 5.058926]\n",
            "6434 [ D loss: 0.071657, acc.: 97%] [G loss: 6.179484]\n",
            "6435 [ D loss: 0.244867, acc.: 91%] [G loss: 2.992548]\n",
            "6436 [ D loss: 0.251509, acc.: 88%] [G loss: 6.377260]\n",
            "6437 [ D loss: 0.440004, acc.: 81%] [G loss: 9.099748]\n",
            "6438 [ D loss: 0.281708, acc.: 86%] [G loss: 3.891545]\n",
            "6439 [ D loss: 0.101223, acc.: 98%] [G loss: 5.268817]\n",
            "6440 [ D loss: 0.206940, acc.: 92%] [G loss: 6.881625]\n",
            "6441 [ D loss: 0.260144, acc.: 91%] [G loss: 3.689428]\n",
            "6442 [ D loss: 0.153519, acc.: 93%] [G loss: 5.435924]\n",
            "6443 [ D loss: 0.133151, acc.: 95%] [G loss: 6.820972]\n",
            "6444 [ D loss: 0.193964, acc.: 94%] [G loss: 4.522444]\n",
            "6445 [ D loss: 0.151670, acc.: 94%] [G loss: 5.647413]\n",
            "6446 [ D loss: 0.165547, acc.: 92%] [G loss: 4.481844]\n",
            "6447 [ D loss: 0.148064, acc.: 96%] [G loss: 4.760923]\n",
            "6448 [ D loss: 0.162418, acc.: 93%] [G loss: 4.281868]\n",
            "6449 [ D loss: 0.229559, acc.: 91%] [G loss: 5.238508]\n",
            "6450 [ D loss: 0.197775, acc.: 92%] [G loss: 6.527901]\n",
            "6451 [ D loss: 0.130135, acc.: 96%] [G loss: 9.452888]\n",
            "6452 [ D loss: 0.146571, acc.: 96%] [G loss: 6.877097]\n",
            "6453 [ D loss: 0.143286, acc.: 95%] [G loss: 6.218165]\n",
            "6454 [ D loss: 0.161902, acc.: 95%] [G loss: 5.454443]\n",
            "6455 [ D loss: 0.101401, acc.: 95%] [G loss: 4.677444]\n",
            "6456 [ D loss: 0.108363, acc.: 97%] [G loss: 4.745781]\n",
            "6457 [ D loss: 0.149450, acc.: 95%] [G loss: 4.193756]\n",
            "6458 [ D loss: 0.150398, acc.: 95%] [G loss: 7.982683]\n",
            "6459 [ D loss: 0.197501, acc.: 92%] [G loss: 4.426637]\n",
            "6460 [ D loss: 0.165656, acc.: 93%] [G loss: 5.696493]\n",
            "6461 [ D loss: 0.181319, acc.: 95%] [G loss: 5.050546]\n",
            "6462 [ D loss: 0.119117, acc.: 95%] [G loss: 7.128505]\n",
            "6463 [ D loss: 0.153687, acc.: 95%] [G loss: 4.940715]\n",
            "6464 [ D loss: 0.191361, acc.: 92%] [G loss: 7.803211]\n",
            "6465 [ D loss: 0.171473, acc.: 94%] [G loss: 5.560215]\n",
            "6466 [ D loss: 0.183814, acc.: 92%] [G loss: 5.396979]\n",
            "6467 [ D loss: 0.088302, acc.: 98%] [G loss: 4.777637]\n",
            "6468 [ D loss: 0.190235, acc.: 93%] [G loss: 9.540579]\n",
            "6469 [ D loss: 0.147472, acc.: 95%] [G loss: 6.085263]\n",
            "6470 [ D loss: 0.201781, acc.: 91%] [G loss: 8.482137]\n",
            "6471 [ D loss: 0.066788, acc.: 98%] [G loss: 5.080617]\n",
            "6472 [ D loss: 0.146751, acc.: 95%] [G loss: 8.430889]\n",
            "6473 [ D loss: 0.113815, acc.: 96%] [G loss: 5.841031]\n",
            "6474 [ D loss: 0.176474, acc.: 94%] [G loss: 6.946356]\n",
            "6475 [ D loss: 0.202220, acc.: 91%] [G loss: 5.442724]\n",
            "6476 [ D loss: 0.227885, acc.: 91%] [G loss: 4.419766]\n",
            "6477 [ D loss: 0.176602, acc.: 95%] [G loss: 4.533590]\n",
            "6478 [ D loss: 0.250050, acc.: 90%] [G loss: 4.505480]\n",
            "6479 [ D loss: 0.278358, acc.: 87%] [G loss: 4.698362]\n",
            "6480 [ D loss: 0.222144, acc.: 91%] [G loss: 4.263744]\n",
            "6481 [ D loss: 0.119282, acc.: 98%] [G loss: 5.417482]\n",
            "6482 [ D loss: 0.240283, acc.: 88%] [G loss: 5.212758]\n",
            "6483 [ D loss: 0.153612, acc.: 96%] [G loss: 5.263996]\n",
            "6484 [ D loss: 0.120051, acc.: 97%] [G loss: 4.802524]\n",
            "6485 [ D loss: 0.165977, acc.: 95%] [G loss: 4.704669]\n",
            "6486 [ D loss: 0.152125, acc.: 98%] [G loss: 5.176669]\n",
            "6487 [ D loss: 0.174420, acc.: 95%] [G loss: 5.376781]\n",
            "6488 [ D loss: 0.260763, acc.: 91%] [G loss: 5.324695]\n",
            "6489 [ D loss: 0.309129, acc.: 87%] [G loss: 5.228029]\n",
            "6490 [ D loss: 0.118799, acc.: 96%] [G loss: 6.568914]\n",
            "6491 [ D loss: 0.119941, acc.: 95%] [G loss: 8.386588]\n",
            "6492 [ D loss: 0.117079, acc.: 98%] [G loss: 8.945297]\n",
            "6493 [ D loss: 0.111686, acc.: 95%] [G loss: 4.811325]\n",
            "6494 [ D loss: 0.117860, acc.: 98%] [G loss: 7.387343]\n",
            "6495 [ D loss: 0.110126, acc.: 96%] [G loss: 5.861672]\n",
            "6496 [ D loss: 0.204449, acc.: 94%] [G loss: 6.745358]\n",
            "6497 [ D loss: 0.143502, acc.: 95%] [G loss: 4.790598]\n",
            "6498 [ D loss: 0.234060, acc.: 91%] [G loss: 4.574026]\n",
            "6499 [ D loss: 0.166348, acc.: 91%] [G loss: 4.340640]\n",
            "6500 [ D loss: 0.117467, acc.: 98%] [G loss: 5.240295]\n",
            "6501 [ D loss: 0.209570, acc.: 95%] [G loss: 3.912166]\n",
            "6502 [ D loss: 0.200329, acc.: 92%] [G loss: 4.354549]\n",
            "6503 [ D loss: 0.204664, acc.: 92%] [G loss: 4.854118]\n",
            "6504 [ D loss: 0.260490, acc.: 89%] [G loss: 5.272510]\n",
            "6505 [ D loss: 0.191379, acc.: 90%] [G loss: 4.790503]\n",
            "6506 [ D loss: 0.202831, acc.: 91%] [G loss: 4.724377]\n",
            "6507 [ D loss: 0.244470, acc.: 90%] [G loss: 5.721118]\n",
            "6508 [ D loss: 0.066328, acc.: 99%] [G loss: 5.208813]\n",
            "6509 [ D loss: 0.229656, acc.: 91%] [G loss: 6.127835]\n",
            "6510 [ D loss: 0.157606, acc.: 95%] [G loss: 4.877414]\n",
            "6511 [ D loss: 0.168982, acc.: 92%] [G loss: 5.773134]\n",
            "6512 [ D loss: 0.257135, acc.: 89%] [G loss: 5.334381]\n",
            "6513 [ D loss: 0.163090, acc.: 93%] [G loss: 5.249332]\n",
            "6514 [ D loss: 0.154182, acc.: 94%] [G loss: 4.471702]\n",
            "6515 [ D loss: 0.215441, acc.: 94%] [G loss: 5.599661]\n",
            "6516 [ D loss: 0.272727, acc.: 90%] [G loss: 4.859479]\n",
            "6517 [ D loss: 0.072610, acc.: 98%] [G loss: 5.559508]\n",
            "6518 [ D loss: 0.099937, acc.: 97%] [G loss: 5.177809]\n",
            "6519 [ D loss: 0.142790, acc.: 96%] [G loss: 7.179262]\n",
            "6520 [ D loss: 0.130143, acc.: 95%] [G loss: 5.422665]\n",
            "6521 [ D loss: 0.094548, acc.: 98%] [G loss: 9.677067]\n",
            "6522 [ D loss: 0.142668, acc.: 94%] [G loss: 5.256759]\n",
            "6523 [ D loss: 0.123395, acc.: 95%] [G loss: 7.358547]\n",
            "6524 [ D loss: 0.188124, acc.: 91%] [G loss: 6.112072]\n",
            "6525 [ D loss: 0.232819, acc.: 89%] [G loss: 5.561970]\n",
            "6526 [ D loss: 0.197981, acc.: 91%] [G loss: 7.374381]\n",
            "6527 [ D loss: 0.187356, acc.: 94%] [G loss: 4.345877]\n",
            "6528 [ D loss: 0.083202, acc.: 98%] [G loss: 6.856853]\n",
            "6529 [ D loss: 0.199717, acc.: 91%] [G loss: 4.348328]\n",
            "6530 [ D loss: 0.155660, acc.: 93%] [G loss: 4.601591]\n",
            "6531 [ D loss: 0.187251, acc.: 91%] [G loss: 5.607001]\n",
            "6532 [ D loss: 0.163122, acc.: 95%] [G loss: 4.903290]\n",
            "6533 [ D loss: 0.142860, acc.: 95%] [G loss: 6.194734]\n",
            "6534 [ D loss: 0.201924, acc.: 90%] [G loss: 4.972038]\n",
            "6535 [ D loss: 0.137190, acc.: 96%] [G loss: 5.649538]\n",
            "6536 [ D loss: 0.130915, acc.: 96%] [G loss: 4.986253]\n",
            "6537 [ D loss: 0.133380, acc.: 94%] [G loss: 5.357985]\n",
            "6538 [ D loss: 0.072548, acc.: 98%] [G loss: 5.500089]\n",
            "6539 [ D loss: 0.261190, acc.: 89%] [G loss: 4.478903]\n",
            "6540 [ D loss: 0.166901, acc.: 94%] [G loss: 5.252903]\n",
            "6541 [ D loss: 0.178919, acc.: 95%] [G loss: 5.006531]\n",
            "6542 [ D loss: 0.111434, acc.: 96%] [G loss: 8.456539]\n",
            "6543 [ D loss: 0.135542, acc.: 95%] [G loss: 6.437784]\n",
            "6544 [ D loss: 0.189511, acc.: 96%] [G loss: 5.695804]\n",
            "6545 [ D loss: 0.202499, acc.: 90%] [G loss: 5.671015]\n",
            "6546 [ D loss: 0.159581, acc.: 95%] [G loss: 4.523507]\n",
            "6547 [ D loss: 0.209532, acc.: 89%] [G loss: 5.065308]\n",
            "6548 [ D loss: 0.185235, acc.: 91%] [G loss: 4.967546]\n",
            "6549 [ D loss: 0.278519, acc.: 88%] [G loss: 4.375309]\n",
            "6550 [ D loss: 0.199180, acc.: 95%] [G loss: 5.513499]\n",
            "6551 [ D loss: 0.216920, acc.: 90%] [G loss: 5.672403]\n",
            "6552 [ D loss: 0.191646, acc.: 92%] [G loss: 8.310546]\n",
            "6553 [ D loss: 0.158073, acc.: 95%] [G loss: 5.032251]\n",
            "6554 [ D loss: 0.087691, acc.: 96%] [G loss: 8.090313]\n",
            "6555 [ D loss: 0.154118, acc.: 96%] [G loss: 6.982446]\n",
            "6556 [ D loss: 0.192587, acc.: 92%] [G loss: 6.451641]\n",
            "6557 [ D loss: 0.160149, acc.: 95%] [G loss: 5.619934]\n",
            "6558 [ D loss: 0.159667, acc.: 93%] [G loss: 4.666674]\n",
            "6559 [ D loss: 0.181714, acc.: 93%] [G loss: 4.666334]\n",
            "6560 [ D loss: 0.216974, acc.: 88%] [G loss: 6.453094]\n",
            "6561 [ D loss: 0.127772, acc.: 95%] [G loss: 5.754524]\n",
            "6562 [ D loss: 0.119279, acc.: 95%] [G loss: 8.305042]\n",
            "6563 [ D loss: 0.155513, acc.: 94%] [G loss: 7.215663]\n",
            "6564 [ D loss: 0.141688, acc.: 95%] [G loss: 6.209263]\n",
            "6565 [ D loss: 0.167953, acc.: 95%] [G loss: 9.039899]\n",
            "6566 [ D loss: 0.118377, acc.: 94%] [G loss: 7.456797]\n",
            "6567 [ D loss: 0.131207, acc.: 94%] [G loss: 5.775545]\n",
            "6568 [ D loss: 0.125252, acc.: 96%] [G loss: 5.194909]\n",
            "6569 [ D loss: 0.306463, acc.: 87%] [G loss: 5.517831]\n",
            "6570 [ D loss: 0.150347, acc.: 94%] [G loss: 6.771747]\n",
            "6571 [ D loss: 0.199082, acc.: 94%] [G loss: 5.620017]\n",
            "6572 [ D loss: 0.165287, acc.: 89%] [G loss: 4.154411]\n",
            "6573 [ D loss: 0.143299, acc.: 96%] [G loss: 5.717806]\n",
            "6574 [ D loss: 0.148926, acc.: 95%] [G loss: 3.952917]\n",
            "6575 [ D loss: 0.167619, acc.: 94%] [G loss: 6.009762]\n",
            "6576 [ D loss: 0.145973, acc.: 94%] [G loss: 5.844989]\n",
            "6577 [ D loss: 0.104861, acc.: 97%] [G loss: 5.946316]\n",
            "6578 [ D loss: 0.079733, acc.: 98%] [G loss: 4.163295]\n",
            "6579 [ D loss: 0.115920, acc.: 95%] [G loss: 7.301781]\n",
            "6580 [ D loss: 0.067413, acc.: 99%] [G loss: 4.277161]\n",
            "6581 [ D loss: 0.187503, acc.: 91%] [G loss: 5.619884]\n",
            "6582 [ D loss: 0.165733, acc.: 92%] [G loss: 4.308392]\n",
            "6583 [ D loss: 0.171196, acc.: 95%] [G loss: 5.342540]\n",
            "6584 [ D loss: 0.170545, acc.: 95%] [G loss: 8.487724]\n",
            "6585 [ D loss: 0.113276, acc.: 96%] [G loss: 7.200744]\n",
            "6586 [ D loss: 0.195069, acc.: 93%] [G loss: 5.909806]\n",
            "6587 [ D loss: 0.105699, acc.: 96%] [G loss: 6.088399]\n",
            "6588 [ D loss: 0.286701, acc.: 90%] [G loss: 4.699574]\n",
            "6589 [ D loss: 0.158373, acc.: 92%] [G loss: 4.346478]\n",
            "6590 [ D loss: 0.176411, acc.: 91%] [G loss: 5.568321]\n",
            "6591 [ D loss: 0.168674, acc.: 95%] [G loss: 4.140284]\n",
            "6592 [ D loss: 0.208259, acc.: 93%] [G loss: 4.292960]\n",
            "6593 [ D loss: 0.130585, acc.: 96%] [G loss: 6.691015]\n",
            "6594 [ D loss: 0.172880, acc.: 95%] [G loss: 3.858466]\n",
            "6595 [ D loss: 0.107243, acc.: 98%] [G loss: 4.429666]\n",
            "6596 [ D loss: 0.159428, acc.: 95%] [G loss: 7.114286]\n",
            "6597 [ D loss: 0.233831, acc.: 91%] [G loss: 7.636719]\n",
            "6598 [ D loss: 0.329755, acc.: 88%] [G loss: 4.152176]\n",
            "6599 [ D loss: 0.432158, acc.: 79%] [G loss: 6.136794]\n",
            "6600 [ D loss: 0.093043, acc.: 95%] [G loss: 6.796566]\n",
            "6601 [ D loss: 0.147546, acc.: 95%] [G loss: 4.891683]\n",
            "6602 [ D loss: 0.206878, acc.: 91%] [G loss: 8.037100]\n",
            "6603 [ D loss: 0.121482, acc.: 97%] [G loss: 5.553536]\n",
            "6604 [ D loss: 0.101989, acc.: 95%] [G loss: 12.544115]\n",
            "6605 [ D loss: 0.131933, acc.: 95%] [G loss: 5.735718]\n",
            "6606 [ D loss: 0.046445, acc.: 100%] [G loss: 6.630698]\n",
            "6607 [ D loss: 0.079473, acc.: 98%] [G loss: 7.860348]\n",
            "6608 [ D loss: 0.172272, acc.: 92%] [G loss: 5.361008]\n",
            "6609 [ D loss: 0.220350, acc.: 92%] [G loss: 5.147793]\n",
            "6610 [ D loss: 0.132729, acc.: 94%] [G loss: 6.670084]\n",
            "6611 [ D loss: 0.238640, acc.: 91%] [G loss: 4.377460]\n",
            "6612 [ D loss: 0.170188, acc.: 92%] [G loss: 5.045693]\n",
            "6613 [ D loss: 0.165255, acc.: 94%] [G loss: 6.301755]\n",
            "6614 [ D loss: 0.204495, acc.: 91%] [G loss: 4.981065]\n",
            "6615 [ D loss: 0.239570, acc.: 90%] [G loss: 5.336159]\n",
            "6616 [ D loss: 0.164367, acc.: 91%] [G loss: 7.540727]\n",
            "6617 [ D loss: 0.142260, acc.: 92%] [G loss: 5.818453]\n",
            "6618 [ D loss: 0.266572, acc.: 86%] [G loss: 5.952957]\n",
            "6619 [ D loss: 0.145804, acc.: 95%] [G loss: 5.580347]\n",
            "6620 [ D loss: 0.114105, acc.: 98%] [G loss: 4.510967]\n",
            "6621 [ D loss: 0.207885, acc.: 94%] [G loss: 4.891842]\n",
            "6622 [ D loss: 0.108823, acc.: 97%] [G loss: 6.972654]\n",
            "6623 [ D loss: 0.154666, acc.: 95%] [G loss: 5.949454]\n",
            "6624 [ D loss: 0.106242, acc.: 96%] [G loss: 7.585970]\n",
            "6625 [ D loss: 0.106025, acc.: 98%] [G loss: 5.751093]\n",
            "6626 [ D loss: 0.087310, acc.: 97%] [G loss: 6.124500]\n",
            "6627 [ D loss: 0.229404, acc.: 90%] [G loss: 5.466539]\n",
            "6628 [ D loss: 0.171742, acc.: 93%] [G loss: 5.344795]\n",
            "6629 [ D loss: 0.218332, acc.: 93%] [G loss: 5.120097]\n",
            "6630 [ D loss: 0.255611, acc.: 90%] [G loss: 4.561903]\n",
            "6631 [ D loss: 0.121390, acc.: 98%] [G loss: 5.728991]\n",
            "6632 [ D loss: 0.237560, acc.: 92%] [G loss: 2.892086]\n",
            "6633 [ D loss: 0.133583, acc.: 95%] [G loss: 3.603760]\n",
            "6634 [ D loss: 0.312241, acc.: 91%] [G loss: 6.510982]\n",
            "6635 [ D loss: 0.160755, acc.: 95%] [G loss: 5.129820]\n",
            "6636 [ D loss: 0.144855, acc.: 95%] [G loss: 5.141677]\n",
            "6637 [ D loss: 0.125337, acc.: 95%] [G loss: 6.861416]\n",
            "6638 [ D loss: 0.235703, acc.: 93%] [G loss: 7.108859]\n",
            "6639 [ D loss: 0.168105, acc.: 96%] [G loss: 9.322540]\n",
            "6640 [ D loss: 0.150758, acc.: 93%] [G loss: 6.168838]\n",
            "6641 [ D loss: 0.147283, acc.: 94%] [G loss: 6.997328]\n",
            "6642 [ D loss: 0.164552, acc.: 95%] [G loss: 5.985004]\n",
            "6643 [ D loss: 0.263839, acc.: 88%] [G loss: 4.105293]\n",
            "6644 [ D loss: 0.202699, acc.: 94%] [G loss: 5.345407]\n",
            "6645 [ D loss: 0.115765, acc.: 96%] [G loss: 6.006807]\n",
            "6646 [ D loss: 0.171139, acc.: 95%] [G loss: 4.727454]\n",
            "6647 [ D loss: 0.245188, acc.: 91%] [G loss: 5.375585]\n",
            "6648 [ D loss: 0.088542, acc.: 98%] [G loss: 4.663626]\n",
            "6649 [ D loss: 0.265641, acc.: 88%] [G loss: 6.802781]\n",
            "6650 [ D loss: 0.179246, acc.: 92%] [G loss: 6.032191]\n",
            "6651 [ D loss: 0.091924, acc.: 98%] [G loss: 4.682372]\n",
            "6652 [ D loss: 0.082043, acc.: 98%] [G loss: 9.681889]\n",
            "6653 [ D loss: 0.200570, acc.: 94%] [G loss: 5.857402]\n",
            "6654 [ D loss: 0.089828, acc.: 97%] [G loss: 5.953166]\n",
            "6655 [ D loss: 0.093860, acc.: 98%] [G loss: 3.408590]\n",
            "6656 [ D loss: 0.144336, acc.: 96%] [G loss: 6.523773]\n",
            "6657 [ D loss: 0.150611, acc.: 95%] [G loss: 5.532243]\n",
            "6658 [ D loss: 0.213530, acc.: 92%] [G loss: 6.898031]\n",
            "6659 [ D loss: 0.189111, acc.: 94%] [G loss: 10.031288]\n",
            "6660 [ D loss: 0.173214, acc.: 94%] [G loss: 5.260056]\n",
            "6661 [ D loss: 0.105839, acc.: 98%] [G loss: 4.370165]\n",
            "6662 [ D loss: 0.133921, acc.: 97%] [G loss: 6.326350]\n",
            "6663 [ D loss: 0.177667, acc.: 93%] [G loss: 6.670699]\n",
            "6664 [ D loss: 0.279377, acc.: 89%] [G loss: 4.019292]\n",
            "6665 [ D loss: 0.145499, acc.: 94%] [G loss: 5.956032]\n",
            "6666 [ D loss: 0.098350, acc.: 98%] [G loss: 5.914841]\n",
            "6667 [ D loss: 0.260100, acc.: 93%] [G loss: 3.970536]\n",
            "6668 [ D loss: 0.123975, acc.: 96%] [G loss: 4.331091]\n",
            "6669 [ D loss: 0.256629, acc.: 90%] [G loss: 3.831025]\n",
            "6670 [ D loss: 0.213374, acc.: 91%] [G loss: 5.495117]\n",
            "6671 [ D loss: 0.162795, acc.: 94%] [G loss: 4.167920]\n",
            "6672 [ D loss: 0.209288, acc.: 94%] [G loss: 3.814700]\n",
            "6673 [ D loss: 0.261782, acc.: 89%] [G loss: 4.611308]\n",
            "6674 [ D loss: 0.116517, acc.: 97%] [G loss: 4.680423]\n",
            "6675 [ D loss: 0.313821, acc.: 84%] [G loss: 6.583429]\n",
            "6676 [ D loss: 0.147517, acc.: 95%] [G loss: 4.682103]\n",
            "6677 [ D loss: 0.226759, acc.: 92%] [G loss: 6.004262]\n",
            "6678 [ D loss: 0.114791, acc.: 96%] [G loss: 5.879675]\n",
            "6679 [ D loss: 0.170761, acc.: 95%] [G loss: 3.608753]\n",
            "6680 [ D loss: 0.138890, acc.: 94%] [G loss: 3.353079]\n",
            "6681 [ D loss: 0.111088, acc.: 98%] [G loss: 4.865390]\n",
            "6682 [ D loss: 0.222575, acc.: 92%] [G loss: 5.134846]\n",
            "6683 [ D loss: 0.162689, acc.: 92%] [G loss: 6.088041]\n",
            "6684 [ D loss: 0.126844, acc.: 94%] [G loss: 8.411160]\n",
            "6685 [ D loss: 0.166221, acc.: 94%] [G loss: 9.541095]\n",
            "6686 [ D loss: 0.200359, acc.: 93%] [G loss: 6.061046]\n",
            "6687 [ D loss: 0.140161, acc.: 95%] [G loss: 5.140926]\n",
            "6688 [ D loss: 0.193307, acc.: 96%] [G loss: 8.823660]\n",
            "6689 [ D loss: 0.100298, acc.: 97%] [G loss: 8.227575]\n",
            "6690 [ D loss: 0.132466, acc.: 96%] [G loss: 9.394312]\n",
            "6691 [ D loss: 0.089190, acc.: 97%] [G loss: 8.976224]\n",
            "6692 [ D loss: 0.107229, acc.: 96%] [G loss: 7.772889]\n",
            "6693 [ D loss: 0.200130, acc.: 91%] [G loss: 6.881631]\n",
            "6694 [ D loss: 0.105444, acc.: 97%] [G loss: 7.664999]\n",
            "6695 [ D loss: 0.128712, acc.: 95%] [G loss: 5.712537]\n",
            "6696 [ D loss: 0.113110, acc.: 95%] [G loss: 5.649523]\n",
            "6697 [ D loss: 0.087333, acc.: 98%] [G loss: 6.299655]\n",
            "6698 [ D loss: 0.137883, acc.: 95%] [G loss: 5.701138]\n",
            "6699 [ D loss: 0.137382, acc.: 95%] [G loss: 5.862148]\n",
            "6700 [ D loss: 0.128196, acc.: 95%] [G loss: 10.626800]\n",
            "6701 [ D loss: 0.249558, acc.: 88%] [G loss: 5.741706]\n",
            "6702 [ D loss: 0.151914, acc.: 95%] [G loss: 5.527874]\n",
            "6703 [ D loss: 0.093838, acc.: 96%] [G loss: 4.981916]\n",
            "6704 [ D loss: 0.127388, acc.: 98%] [G loss: 6.614220]\n",
            "6705 [ D loss: 0.061586, acc.: 98%] [G loss: 6.759004]\n",
            "6706 [ D loss: 0.131168, acc.: 95%] [G loss: 5.773813]\n",
            "6707 [ D loss: 0.153942, acc.: 95%] [G loss: 5.099129]\n",
            "6708 [ D loss: 0.171113, acc.: 92%] [G loss: 6.143647]\n",
            "6709 [ D loss: 0.157900, acc.: 95%] [G loss: 6.398965]\n",
            "6710 [ D loss: 0.143304, acc.: 95%] [G loss: 6.696259]\n",
            "6711 [ D loss: 0.076652, acc.: 99%] [G loss: 8.785733]\n",
            "6712 [ D loss: 0.188842, acc.: 93%] [G loss: 6.649359]\n",
            "6713 [ D loss: 0.171216, acc.: 95%] [G loss: 5.208971]\n",
            "6714 [ D loss: 0.174282, acc.: 94%] [G loss: 9.680798]\n",
            "6715 [ D loss: 0.186862, acc.: 92%] [G loss: 9.204506]\n",
            "6716 [ D loss: 0.120913, acc.: 97%] [G loss: 10.103863]\n",
            "6717 [ D loss: 0.094321, acc.: 97%] [G loss: 5.699905]\n",
            "6718 [ D loss: 0.075636, acc.: 98%] [G loss: 6.676168]\n",
            "6719 [ D loss: 0.163295, acc.: 95%] [G loss: 12.921000]\n",
            "6720 [ D loss: 0.100292, acc.: 96%] [G loss: 7.520710]\n",
            "6721 [ D loss: 0.120843, acc.: 95%] [G loss: 6.283527]\n",
            "6722 [ D loss: 0.114986, acc.: 98%] [G loss: 6.706196]\n",
            "6723 [ D loss: 0.178375, acc.: 93%] [G loss: 5.796257]\n",
            "6724 [ D loss: 0.181548, acc.: 93%] [G loss: 6.134303]\n",
            "6725 [ D loss: 0.117386, acc.: 98%] [G loss: 5.819997]\n",
            "6726 [ D loss: 0.134307, acc.: 93%] [G loss: 9.456861]\n",
            "6727 [ D loss: 0.124515, acc.: 95%] [G loss: 10.654390]\n",
            "6728 [ D loss: 0.148919, acc.: 95%] [G loss: 8.529831]\n",
            "6729 [ D loss: 0.081811, acc.: 98%] [G loss: 7.009042]\n",
            "6730 [ D loss: 0.136976, acc.: 95%] [G loss: 7.380925]\n",
            "6731 [ D loss: 0.102775, acc.: 96%] [G loss: 5.598040]\n",
            "6732 [ D loss: 0.239073, acc.: 88%] [G loss: 5.661483]\n",
            "6733 [ D loss: 0.189852, acc.: 94%] [G loss: 7.729779]\n",
            "6734 [ D loss: 0.248528, acc.: 88%] [G loss: 4.647447]\n",
            "6735 [ D loss: 0.195987, acc.: 93%] [G loss: 5.029352]\n",
            "6736 [ D loss: 0.178486, acc.: 93%] [G loss: 4.944664]\n",
            "6737 [ D loss: 0.101513, acc.: 97%] [G loss: 5.127993]\n",
            "6738 [ D loss: 0.185094, acc.: 94%] [G loss: 4.925927]\n",
            "6739 [ D loss: 0.160942, acc.: 96%] [G loss: 5.397185]\n",
            "6740 [ D loss: 0.154795, acc.: 94%] [G loss: 5.089793]\n",
            "6741 [ D loss: 0.186381, acc.: 92%] [G loss: 6.401250]\n",
            "6742 [ D loss: 0.234894, acc.: 88%] [G loss: 7.768042]\n",
            "6743 [ D loss: 0.122733, acc.: 95%] [G loss: 7.493154]\n",
            "6744 [ D loss: 0.260586, acc.: 89%] [G loss: 4.900846]\n",
            "6745 [ D loss: 0.113460, acc.: 98%] [G loss: 7.375512]\n",
            "6746 [ D loss: 0.236238, acc.: 91%] [G loss: 7.767754]\n",
            "6747 [ D loss: 0.141667, acc.: 96%] [G loss: 6.035147]\n",
            "6748 [ D loss: 0.082799, acc.: 96%] [G loss: 9.147009]\n",
            "6749 [ D loss: 0.105596, acc.: 95%] [G loss: 7.762779]\n",
            "6750 [ D loss: 0.134570, acc.: 95%] [G loss: 9.340128]\n",
            "6751 [ D loss: 0.136731, acc.: 94%] [G loss: 11.000550]\n",
            "6752 [ D loss: 0.065789, acc.: 98%] [G loss: 12.936159]\n",
            "6753 [ D loss: 0.053521, acc.: 98%] [G loss: 10.697714]\n",
            "6754 [ D loss: 0.148673, acc.: 95%] [G loss: 7.609296]\n",
            "6755 [ D loss: 0.091982, acc.: 97%] [G loss: 6.922353]\n",
            "6756 [ D loss: 0.117760, acc.: 94%] [G loss: 5.481989]\n",
            "6757 [ D loss: 0.123978, acc.: 96%] [G loss: 5.662520]\n",
            "6758 [ D loss: 0.206357, acc.: 91%] [G loss: 5.282030]\n",
            "6759 [ D loss: 0.161872, acc.: 95%] [G loss: 5.220646]\n",
            "6760 [ D loss: 0.153228, acc.: 94%] [G loss: 5.654306]\n",
            "6761 [ D loss: 0.159823, acc.: 91%] [G loss: 4.399406]\n",
            "6762 [ D loss: 0.252851, acc.: 88%] [G loss: 6.373191]\n",
            "6763 [ D loss: 0.178932, acc.: 94%] [G loss: 5.793338]\n",
            "6764 [ D loss: 0.217911, acc.: 89%] [G loss: 6.336644]\n",
            "6765 [ D loss: 0.107435, acc.: 96%] [G loss: 8.063368]\n",
            "6766 [ D loss: 0.210367, acc.: 90%] [G loss: 5.384667]\n",
            "6767 [ D loss: 0.133975, acc.: 97%] [G loss: 7.423660]\n",
            "6768 [ D loss: 0.117230, acc.: 96%] [G loss: 5.588240]\n",
            "6769 [ D loss: 0.100711, acc.: 98%] [G loss: 6.021192]\n",
            "6770 [ D loss: 0.234305, acc.: 88%] [G loss: 5.262333]\n",
            "6771 [ D loss: 0.127949, acc.: 94%] [G loss: 4.940673]\n",
            "6772 [ D loss: 0.170205, acc.: 94%] [G loss: 9.143250]\n",
            "6773 [ D loss: 0.182760, acc.: 92%] [G loss: 5.478275]\n",
            "6774 [ D loss: 0.311124, acc.: 94%] [G loss: 5.337138]\n",
            "6775 [ D loss: 0.172834, acc.: 94%] [G loss: 6.265055]\n",
            "6776 [ D loss: 0.131820, acc.: 97%] [G loss: 6.574145]\n",
            "6777 [ D loss: 0.157696, acc.: 95%] [G loss: 5.676222]\n",
            "6778 [ D loss: 0.293162, acc.: 90%] [G loss: 6.200034]\n",
            "6779 [ D loss: 0.159080, acc.: 94%] [G loss: 5.583829]\n",
            "6780 [ D loss: 0.243005, acc.: 89%] [G loss: 9.562752]\n",
            "6781 [ D loss: 0.245198, acc.: 88%] [G loss: 6.983200]\n",
            "6782 [ D loss: 0.193060, acc.: 91%] [G loss: 11.835596]\n",
            "6783 [ D loss: 0.179658, acc.: 94%] [G loss: 7.635643]\n",
            "6784 [ D loss: 0.078055, acc.: 98%] [G loss: 6.616747]\n",
            "6785 [ D loss: 0.086479, acc.: 97%] [G loss: 11.307036]\n",
            "6786 [ D loss: 0.128696, acc.: 95%] [G loss: 11.047358]\n",
            "6787 [ D loss: 0.172450, acc.: 89%] [G loss: 9.399697]\n",
            "6788 [ D loss: 0.119029, acc.: 98%] [G loss: 8.021244]\n",
            "6789 [ D loss: 0.066168, acc.: 99%] [G loss: 5.497696]\n",
            "6790 [ D loss: 0.186473, acc.: 92%] [G loss: 7.106190]\n",
            "6791 [ D loss: 0.072694, acc.: 98%] [G loss: 9.785950]\n",
            "6792 [ D loss: 0.085998, acc.: 97%] [G loss: 5.207172]\n",
            "6793 [ D loss: 0.199932, acc.: 94%] [G loss: 4.809705]\n",
            "6794 [ D loss: 0.210514, acc.: 91%] [G loss: 3.962141]\n",
            "6795 [ D loss: 0.283893, acc.: 91%] [G loss: 4.929104]\n",
            "6796 [ D loss: 0.261114, acc.: 87%] [G loss: 6.441401]\n",
            "6797 [ D loss: 0.478044, acc.: 80%] [G loss: 5.205616]\n",
            "6798 [ D loss: 0.352829, acc.: 80%] [G loss: 10.555079]\n",
            "6799 [ D loss: 0.074487, acc.: 97%] [G loss: 7.020248]\n",
            "6800 [ D loss: 0.077902, acc.: 98%] [G loss: 8.428966]\n",
            "6801 [ D loss: 0.325991, acc.: 88%] [G loss: 5.837437]\n",
            "6802 [ D loss: 0.153039, acc.: 94%] [G loss: 5.586222]\n",
            "6803 [ D loss: 0.103237, acc.: 95%] [G loss: 5.516547]\n",
            "6804 [ D loss: 0.237544, acc.: 93%] [G loss: 4.883544]\n",
            "6805 [ D loss: 0.169931, acc.: 94%] [G loss: 9.110830]\n",
            "6806 [ D loss: 0.079675, acc.: 98%] [G loss: 7.123698]\n",
            "6807 [ D loss: 0.118647, acc.: 95%] [G loss: 6.079221]\n",
            "6808 [ D loss: 0.172013, acc.: 93%] [G loss: 6.122717]\n",
            "6809 [ D loss: 0.097117, acc.: 97%] [G loss: 5.098716]\n",
            "6810 [ D loss: 0.097854, acc.: 96%] [G loss: 5.249050]\n",
            "6811 [ D loss: 0.145906, acc.: 93%] [G loss: 5.526392]\n",
            "6812 [ D loss: 0.082372, acc.: 98%] [G loss: 4.661318]\n",
            "6813 [ D loss: 0.114135, acc.: 98%] [G loss: 5.183345]\n",
            "6814 [ D loss: 0.152122, acc.: 96%] [G loss: 5.451396]\n",
            "6815 [ D loss: 0.205308, acc.: 91%] [G loss: 3.966870]\n",
            "6816 [ D loss: 0.266761, acc.: 91%] [G loss: 4.768620]\n",
            "6817 [ D loss: 0.171393, acc.: 95%] [G loss: 4.660848]\n",
            "6818 [ D loss: 0.345804, acc.: 83%] [G loss: 4.970500]\n",
            "6819 [ D loss: 0.409182, acc.: 80%] [G loss: 5.893503]\n",
            "6820 [ D loss: 0.184852, acc.: 91%] [G loss: 8.944937]\n",
            "6821 [ D loss: 0.177173, acc.: 92%] [G loss: 5.688222]\n",
            "6822 [ D loss: 0.131869, acc.: 95%] [G loss: 5.286357]\n",
            "6823 [ D loss: 0.233789, acc.: 91%] [G loss: 4.337994]\n",
            "6824 [ D loss: 0.072563, acc.: 99%] [G loss: 5.637146]\n",
            "6825 [ D loss: 0.140813, acc.: 95%] [G loss: 4.856553]\n",
            "6826 [ D loss: 0.214917, acc.: 90%] [G loss: 4.827089]\n",
            "6827 [ D loss: 0.086108, acc.: 99%] [G loss: 5.536365]\n",
            "6828 [ D loss: 0.130149, acc.: 95%] [G loss: 5.286218]\n",
            "6829 [ D loss: 0.252312, acc.: 85%] [G loss: 6.003105]\n",
            "6830 [ D loss: 0.192191, acc.: 92%] [G loss: 6.726301]\n",
            "6831 [ D loss: 0.236046, acc.: 94%] [G loss: 5.387504]\n",
            "6832 [ D loss: 0.134725, acc.: 94%] [G loss: 3.774936]\n",
            "6833 [ D loss: 0.171499, acc.: 95%] [G loss: 6.016437]\n",
            "6834 [ D loss: 0.128719, acc.: 94%] [G loss: 6.052658]\n",
            "6835 [ D loss: 0.151380, acc.: 95%] [G loss: 4.665677]\n",
            "6836 [ D loss: 0.141528, acc.: 95%] [G loss: 5.226840]\n",
            "6837 [ D loss: 0.151036, acc.: 95%] [G loss: 4.290095]\n",
            "6838 [ D loss: 0.124408, acc.: 97%] [G loss: 5.929420]\n",
            "6839 [ D loss: 0.126353, acc.: 97%] [G loss: 3.790622]\n",
            "6840 [ D loss: 0.159447, acc.: 94%] [G loss: 5.669088]\n",
            "6841 [ D loss: 0.243681, acc.: 92%] [G loss: 5.725827]\n",
            "6842 [ D loss: 0.183943, acc.: 95%] [G loss: 4.376591]\n",
            "6843 [ D loss: 0.128535, acc.: 95%] [G loss: 8.518295]\n",
            "6844 [ D loss: 0.148496, acc.: 95%] [G loss: 5.310853]\n",
            "6845 [ D loss: 0.094036, acc.: 99%] [G loss: 4.513522]\n",
            "6846 [ D loss: 0.247998, acc.: 91%] [G loss: 5.243340]\n",
            "6847 [ D loss: 0.108352, acc.: 98%] [G loss: 5.072831]\n",
            "6848 [ D loss: 0.199932, acc.: 92%] [G loss: 4.218161]\n",
            "6849 [ D loss: 0.310954, acc.: 88%] [G loss: 6.799701]\n",
            "6850 [ D loss: 0.362865, acc.: 81%] [G loss: 4.865466]\n",
            "6851 [ D loss: 0.174853, acc.: 95%] [G loss: 6.619834]\n",
            "6852 [ D loss: 0.193351, acc.: 95%] [G loss: 6.430346]\n",
            "6853 [ D loss: 0.090686, acc.: 97%] [G loss: 3.918131]\n",
            "6854 [ D loss: 0.215481, acc.: 92%] [G loss: 5.399749]\n",
            "6855 [ D loss: 0.242074, acc.: 90%] [G loss: 6.059747]\n",
            "6856 [ D loss: 0.178621, acc.: 94%] [G loss: 6.403424]\n",
            "6857 [ D loss: 0.160622, acc.: 93%] [G loss: 7.166331]\n",
            "6858 [ D loss: 0.271991, acc.: 88%] [G loss: 4.351474]\n",
            "6859 [ D loss: 0.292949, acc.: 84%] [G loss: 10.101484]\n",
            "6860 [ D loss: 0.215536, acc.: 90%] [G loss: 5.538354]\n",
            "6861 [ D loss: 0.215065, acc.: 91%] [G loss: 5.498985]\n",
            "6862 [ D loss: 0.114531, acc.: 95%] [G loss: 6.132916]\n",
            "6863 [ D loss: 0.181856, acc.: 92%] [G loss: 8.128696]\n",
            "6864 [ D loss: 0.101531, acc.: 98%] [G loss: 8.058722]\n",
            "6865 [ D loss: 0.141712, acc.: 95%] [G loss: 6.917109]\n",
            "6866 [ D loss: 0.119685, acc.: 94%] [G loss: 3.878062]\n",
            "6867 [ D loss: 0.204925, acc.: 91%] [G loss: 4.594955]\n",
            "6868 [ D loss: 0.141834, acc.: 95%] [G loss: 4.933838]\n",
            "6869 [ D loss: 0.197567, acc.: 93%] [G loss: 4.372855]\n",
            "6870 [ D loss: 0.086902, acc.: 99%] [G loss: 4.617858]\n",
            "6871 [ D loss: 0.199334, acc.: 95%] [G loss: 4.736804]\n",
            "6872 [ D loss: 0.259310, acc.: 91%] [G loss: 5.359645]\n",
            "6873 [ D loss: 0.182543, acc.: 92%] [G loss: 4.916654]\n",
            "6874 [ D loss: 0.249147, acc.: 91%] [G loss: 5.744699]\n",
            "6875 [ D loss: 0.148910, acc.: 94%] [G loss: 5.821170]\n",
            "6876 [ D loss: 0.075228, acc.: 98%] [G loss: 7.431540]\n",
            "6877 [ D loss: 0.137152, acc.: 95%] [G loss: 9.058818]\n",
            "6878 [ D loss: 0.142653, acc.: 94%] [G loss: 7.190254]\n",
            "6879 [ D loss: 0.100015, acc.: 96%] [G loss: 4.490666]\n",
            "6880 [ D loss: 0.135835, acc.: 95%] [G loss: 5.936543]\n",
            "6881 [ D loss: 0.191954, acc.: 91%] [G loss: 5.978879]\n",
            "6882 [ D loss: 0.090256, acc.: 98%] [G loss: 5.668576]\n",
            "6883 [ D loss: 0.198793, acc.: 91%] [G loss: 4.313569]\n",
            "6884 [ D loss: 0.233143, acc.: 94%] [G loss: 6.770449]\n",
            "6885 [ D loss: 0.325188, acc.: 88%] [G loss: 4.646229]\n",
            "6886 [ D loss: 0.231908, acc.: 91%] [G loss: 4.754370]\n",
            "6887 [ D loss: 0.085914, acc.: 98%] [G loss: 5.271582]\n",
            "6888 [ D loss: 0.116788, acc.: 96%] [G loss: 6.965946]\n",
            "6889 [ D loss: 0.131040, acc.: 95%] [G loss: 6.223401]\n",
            "6890 [ D loss: 0.188704, acc.: 91%] [G loss: 5.397940]\n",
            "6891 [ D loss: 0.137962, acc.: 95%] [G loss: 5.371914]\n",
            "6892 [ D loss: 0.195225, acc.: 92%] [G loss: 4.431799]\n",
            "6893 [ D loss: 0.176866, acc.: 96%] [G loss: 5.323694]\n",
            "6894 [ D loss: 0.148783, acc.: 95%] [G loss: 4.394293]\n",
            "6895 [ D loss: 0.109304, acc.: 96%] [G loss: 6.319105]\n",
            "6896 [ D loss: 0.181441, acc.: 92%] [G loss: 3.878991]\n",
            "6897 [ D loss: 0.248288, acc.: 90%] [G loss: 4.803024]\n",
            "6898 [ D loss: 0.153001, acc.: 94%] [G loss: 6.439384]\n",
            "6899 [ D loss: 0.172008, acc.: 91%] [G loss: 8.182487]\n",
            "6900 [ D loss: 0.221469, acc.: 93%] [G loss: 5.141139]\n",
            "6901 [ D loss: 0.092376, acc.: 99%] [G loss: 4.957076]\n",
            "6902 [ D loss: 0.218018, acc.: 91%] [G loss: 4.073529]\n",
            "6903 [ D loss: 0.211780, acc.: 95%] [G loss: 5.265809]\n",
            "6904 [ D loss: 0.135951, acc.: 96%] [G loss: 5.151132]\n",
            "6905 [ D loss: 0.150765, acc.: 94%] [G loss: 4.920465]\n",
            "6906 [ D loss: 0.184846, acc.: 93%] [G loss: 4.857282]\n",
            "6907 [ D loss: 0.113344, acc.: 97%] [G loss: 6.102238]\n",
            "6908 [ D loss: 0.120000, acc.: 97%] [G loss: 7.892145]\n",
            "6909 [ D loss: 0.287462, acc.: 88%] [G loss: 6.240902]\n",
            "6910 [ D loss: 0.171438, acc.: 93%] [G loss: 6.290967]\n",
            "6911 [ D loss: 0.235978, acc.: 89%] [G loss: 6.742465]\n",
            "6912 [ D loss: 0.053781, acc.: 98%] [G loss: 6.219787]\n",
            "6913 [ D loss: 0.159391, acc.: 93%] [G loss: 4.324043]\n",
            "6914 [ D loss: 0.091258, acc.: 99%] [G loss: 5.062009]\n",
            "6915 [ D loss: 0.269507, acc.: 84%] [G loss: 5.281929]\n",
            "6916 [ D loss: 0.169381, acc.: 94%] [G loss: 5.231496]\n",
            "6917 [ D loss: 0.115978, acc.: 95%] [G loss: 4.443051]\n",
            "6918 [ D loss: 0.265536, acc.: 89%] [G loss: 4.402068]\n",
            "6919 [ D loss: 0.086347, acc.: 97%] [G loss: 6.063581]\n",
            "6920 [ D loss: 0.149424, acc.: 96%] [G loss: 4.024807]\n",
            "6921 [ D loss: 0.235729, acc.: 93%] [G loss: 5.113767]\n",
            "6922 [ D loss: 0.169861, acc.: 94%] [G loss: 5.683064]\n",
            "6923 [ D loss: 0.186761, acc.: 93%] [G loss: 5.572242]\n",
            "6924 [ D loss: 0.121651, acc.: 95%] [G loss: 4.364175]\n",
            "6925 [ D loss: 0.193572, acc.: 94%] [G loss: 5.369295]\n",
            "6926 [ D loss: 0.190567, acc.: 94%] [G loss: 10.756840]\n",
            "6927 [ D loss: 0.111044, acc.: 98%] [G loss: 6.427090]\n",
            "6928 [ D loss: 0.084977, acc.: 97%] [G loss: 6.608102]\n",
            "6929 [ D loss: 0.042262, acc.: 98%] [G loss: 8.611614]\n",
            "6930 [ D loss: 0.189243, acc.: 91%] [G loss: 5.627723]\n",
            "6931 [ D loss: 0.116537, acc.: 97%] [G loss: 6.618066]\n",
            "6932 [ D loss: 0.155948, acc.: 91%] [G loss: 5.318259]\n",
            "6933 [ D loss: 0.095791, acc.: 98%] [G loss: 4.910118]\n",
            "6934 [ D loss: 0.216521, acc.: 91%] [G loss: 4.921511]\n",
            "6935 [ D loss: 0.164491, acc.: 94%] [G loss: 4.809582]\n",
            "6936 [ D loss: 0.224527, acc.: 91%] [G loss: 4.273742]\n",
            "6937 [ D loss: 0.265793, acc.: 88%] [G loss: 4.681630]\n",
            "6938 [ D loss: 0.367989, acc.: 84%] [G loss: 4.893383]\n",
            "6939 [ D loss: 0.315578, acc.: 87%] [G loss: 5.113903]\n",
            "6940 [ D loss: 0.192837, acc.: 92%] [G loss: 6.477757]\n",
            "6941 [ D loss: 0.164103, acc.: 94%] [G loss: 6.739433]\n",
            "6942 [ D loss: 0.140806, acc.: 95%] [G loss: 8.338598]\n",
            "6943 [ D loss: 0.125394, acc.: 97%] [G loss: 8.458052]\n",
            "6944 [ D loss: 0.117217, acc.: 98%] [G loss: 6.555539]\n",
            "6945 [ D loss: 0.126409, acc.: 95%] [G loss: 7.465276]\n",
            "6946 [ D loss: 0.124708, acc.: 95%] [G loss: 6.426788]\n",
            "6947 [ D loss: 0.193276, acc.: 92%] [G loss: 4.801229]\n",
            "6948 [ D loss: 0.173657, acc.: 94%] [G loss: 5.127820]\n",
            "6949 [ D loss: 0.161678, acc.: 95%] [G loss: 5.165729]\n",
            "6950 [ D loss: 0.208241, acc.: 93%] [G loss: 4.848747]\n",
            "6951 [ D loss: 0.170004, acc.: 95%] [G loss: 6.367096]\n",
            "6952 [ D loss: 0.169206, acc.: 93%] [G loss: 4.641166]\n",
            "6953 [ D loss: 0.235371, acc.: 91%] [G loss: 3.990216]\n",
            "6954 [ D loss: 0.207338, acc.: 95%] [G loss: 3.803868]\n",
            "6955 [ D loss: 0.282997, acc.: 85%] [G loss: 5.368104]\n",
            "6956 [ D loss: 0.171934, acc.: 93%] [G loss: 5.902719]\n",
            "6957 [ D loss: 0.190757, acc.: 91%] [G loss: 5.038598]\n",
            "6958 [ D loss: 0.128319, acc.: 96%] [G loss: 3.697968]\n",
            "6959 [ D loss: 0.259530, acc.: 88%] [G loss: 5.551129]\n",
            "6960 [ D loss: 0.204584, acc.: 93%] [G loss: 5.464335]\n",
            "6961 [ D loss: 0.185307, acc.: 93%] [G loss: 6.006319]\n",
            "6962 [ D loss: 0.177008, acc.: 93%] [G loss: 6.672732]\n",
            "6963 [ D loss: 0.145312, acc.: 94%] [G loss: 4.347446]\n",
            "6964 [ D loss: 0.140344, acc.: 95%] [G loss: 5.577369]\n",
            "6965 [ D loss: 0.126955, acc.: 98%] [G loss: 6.949027]\n",
            "6966 [ D loss: 0.091565, acc.: 96%] [G loss: 8.027353]\n",
            "6967 [ D loss: 0.181192, acc.: 94%] [G loss: 3.872669]\n",
            "6968 [ D loss: 0.094536, acc.: 96%] [G loss: 7.181919]\n",
            "6969 [ D loss: 0.213361, acc.: 92%] [G loss: 6.036811]\n",
            "6970 [ D loss: 0.105095, acc.: 96%] [G loss: 7.648495]\n",
            "6971 [ D loss: 0.133140, acc.: 97%] [G loss: 8.190186]\n",
            "6972 [ D loss: 0.208511, acc.: 93%] [G loss: 5.710817]\n",
            "6973 [ D loss: 0.171251, acc.: 94%] [G loss: 6.022357]\n",
            "6974 [ D loss: 0.151251, acc.: 95%] [G loss: 4.339401]\n",
            "6975 [ D loss: 0.174437, acc.: 94%] [G loss: 4.594911]\n",
            "6976 [ D loss: 0.120972, acc.: 97%] [G loss: 5.376531]\n",
            "6977 [ D loss: 0.153330, acc.: 94%] [G loss: 4.485929]\n",
            "6978 [ D loss: 0.122224, acc.: 96%] [G loss: 5.423126]\n",
            "6979 [ D loss: 0.264385, acc.: 91%] [G loss: 4.970973]\n",
            "6980 [ D loss: 0.143934, acc.: 97%] [G loss: 4.206080]\n",
            "6981 [ D loss: 0.185972, acc.: 95%] [G loss: 4.358438]\n",
            "6982 [ D loss: 0.226220, acc.: 89%] [G loss: 4.156676]\n",
            "6983 [ D loss: 0.236482, acc.: 89%] [G loss: 7.482964]\n",
            "6984 [ D loss: 0.193793, acc.: 93%] [G loss: 4.164244]\n",
            "6985 [ D loss: 0.079176, acc.: 98%] [G loss: 8.281410]\n",
            "6986 [ D loss: 0.221069, acc.: 92%] [G loss: 8.204818]\n",
            "6987 [ D loss: 0.320303, acc.: 86%] [G loss: 7.599321]\n",
            "6988 [ D loss: 0.050254, acc.: 99%] [G loss: 5.977207]\n",
            "6989 [ D loss: 0.284897, acc.: 88%] [G loss: 4.792308]\n",
            "6990 [ D loss: 0.090903, acc.: 98%] [G loss: 9.365705]\n",
            "6991 [ D loss: 0.147665, acc.: 93%] [G loss: 7.564503]\n",
            "6992 [ D loss: 0.164883, acc.: 95%] [G loss: 4.586349]\n",
            "6993 [ D loss: 0.111551, acc.: 96%] [G loss: 5.062752]\n",
            "6994 [ D loss: 0.101155, acc.: 98%] [G loss: 4.922750]\n",
            "6995 [ D loss: 0.108829, acc.: 97%] [G loss: 5.563804]\n",
            "6996 [ D loss: 0.154765, acc.: 96%] [G loss: 4.482984]\n",
            "6997 [ D loss: 0.170622, acc.: 93%] [G loss: 7.735498]\n",
            "6998 [ D loss: 0.162209, acc.: 94%] [G loss: 6.719270]\n",
            "6999 [ D loss: 0.102179, acc.: 97%] [G loss: 4.964706]\n",
            "7000 [ D loss: 0.142001, acc.: 96%] [G loss: 5.752952]\n",
            "7001 [ D loss: 0.111491, acc.: 96%] [G loss: 6.246980]\n",
            "7002 [ D loss: 0.113471, acc.: 96%] [G loss: 6.563496]\n",
            "7003 [ D loss: 0.201386, acc.: 92%] [G loss: 4.387434]\n",
            "7004 [ D loss: 0.222057, acc.: 89%] [G loss: 5.223839]\n",
            "7005 [ D loss: 0.201834, acc.: 94%] [G loss: 4.443332]\n",
            "7006 [ D loss: 0.238725, acc.: 90%] [G loss: 5.512258]\n",
            "7007 [ D loss: 0.183690, acc.: 90%] [G loss: 6.030926]\n",
            "7008 [ D loss: 0.125751, acc.: 96%] [G loss: 4.813459]\n",
            "7009 [ D loss: 0.300376, acc.: 84%] [G loss: 5.628516]\n",
            "7010 [ D loss: 0.239497, acc.: 91%] [G loss: 5.819449]\n",
            "7011 [ D loss: 0.182365, acc.: 92%] [G loss: 5.187209]\n",
            "7012 [ D loss: 0.080180, acc.: 98%] [G loss: 5.331827]\n",
            "7013 [ D loss: 0.192871, acc.: 92%] [G loss: 4.159573]\n",
            "7014 [ D loss: 0.108589, acc.: 98%] [G loss: 5.361561]\n",
            "7015 [ D loss: 0.229658, acc.: 92%] [G loss: 5.087386]\n",
            "7016 [ D loss: 0.198815, acc.: 93%] [G loss: 4.654054]\n",
            "7017 [ D loss: 0.162627, acc.: 95%] [G loss: 5.807187]\n",
            "7018 [ D loss: 0.175639, acc.: 95%] [G loss: 5.168561]\n",
            "7019 [ D loss: 0.153556, acc.: 95%] [G loss: 5.795267]\n",
            "7020 [ D loss: 0.153278, acc.: 93%] [G loss: 6.054739]\n",
            "7021 [ D loss: 0.252256, acc.: 87%] [G loss: 5.470383]\n",
            "7022 [ D loss: 0.084721, acc.: 98%] [G loss: 6.368052]\n",
            "7023 [ D loss: 0.168466, acc.: 94%] [G loss: 7.287285]\n",
            "7024 [ D loss: 0.167414, acc.: 95%] [G loss: 7.546037]\n",
            "7025 [ D loss: 0.069023, acc.: 98%] [G loss: 7.895460]\n",
            "7026 [ D loss: 0.179056, acc.: 92%] [G loss: 5.194830]\n",
            "7027 [ D loss: 0.155610, acc.: 95%] [G loss: 4.339771]\n",
            "7028 [ D loss: 0.150872, acc.: 95%] [G loss: 4.789844]\n",
            "7029 [ D loss: 0.090352, acc.: 99%] [G loss: 6.651265]\n",
            "7030 [ D loss: 0.140411, acc.: 95%] [G loss: 5.451098]\n",
            "7031 [ D loss: 0.094687, acc.: 96%] [G loss: 5.646959]\n",
            "7032 [ D loss: 0.128939, acc.: 96%] [G loss: 9.898146]\n",
            "7033 [ D loss: 0.105657, acc.: 97%] [G loss: 7.640726]\n",
            "7034 [ D loss: 0.149787, acc.: 95%] [G loss: 5.242554]\n",
            "7035 [ D loss: 0.117169, acc.: 98%] [G loss: 5.424145]\n",
            "7036 [ D loss: 0.190330, acc.: 92%] [G loss: 4.873271]\n",
            "7037 [ D loss: 0.120852, acc.: 95%] [G loss: 4.972473]\n",
            "7038 [ D loss: 0.113510, acc.: 98%] [G loss: 4.026608]\n",
            "7039 [ D loss: 0.130556, acc.: 97%] [G loss: 4.398653]\n",
            "7040 [ D loss: 0.239102, acc.: 89%] [G loss: 6.296244]\n",
            "7041 [ D loss: 0.182104, acc.: 91%] [G loss: 6.271276]\n",
            "7042 [ D loss: 0.135949, acc.: 95%] [G loss: 3.176449]\n",
            "7043 [ D loss: 0.149405, acc.: 97%] [G loss: 5.784644]\n",
            "7044 [ D loss: 0.112652, acc.: 96%] [G loss: 4.236101]\n",
            "7045 [ D loss: 0.082334, acc.: 98%] [G loss: 3.655294]\n",
            "7046 [ D loss: 0.234003, acc.: 88%] [G loss: 8.596333]\n",
            "7047 [ D loss: 0.207056, acc.: 94%] [G loss: 7.326527]\n",
            "7048 [ D loss: 0.203381, acc.: 91%] [G loss: 4.463578]\n",
            "7049 [ D loss: 0.263096, acc.: 91%] [G loss: 6.975388]\n",
            "7050 [ D loss: 0.193753, acc.: 93%] [G loss: 8.828922]\n",
            "7051 [ D loss: 0.130818, acc.: 96%] [G loss: 6.719712]\n",
            "7052 [ D loss: 0.156805, acc.: 93%] [G loss: 5.389657]\n",
            "7053 [ D loss: 0.064739, acc.: 98%] [G loss: 6.019721]\n",
            "7054 [ D loss: 0.140831, acc.: 95%] [G loss: 7.146558]\n",
            "7055 [ D loss: 0.066553, acc.: 99%] [G loss: 7.437755]\n",
            "7056 [ D loss: 0.269919, acc.: 86%] [G loss: 5.984011]\n",
            "7057 [ D loss: 0.154033, acc.: 97%] [G loss: 11.211880]\n",
            "7058 [ D loss: 0.129798, acc.: 96%] [G loss: 5.906258]\n",
            "7059 [ D loss: 0.086538, acc.: 98%] [G loss: 5.480741]\n",
            "7060 [ D loss: 0.114289, acc.: 97%] [G loss: 7.674778]\n",
            "7061 [ D loss: 0.183284, acc.: 94%] [G loss: 6.791090]\n",
            "7062 [ D loss: 0.089451, acc.: 95%] [G loss: 5.904916]\n",
            "7063 [ D loss: 0.077748, acc.: 98%] [G loss: 4.206439]\n",
            "7064 [ D loss: 0.102992, acc.: 96%] [G loss: 5.748823]\n",
            "7065 [ D loss: 0.273857, acc.: 92%] [G loss: 6.388677]\n",
            "7066 [ D loss: 0.313031, acc.: 84%] [G loss: 6.761370]\n",
            "7067 [ D loss: 0.109481, acc.: 97%] [G loss: 7.231376]\n",
            "7068 [ D loss: 0.217135, acc.: 92%] [G loss: 7.488706]\n",
            "7069 [ D loss: 0.063514, acc.: 98%] [G loss: 6.608402]\n",
            "7070 [ D loss: 0.114357, acc.: 97%] [G loss: 5.713389]\n",
            "7071 [ D loss: 0.116984, acc.: 96%] [G loss: 5.709724]\n",
            "7072 [ D loss: 0.121569, acc.: 95%] [G loss: 4.881705]\n",
            "7073 [ D loss: 0.255793, acc.: 88%] [G loss: 4.992038]\n",
            "7074 [ D loss: 0.129501, acc.: 94%] [G loss: 7.812438]\n",
            "7075 [ D loss: 0.047469, acc.: 99%] [G loss: 7.875183]\n",
            "7076 [ D loss: 0.111906, acc.: 96%] [G loss: 5.515528]\n",
            "7077 [ D loss: 0.097660, acc.: 98%] [G loss: 5.371517]\n",
            "7078 [ D loss: 0.176061, acc.: 95%] [G loss: 5.400868]\n",
            "7079 [ D loss: 0.142259, acc.: 95%] [G loss: 4.912992]\n",
            "7080 [ D loss: 0.121451, acc.: 97%] [G loss: 6.990423]\n",
            "7081 [ D loss: 0.151863, acc.: 94%] [G loss: 5.169511]\n",
            "7082 [ D loss: 0.219409, acc.: 88%] [G loss: 5.008489]\n",
            "7083 [ D loss: 0.141501, acc.: 97%] [G loss: 7.303630]\n",
            "7084 [ D loss: 0.150150, acc.: 95%] [G loss: 10.845902]\n",
            "7085 [ D loss: 0.138718, acc.: 95%] [G loss: 6.152179]\n",
            "7086 [ D loss: 0.074432, acc.: 98%] [G loss: 5.756431]\n",
            "7087 [ D loss: 0.144009, acc.: 95%] [G loss: 5.255203]\n",
            "7088 [ D loss: 0.099195, acc.: 98%] [G loss: 5.654027]\n",
            "7089 [ D loss: 0.111080, acc.: 95%] [G loss: 6.482008]\n",
            "7090 [ D loss: 0.182611, acc.: 91%] [G loss: 6.062837]\n",
            "7091 [ D loss: 0.187333, acc.: 90%] [G loss: 4.678046]\n",
            "7092 [ D loss: 0.279749, acc.: 88%] [G loss: 7.384533]\n",
            "7093 [ D loss: 0.226677, acc.: 90%] [G loss: 5.494831]\n",
            "7094 [ D loss: 0.152875, acc.: 92%] [G loss: 5.838299]\n",
            "7095 [ D loss: 0.159677, acc.: 94%] [G loss: 5.362333]\n",
            "7096 [ D loss: 0.145965, acc.: 96%] [G loss: 4.783312]\n",
            "7097 [ D loss: 0.234751, acc.: 91%] [G loss: 4.863865]\n",
            "7098 [ D loss: 0.074599, acc.: 98%] [G loss: 4.821011]\n",
            "7099 [ D loss: 0.139685, acc.: 95%] [G loss: 4.688475]\n",
            "7100 [ D loss: 0.114067, acc.: 96%] [G loss: 6.914281]\n",
            "7101 [ D loss: 0.202552, acc.: 91%] [G loss: 4.936152]\n",
            "7102 [ D loss: 0.216069, acc.: 94%] [G loss: 3.605904]\n",
            "7103 [ D loss: 0.282501, acc.: 90%] [G loss: 5.228303]\n",
            "7104 [ D loss: 0.117586, acc.: 97%] [G loss: 4.860247]\n",
            "7105 [ D loss: 0.166579, acc.: 94%] [G loss: 4.775612]\n",
            "7106 [ D loss: 0.188297, acc.: 93%] [G loss: 5.923715]\n",
            "7107 [ D loss: 0.226939, acc.: 90%] [G loss: 5.782775]\n",
            "7108 [ D loss: 0.165075, acc.: 96%] [G loss: 3.669773]\n",
            "7109 [ D loss: 0.116704, acc.: 96%] [G loss: 5.601529]\n",
            "7110 [ D loss: 0.164636, acc.: 95%] [G loss: 5.181960]\n",
            "7111 [ D loss: 0.300666, acc.: 88%] [G loss: 5.278553]\n",
            "7112 [ D loss: 0.162387, acc.: 95%] [G loss: 7.368029]\n",
            "7113 [ D loss: 0.138617, acc.: 95%] [G loss: 9.849224]\n",
            "7114 [ D loss: 0.094236, acc.: 97%] [G loss: 5.222909]\n",
            "7115 [ D loss: 0.173499, acc.: 94%] [G loss: 6.271095]\n",
            "7116 [ D loss: 0.135066, acc.: 95%] [G loss: 6.055798]\n",
            "7117 [ D loss: 0.100114, acc.: 98%] [G loss: 5.842172]\n",
            "7118 [ D loss: 0.102148, acc.: 97%] [G loss: 4.992544]\n",
            "7119 [ D loss: 0.082648, acc.: 97%] [G loss: 4.404797]\n",
            "7120 [ D loss: 0.199110, acc.: 94%] [G loss: 6.675669]\n",
            "7121 [ D loss: 0.237578, acc.: 90%] [G loss: 5.494092]\n",
            "7122 [ D loss: 0.207909, acc.: 91%] [G loss: 4.200052]\n",
            "7123 [ D loss: 0.167181, acc.: 95%] [G loss: 6.852649]\n",
            "7124 [ D loss: 0.150872, acc.: 94%] [G loss: 5.291735]\n",
            "7125 [ D loss: 0.063429, acc.: 99%] [G loss: 7.646970]\n",
            "7126 [ D loss: 0.219033, acc.: 90%] [G loss: 6.043348]\n",
            "7127 [ D loss: 0.101317, acc.: 96%] [G loss: 5.436454]\n",
            "7128 [ D loss: 0.101013, acc.: 96%] [G loss: 11.195838]\n",
            "7129 [ D loss: 0.109101, acc.: 97%] [G loss: 9.998808]\n",
            "7130 [ D loss: 0.101583, acc.: 95%] [G loss: 5.856915]\n",
            "7131 [ D loss: 0.132620, acc.: 95%] [G loss: 5.782004]\n",
            "7132 [ D loss: 0.254213, acc.: 89%] [G loss: 4.442643]\n",
            "7133 [ D loss: 0.160546, acc.: 95%] [G loss: 4.360789]\n",
            "7134 [ D loss: 0.120030, acc.: 97%] [G loss: 6.001876]\n",
            "7135 [ D loss: 0.181217, acc.: 91%] [G loss: 4.948773]\n",
            "7136 [ D loss: 0.117956, acc.: 96%] [G loss: 5.387043]\n",
            "7137 [ D loss: 0.258797, acc.: 88%] [G loss: 4.814834]\n",
            "7138 [ D loss: 0.148333, acc.: 97%] [G loss: 7.355764]\n",
            "7139 [ D loss: 0.167432, acc.: 92%] [G loss: 5.089771]\n",
            "7140 [ D loss: 0.149010, acc.: 95%] [G loss: 7.064462]\n",
            "7141 [ D loss: 0.094525, acc.: 98%] [G loss: 5.403528]\n",
            "7142 [ D loss: 0.148259, acc.: 94%] [G loss: 6.193832]\n",
            "7143 [ D loss: 0.113314, acc.: 96%] [G loss: 5.627504]\n",
            "7144 [ D loss: 0.129764, acc.: 96%] [G loss: 6.169841]\n",
            "7145 [ D loss: 0.204666, acc.: 90%] [G loss: 6.946611]\n",
            "7146 [ D loss: 0.112537, acc.: 95%] [G loss: 4.956618]\n",
            "7147 [ D loss: 0.145397, acc.: 94%] [G loss: 5.296883]\n",
            "7148 [ D loss: 0.108063, acc.: 96%] [G loss: 7.682076]\n",
            "7149 [ D loss: 0.081708, acc.: 98%] [G loss: 10.784210]\n",
            "7150 [ D loss: 0.121524, acc.: 97%] [G loss: 6.233820]\n",
            "7151 [ D loss: 0.219291, acc.: 92%] [G loss: 5.599139]\n",
            "7152 [ D loss: 0.334600, acc.: 90%] [G loss: 4.924872]\n",
            "7153 [ D loss: 0.123935, acc.: 95%] [G loss: 5.803127]\n",
            "7154 [ D loss: 0.091504, acc.: 98%] [G loss: 4.162986]\n",
            "7155 [ D loss: 0.168278, acc.: 92%] [G loss: 4.977908]\n",
            "7156 [ D loss: 0.134349, acc.: 94%] [G loss: 5.102522]\n",
            "7157 [ D loss: 0.274396, acc.: 88%] [G loss: 8.460620]\n",
            "7158 [ D loss: 0.214824, acc.: 92%] [G loss: 3.637799]\n",
            "7159 [ D loss: 0.180223, acc.: 92%] [G loss: 5.647980]\n",
            "7160 [ D loss: 0.091094, acc.: 98%] [G loss: 10.654573]\n",
            "7161 [ D loss: 0.152990, acc.: 94%] [G loss: 8.511027]\n",
            "7162 [ D loss: 0.154966, acc.: 94%] [G loss: 5.972105]\n",
            "7163 [ D loss: 0.115610, acc.: 98%] [G loss: 5.066089]\n",
            "7164 [ D loss: 0.168991, acc.: 95%] [G loss: 4.260813]\n",
            "7165 [ D loss: 0.238908, acc.: 89%] [G loss: 5.505861]\n",
            "7166 [ D loss: 0.238272, acc.: 92%] [G loss: 5.212906]\n",
            "7167 [ D loss: 0.065077, acc.: 99%] [G loss: 9.381627]\n",
            "7168 [ D loss: 0.149585, acc.: 95%] [G loss: 5.079376]\n",
            "7169 [ D loss: 0.086177, acc.: 98%] [G loss: 6.751724]\n",
            "7170 [ D loss: 0.112392, acc.: 98%] [G loss: 6.567671]\n",
            "7171 [ D loss: 0.091333, acc.: 97%] [G loss: 6.904244]\n",
            "7172 [ D loss: 0.140827, acc.: 93%] [G loss: 5.791037]\n",
            "7173 [ D loss: 0.109426, acc.: 96%] [G loss: 9.065013]\n",
            "7174 [ D loss: 0.088245, acc.: 95%] [G loss: 11.844553]\n",
            "7175 [ D loss: 0.035205, acc.: 98%] [G loss: 14.540609]\n",
            "7176 [ D loss: 0.056232, acc.: 98%] [G loss: 11.541325]\n",
            "7177 [ D loss: 0.055851, acc.: 98%] [G loss: 8.108351]\n",
            "7178 [ D loss: 0.104755, acc.: 95%] [G loss: 8.883966]\n",
            "7179 [ D loss: 0.088912, acc.: 96%] [G loss: 7.121801]\n",
            "7180 [ D loss: 0.114308, acc.: 97%] [G loss: 6.449448]\n",
            "7181 [ D loss: 0.110729, acc.: 97%] [G loss: 4.292364]\n",
            "7182 [ D loss: 0.229007, acc.: 92%] [G loss: 8.581354]\n",
            "7183 [ D loss: 0.116795, acc.: 96%] [G loss: 7.588764]\n",
            "7184 [ D loss: 0.097615, acc.: 98%] [G loss: 7.047832]\n",
            "7185 [ D loss: 0.112565, acc.: 96%] [G loss: 5.032867]\n",
            "7186 [ D loss: 0.164150, acc.: 95%] [G loss: 5.783454]\n",
            "7187 [ D loss: 0.185571, acc.: 95%] [G loss: 5.656862]\n",
            "7188 [ D loss: 0.163902, acc.: 95%] [G loss: 5.071190]\n",
            "7189 [ D loss: 0.216051, acc.: 89%] [G loss: 5.510169]\n",
            "7190 [ D loss: 0.275683, acc.: 89%] [G loss: 4.343389]\n",
            "7191 [ D loss: 0.265356, acc.: 88%] [G loss: 5.299376]\n",
            "7192 [ D loss: 0.159474, acc.: 95%] [G loss: 4.694755]\n",
            "7193 [ D loss: 0.154476, acc.: 94%] [G loss: 5.387714]\n",
            "7194 [ D loss: 0.176008, acc.: 95%] [G loss: 3.697024]\n",
            "7195 [ D loss: 0.171837, acc.: 95%] [G loss: 5.179557]\n",
            "7196 [ D loss: 0.196476, acc.: 95%] [G loss: 6.367719]\n",
            "7197 [ D loss: 0.147649, acc.: 93%] [G loss: 6.798959]\n",
            "7198 [ D loss: 0.289320, acc.: 85%] [G loss: 6.842496]\n",
            "7199 [ D loss: 0.096497, acc.: 97%] [G loss: 5.992611]\n",
            "7200 [ D loss: 0.133915, acc.: 95%] [G loss: 8.385610]\n",
            "7201 [ D loss: 0.159288, acc.: 94%] [G loss: 4.869269]\n",
            "7202 [ D loss: 0.050053, acc.: 98%] [G loss: 6.031031]\n",
            "7203 [ D loss: 0.154362, acc.: 93%] [G loss: 6.423734]\n",
            "7204 [ D loss: 0.128745, acc.: 95%] [G loss: 9.913705]\n",
            "7205 [ D loss: 0.138404, acc.: 95%] [G loss: 5.463844]\n",
            "7206 [ D loss: 0.281617, acc.: 87%] [G loss: 12.008984]\n",
            "7207 [ D loss: 0.264782, acc.: 88%] [G loss: 6.054741]\n",
            "7208 [ D loss: 0.271335, acc.: 85%] [G loss: 6.049292]\n",
            "7209 [ D loss: 0.181401, acc.: 95%] [G loss: 7.379488]\n",
            "7210 [ D loss: 0.098800, acc.: 97%] [G loss: 6.632512]\n",
            "7211 [ D loss: 0.100336, acc.: 97%] [G loss: 12.867767]\n",
            "7212 [ D loss: 0.109234, acc.: 97%] [G loss: 7.450183]\n",
            "7213 [ D loss: 0.115503, acc.: 96%] [G loss: 7.379194]\n",
            "7214 [ D loss: 0.067790, acc.: 98%] [G loss: 6.754373]\n",
            "7215 [ D loss: 0.048828, acc.: 100%] [G loss: 7.009188]\n",
            "7216 [ D loss: 0.121481, acc.: 96%] [G loss: 5.036016]\n",
            "7217 [ D loss: 0.136588, acc.: 95%] [G loss: 5.969130]\n",
            "7218 [ D loss: 0.148391, acc.: 95%] [G loss: 4.906071]\n",
            "7219 [ D loss: 0.255664, acc.: 89%] [G loss: 6.307147]\n",
            "7220 [ D loss: 0.201127, acc.: 93%] [G loss: 7.503416]\n",
            "7221 [ D loss: 0.257089, acc.: 88%] [G loss: 6.488151]\n",
            "7222 [ D loss: 0.138487, acc.: 95%] [G loss: 5.775179]\n",
            "7223 [ D loss: 0.100806, acc.: 97%] [G loss: 9.096803]\n",
            "7224 [ D loss: 0.161174, acc.: 93%] [G loss: 5.222178]\n",
            "7225 [ D loss: 0.137961, acc.: 94%] [G loss: 5.883514]\n",
            "7226 [ D loss: 0.208650, acc.: 91%] [G loss: 8.667117]\n",
            "7227 [ D loss: 0.138155, acc.: 96%] [G loss: 5.893065]\n",
            "7228 [ D loss: 0.078760, acc.: 99%] [G loss: 5.207003]\n",
            "7229 [ D loss: 0.144288, acc.: 95%] [G loss: 5.079954]\n",
            "7230 [ D loss: 0.076256, acc.: 98%] [G loss: 5.691860]\n",
            "7231 [ D loss: 0.077187, acc.: 98%] [G loss: 6.973511]\n",
            "7232 [ D loss: 0.125322, acc.: 98%] [G loss: 5.564686]\n",
            "7233 [ D loss: 0.092059, acc.: 98%] [G loss: 8.313242]\n",
            "7234 [ D loss: 0.147279, acc.: 95%] [G loss: 7.140819]\n",
            "7235 [ D loss: 0.115087, acc.: 96%] [G loss: 5.145695]\n",
            "7236 [ D loss: 0.146016, acc.: 95%] [G loss: 3.710635]\n",
            "7237 [ D loss: 0.240472, acc.: 89%] [G loss: 6.891267]\n",
            "7238 [ D loss: 0.087992, acc.: 98%] [G loss: 7.844462]\n",
            "7239 [ D loss: 0.070809, acc.: 97%] [G loss: 4.839108]\n",
            "7240 [ D loss: 0.151187, acc.: 94%] [G loss: 6.690203]\n",
            "7241 [ D loss: 0.099432, acc.: 98%] [G loss: 5.230595]\n",
            "7242 [ D loss: 0.122581, acc.: 97%] [G loss: 3.954210]\n",
            "7243 [ D loss: 0.222407, acc.: 91%] [G loss: 4.361737]\n",
            "7244 [ D loss: 0.105446, acc.: 98%] [G loss: 6.232987]\n",
            "7245 [ D loss: 0.162633, acc.: 97%] [G loss: 5.339344]\n",
            "7246 [ D loss: 0.109463, acc.: 99%] [G loss: 5.163322]\n",
            "7247 [ D loss: 0.184456, acc.: 89%] [G loss: 4.157222]\n",
            "7248 [ D loss: 0.197210, acc.: 91%] [G loss: 6.521852]\n",
            "7249 [ D loss: 0.077473, acc.: 99%] [G loss: 6.471371]\n",
            "7250 [ D loss: 0.205766, acc.: 90%] [G loss: 4.560753]\n",
            "7251 [ D loss: 0.200810, acc.: 91%] [G loss: 4.789766]\n",
            "7252 [ D loss: 0.213117, acc.: 95%] [G loss: 5.014755]\n",
            "7253 [ D loss: 0.181735, acc.: 93%] [G loss: 4.684014]\n",
            "7254 [ D loss: 0.208154, acc.: 93%] [G loss: 5.249454]\n",
            "7255 [ D loss: 0.290666, acc.: 89%] [G loss: 4.528941]\n",
            "7256 [ D loss: 0.081038, acc.: 98%] [G loss: 7.132369]\n",
            "7257 [ D loss: 0.136535, acc.: 95%] [G loss: 7.572902]\n",
            "7258 [ D loss: 0.084383, acc.: 98%] [G loss: 5.292325]\n",
            "7259 [ D loss: 0.120995, acc.: 97%] [G loss: 5.405400]\n",
            "7260 [ D loss: 0.118036, acc.: 95%] [G loss: 4.534429]\n",
            "7261 [ D loss: 0.208835, acc.: 91%] [G loss: 5.437523]\n",
            "7262 [ D loss: 0.166238, acc.: 95%] [G loss: 4.717782]\n",
            "7263 [ D loss: 0.188622, acc.: 92%] [G loss: 5.290297]\n",
            "7264 [ D loss: 0.168548, acc.: 95%] [G loss: 7.328000]\n",
            "7265 [ D loss: 0.131120, acc.: 96%] [G loss: 5.386503]\n",
            "7266 [ D loss: 0.135914, acc.: 96%] [G loss: 4.610569]\n",
            "7267 [ D loss: 0.277514, acc.: 88%] [G loss: 7.746137]\n",
            "7268 [ D loss: 0.054319, acc.: 99%] [G loss: 4.937372]\n",
            "7269 [ D loss: 0.204171, acc.: 91%] [G loss: 5.394063]\n",
            "7270 [ D loss: 0.196318, acc.: 91%] [G loss: 6.182509]\n",
            "7271 [ D loss: 0.095229, acc.: 95%] [G loss: 7.973217]\n",
            "7272 [ D loss: 0.188052, acc.: 92%] [G loss: 6.056083]\n",
            "7273 [ D loss: 0.107376, acc.: 97%] [G loss: 6.353298]\n",
            "7274 [ D loss: 0.103559, acc.: 97%] [G loss: 5.103371]\n",
            "7275 [ D loss: 0.205869, acc.: 92%] [G loss: 5.765123]\n",
            "7276 [ D loss: 0.115088, acc.: 98%] [G loss: 4.970582]\n",
            "7277 [ D loss: 0.131252, acc.: 98%] [G loss: 4.214232]\n",
            "7278 [ D loss: 0.209285, acc.: 94%] [G loss: 5.473343]\n",
            "7279 [ D loss: 0.194022, acc.: 92%] [G loss: 5.094078]\n",
            "7280 [ D loss: 0.158726, acc.: 96%] [G loss: 5.601593]\n",
            "7281 [ D loss: 0.127957, acc.: 94%] [G loss: 11.064823]\n",
            "7282 [ D loss: 0.075943, acc.: 99%] [G loss: 9.550186]\n",
            "7283 [ D loss: 0.052855, acc.: 99%] [G loss: 7.218466]\n",
            "7284 [ D loss: 0.115826, acc.: 96%] [G loss: 7.018877]\n",
            "7285 [ D loss: 0.103408, acc.: 98%] [G loss: 6.010132]\n",
            "7286 [ D loss: 0.096324, acc.: 97%] [G loss: 3.963513]\n",
            "7287 [ D loss: 0.098076, acc.: 98%] [G loss: 3.448481]\n",
            "7288 [ D loss: 0.149317, acc.: 95%] [G loss: 9.187514]\n",
            "7289 [ D loss: 0.116237, acc.: 96%] [G loss: 5.746805]\n",
            "7290 [ D loss: 0.133251, acc.: 93%] [G loss: 8.206815]\n",
            "7291 [ D loss: 0.050841, acc.: 98%] [G loss: 9.140299]\n",
            "7292 [ D loss: 0.145941, acc.: 95%] [G loss: 6.632957]\n",
            "7293 [ D loss: 0.063906, acc.: 98%] [G loss: 6.383554]\n",
            "7294 [ D loss: 0.163529, acc.: 95%] [G loss: 4.892639]\n",
            "7295 [ D loss: 0.137870, acc.: 95%] [G loss: 6.217699]\n",
            "7296 [ D loss: 0.163959, acc.: 95%] [G loss: 6.438518]\n",
            "7297 [ D loss: 0.131907, acc.: 94%] [G loss: 8.453813]\n",
            "7298 [ D loss: 0.235388, acc.: 89%] [G loss: 7.598841]\n",
            "7299 [ D loss: 0.120214, acc.: 95%] [G loss: 7.652932]\n",
            "7300 [ D loss: 0.152469, acc.: 95%] [G loss: 6.424342]\n",
            "7301 [ D loss: 0.102277, acc.: 97%] [G loss: 11.739679]\n",
            "7302 [ D loss: 0.069688, acc.: 99%] [G loss: 7.713615]\n",
            "7303 [ D loss: 0.147301, acc.: 92%] [G loss: 6.128355]\n",
            "7304 [ D loss: 0.061397, acc.: 98%] [G loss: 7.340034]\n",
            "7305 [ D loss: 0.110146, acc.: 97%] [G loss: 5.079875]\n",
            "7306 [ D loss: 0.046556, acc.: 98%] [G loss: 5.792464]\n",
            "7307 [ D loss: 0.083854, acc.: 97%] [G loss: 9.737518]\n",
            "7308 [ D loss: 0.039725, acc.: 98%] [G loss: 9.780289]\n",
            "7309 [ D loss: 0.176934, acc.: 92%] [G loss: 7.954493]\n",
            "7310 [ D loss: 0.119832, acc.: 95%] [G loss: 6.399498]\n",
            "7311 [ D loss: 0.123906, acc.: 95%] [G loss: 11.064787]\n",
            "7312 [ D loss: 0.101409, acc.: 96%] [G loss: 5.729231]\n",
            "7313 [ D loss: 0.200084, acc.: 94%] [G loss: 5.671910]\n",
            "7314 [ D loss: 0.259616, acc.: 88%] [G loss: 4.554460]\n",
            "7315 [ D loss: 0.169925, acc.: 95%] [G loss: 3.924357]\n",
            "7316 [ D loss: 0.178433, acc.: 94%] [G loss: 4.361043]\n",
            "7317 [ D loss: 0.103298, acc.: 98%] [G loss: 4.885817]\n",
            "7318 [ D loss: 0.288611, acc.: 87%] [G loss: 4.671394]\n",
            "7319 [ D loss: 0.188742, acc.: 94%] [G loss: 4.729413]\n",
            "7320 [ D loss: 0.153678, acc.: 97%] [G loss: 6.271606]\n",
            "7321 [ D loss: 0.113000, acc.: 97%] [G loss: 4.857306]\n",
            "7322 [ D loss: 0.196447, acc.: 92%] [G loss: 6.100424]\n",
            "7323 [ D loss: 0.106394, acc.: 97%] [G loss: 6.829972]\n",
            "7324 [ D loss: 0.120448, acc.: 97%] [G loss: 4.915376]\n",
            "7325 [ D loss: 0.136539, acc.: 94%] [G loss: 5.830117]\n",
            "7326 [ D loss: 0.112706, acc.: 96%] [G loss: 6.647190]\n",
            "7327 [ D loss: 0.079204, acc.: 96%] [G loss: 6.007468]\n",
            "7328 [ D loss: 0.124398, acc.: 94%] [G loss: 6.377327]\n",
            "7329 [ D loss: 0.156192, acc.: 95%] [G loss: 4.721383]\n",
            "7330 [ D loss: 0.138132, acc.: 94%] [G loss: 6.292159]\n",
            "7331 [ D loss: 0.077785, acc.: 98%] [G loss: 9.770678]\n",
            "7332 [ D loss: 0.077188, acc.: 98%] [G loss: 4.807425]\n",
            "7333 [ D loss: 0.098786, acc.: 97%] [G loss: 7.340195]\n",
            "7334 [ D loss: 0.130739, acc.: 95%] [G loss: 11.363762]\n",
            "7335 [ D loss: 0.079198, acc.: 98%] [G loss: 11.299698]\n",
            "7336 [ D loss: 0.099094, acc.: 98%] [G loss: 8.547043]\n",
            "7337 [ D loss: 0.134490, acc.: 96%] [G loss: 5.465755]\n",
            "7338 [ D loss: 0.108092, acc.: 97%] [G loss: 5.639246]\n",
            "7339 [ D loss: 0.178463, acc.: 94%] [G loss: 5.458737]\n",
            "7340 [ D loss: 0.108626, acc.: 98%] [G loss: 7.839155]\n",
            "7341 [ D loss: 0.121842, acc.: 94%] [G loss: 6.906947]\n",
            "7342 [ D loss: 0.092380, acc.: 98%] [G loss: 13.850420]\n",
            "7343 [ D loss: 0.090278, acc.: 96%] [G loss: 7.345545]\n",
            "7344 [ D loss: 0.194695, acc.: 93%] [G loss: 6.020768]\n",
            "7345 [ D loss: 0.054238, acc.: 98%] [G loss: 6.356242]\n",
            "7346 [ D loss: 0.179652, acc.: 93%] [G loss: 4.597033]\n",
            "7347 [ D loss: 0.171436, acc.: 95%] [G loss: 6.100793]\n",
            "7348 [ D loss: 0.133382, acc.: 95%] [G loss: 4.932621]\n",
            "7349 [ D loss: 0.175351, acc.: 94%] [G loss: 7.658011]\n",
            "7350 [ D loss: 0.126958, acc.: 96%] [G loss: 6.721371]\n",
            "7351 [ D loss: 0.179616, acc.: 94%] [G loss: 6.135248]\n",
            "7352 [ D loss: 0.176446, acc.: 94%] [G loss: 8.539948]\n",
            "7353 [ D loss: 0.240192, acc.: 92%] [G loss: 9.619496]\n",
            "7354 [ D loss: 0.199939, acc.: 92%] [G loss: 7.295945]\n",
            "7355 [ D loss: 0.080505, acc.: 96%] [G loss: 12.955933]\n",
            "7356 [ D loss: 0.062543, acc.: 98%] [G loss: 10.385219]\n",
            "7357 [ D loss: 0.118124, acc.: 95%] [G loss: 7.017153]\n",
            "7358 [ D loss: 0.136933, acc.: 95%] [G loss: 5.783282]\n",
            "7359 [ D loss: 0.115367, acc.: 95%] [G loss: 5.472393]\n",
            "7360 [ D loss: 0.145528, acc.: 97%] [G loss: 3.364507]\n",
            "7361 [ D loss: 0.191402, acc.: 91%] [G loss: 6.574393]\n",
            "7362 [ D loss: 0.185084, acc.: 92%] [G loss: 7.789242]\n",
            "7363 [ D loss: 0.185371, acc.: 91%] [G loss: 10.249694]\n",
            "7364 [ D loss: 0.078596, acc.: 97%] [G loss: 7.068301]\n",
            "7365 [ D loss: 0.127826, acc.: 96%] [G loss: 8.689813]\n",
            "7366 [ D loss: 0.166862, acc.: 94%] [G loss: 5.912137]\n",
            "7367 [ D loss: 0.066990, acc.: 98%] [G loss: 10.044971]\n",
            "7368 [ D loss: 0.088497, acc.: 97%] [G loss: 10.806010]\n",
            "7369 [ D loss: 0.082319, acc.: 96%] [G loss: 5.252390]\n",
            "7370 [ D loss: 0.068669, acc.: 99%] [G loss: 8.055624]\n",
            "7371 [ D loss: 0.115004, acc.: 97%] [G loss: 6.315376]\n",
            "7372 [ D loss: 0.089666, acc.: 97%] [G loss: 6.124155]\n",
            "7373 [ D loss: 0.287706, acc.: 87%] [G loss: 6.776093]\n",
            "7374 [ D loss: 0.128485, acc.: 94%] [G loss: 5.466514]\n",
            "7375 [ D loss: 0.246250, acc.: 91%] [G loss: 6.473800]\n",
            "7376 [ D loss: 0.107548, acc.: 96%] [G loss: 4.844433]\n",
            "7377 [ D loss: 0.151696, acc.: 94%] [G loss: 6.561287]\n",
            "7378 [ D loss: 0.228258, acc.: 89%] [G loss: 5.482642]\n",
            "7379 [ D loss: 0.096666, acc.: 96%] [G loss: 5.337797]\n",
            "7380 [ D loss: 0.289438, acc.: 84%] [G loss: 5.679959]\n",
            "7381 [ D loss: 0.077734, acc.: 98%] [G loss: 7.032146]\n",
            "7382 [ D loss: 0.175035, acc.: 95%] [G loss: 5.987107]\n",
            "7383 [ D loss: 0.272969, acc.: 92%] [G loss: 4.832821]\n",
            "7384 [ D loss: 0.268831, acc.: 89%] [G loss: 7.242891]\n",
            "7385 [ D loss: 0.045052, acc.: 100%] [G loss: 15.240067]\n",
            "7386 [ D loss: 0.123533, acc.: 97%] [G loss: 7.566252]\n",
            "7387 [ D loss: 0.060876, acc.: 97%] [G loss: 4.944478]\n",
            "7388 [ D loss: 0.194260, acc.: 92%] [G loss: 7.494972]\n",
            "7389 [ D loss: 0.204539, acc.: 91%] [G loss: 7.991160]\n",
            "7390 [ D loss: 0.161815, acc.: 94%] [G loss: 5.422186]\n",
            "7391 [ D loss: 0.124360, acc.: 96%] [G loss: 7.908233]\n",
            "7392 [ D loss: 0.066486, acc.: 98%] [G loss: 11.240223]\n",
            "7393 [ D loss: 0.052155, acc.: 98%] [G loss: 6.421256]\n",
            "7394 [ D loss: 0.192376, acc.: 93%] [G loss: 8.486588]\n",
            "7395 [ D loss: 0.203842, acc.: 93%] [G loss: 9.832230]\n",
            "7396 [ D loss: 0.102109, acc.: 96%] [G loss: 8.237539]\n",
            "7397 [ D loss: 0.109088, acc.: 98%] [G loss: 7.075247]\n",
            "7398 [ D loss: 0.084209, acc.: 97%] [G loss: 8.645329]\n",
            "7399 [ D loss: 0.111016, acc.: 97%] [G loss: 8.026408]\n",
            "7400 [ D loss: 0.137179, acc.: 97%] [G loss: 5.983721]\n",
            "7401 [ D loss: 0.204072, acc.: 90%] [G loss: 5.317555]\n",
            "7402 [ D loss: 0.200295, acc.: 93%] [G loss: 5.540720]\n",
            "7403 [ D loss: 0.192357, acc.: 93%] [G loss: 5.606291]\n",
            "7404 [ D loss: 0.140235, acc.: 95%] [G loss: 6.143988]\n",
            "7405 [ D loss: 0.192080, acc.: 91%] [G loss: 5.124127]\n",
            "7406 [ D loss: 0.114399, acc.: 96%] [G loss: 5.597109]\n",
            "7407 [ D loss: 0.210259, acc.: 93%] [G loss: 4.412751]\n",
            "7408 [ D loss: 0.108498, acc.: 96%] [G loss: 5.296357]\n",
            "7409 [ D loss: 0.159515, acc.: 97%] [G loss: 5.556636]\n",
            "7410 [ D loss: 0.142506, acc.: 95%] [G loss: 5.441849]\n",
            "7411 [ D loss: 0.066923, acc.: 98%] [G loss: 7.942647]\n",
            "7412 [ D loss: 0.139304, acc.: 95%] [G loss: 6.486469]\n",
            "7413 [ D loss: 0.072130, acc.: 98%] [G loss: 7.067242]\n",
            "7414 [ D loss: 0.118601, acc.: 97%] [G loss: 7.394199]\n",
            "7415 [ D loss: 0.119071, acc.: 95%] [G loss: 7.492836]\n",
            "7416 [ D loss: 0.107845, acc.: 95%] [G loss: 6.065010]\n",
            "7417 [ D loss: 0.134334, acc.: 93%] [G loss: 6.837905]\n",
            "7418 [ D loss: 0.142878, acc.: 94%] [G loss: 6.029602]\n",
            "7419 [ D loss: 0.114053, acc.: 96%] [G loss: 5.253888]\n",
            "7420 [ D loss: 0.165529, acc.: 92%] [G loss: 6.243797]\n",
            "7421 [ D loss: 0.119652, acc.: 97%] [G loss: 7.279731]\n",
            "7422 [ D loss: 0.220151, acc.: 91%] [G loss: 8.680215]\n",
            "7423 [ D loss: 0.166840, acc.: 94%] [G loss: 5.330128]\n",
            "7424 [ D loss: 0.130693, acc.: 97%] [G loss: 5.848684]\n",
            "7425 [ D loss: 0.125834, acc.: 96%] [G loss: 5.082087]\n",
            "7426 [ D loss: 0.164805, acc.: 94%] [G loss: 7.977467]\n",
            "7427 [ D loss: 0.182002, acc.: 91%] [G loss: 6.104198]\n",
            "7428 [ D loss: 0.097968, acc.: 97%] [G loss: 5.197916]\n",
            "7429 [ D loss: 0.278223, acc.: 88%] [G loss: 5.406870]\n",
            "7430 [ D loss: 0.222969, acc.: 91%] [G loss: 5.777501]\n",
            "7431 [ D loss: 0.114950, acc.: 96%] [G loss: 5.243736]\n",
            "7432 [ D loss: 0.122271, acc.: 96%] [G loss: 6.160542]\n",
            "7433 [ D loss: 0.087425, acc.: 98%] [G loss: 6.448566]\n",
            "7434 [ D loss: 0.145492, acc.: 95%] [G loss: 7.242032]\n",
            "7435 [ D loss: 0.124950, acc.: 94%] [G loss: 5.468808]\n",
            "7436 [ D loss: 0.223439, acc.: 94%] [G loss: 7.089923]\n",
            "7437 [ D loss: 0.128851, acc.: 95%] [G loss: 10.028891]\n",
            "7438 [ D loss: 0.157526, acc.: 92%] [G loss: 11.072016]\n",
            "7439 [ D loss: 0.180084, acc.: 95%] [G loss: 6.040412]\n",
            "7440 [ D loss: 0.070897, acc.: 98%] [G loss: 5.646636]\n",
            "7441 [ D loss: 0.172493, acc.: 91%] [G loss: 5.651652]\n",
            "7442 [ D loss: 0.213589, acc.: 93%] [G loss: 5.936472]\n",
            "7443 [ D loss: 0.097061, acc.: 98%] [G loss: 5.472527]\n",
            "7444 [ D loss: 0.401614, acc.: 80%] [G loss: 4.966030]\n",
            "7445 [ D loss: 0.077399, acc.: 99%] [G loss: 5.353767]\n",
            "7446 [ D loss: 0.210383, acc.: 88%] [G loss: 5.252685]\n",
            "7447 [ D loss: 0.157666, acc.: 91%] [G loss: 6.648447]\n",
            "7448 [ D loss: 0.126831, acc.: 97%] [G loss: 7.692878]\n",
            "7449 [ D loss: 0.182450, acc.: 93%] [G loss: 5.639446]\n",
            "7450 [ D loss: 0.161334, acc.: 95%] [G loss: 4.771466]\n",
            "7451 [ D loss: 0.303928, acc.: 85%] [G loss: 8.003938]\n",
            "7452 [ D loss: 0.147172, acc.: 95%] [G loss: 6.724778]\n",
            "7453 [ D loss: 0.104773, acc.: 95%] [G loss: 4.567166]\n",
            "7454 [ D loss: 0.183064, acc.: 91%] [G loss: 5.573187]\n",
            "7455 [ D loss: 0.244997, acc.: 88%] [G loss: 5.577697]\n",
            "7456 [ D loss: 0.117961, acc.: 96%] [G loss: 4.767594]\n",
            "7457 [ D loss: 0.079194, acc.: 96%] [G loss: 5.446935]\n",
            "7458 [ D loss: 0.155484, acc.: 94%] [G loss: 8.233910]\n",
            "7459 [ D loss: 0.268631, acc.: 88%] [G loss: 6.291298]\n",
            "7460 [ D loss: 0.075574, acc.: 98%] [G loss: 8.484716]\n",
            "7461 [ D loss: 0.117917, acc.: 95%] [G loss: 8.328057]\n",
            "7462 [ D loss: 0.103536, acc.: 96%] [G loss: 8.984695]\n",
            "7463 [ D loss: 0.119373, acc.: 95%] [G loss: 7.368410]\n",
            "7464 [ D loss: 0.108806, acc.: 97%] [G loss: 5.933352]\n",
            "7465 [ D loss: 0.150801, acc.: 95%] [G loss: 4.450027]\n",
            "7466 [ D loss: 0.182447, acc.: 92%] [G loss: 5.775245]\n",
            "7467 [ D loss: 0.252675, acc.: 91%] [G loss: 5.343400]\n",
            "7468 [ D loss: 0.171842, acc.: 94%] [G loss: 4.887670]\n",
            "7469 [ D loss: 0.157500, acc.: 96%] [G loss: 5.182172]\n",
            "7470 [ D loss: 0.167426, acc.: 93%] [G loss: 4.543294]\n",
            "7471 [ D loss: 0.203686, acc.: 92%] [G loss: 5.395790]\n",
            "7472 [ D loss: 0.148145, acc.: 94%] [G loss: 7.798923]\n",
            "7473 [ D loss: 0.203963, acc.: 93%] [G loss: 6.419107]\n",
            "7474 [ D loss: 0.141133, acc.: 94%] [G loss: 4.793326]\n",
            "7475 [ D loss: 0.070988, acc.: 98%] [G loss: 8.590647]\n",
            "7476 [ D loss: 0.227955, acc.: 89%] [G loss: 5.153759]\n",
            "7477 [ D loss: 0.206656, acc.: 91%] [G loss: 6.982391]\n",
            "7478 [ D loss: 0.159724, acc.: 93%] [G loss: 5.846702]\n",
            "7479 [ D loss: 0.241044, acc.: 90%] [G loss: 5.702421]\n",
            "7480 [ D loss: 0.068827, acc.: 98%] [G loss: 5.768999]\n",
            "7481 [ D loss: 0.298494, acc.: 87%] [G loss: 7.160047]\n",
            "7482 [ D loss: 0.172703, acc.: 95%] [G loss: 8.380104]\n",
            "7483 [ D loss: 0.082903, acc.: 96%] [G loss: 4.412838]\n",
            "7484 [ D loss: 0.153993, acc.: 94%] [G loss: 8.665524]\n",
            "7485 [ D loss: 0.032714, acc.: 98%] [G loss: 9.023720]\n",
            "7486 [ D loss: 0.064836, acc.: 98%] [G loss: 6.461000]\n",
            "7487 [ D loss: 0.118825, acc.: 96%] [G loss: 9.681892]\n",
            "7488 [ D loss: 0.058888, acc.: 98%] [G loss: 8.570922]\n",
            "7489 [ D loss: 0.066181, acc.: 98%] [G loss: 5.951486]\n",
            "7490 [ D loss: 0.131498, acc.: 95%] [G loss: 5.119015]\n",
            "7491 [ D loss: 0.062568, acc.: 98%] [G loss: 5.501490]\n",
            "7492 [ D loss: 0.198234, acc.: 94%] [G loss: 5.698941]\n",
            "7493 [ D loss: 0.052841, acc.: 100%] [G loss: 5.277192]\n",
            "7494 [ D loss: 0.124357, acc.: 97%] [G loss: 4.338151]\n",
            "7495 [ D loss: 0.153259, acc.: 95%] [G loss: 5.150927]\n",
            "7496 [ D loss: 0.224307, acc.: 94%] [G loss: 5.675207]\n",
            "7497 [ D loss: 0.260296, acc.: 91%] [G loss: 4.218470]\n",
            "7498 [ D loss: 0.127990, acc.: 97%] [G loss: 4.684114]\n",
            "7499 [ D loss: 0.303548, acc.: 90%] [G loss: 5.096469]\n",
            "7500 [ D loss: 0.226889, acc.: 91%] [G loss: 4.219484]\n",
            "7501 [ D loss: 0.244063, acc.: 91%] [G loss: 5.032440]\n",
            "7502 [ D loss: 0.086603, acc.: 98%] [G loss: 5.836660]\n",
            "7503 [ D loss: 0.217596, acc.: 95%] [G loss: 4.413712]\n",
            "7504 [ D loss: 0.170515, acc.: 94%] [G loss: 5.176328]\n",
            "7505 [ D loss: 0.194154, acc.: 95%] [G loss: 5.435436]\n",
            "7506 [ D loss: 0.165217, acc.: 94%] [G loss: 8.040784]\n",
            "7507 [ D loss: 0.114955, acc.: 96%] [G loss: 7.137193]\n",
            "7508 [ D loss: 0.055972, acc.: 100%] [G loss: 7.063542]\n",
            "7509 [ D loss: 0.079708, acc.: 99%] [G loss: 7.810420]\n",
            "7510 [ D loss: 0.081338, acc.: 97%] [G loss: 8.843485]\n",
            "7511 [ D loss: 0.082659, acc.: 98%] [G loss: 9.699274]\n",
            "7512 [ D loss: 0.062102, acc.: 99%] [G loss: 13.149142]\n",
            "7513 [ D loss: 0.042688, acc.: 99%] [G loss: 8.645439]\n",
            "7514 [ D loss: 0.044139, acc.: 100%] [G loss: 5.758619]\n",
            "7515 [ D loss: 0.124888, acc.: 95%] [G loss: 6.794058]\n",
            "7516 [ D loss: 0.176388, acc.: 94%] [G loss: 5.297444]\n",
            "7517 [ D loss: 0.155925, acc.: 95%] [G loss: 5.561219]\n",
            "7518 [ D loss: 0.161176, acc.: 94%] [G loss: 5.714725]\n",
            "7519 [ D loss: 0.153082, acc.: 95%] [G loss: 5.713714]\n",
            "7520 [ D loss: 0.126636, acc.: 96%] [G loss: 4.900225]\n",
            "7521 [ D loss: 0.106338, acc.: 98%] [G loss: 4.905573]\n",
            "7522 [ D loss: 0.251278, acc.: 88%] [G loss: 5.449812]\n",
            "7523 [ D loss: 0.101623, acc.: 95%] [G loss: 6.254800]\n",
            "7524 [ D loss: 0.189609, acc.: 92%] [G loss: 5.188101]\n",
            "7525 [ D loss: 0.209485, acc.: 92%] [G loss: 5.803228]\n",
            "7526 [ D loss: 0.223336, acc.: 91%] [G loss: 3.804327]\n",
            "7527 [ D loss: 0.137705, acc.: 95%] [G loss: 4.810083]\n",
            "7528 [ D loss: 0.186349, acc.: 91%] [G loss: 5.523501]\n",
            "7529 [ D loss: 0.144717, acc.: 96%] [G loss: 6.539989]\n",
            "7530 [ D loss: 0.180841, acc.: 93%] [G loss: 4.822304]\n",
            "7531 [ D loss: 0.227956, acc.: 92%] [G loss: 5.545597]\n",
            "7532 [ D loss: 0.141130, acc.: 95%] [G loss: 5.949630]\n",
            "7533 [ D loss: 0.306017, acc.: 83%] [G loss: 6.665818]\n",
            "7534 [ D loss: 0.309040, acc.: 87%] [G loss: 6.669472]\n",
            "7535 [ D loss: 0.239449, acc.: 90%] [G loss: 7.792350]\n",
            "7536 [ D loss: 0.152279, acc.: 93%] [G loss: 9.102011]\n",
            "7537 [ D loss: 0.091737, acc.: 98%] [G loss: 10.047911]\n",
            "7538 [ D loss: 0.084458, acc.: 98%] [G loss: 15.597235]\n",
            "7539 [ D loss: 0.055147, acc.: 98%] [G loss: 12.256313]\n",
            "7540 [ D loss: 0.036575, acc.: 98%] [G loss: 12.518674]\n",
            "7541 [ D loss: 0.040507, acc.: 99%] [G loss: 11.447512]\n",
            "7542 [ D loss: 0.040284, acc.: 98%] [G loss: 9.591790]\n",
            "7543 [ D loss: 0.058767, acc.: 98%] [G loss: 9.529237]\n",
            "7544 [ D loss: 0.116509, acc.: 96%] [G loss: 6.509816]\n",
            "7545 [ D loss: 0.121583, acc.: 96%] [G loss: 7.812494]\n",
            "7546 [ D loss: 0.100472, acc.: 96%] [G loss: 6.649764]\n",
            "7547 [ D loss: 0.160505, acc.: 92%] [G loss: 5.700618]\n",
            "7548 [ D loss: 0.124471, acc.: 95%] [G loss: 5.709180]\n",
            "7549 [ D loss: 0.106446, acc.: 97%] [G loss: 8.175522]\n",
            "7550 [ D loss: 0.083416, acc.: 96%] [G loss: 5.507233]\n",
            "7551 [ D loss: 0.093822, acc.: 97%] [G loss: 13.406227]\n",
            "7552 [ D loss: 0.075001, acc.: 98%] [G loss: 6.065510]\n",
            "7553 [ D loss: 0.127303, acc.: 95%] [G loss: 7.185163]\n",
            "7554 [ D loss: 0.164755, acc.: 91%] [G loss: 6.150479]\n",
            "7555 [ D loss: 0.131362, acc.: 94%] [G loss: 6.251512]\n",
            "7556 [ D loss: 0.105705, acc.: 96%] [G loss: 8.640051]\n",
            "7557 [ D loss: 0.217360, acc.: 91%] [G loss: 4.958288]\n",
            "7558 [ D loss: 0.209686, acc.: 91%] [G loss: 6.500061]\n",
            "7559 [ D loss: 0.159720, acc.: 93%] [G loss: 5.364047]\n",
            "7560 [ D loss: 0.098431, acc.: 98%] [G loss: 6.906382]\n",
            "7561 [ D loss: 0.162274, acc.: 94%] [G loss: 5.783466]\n",
            "7562 [ D loss: 0.176513, acc.: 88%] [G loss: 5.875619]\n",
            "7563 [ D loss: 0.184459, acc.: 95%] [G loss: 4.303022]\n",
            "7564 [ D loss: 0.121721, acc.: 96%] [G loss: 5.724849]\n",
            "7565 [ D loss: 0.159114, acc.: 95%] [G loss: 6.735730]\n",
            "7566 [ D loss: 0.144692, acc.: 96%] [G loss: 5.889202]\n",
            "7567 [ D loss: 0.126518, acc.: 96%] [G loss: 4.539621]\n",
            "7568 [ D loss: 0.120366, acc.: 97%] [G loss: 6.645440]\n",
            "7569 [ D loss: 0.265544, acc.: 89%] [G loss: 4.712873]\n",
            "7570 [ D loss: 0.111099, acc.: 95%] [G loss: 5.506637]\n",
            "7571 [ D loss: 0.142648, acc.: 95%] [G loss: 4.689580]\n",
            "7572 [ D loss: 0.143585, acc.: 94%] [G loss: 5.390263]\n",
            "7573 [ D loss: 0.195281, acc.: 94%] [G loss: 8.871370]\n",
            "7574 [ D loss: 0.119468, acc.: 92%] [G loss: 6.499029]\n",
            "7575 [ D loss: 0.101365, acc.: 97%] [G loss: 5.680889]\n",
            "7576 [ D loss: 0.086159, acc.: 98%] [G loss: 8.269010]\n",
            "7577 [ D loss: 0.115136, acc.: 98%] [G loss: 5.736896]\n",
            "7578 [ D loss: 0.143400, acc.: 97%] [G loss: 6.718606]\n",
            "7579 [ D loss: 0.135348, acc.: 97%] [G loss: 3.770278]\n",
            "7580 [ D loss: 0.137461, acc.: 95%] [G loss: 7.140844]\n",
            "7581 [ D loss: 0.212019, acc.: 93%] [G loss: 6.853465]\n",
            "7582 [ D loss: 0.222055, acc.: 89%] [G loss: 12.396372]\n",
            "7583 [ D loss: 0.151797, acc.: 95%] [G loss: 5.857194]\n",
            "7584 [ D loss: 0.193765, acc.: 93%] [G loss: 5.510120]\n",
            "7585 [ D loss: 0.108229, acc.: 97%] [G loss: 4.443057]\n",
            "7586 [ D loss: 0.166174, acc.: 95%] [G loss: 9.372263]\n",
            "7587 [ D loss: 0.137042, acc.: 95%] [G loss: 5.972361]\n",
            "7588 [ D loss: 0.049130, acc.: 99%] [G loss: 9.164290]\n",
            "7589 [ D loss: 0.075991, acc.: 97%] [G loss: 7.786123]\n",
            "7590 [ D loss: 0.147117, acc.: 94%] [G loss: 6.624250]\n",
            "7591 [ D loss: 0.106706, acc.: 98%] [G loss: 5.968494]\n",
            "7592 [ D loss: 0.152523, acc.: 95%] [G loss: 13.103458]\n",
            "7593 [ D loss: 0.087136, acc.: 97%] [G loss: 6.817226]\n",
            "7594 [ D loss: 0.095240, acc.: 97%] [G loss: 10.893468]\n",
            "7595 [ D loss: 0.138885, acc.: 95%] [G loss: 7.679894]\n",
            "7596 [ D loss: 0.201803, acc.: 91%] [G loss: 8.115904]\n",
            "7597 [ D loss: 0.118512, acc.: 96%] [G loss: 5.128791]\n",
            "7598 [ D loss: 0.193092, acc.: 95%] [G loss: 4.480997]\n",
            "7599 [ D loss: 0.085410, acc.: 98%] [G loss: 7.834943]\n",
            "7600 [ D loss: 0.103559, acc.: 98%] [G loss: 7.869040]\n",
            "7601 [ D loss: 0.101826, acc.: 98%] [G loss: 5.895778]\n",
            "7602 [ D loss: 0.149539, acc.: 95%] [G loss: 4.465669]\n",
            "7603 [ D loss: 0.159062, acc.: 94%] [G loss: 5.708975]\n",
            "7604 [ D loss: 0.229247, acc.: 91%] [G loss: 11.894505]\n",
            "7605 [ D loss: 0.096013, acc.: 96%] [G loss: 7.981084]\n",
            "7606 [ D loss: 0.187476, acc.: 88%] [G loss: 7.795490]\n",
            "7607 [ D loss: 0.108599, acc.: 95%] [G loss: 7.332643]\n",
            "7608 [ D loss: 0.302377, acc.: 85%] [G loss: 6.375114]\n",
            "7609 [ D loss: 0.283097, acc.: 85%] [G loss: 6.442597]\n",
            "7610 [ D loss: 0.295908, acc.: 88%] [G loss: 4.353994]\n",
            "7611 [ D loss: 0.295975, acc.: 89%] [G loss: 11.587014]\n",
            "7612 [ D loss: 0.339279, acc.: 85%] [G loss: 6.206841]\n",
            "7613 [ D loss: 0.275061, acc.: 84%] [G loss: 6.154548]\n",
            "7614 [ D loss: 0.200001, acc.: 91%] [G loss: 10.106462]\n",
            "7615 [ D loss: 0.079451, acc.: 97%] [G loss: 6.716017]\n",
            "7616 [ D loss: 0.059695, acc.: 98%] [G loss: 7.887144]\n",
            "7617 [ D loss: 0.083389, acc.: 97%] [G loss: 5.616271]\n",
            "7618 [ D loss: 0.083903, acc.: 97%] [G loss: 5.823324]\n",
            "7619 [ D loss: 0.078773, acc.: 96%] [G loss: 7.242639]\n",
            "7620 [ D loss: 0.194225, acc.: 91%] [G loss: 6.670918]\n",
            "7621 [ D loss: 0.105264, acc.: 96%] [G loss: 6.713410]\n",
            "7622 [ D loss: 0.065464, acc.: 98%] [G loss: 6.554481]\n",
            "7623 [ D loss: 0.180375, acc.: 90%] [G loss: 6.590897]\n",
            "7624 [ D loss: 0.173454, acc.: 92%] [G loss: 5.549020]\n",
            "7625 [ D loss: 0.191249, acc.: 92%] [G loss: 8.243034]\n",
            "7626 [ D loss: 0.114952, acc.: 96%] [G loss: 5.728687]\n",
            "7627 [ D loss: 0.078592, acc.: 97%] [G loss: 7.409604]\n",
            "7628 [ D loss: 0.074127, acc.: 97%] [G loss: 5.428628]\n",
            "7629 [ D loss: 0.118847, acc.: 94%] [G loss: 6.457598]\n",
            "7630 [ D loss: 0.114403, acc.: 95%] [G loss: 5.637426]\n",
            "7631 [ D loss: 0.166946, acc.: 92%] [G loss: 4.596814]\n",
            "7632 [ D loss: 0.136095, acc.: 96%] [G loss: 4.758933]\n",
            "7633 [ D loss: 0.184380, acc.: 96%] [G loss: 6.221727]\n",
            "7634 [ D loss: 0.197967, acc.: 93%] [G loss: 4.817437]\n",
            "7635 [ D loss: 0.064284, acc.: 98%] [G loss: 8.009097]\n",
            "7636 [ D loss: 0.063804, acc.: 98%] [G loss: 6.447593]\n",
            "7637 [ D loss: 0.111119, acc.: 97%] [G loss: 5.564091]\n",
            "7638 [ D loss: 0.269694, acc.: 90%] [G loss: 5.921284]\n",
            "7639 [ D loss: 0.187263, acc.: 90%] [G loss: 6.678041]\n",
            "7640 [ D loss: 0.246529, acc.: 89%] [G loss: 5.709457]\n",
            "7641 [ D loss: 0.132667, acc.: 96%] [G loss: 6.212734]\n",
            "7642 [ D loss: 0.112151, acc.: 95%] [G loss: 5.215220]\n",
            "7643 [ D loss: 0.106476, acc.: 97%] [G loss: 6.715471]\n",
            "7644 [ D loss: 0.096102, acc.: 96%] [G loss: 7.108796]\n",
            "7645 [ D loss: 0.177019, acc.: 93%] [G loss: 6.525657]\n",
            "7646 [ D loss: 0.134726, acc.: 94%] [G loss: 6.203107]\n",
            "7647 [ D loss: 0.127227, acc.: 95%] [G loss: 9.244745]\n",
            "7648 [ D loss: 0.081264, acc.: 95%] [G loss: 5.137512]\n",
            "7649 [ D loss: 0.049637, acc.: 98%] [G loss: 12.804955]\n",
            "7650 [ D loss: 0.116376, acc.: 94%] [G loss: 10.055191]\n",
            "7651 [ D loss: 0.032192, acc.: 100%] [G loss: 8.001701]\n",
            "7652 [ D loss: 0.094467, acc.: 97%] [G loss: 10.536320]\n",
            "7653 [ D loss: 0.127285, acc.: 94%] [G loss: 5.216645]\n",
            "7654 [ D loss: 0.221657, acc.: 91%] [G loss: 5.103158]\n",
            "7655 [ D loss: 0.201447, acc.: 91%] [G loss: 6.346931]\n",
            "7656 [ D loss: 0.171002, acc.: 94%] [G loss: 5.229617]\n",
            "7657 [ D loss: 0.234796, acc.: 91%] [G loss: 4.695439]\n",
            "7658 [ D loss: 0.154311, acc.: 95%] [G loss: 5.437892]\n",
            "7659 [ D loss: 0.164279, acc.: 94%] [G loss: 8.609890]\n",
            "7660 [ D loss: 0.104629, acc.: 95%] [G loss: 6.962756]\n",
            "7661 [ D loss: 0.087223, acc.: 98%] [G loss: 7.129851]\n",
            "7662 [ D loss: 0.088175, acc.: 97%] [G loss: 7.450726]\n",
            "7663 [ D loss: 0.087805, acc.: 95%] [G loss: 12.540277]\n",
            "7664 [ D loss: 0.108539, acc.: 95%] [G loss: 6.685678]\n",
            "7665 [ D loss: 0.093328, acc.: 95%] [G loss: 8.155112]\n",
            "7666 [ D loss: 0.141477, acc.: 95%] [G loss: 4.844199]\n",
            "7667 [ D loss: 0.047898, acc.: 99%] [G loss: 14.647922]\n",
            "7668 [ D loss: 0.056084, acc.: 99%] [G loss: 10.870043]\n",
            "7669 [ D loss: 0.044309, acc.: 98%] [G loss: 13.559206]\n",
            "7670 [ D loss: 0.065323, acc.: 97%] [G loss: 8.551144]\n",
            "7671 [ D loss: 0.115907, acc.: 95%] [G loss: 8.700459]\n",
            "7672 [ D loss: 0.084032, acc.: 99%] [G loss: 4.719017]\n",
            "7673 [ D loss: 0.082734, acc.: 98%] [G loss: 6.063456]\n",
            "7674 [ D loss: 0.167621, acc.: 92%] [G loss: 3.825184]\n",
            "7675 [ D loss: 0.114281, acc.: 97%] [G loss: 6.048943]\n",
            "7676 [ D loss: 0.111475, acc.: 98%] [G loss: 5.066419]\n",
            "7677 [ D loss: 0.140396, acc.: 95%] [G loss: 4.746266]\n",
            "7678 [ D loss: 0.145054, acc.: 95%] [G loss: 5.185646]\n",
            "7679 [ D loss: 0.260530, acc.: 87%] [G loss: 6.036919]\n",
            "7680 [ D loss: 0.259787, acc.: 87%] [G loss: 5.003033]\n",
            "7681 [ D loss: 0.223664, acc.: 91%] [G loss: 6.808481]\n",
            "7682 [ D loss: 0.193748, acc.: 97%] [G loss: 10.450064]\n",
            "7683 [ D loss: 0.099894, acc.: 98%] [G loss: 8.257562]\n",
            "7684 [ D loss: 0.098176, acc.: 97%] [G loss: 6.918860]\n",
            "7685 [ D loss: 0.083847, acc.: 98%] [G loss: 6.727845]\n",
            "7686 [ D loss: 0.114423, acc.: 98%] [G loss: 6.494159]\n",
            "7687 [ D loss: 0.129846, acc.: 97%] [G loss: 5.789902]\n",
            "7688 [ D loss: 0.281439, acc.: 90%] [G loss: 5.275967]\n",
            "7689 [ D loss: 0.174566, acc.: 93%] [G loss: 8.839128]\n",
            "7690 [ D loss: 0.167861, acc.: 93%] [G loss: 8.120028]\n",
            "7691 [ D loss: 0.103976, acc.: 96%] [G loss: 6.360332]\n",
            "7692 [ D loss: 0.049818, acc.: 99%] [G loss: 5.432878]\n",
            "7693 [ D loss: 0.116456, acc.: 98%] [G loss: 4.698651]\n",
            "7694 [ D loss: 0.160737, acc.: 94%] [G loss: 5.026814]\n",
            "7695 [ D loss: 0.174474, acc.: 94%] [G loss: 7.022491]\n",
            "7696 [ D loss: 0.056104, acc.: 98%] [G loss: 7.108183]\n",
            "7697 [ D loss: 0.141612, acc.: 93%] [G loss: 15.269354]\n",
            "7698 [ D loss: 0.054299, acc.: 98%] [G loss: 11.988974]\n",
            "7699 [ D loss: 0.057406, acc.: 98%] [G loss: 8.667848]\n",
            "7700 [ D loss: 0.115916, acc.: 95%] [G loss: 11.115732]\n",
            "7701 [ D loss: 0.094282, acc.: 98%] [G loss: 9.163496]\n",
            "7702 [ D loss: 0.081706, acc.: 98%] [G loss: 8.967527]\n",
            "7703 [ D loss: 0.196256, acc.: 92%] [G loss: 6.979713]\n",
            "7704 [ D loss: 0.091877, acc.: 98%] [G loss: 9.875032]\n",
            "7705 [ D loss: 0.120754, acc.: 98%] [G loss: 6.300479]\n",
            "7706 [ D loss: 0.122136, acc.: 95%] [G loss: 8.247870]\n",
            "7707 [ D loss: 0.048229, acc.: 98%] [G loss: 9.294747]\n",
            "7708 [ D loss: 0.146304, acc.: 95%] [G loss: 7.075219]\n",
            "7709 [ D loss: 0.167539, acc.: 93%] [G loss: 4.844166]\n",
            "7710 [ D loss: 0.131746, acc.: 95%] [G loss: 7.075789]\n",
            "7711 [ D loss: 0.166600, acc.: 94%] [G loss: 5.445563]\n",
            "7712 [ D loss: 0.147969, acc.: 92%] [G loss: 5.972625]\n",
            "7713 [ D loss: 0.226660, acc.: 89%] [G loss: 4.925272]\n",
            "7714 [ D loss: 0.163514, acc.: 91%] [G loss: 7.015178]\n",
            "7715 [ D loss: 0.389916, acc.: 84%] [G loss: 5.735602]\n",
            "7716 [ D loss: 0.460038, acc.: 80%] [G loss: 5.337335]\n",
            "7717 [ D loss: 0.369279, acc.: 83%] [G loss: 6.959589]\n",
            "7718 [ D loss: 0.295153, acc.: 86%] [G loss: 9.049975]\n",
            "7719 [ D loss: 0.247947, acc.: 91%] [G loss: 8.769943]\n",
            "7720 [ D loss: 0.279131, acc.: 88%] [G loss: 6.033962]\n",
            "7721 [ D loss: 0.032516, acc.: 99%] [G loss: 10.919921]\n",
            "7722 [ D loss: 0.512858, acc.: 80%] [G loss: 6.647056]\n",
            "7723 [ D loss: 0.240377, acc.: 91%] [G loss: 12.095519]\n",
            "7724 [ D loss: 0.019839, acc.: 100%] [G loss: 12.406480]\n",
            "7725 [ D loss: 0.057768, acc.: 97%] [G loss: 9.788543]\n",
            "7726 [ D loss: 0.079757, acc.: 97%] [G loss: 10.412971]\n",
            "7727 [ D loss: 0.022483, acc.: 100%] [G loss: 12.143284]\n",
            "7728 [ D loss: 0.062157, acc.: 98%] [G loss: 9.114247]\n",
            "7729 [ D loss: 0.065872, acc.: 98%] [G loss: 6.848377]\n",
            "7730 [ D loss: 0.049001, acc.: 100%] [G loss: 6.982107]\n",
            "7731 [ D loss: 0.064757, acc.: 98%] [G loss: 8.477385]\n",
            "7732 [ D loss: 0.048663, acc.: 99%] [G loss: 9.445333]\n",
            "7733 [ D loss: 0.101620, acc.: 95%] [G loss: 5.855411]\n",
            "7734 [ D loss: 0.084903, acc.: 96%] [G loss: 7.307514]\n",
            "7735 [ D loss: 0.044929, acc.: 98%] [G loss: 9.928841]\n",
            "7736 [ D loss: 0.102717, acc.: 98%] [G loss: 8.172153]\n",
            "7737 [ D loss: 0.089009, acc.: 97%] [G loss: 5.917856]\n",
            "7738 [ D loss: 0.097195, acc.: 97%] [G loss: 4.468259]\n",
            "7739 [ D loss: 0.074447, acc.: 98%] [G loss: 5.876777]\n",
            "7740 [ D loss: 0.112846, acc.: 96%] [G loss: 5.366527]\n",
            "7741 [ D loss: 0.137638, acc.: 95%] [G loss: 6.243393]\n",
            "7742 [ D loss: 0.089926, acc.: 97%] [G loss: 5.649278]\n",
            "7743 [ D loss: 0.166501, acc.: 96%] [G loss: 4.808156]\n",
            "7744 [ D loss: 0.163310, acc.: 92%] [G loss: 4.651896]\n",
            "7745 [ D loss: 0.207240, acc.: 91%] [G loss: 4.846950]\n",
            "7746 [ D loss: 0.117726, acc.: 97%] [G loss: 4.786689]\n",
            "7747 [ D loss: 0.215184, acc.: 91%] [G loss: 4.849428]\n",
            "7748 [ D loss: 0.117883, acc.: 97%] [G loss: 4.841216]\n",
            "7749 [ D loss: 0.179008, acc.: 94%] [G loss: 5.739140]\n",
            "7750 [ D loss: 0.149927, acc.: 95%] [G loss: 7.694186]\n",
            "7751 [ D loss: 0.191807, acc.: 93%] [G loss: 5.747777]\n",
            "7752 [ D loss: 0.130862, acc.: 95%] [G loss: 6.343925]\n",
            "7753 [ D loss: 0.280202, acc.: 88%] [G loss: 4.338372]\n",
            "7754 [ D loss: 0.231050, acc.: 88%] [G loss: 6.085026]\n",
            "7755 [ D loss: 0.184397, acc.: 94%] [G loss: 6.534605]\n",
            "7756 [ D loss: 0.158683, acc.: 95%] [G loss: 5.942012]\n",
            "7757 [ D loss: 0.134872, acc.: 96%] [G loss: 3.247207]\n",
            "7758 [ D loss: 0.186828, acc.: 92%] [G loss: 5.211549]\n",
            "7759 [ D loss: 0.107948, acc.: 94%] [G loss: 7.323221]\n",
            "7760 [ D loss: 0.147731, acc.: 95%] [G loss: 4.974083]\n",
            "7761 [ D loss: 0.057451, acc.: 98%] [G loss: 9.638614]\n",
            "7762 [ D loss: 0.158803, acc.: 94%] [G loss: 4.910116]\n",
            "7763 [ D loss: 0.098567, acc.: 98%] [G loss: 8.315325]\n",
            "7764 [ D loss: 0.118355, acc.: 96%] [G loss: 6.403660]\n",
            "7765 [ D loss: 0.160858, acc.: 95%] [G loss: 13.006207]\n",
            "7766 [ D loss: 0.118600, acc.: 95%] [G loss: 8.584720]\n",
            "7767 [ D loss: 0.141196, acc.: 95%] [G loss: 5.857884]\n",
            "7768 [ D loss: 0.068910, acc.: 99%] [G loss: 5.532506]\n",
            "7769 [ D loss: 0.237722, acc.: 87%] [G loss: 5.731571]\n",
            "7770 [ D loss: 0.120684, acc.: 97%] [G loss: 4.488657]\n",
            "7771 [ D loss: 0.143797, acc.: 92%] [G loss: 5.871790]\n",
            "7772 [ D loss: 0.127779, acc.: 97%] [G loss: 4.478570]\n",
            "7773 [ D loss: 0.110500, acc.: 98%] [G loss: 5.624508]\n",
            "7774 [ D loss: 0.272108, acc.: 86%] [G loss: 4.458378]\n",
            "7775 [ D loss: 0.155543, acc.: 94%] [G loss: 5.826921]\n",
            "7776 [ D loss: 0.164026, acc.: 95%] [G loss: 6.006278]\n",
            "7777 [ D loss: 0.168370, acc.: 95%] [G loss: 4.718783]\n",
            "7778 [ D loss: 0.138128, acc.: 96%] [G loss: 5.386441]\n",
            "7779 [ D loss: 0.094834, acc.: 98%] [G loss: 4.041457]\n",
            "7780 [ D loss: 0.144116, acc.: 94%] [G loss: 5.410324]\n",
            "7781 [ D loss: 0.153853, acc.: 93%] [G loss: 5.034655]\n",
            "7782 [ D loss: 0.208009, acc.: 95%] [G loss: 6.664102]\n",
            "7783 [ D loss: 0.090329, acc.: 96%] [G loss: 7.478599]\n",
            "7784 [ D loss: 0.063586, acc.: 98%] [G loss: 11.640128]\n",
            "7785 [ D loss: 0.061820, acc.: 98%] [G loss: 6.501359]\n",
            "7786 [ D loss: 0.107198, acc.: 96%] [G loss: 8.234429]\n",
            "7787 [ D loss: 0.066697, acc.: 98%] [G loss: 10.159328]\n",
            "7788 [ D loss: 0.154530, acc.: 94%] [G loss: 6.245674]\n",
            "7789 [ D loss: 0.111161, acc.: 95%] [G loss: 4.769340]\n",
            "7790 [ D loss: 0.200290, acc.: 91%] [G loss: 6.023625]\n",
            "7791 [ D loss: 0.080599, acc.: 98%] [G loss: 5.941914]\n",
            "7792 [ D loss: 0.124698, acc.: 95%] [G loss: 6.998566]\n",
            "7793 [ D loss: 0.105176, acc.: 95%] [G loss: 6.512853]\n",
            "7794 [ D loss: 0.173332, acc.: 94%] [G loss: 7.400413]\n",
            "7795 [ D loss: 0.088076, acc.: 98%] [G loss: 6.862140]\n",
            "7796 [ D loss: 0.130323, acc.: 95%] [G loss: 4.601190]\n",
            "7797 [ D loss: 0.089499, acc.: 98%] [G loss: 7.558361]\n",
            "7798 [ D loss: 0.084791, acc.: 98%] [G loss: 7.260232]\n",
            "7799 [ D loss: 0.094562, acc.: 98%] [G loss: 6.567461]\n",
            "7800 [ D loss: 0.073308, acc.: 99%] [G loss: 5.788865]\n",
            "7801 [ D loss: 0.139574, acc.: 96%] [G loss: 3.645447]\n",
            "7802 [ D loss: 0.166030, acc.: 94%] [G loss: 7.448133]\n",
            "7803 [ D loss: 0.150367, acc.: 95%] [G loss: 5.130562]\n",
            "7804 [ D loss: 0.221285, acc.: 90%] [G loss: 7.586515]\n",
            "7805 [ D loss: 0.217324, acc.: 89%] [G loss: 5.132382]\n",
            "7806 [ D loss: 0.130429, acc.: 95%] [G loss: 5.088782]\n",
            "7807 [ D loss: 0.097315, acc.: 98%] [G loss: 7.554206]\n",
            "7808 [ D loss: 0.139770, acc.: 94%] [G loss: 6.577506]\n",
            "7809 [ D loss: 0.123216, acc.: 96%] [G loss: 5.652986]\n",
            "7810 [ D loss: 0.075226, acc.: 98%] [G loss: 5.427666]\n",
            "7811 [ D loss: 0.190164, acc.: 92%] [G loss: 4.254442]\n",
            "7812 [ D loss: 0.211324, acc.: 91%] [G loss: 5.805912]\n",
            "7813 [ D loss: 0.108279, acc.: 95%] [G loss: 5.123457]\n",
            "7814 [ D loss: 0.084356, acc.: 98%] [G loss: 11.950613]\n",
            "7815 [ D loss: 0.076455, acc.: 98%] [G loss: 5.255155]\n",
            "7816 [ D loss: 0.053046, acc.: 99%] [G loss: 10.397465]\n",
            "7817 [ D loss: 0.084075, acc.: 96%] [G loss: 5.114387]\n",
            "7818 [ D loss: 0.052338, acc.: 98%] [G loss: 14.761641]\n",
            "7819 [ D loss: 0.051018, acc.: 98%] [G loss: 6.373227]\n",
            "7820 [ D loss: 0.124915, acc.: 94%] [G loss: 12.849369]\n",
            "7821 [ D loss: 0.072266, acc.: 97%] [G loss: 8.692268]\n",
            "7822 [ D loss: 0.145891, acc.: 95%] [G loss: 9.892088]\n",
            "7823 [ D loss: 0.092120, acc.: 98%] [G loss: 7.922028]\n",
            "7824 [ D loss: 0.112817, acc.: 95%] [G loss: 7.858736]\n",
            "7825 [ D loss: 0.226180, acc.: 90%] [G loss: 5.359736]\n",
            "7826 [ D loss: 0.077298, acc.: 97%] [G loss: 8.869215]\n",
            "7827 [ D loss: 0.121552, acc.: 96%] [G loss: 5.198993]\n",
            "7828 [ D loss: 0.145676, acc.: 95%] [G loss: 4.799020]\n",
            "7829 [ D loss: 0.101466, acc.: 99%] [G loss: 5.157758]\n",
            "7830 [ D loss: 0.179223, acc.: 94%] [G loss: 6.109734]\n",
            "7831 [ D loss: 0.131842, acc.: 96%] [G loss: 12.068935]\n",
            "7832 [ D loss: 0.152866, acc.: 95%] [G loss: 4.453069]\n",
            "7833 [ D loss: 0.143403, acc.: 97%] [G loss: 9.094257]\n",
            "7834 [ D loss: 0.150057, acc.: 93%] [G loss: 8.726366]\n",
            "7835 [ D loss: 0.125928, acc.: 97%] [G loss: 6.714101]\n",
            "7836 [ D loss: 0.056989, acc.: 99%] [G loss: 7.546922]\n",
            "7837 [ D loss: 0.178296, acc.: 91%] [G loss: 8.299694]\n",
            "7838 [ D loss: 0.166911, acc.: 93%] [G loss: 5.934526]\n",
            "7839 [ D loss: 0.088980, acc.: 97%] [G loss: 5.851381]\n",
            "7840 [ D loss: 0.111676, acc.: 95%] [G loss: 8.297306]\n",
            "7841 [ D loss: 0.133167, acc.: 95%] [G loss: 7.213364]\n",
            "7842 [ D loss: 0.170308, acc.: 96%] [G loss: 6.073685]\n",
            "7843 [ D loss: 0.090030, acc.: 97%] [G loss: 5.189065]\n",
            "7844 [ D loss: 0.136447, acc.: 95%] [G loss: 4.677208]\n",
            "7845 [ D loss: 0.147232, acc.: 97%] [G loss: 4.568789]\n",
            "7846 [ D loss: 0.208022, acc.: 90%] [G loss: 6.027359]\n",
            "7847 [ D loss: 0.317618, acc.: 87%] [G loss: 4.857500]\n",
            "7848 [ D loss: 0.070565, acc.: 98%] [G loss: 5.948258]\n",
            "7849 [ D loss: 0.152394, acc.: 95%] [G loss: 4.761646]\n",
            "7850 [ D loss: 0.191047, acc.: 91%] [G loss: 5.358353]\n",
            "7851 [ D loss: 0.431166, acc.: 81%] [G loss: 5.833345]\n",
            "7852 [ D loss: 0.309230, acc.: 81%] [G loss: 5.485017]\n",
            "7853 [ D loss: 0.139800, acc.: 95%] [G loss: 5.581616]\n",
            "7854 [ D loss: 0.151190, acc.: 93%] [G loss: 10.147824]\n",
            "7855 [ D loss: 0.091572, acc.: 98%] [G loss: 4.650282]\n",
            "7856 [ D loss: 0.059172, acc.: 98%] [G loss: 7.899129]\n",
            "7857 [ D loss: 0.129848, acc.: 95%] [G loss: 5.294941]\n",
            "7858 [ D loss: 0.136005, acc.: 95%] [G loss: 5.443810]\n",
            "7859 [ D loss: 0.116613, acc.: 98%] [G loss: 6.798456]\n",
            "7860 [ D loss: 0.122229, acc.: 98%] [G loss: 5.524097]\n",
            "7861 [ D loss: 0.256094, acc.: 87%] [G loss: 8.562064]\n",
            "7862 [ D loss: 0.092935, acc.: 95%] [G loss: 8.332758]\n",
            "7863 [ D loss: 0.151762, acc.: 95%] [G loss: 5.815579]\n",
            "7864 [ D loss: 0.144829, acc.: 95%] [G loss: 9.369973]\n",
            "7865 [ D loss: 0.131965, acc.: 95%] [G loss: 5.619888]\n",
            "7866 [ D loss: 0.071205, acc.: 98%] [G loss: 9.346935]\n",
            "7867 [ D loss: 0.093827, acc.: 97%] [G loss: 8.453499]\n",
            "7868 [ D loss: 0.120194, acc.: 95%] [G loss: 5.405653]\n",
            "7869 [ D loss: 0.112554, acc.: 94%] [G loss: 7.323871]\n",
            "7870 [ D loss: 0.148082, acc.: 95%] [G loss: 8.243711]\n",
            "7871 [ D loss: 0.082399, acc.: 97%] [G loss: 10.524917]\n",
            "7872 [ D loss: 0.070424, acc.: 98%] [G loss: 9.317961]\n",
            "7873 [ D loss: 0.080523, acc.: 96%] [G loss: 10.723820]\n",
            "7874 [ D loss: 0.101574, acc.: 97%] [G loss: 8.277836]\n",
            "7875 [ D loss: 0.127482, acc.: 96%] [G loss: 14.247616]\n",
            "7876 [ D loss: 0.073899, acc.: 97%] [G loss: 9.054321]\n",
            "7877 [ D loss: 0.099515, acc.: 98%] [G loss: 7.162252]\n",
            "7878 [ D loss: 0.125913, acc.: 95%] [G loss: 8.400728]\n",
            "7879 [ D loss: 0.105254, acc.: 98%] [G loss: 9.707781]\n",
            "7880 [ D loss: 0.084791, acc.: 95%] [G loss: 7.748536]\n",
            "7881 [ D loss: 0.081912, acc.: 98%] [G loss: 9.507420]\n",
            "7882 [ D loss: 0.057848, acc.: 98%] [G loss: 7.366439]\n",
            "7883 [ D loss: 0.029337, acc.: 100%] [G loss: 7.055501]\n",
            "7884 [ D loss: 0.066083, acc.: 98%] [G loss: 11.467863]\n",
            "7885 [ D loss: 0.095028, acc.: 95%] [G loss: 11.037714]\n",
            "7886 [ D loss: 0.051292, acc.: 99%] [G loss: 11.305660]\n",
            "7887 [ D loss: 0.097264, acc.: 95%] [G loss: 9.228224]\n",
            "7888 [ D loss: 0.064298, acc.: 100%] [G loss: 8.440338]\n",
            "7889 [ D loss: 0.113224, acc.: 97%] [G loss: 8.012901]\n",
            "7890 [ D loss: 0.114843, acc.: 96%] [G loss: 12.857111]\n",
            "7891 [ D loss: 0.048328, acc.: 98%] [G loss: 11.579256]\n",
            "7892 [ D loss: 0.050635, acc.: 98%] [G loss: 6.844332]\n",
            "7893 [ D loss: 0.129332, acc.: 93%] [G loss: 12.344204]\n",
            "7894 [ D loss: 0.081696, acc.: 98%] [G loss: 8.608356]\n",
            "7895 [ D loss: 0.164819, acc.: 95%] [G loss: 8.048197]\n",
            "7896 [ D loss: 0.172011, acc.: 95%] [G loss: 9.179028]\n",
            "7897 [ D loss: 0.070725, acc.: 99%] [G loss: 5.729367]\n",
            "7898 [ D loss: 0.130258, acc.: 94%] [G loss: 3.979062]\n",
            "7899 [ D loss: 0.070322, acc.: 95%] [G loss: 7.593337]\n",
            "7900 [ D loss: 0.254081, acc.: 88%] [G loss: 5.771256]\n",
            "7901 [ D loss: 0.175984, acc.: 93%] [G loss: 8.879226]\n",
            "7902 [ D loss: 0.265163, acc.: 88%] [G loss: 7.201475]\n",
            "7903 [ D loss: 0.113111, acc.: 95%] [G loss: 12.790512]\n",
            "7904 [ D loss: 0.193680, acc.: 91%] [G loss: 10.194238]\n",
            "7905 [ D loss: 0.167559, acc.: 95%] [G loss: 7.762848]\n",
            "7906 [ D loss: 0.126846, acc.: 93%] [G loss: 6.109722]\n",
            "7907 [ D loss: 0.126549, acc.: 95%] [G loss: 7.209514]\n",
            "7908 [ D loss: 0.100310, acc.: 97%] [G loss: 7.486358]\n",
            "7909 [ D loss: 0.036826, acc.: 99%] [G loss: 9.627142]\n",
            "7910 [ D loss: 0.114047, acc.: 95%] [G loss: 4.734643]\n",
            "7911 [ D loss: 0.099863, acc.: 97%] [G loss: 6.750591]\n",
            "7912 [ D loss: 0.104830, acc.: 98%] [G loss: 5.146052]\n",
            "7913 [ D loss: 0.146226, acc.: 94%] [G loss: 4.551862]\n",
            "7914 [ D loss: 0.130836, acc.: 95%] [G loss: 5.533520]\n",
            "7915 [ D loss: 0.098985, acc.: 97%] [G loss: 6.891442]\n",
            "7916 [ D loss: 0.123142, acc.: 96%] [G loss: 6.126253]\n",
            "7917 [ D loss: 0.151897, acc.: 95%] [G loss: 5.740002]\n",
            "7918 [ D loss: 0.070279, acc.: 98%] [G loss: 8.317383]\n",
            "7919 [ D loss: 0.141988, acc.: 93%] [G loss: 6.928188]\n",
            "7920 [ D loss: 0.140716, acc.: 91%] [G loss: 10.139358]\n",
            "7921 [ D loss: 0.142950, acc.: 95%] [G loss: 5.133065]\n",
            "7922 [ D loss: 0.146733, acc.: 95%] [G loss: 12.619415]\n",
            "7923 [ D loss: 0.068549, acc.: 98%] [G loss: 5.744224]\n",
            "7924 [ D loss: 0.203720, acc.: 91%] [G loss: 6.186993]\n",
            "7925 [ D loss: 0.116325, acc.: 98%] [G loss: 4.373048]\n",
            "7926 [ D loss: 0.200435, acc.: 92%] [G loss: 4.468384]\n",
            "7927 [ D loss: 0.132390, acc.: 96%] [G loss: 4.561346]\n",
            "7928 [ D loss: 0.244598, acc.: 91%] [G loss: 5.586927]\n",
            "7929 [ D loss: 0.284535, acc.: 89%] [G loss: 5.294305]\n",
            "7930 [ D loss: 0.177216, acc.: 95%] [G loss: 6.145745]\n",
            "7931 [ D loss: 0.261106, acc.: 90%] [G loss: 5.102758]\n",
            "7932 [ D loss: 0.075881, acc.: 98%] [G loss: 5.425248]\n",
            "7933 [ D loss: 0.167990, acc.: 92%] [G loss: 6.050122]\n",
            "7934 [ D loss: 0.098387, acc.: 94%] [G loss: 9.837529]\n",
            "7935 [ D loss: 0.188316, acc.: 93%] [G loss: 4.996334]\n",
            "7936 [ D loss: 0.126596, acc.: 94%] [G loss: 7.752741]\n",
            "7937 [ D loss: 0.112311, acc.: 95%] [G loss: 7.070650]\n",
            "7938 [ D loss: 0.154686, acc.: 94%] [G loss: 4.366658]\n",
            "7939 [ D loss: 0.115778, acc.: 97%] [G loss: 6.756039]\n",
            "7940 [ D loss: 0.135830, acc.: 95%] [G loss: 6.127326]\n",
            "7941 [ D loss: 0.164628, acc.: 92%] [G loss: 8.061216]\n",
            "7942 [ D loss: 0.172997, acc.: 91%] [G loss: 8.591942]\n",
            "7943 [ D loss: 0.182049, acc.: 91%] [G loss: 7.145890]\n",
            "7944 [ D loss: 0.102426, acc.: 94%] [G loss: 7.604840]\n",
            "7945 [ D loss: 0.088198, acc.: 98%] [G loss: 7.226592]\n",
            "7946 [ D loss: 0.100298, acc.: 95%] [G loss: 5.286024]\n",
            "7947 [ D loss: 0.143632, acc.: 96%] [G loss: 5.737732]\n",
            "7948 [ D loss: 0.042167, acc.: 98%] [G loss: 12.910914]\n",
            "7949 [ D loss: 0.110916, acc.: 95%] [G loss: 8.093574]\n",
            "7950 [ D loss: 0.144221, acc.: 93%] [G loss: 5.344975]\n",
            "7951 [ D loss: 0.088311, acc.: 98%] [G loss: 7.648896]\n",
            "7952 [ D loss: 0.220158, acc.: 91%] [G loss: 4.774087]\n",
            "7953 [ D loss: 0.085971, acc.: 98%] [G loss: 5.548744]\n",
            "7954 [ D loss: 0.026875, acc.: 100%] [G loss: 6.136295]\n",
            "7955 [ D loss: 0.156099, acc.: 96%] [G loss: 5.645250]\n",
            "7956 [ D loss: 0.099974, acc.: 98%] [G loss: 7.873056]\n",
            "7957 [ D loss: 0.120514, acc.: 99%] [G loss: 6.833289]\n",
            "7958 [ D loss: 0.116924, acc.: 97%] [G loss: 5.662962]\n",
            "7959 [ D loss: 0.135704, acc.: 95%] [G loss: 6.142612]\n",
            "7960 [ D loss: 0.215052, acc.: 92%] [G loss: 4.856473]\n",
            "7961 [ D loss: 0.239424, acc.: 88%] [G loss: 4.460227]\n",
            "7962 [ D loss: 0.138741, acc.: 97%] [G loss: 4.781338]\n",
            "7963 [ D loss: 0.102869, acc.: 96%] [G loss: 5.524801]\n",
            "7964 [ D loss: 0.112010, acc.: 96%] [G loss: 5.012626]\n",
            "7965 [ D loss: 0.220438, acc.: 92%] [G loss: 4.771458]\n",
            "7966 [ D loss: 0.223847, acc.: 91%] [G loss: 7.412298]\n",
            "7967 [ D loss: 0.392881, acc.: 84%] [G loss: 7.622713]\n",
            "7968 [ D loss: 0.256930, acc.: 86%] [G loss: 7.191639]\n",
            "7969 [ D loss: 0.735560, acc.: 72%] [G loss: 5.296578]\n",
            "7970 [ D loss: 0.053945, acc.: 98%] [G loss: 11.089288]\n",
            "7971 [ D loss: 0.461665, acc.: 81%] [G loss: 4.158191]\n",
            "7972 [ D loss: 0.135822, acc.: 95%] [G loss: 5.975218]\n",
            "7973 [ D loss: 0.111521, acc.: 97%] [G loss: 6.246766]\n",
            "7974 [ D loss: 0.137221, acc.: 95%] [G loss: 4.352761]\n",
            "7975 [ D loss: 0.186402, acc.: 94%] [G loss: 5.307442]\n",
            "7976 [ D loss: 0.221406, acc.: 90%] [G loss: 5.251187]\n",
            "7977 [ D loss: 0.137106, acc.: 95%] [G loss: 5.584308]\n",
            "7978 [ D loss: 0.153196, acc.: 95%] [G loss: 4.986719]\n",
            "7979 [ D loss: 0.201659, acc.: 92%] [G loss: 4.977846]\n",
            "7980 [ D loss: 0.147803, acc.: 95%] [G loss: 5.996256]\n",
            "7981 [ D loss: 0.168806, acc.: 92%] [G loss: 4.833490]\n",
            "7982 [ D loss: 0.096630, acc.: 97%] [G loss: 5.813358]\n",
            "7983 [ D loss: 0.139566, acc.: 95%] [G loss: 4.306527]\n",
            "7984 [ D loss: 0.237307, acc.: 93%] [G loss: 6.256625]\n",
            "7985 [ D loss: 0.152677, acc.: 97%] [G loss: 4.457742]\n",
            "7986 [ D loss: 0.122125, acc.: 97%] [G loss: 5.484911]\n",
            "7987 [ D loss: 0.122936, acc.: 96%] [G loss: 5.074439]\n",
            "7988 [ D loss: 0.075946, acc.: 98%] [G loss: 6.609953]\n",
            "7989 [ D loss: 0.076381, acc.: 97%] [G loss: 8.852509]\n",
            "7990 [ D loss: 0.054209, acc.: 98%] [G loss: 7.527529]\n",
            "7991 [ D loss: 0.149183, acc.: 95%] [G loss: 9.200242]\n",
            "7992 [ D loss: 0.129150, acc.: 95%] [G loss: 6.809234]\n",
            "7993 [ D loss: 0.150031, acc.: 93%] [G loss: 7.278897]\n",
            "7994 [ D loss: 0.080259, acc.: 98%] [G loss: 4.476828]\n",
            "7995 [ D loss: 0.109416, acc.: 98%] [G loss: 5.753719]\n",
            "7996 [ D loss: 0.197243, acc.: 92%] [G loss: 6.179224]\n",
            "7997 [ D loss: 0.199328, acc.: 91%] [G loss: 5.784374]\n",
            "7998 [ D loss: 0.249565, acc.: 88%] [G loss: 6.187215]\n",
            "7999 [ D loss: 0.119432, acc.: 98%] [G loss: 5.058350]\n",
            "8000 [ D loss: 0.128312, acc.: 98%] [G loss: 3.080331]\n",
            "8001 [ D loss: 0.372444, acc.: 81%] [G loss: 7.038201]\n",
            "8002 [ D loss: 0.103686, acc.: 97%] [G loss: 6.336236]\n",
            "8003 [ D loss: 0.142022, acc.: 95%] [G loss: 4.949642]\n",
            "8004 [ D loss: 0.074934, acc.: 98%] [G loss: 6.507715]\n",
            "8005 [ D loss: 0.086973, acc.: 98%] [G loss: 4.830704]\n",
            "8006 [ D loss: 0.173171, acc.: 93%] [G loss: 4.572210]\n",
            "8007 [ D loss: 0.128017, acc.: 95%] [G loss: 4.913924]\n",
            "8008 [ D loss: 0.172113, acc.: 94%] [G loss: 9.251328]\n",
            "8009 [ D loss: 0.192366, acc.: 95%] [G loss: 6.634147]\n",
            "8010 [ D loss: 0.154668, acc.: 92%] [G loss: 6.244861]\n",
            "8011 [ D loss: 0.065986, acc.: 98%] [G loss: 13.495859]\n",
            "8012 [ D loss: 0.042075, acc.: 98%] [G loss: 11.391106]\n",
            "8013 [ D loss: 0.036763, acc.: 98%] [G loss: 9.649959]\n",
            "8014 [ D loss: 0.066292, acc.: 98%] [G loss: 7.943928]\n",
            "8015 [ D loss: 0.136936, acc.: 95%] [G loss: 8.935377]\n",
            "8016 [ D loss: 0.122989, acc.: 95%] [G loss: 8.910987]\n",
            "8017 [ D loss: 0.096848, acc.: 97%] [G loss: 7.841188]\n",
            "8018 [ D loss: 0.101363, acc.: 96%] [G loss: 8.060712]\n",
            "8019 [ D loss: 0.046773, acc.: 99%] [G loss: 5.155072]\n",
            "8020 [ D loss: 0.183940, acc.: 94%] [G loss: 5.787073]\n",
            "8021 [ D loss: 0.202725, acc.: 94%] [G loss: 7.534297]\n",
            "8022 [ D loss: 0.135976, acc.: 95%] [G loss: 5.345239]\n",
            "8023 [ D loss: 0.231834, acc.: 88%] [G loss: 4.031766]\n",
            "8024 [ D loss: 0.091924, acc.: 97%] [G loss: 15.940930]\n",
            "8025 [ D loss: 0.217010, acc.: 90%] [G loss: 4.552793]\n",
            "8026 [ D loss: 0.195688, acc.: 93%] [G loss: 5.609087]\n",
            "8027 [ D loss: 0.086937, acc.: 98%] [G loss: 7.530426]\n",
            "8028 [ D loss: 0.183863, acc.: 91%] [G loss: 4.156973]\n",
            "8029 [ D loss: 0.118293, acc.: 96%] [G loss: 4.421930]\n",
            "8030 [ D loss: 0.190510, acc.: 92%] [G loss: 5.875392]\n",
            "8031 [ D loss: 0.152876, acc.: 96%] [G loss: 7.368703]\n",
            "8032 [ D loss: 0.240366, acc.: 90%] [G loss: 10.941225]\n",
            "8033 [ D loss: 0.173658, acc.: 92%] [G loss: 7.859230]\n",
            "8034 [ D loss: 0.091657, acc.: 96%] [G loss: 7.045666]\n",
            "8035 [ D loss: 0.035419, acc.: 100%] [G loss: 4.788643]\n",
            "8036 [ D loss: 0.090953, acc.: 98%] [G loss: 7.339606]\n",
            "8037 [ D loss: 0.125599, acc.: 96%] [G loss: 5.970382]\n",
            "8038 [ D loss: 0.073815, acc.: 98%] [G loss: 5.708335]\n",
            "8039 [ D loss: 0.182625, acc.: 94%] [G loss: 4.541860]\n",
            "8040 [ D loss: 0.141681, acc.: 94%] [G loss: 6.593602]\n",
            "8041 [ D loss: 0.122729, acc.: 91%] [G loss: 7.223938]\n",
            "8042 [ D loss: 0.105748, acc.: 95%] [G loss: 6.662464]\n",
            "8043 [ D loss: 0.164686, acc.: 95%] [G loss: 5.989473]\n",
            "8044 [ D loss: 0.196228, acc.: 89%] [G loss: 10.741940]\n",
            "8045 [ D loss: 0.141440, acc.: 93%] [G loss: 8.294313]\n",
            "8046 [ D loss: 0.132024, acc.: 95%] [G loss: 5.598613]\n",
            "8047 [ D loss: 0.107488, acc.: 96%] [G loss: 6.895508]\n",
            "8048 [ D loss: 0.089370, acc.: 96%] [G loss: 7.225326]\n",
            "8049 [ D loss: 0.154665, acc.: 94%] [G loss: 5.457217]\n",
            "8050 [ D loss: 0.342475, acc.: 84%] [G loss: 5.698730]\n",
            "8051 [ D loss: 0.144236, acc.: 97%] [G loss: 5.003225]\n",
            "8052 [ D loss: 0.238338, acc.: 91%] [G loss: 3.760485]\n",
            "8053 [ D loss: 0.141888, acc.: 96%] [G loss: 4.365042]\n",
            "8054 [ D loss: 0.216996, acc.: 93%] [G loss: 5.887074]\n",
            "8055 [ D loss: 0.287442, acc.: 87%] [G loss: 4.845872]\n",
            "8056 [ D loss: 0.147999, acc.: 95%] [G loss: 4.539811]\n",
            "8057 [ D loss: 0.117514, acc.: 97%] [G loss: 4.945197]\n",
            "8058 [ D loss: 0.109644, acc.: 96%] [G loss: 4.893704]\n",
            "8059 [ D loss: 0.141810, acc.: 95%] [G loss: 4.213170]\n",
            "8060 [ D loss: 0.363638, acc.: 84%] [G loss: 4.668102]\n",
            "8061 [ D loss: 0.115853, acc.: 97%] [G loss: 6.467786]\n",
            "8062 [ D loss: 0.131395, acc.: 95%] [G loss: 5.501183]\n",
            "8063 [ D loss: 0.066705, acc.: 97%] [G loss: 8.184438]\n",
            "8064 [ D loss: 0.174825, acc.: 95%] [G loss: 7.614957]\n",
            "8065 [ D loss: 0.123213, acc.: 96%] [G loss: 5.207273]\n",
            "8066 [ D loss: 0.115747, acc.: 95%] [G loss: 9.062224]\n",
            "8067 [ D loss: 0.075048, acc.: 96%] [G loss: 5.617837]\n",
            "8068 [ D loss: 0.066376, acc.: 98%] [G loss: 14.246346]\n",
            "8069 [ D loss: 0.084867, acc.: 99%] [G loss: 13.335653]\n",
            "8070 [ D loss: 0.085976, acc.: 96%] [G loss: 13.758776]\n",
            "8071 [ D loss: 0.135086, acc.: 95%] [G loss: 8.052538]\n",
            "8072 [ D loss: 0.113388, acc.: 97%] [G loss: 5.099445]\n",
            "8073 [ D loss: 0.099377, acc.: 98%] [G loss: 5.965592]\n",
            "8074 [ D loss: 0.155738, acc.: 94%] [G loss: 8.816490]\n",
            "8075 [ D loss: 0.093768, acc.: 98%] [G loss: 8.203996]\n",
            "8076 [ D loss: 0.183466, acc.: 91%] [G loss: 10.315954]\n",
            "8077 [ D loss: 0.136256, acc.: 95%] [G loss: 7.375143]\n",
            "8078 [ D loss: 0.177383, acc.: 95%] [G loss: 7.160895]\n",
            "8079 [ D loss: 0.173052, acc.: 94%] [G loss: 8.275951]\n",
            "8080 [ D loss: 0.124724, acc.: 95%] [G loss: 5.499795]\n",
            "8081 [ D loss: 0.365700, acc.: 80%] [G loss: 6.558593]\n",
            "8082 [ D loss: 0.567891, acc.: 73%] [G loss: 4.954753]\n",
            "8083 [ D loss: 0.392471, acc.: 83%] [G loss: 6.272711]\n",
            "8084 [ D loss: 0.192150, acc.: 95%] [G loss: 4.987946]\n",
            "8085 [ D loss: 0.137687, acc.: 95%] [G loss: 6.885227]\n",
            "8086 [ D loss: 0.104678, acc.: 97%] [G loss: 7.330342]\n",
            "8087 [ D loss: 0.179893, acc.: 93%] [G loss: 6.486480]\n",
            "8088 [ D loss: 0.147354, acc.: 95%] [G loss: 8.335723]\n",
            "8089 [ D loss: 0.109700, acc.: 97%] [G loss: 5.213554]\n",
            "8090 [ D loss: 0.058134, acc.: 98%] [G loss: 5.655979]\n",
            "8091 [ D loss: 0.262094, acc.: 88%] [G loss: 6.734249]\n",
            "8092 [ D loss: 0.114551, acc.: 96%] [G loss: 8.369993]\n",
            "8093 [ D loss: 0.165045, acc.: 95%] [G loss: 6.166010]\n",
            "8094 [ D loss: 0.070511, acc.: 99%] [G loss: 5.185845]\n",
            "8095 [ D loss: 0.087525, acc.: 98%] [G loss: 6.492525]\n",
            "8096 [ D loss: 0.123382, acc.: 98%] [G loss: 4.594312]\n",
            "8097 [ D loss: 0.109524, acc.: 96%] [G loss: 6.168197]\n",
            "8098 [ D loss: 0.088482, acc.: 98%] [G loss: 4.794722]\n",
            "8099 [ D loss: 0.127289, acc.: 96%] [G loss: 4.789911]\n",
            "8100 [ D loss: 0.166221, acc.: 96%] [G loss: 4.988850]\n",
            "8101 [ D loss: 0.152962, acc.: 94%] [G loss: 4.944861]\n",
            "8102 [ D loss: 0.120800, acc.: 96%] [G loss: 5.354706]\n",
            "8103 [ D loss: 0.209794, acc.: 92%] [G loss: 5.095127]\n",
            "8104 [ D loss: 0.114400, acc.: 98%] [G loss: 5.962383]\n",
            "8105 [ D loss: 0.220511, acc.: 94%] [G loss: 4.699322]\n",
            "8106 [ D loss: 0.107254, acc.: 98%] [G loss: 4.847410]\n",
            "8107 [ D loss: 0.237337, acc.: 88%] [G loss: 5.375899]\n",
            "8108 [ D loss: 0.120257, acc.: 97%] [G loss: 5.718103]\n",
            "8109 [ D loss: 0.130992, acc.: 94%] [G loss: 7.033564]\n",
            "8110 [ D loss: 0.103692, acc.: 95%] [G loss: 8.057687]\n",
            "8111 [ D loss: 0.094002, acc.: 96%] [G loss: 5.697831]\n",
            "8112 [ D loss: 0.151440, acc.: 94%] [G loss: 4.281457]\n",
            "8113 [ D loss: 0.162681, acc.: 96%] [G loss: 5.466813]\n",
            "8114 [ D loss: 0.182304, acc.: 93%] [G loss: 5.363892]\n",
            "8115 [ D loss: 0.187468, acc.: 92%] [G loss: 9.017606]\n",
            "8116 [ D loss: 0.109383, acc.: 96%] [G loss: 5.967134]\n",
            "8117 [ D loss: 0.125102, acc.: 97%] [G loss: 5.049929]\n",
            "8118 [ D loss: 0.158944, acc.: 94%] [G loss: 5.793834]\n",
            "8119 [ D loss: 0.126873, acc.: 96%] [G loss: 7.030283]\n",
            "8120 [ D loss: 0.191567, acc.: 94%] [G loss: 5.414066]\n",
            "8121 [ D loss: 0.157158, acc.: 95%] [G loss: 5.319303]\n",
            "8122 [ D loss: 0.202202, acc.: 92%] [G loss: 5.801178]\n",
            "8123 [ D loss: 0.236734, acc.: 88%] [G loss: 4.775399]\n",
            "8124 [ D loss: 0.182998, acc.: 93%] [G loss: 6.609421]\n",
            "8125 [ D loss: 0.162839, acc.: 94%] [G loss: 6.071316]\n",
            "8126 [ D loss: 0.156846, acc.: 94%] [G loss: 5.952162]\n",
            "8127 [ D loss: 0.146138, acc.: 93%] [G loss: 5.572223]\n",
            "8128 [ D loss: 0.161525, acc.: 96%] [G loss: 5.014884]\n",
            "8129 [ D loss: 0.171418, acc.: 91%] [G loss: 7.698384]\n",
            "8130 [ D loss: 0.162641, acc.: 93%] [G loss: 8.201930]\n",
            "8131 [ D loss: 0.255963, acc.: 92%] [G loss: 9.382157]\n",
            "8132 [ D loss: 0.126585, acc.: 92%] [G loss: 4.970202]\n",
            "8133 [ D loss: 0.102868, acc.: 96%] [G loss: 6.660825]\n",
            "8134 [ D loss: 0.096227, acc.: 96%] [G loss: 6.574882]\n",
            "8135 [ D loss: 0.112911, acc.: 97%] [G loss: 5.716184]\n",
            "8136 [ D loss: 0.130876, acc.: 94%] [G loss: 5.957181]\n",
            "8137 [ D loss: 0.092454, acc.: 98%] [G loss: 5.554600]\n",
            "8138 [ D loss: 0.122914, acc.: 95%] [G loss: 7.845449]\n",
            "8139 [ D loss: 0.108249, acc.: 97%] [G loss: 5.606684]\n",
            "8140 [ D loss: 0.113898, acc.: 95%] [G loss: 6.750237]\n",
            "8141 [ D loss: 0.173780, acc.: 95%] [G loss: 5.308194]\n",
            "8142 [ D loss: 0.134845, acc.: 95%] [G loss: 5.853381]\n",
            "8143 [ D loss: 0.164318, acc.: 92%] [G loss: 4.869890]\n",
            "8144 [ D loss: 0.376024, acc.: 80%] [G loss: 5.722386]\n",
            "8145 [ D loss: 0.126631, acc.: 95%] [G loss: 6.356377]\n",
            "8146 [ D loss: 0.158414, acc.: 94%] [G loss: 6.932277]\n",
            "8147 [ D loss: 0.149252, acc.: 93%] [G loss: 8.737204]\n",
            "8148 [ D loss: 0.108883, acc.: 96%] [G loss: 5.281841]\n",
            "8149 [ D loss: 0.215746, acc.: 92%] [G loss: 6.155283]\n",
            "8150 [ D loss: 0.066163, acc.: 99%] [G loss: 7.380636]\n",
            "8151 [ D loss: 0.089462, acc.: 97%] [G loss: 4.715893]\n",
            "8152 [ D loss: 0.036867, acc.: 98%] [G loss: 9.463127]\n",
            "8153 [ D loss: 0.078470, acc.: 97%] [G loss: 8.037559]\n",
            "8154 [ D loss: 0.149497, acc.: 95%] [G loss: 6.334039]\n",
            "8155 [ D loss: 0.189223, acc.: 92%] [G loss: 5.027876]\n",
            "8156 [ D loss: 0.071493, acc.: 99%] [G loss: 5.608093]\n",
            "8157 [ D loss: 0.181142, acc.: 91%] [G loss: 5.493349]\n",
            "8158 [ D loss: 0.197650, acc.: 92%] [G loss: 11.071866]\n",
            "8159 [ D loss: 0.097380, acc.: 97%] [G loss: 5.260139]\n",
            "8160 [ D loss: 0.194379, acc.: 93%] [G loss: 8.906500]\n",
            "8161 [ D loss: 0.098815, acc.: 98%] [G loss: 6.530060]\n",
            "8162 [ D loss: 0.133137, acc.: 95%] [G loss: 6.524040]\n",
            "8163 [ D loss: 0.109469, acc.: 95%] [G loss: 5.563819]\n",
            "8164 [ D loss: 0.096426, acc.: 98%] [G loss: 4.869204]\n",
            "8165 [ D loss: 0.067045, acc.: 98%] [G loss: 5.293838]\n",
            "8166 [ D loss: 0.096634, acc.: 98%] [G loss: 7.221647]\n",
            "8167 [ D loss: 0.217859, acc.: 93%] [G loss: 6.676210]\n",
            "8168 [ D loss: 0.145160, acc.: 95%] [G loss: 5.429346]\n",
            "8169 [ D loss: 0.213136, acc.: 93%] [G loss: 6.556265]\n",
            "8170 [ D loss: 0.064396, acc.: 97%] [G loss: 10.205837]\n",
            "8171 [ D loss: 0.102350, acc.: 96%] [G loss: 6.685851]\n",
            "8172 [ D loss: 0.171049, acc.: 91%] [G loss: 4.848581]\n",
            "8173 [ D loss: 0.065460, acc.: 98%] [G loss: 9.280688]\n",
            "8174 [ D loss: 0.199523, acc.: 94%] [G loss: 5.931367]\n",
            "8175 [ D loss: 0.083696, acc.: 98%] [G loss: 6.887464]\n",
            "8176 [ D loss: 0.190843, acc.: 91%] [G loss: 5.973044]\n",
            "8177 [ D loss: 0.124616, acc.: 97%] [G loss: 8.772700]\n",
            "8178 [ D loss: 0.124007, acc.: 95%] [G loss: 7.407336]\n",
            "8179 [ D loss: 0.158814, acc.: 94%] [G loss: 5.669234]\n",
            "8180 [ D loss: 0.082042, acc.: 97%] [G loss: 5.335041]\n",
            "8181 [ D loss: 0.234278, acc.: 90%] [G loss: 8.788169]\n",
            "8182 [ D loss: 0.137066, acc.: 95%] [G loss: 5.068952]\n",
            "8183 [ D loss: 0.088863, acc.: 98%] [G loss: 5.315144]\n",
            "8184 [ D loss: 0.246332, acc.: 90%] [G loss: 4.918777]\n",
            "8185 [ D loss: 0.148109, acc.: 96%] [G loss: 4.780836]\n",
            "8186 [ D loss: 0.190374, acc.: 92%] [G loss: 5.287451]\n",
            "8187 [ D loss: 0.152015, acc.: 92%] [G loss: 5.042869]\n",
            "8188 [ D loss: 0.182293, acc.: 94%] [G loss: 7.318928]\n",
            "8189 [ D loss: 0.161354, acc.: 93%] [G loss: 4.605384]\n",
            "8190 [ D loss: 0.102103, acc.: 96%] [G loss: 5.948976]\n",
            "8191 [ D loss: 0.221472, acc.: 91%] [G loss: 5.503722]\n",
            "8192 [ D loss: 0.150209, acc.: 95%] [G loss: 5.554109]\n",
            "8193 [ D loss: 0.283273, acc.: 85%] [G loss: 4.282228]\n",
            "8194 [ D loss: 0.136648, acc.: 95%] [G loss: 5.355892]\n",
            "8195 [ D loss: 0.236230, acc.: 91%] [G loss: 5.098588]\n",
            "8196 [ D loss: 0.204950, acc.: 91%] [G loss: 5.276038]\n",
            "8197 [ D loss: 0.110197, acc.: 98%] [G loss: 7.070613]\n",
            "8198 [ D loss: 0.121146, acc.: 95%] [G loss: 5.765401]\n",
            "8199 [ D loss: 0.069651, acc.: 98%] [G loss: 6.146495]\n",
            "8200 [ D loss: 0.120897, acc.: 96%] [G loss: 7.036517]\n",
            "8201 [ D loss: 0.140114, acc.: 95%] [G loss: 4.858153]\n",
            "8202 [ D loss: 0.124143, acc.: 95%] [G loss: 5.160176]\n",
            "8203 [ D loss: 0.060115, acc.: 99%] [G loss: 6.372802]\n",
            "8204 [ D loss: 0.190089, acc.: 94%] [G loss: 6.465493]\n",
            "8205 [ D loss: 0.135608, acc.: 95%] [G loss: 5.458444]\n",
            "8206 [ D loss: 0.089227, acc.: 97%] [G loss: 8.044663]\n",
            "8207 [ D loss: 0.161266, acc.: 92%] [G loss: 13.426940]\n",
            "8208 [ D loss: 0.156671, acc.: 94%] [G loss: 12.984539]\n",
            "8209 [ D loss: 0.100270, acc.: 96%] [G loss: 10.393368]\n",
            "8210 [ D loss: 0.044510, acc.: 100%] [G loss: 6.662354]\n",
            "8211 [ D loss: 0.194350, acc.: 91%] [G loss: 6.915218]\n",
            "8212 [ D loss: 0.127808, acc.: 96%] [G loss: 10.963571]\n",
            "8213 [ D loss: 0.186838, acc.: 92%] [G loss: 8.621845]\n",
            "8214 [ D loss: 0.093624, acc.: 96%] [G loss: 9.125073]\n",
            "8215 [ D loss: 0.103925, acc.: 97%] [G loss: 7.812816]\n",
            "8216 [ D loss: 0.111979, acc.: 95%] [G loss: 7.456692]\n",
            "8217 [ D loss: 0.100436, acc.: 95%] [G loss: 6.208054]\n",
            "8218 [ D loss: 0.176078, acc.: 94%] [G loss: 5.109114]\n",
            "8219 [ D loss: 0.180140, acc.: 94%] [G loss: 6.577553]\n",
            "8220 [ D loss: 0.087789, acc.: 97%] [G loss: 5.163520]\n",
            "8221 [ D loss: 0.147772, acc.: 94%] [G loss: 7.591455]\n",
            "8222 [ D loss: 0.133769, acc.: 95%] [G loss: 5.346899]\n",
            "8223 [ D loss: 0.115014, acc.: 95%] [G loss: 5.533421]\n",
            "8224 [ D loss: 0.073539, acc.: 98%] [G loss: 8.102571]\n",
            "8225 [ D loss: 0.151046, acc.: 92%] [G loss: 7.024172]\n",
            "8226 [ D loss: 0.086033, acc.: 98%] [G loss: 7.766547]\n",
            "8227 [ D loss: 0.099512, acc.: 98%] [G loss: 6.886579]\n",
            "8228 [ D loss: 0.139759, acc.: 97%] [G loss: 6.887249]\n",
            "8229 [ D loss: 0.169650, acc.: 95%] [G loss: 6.203284]\n",
            "8230 [ D loss: 0.124520, acc.: 95%] [G loss: 4.629594]\n",
            "8231 [ D loss: 0.095814, acc.: 97%] [G loss: 9.378184]\n",
            "8232 [ D loss: 0.141860, acc.: 96%] [G loss: 5.636838]\n",
            "8233 [ D loss: 0.067784, acc.: 99%] [G loss: 6.699990]\n",
            "8234 [ D loss: 0.214635, acc.: 91%] [G loss: 6.655112]\n",
            "8235 [ D loss: 0.179953, acc.: 94%] [G loss: 6.776507]\n",
            "8236 [ D loss: 0.185947, acc.: 93%] [G loss: 6.569793]\n",
            "8237 [ D loss: 0.116742, acc.: 99%] [G loss: 5.769442]\n",
            "8238 [ D loss: 0.154410, acc.: 93%] [G loss: 4.415024]\n",
            "8239 [ D loss: 0.202155, acc.: 94%] [G loss: 5.158679]\n",
            "8240 [ D loss: 0.228208, acc.: 90%] [G loss: 7.660988]\n",
            "8241 [ D loss: 0.232947, acc.: 88%] [G loss: 4.311224]\n",
            "8242 [ D loss: 0.172877, acc.: 92%] [G loss: 8.469236]\n",
            "8243 [ D loss: 0.101062, acc.: 96%] [G loss: 6.967633]\n",
            "8244 [ D loss: 0.162464, acc.: 95%] [G loss: 5.144873]\n",
            "8245 [ D loss: 0.066379, acc.: 98%] [G loss: 11.898695]\n",
            "8246 [ D loss: 0.084925, acc.: 98%] [G loss: 8.311991]\n",
            "8247 [ D loss: 0.066649, acc.: 98%] [G loss: 5.562340]\n",
            "8248 [ D loss: 0.033751, acc.: 99%] [G loss: 7.491269]\n",
            "8249 [ D loss: 0.121247, acc.: 95%] [G loss: 8.939872]\n",
            "8250 [ D loss: 0.052596, acc.: 100%] [G loss: 11.974361]\n",
            "8251 [ D loss: 0.091782, acc.: 98%] [G loss: 6.870415]\n",
            "8252 [ D loss: 0.101974, acc.: 96%] [G loss: 5.899334]\n",
            "8253 [ D loss: 0.175314, acc.: 92%] [G loss: 4.991838]\n",
            "8254 [ D loss: 0.076684, acc.: 98%] [G loss: 5.724551]\n",
            "8255 [ D loss: 0.124028, acc.: 95%] [G loss: 7.386797]\n",
            "8256 [ D loss: 0.071547, acc.: 99%] [G loss: 7.116994]\n",
            "8257 [ D loss: 0.081608, acc.: 98%] [G loss: 4.907881]\n",
            "8258 [ D loss: 0.102130, acc.: 95%] [G loss: 5.623453]\n",
            "8259 [ D loss: 0.066638, acc.: 99%] [G loss: 5.815207]\n",
            "8260 [ D loss: 0.301453, acc.: 88%] [G loss: 5.095709]\n",
            "8261 [ D loss: 0.086706, acc.: 98%] [G loss: 9.003609]\n",
            "8262 [ D loss: 0.220825, acc.: 92%] [G loss: 5.242829]\n",
            "8263 [ D loss: 0.070597, acc.: 97%] [G loss: 8.025532]\n",
            "8264 [ D loss: 0.295233, acc.: 89%] [G loss: 4.049699]\n",
            "8265 [ D loss: 0.069411, acc.: 98%] [G loss: 5.917740]\n",
            "8266 [ D loss: 0.145597, acc.: 95%] [G loss: 6.446065]\n",
            "8267 [ D loss: 0.117999, acc.: 97%] [G loss: 5.728813]\n",
            "8268 [ D loss: 0.154469, acc.: 94%] [G loss: 5.137676]\n",
            "8269 [ D loss: 0.061173, acc.: 97%] [G loss: 7.256438]\n",
            "8270 [ D loss: 0.154385, acc.: 93%] [G loss: 6.022048]\n",
            "8271 [ D loss: 0.124901, acc.: 95%] [G loss: 5.103298]\n",
            "8272 [ D loss: 0.066438, acc.: 98%] [G loss: 6.930052]\n",
            "8273 [ D loss: 0.182890, acc.: 93%] [G loss: 6.578116]\n",
            "8274 [ D loss: 0.074818, acc.: 98%] [G loss: 5.461187]\n",
            "8275 [ D loss: 0.151023, acc.: 94%] [G loss: 4.301034]\n",
            "8276 [ D loss: 0.133781, acc.: 95%] [G loss: 4.759880]\n",
            "8277 [ D loss: 0.130508, acc.: 96%] [G loss: 8.270703]\n",
            "8278 [ D loss: 0.108713, acc.: 97%] [G loss: 6.148920]\n",
            "8279 [ D loss: 0.112011, acc.: 96%] [G loss: 6.902956]\n",
            "8280 [ D loss: 0.106812, acc.: 95%] [G loss: 6.479059]\n",
            "8281 [ D loss: 0.201629, acc.: 91%] [G loss: 6.846478]\n",
            "8282 [ D loss: 0.142144, acc.: 95%] [G loss: 6.745169]\n",
            "8283 [ D loss: 0.263342, acc.: 88%] [G loss: 12.749127]\n",
            "8284 [ D loss: 0.274406, acc.: 88%] [G loss: 7.995468]\n",
            "8285 [ D loss: 0.377779, acc.: 83%] [G loss: 6.709980]\n",
            "8286 [ D loss: 0.091330, acc.: 97%] [G loss: 5.307738]\n",
            "8287 [ D loss: 0.268901, acc.: 90%] [G loss: 6.278673]\n",
            "8288 [ D loss: 0.110616, acc.: 96%] [G loss: 6.174486]\n",
            "8289 [ D loss: 0.075727, acc.: 98%] [G loss: 4.575863]\n",
            "8290 [ D loss: 0.156407, acc.: 93%] [G loss: 5.786420]\n",
            "8291 [ D loss: 0.136324, acc.: 95%] [G loss: 6.358934]\n",
            "8292 [ D loss: 0.198645, acc.: 93%] [G loss: 6.219587]\n",
            "8293 [ D loss: 0.135526, acc.: 95%] [G loss: 3.946572]\n",
            "8294 [ D loss: 0.120083, acc.: 97%] [G loss: 5.021210]\n",
            "8295 [ D loss: 0.216846, acc.: 89%] [G loss: 6.635601]\n",
            "8296 [ D loss: 0.219138, acc.: 90%] [G loss: 4.887783]\n",
            "8297 [ D loss: 0.136796, acc.: 93%] [G loss: 9.673483]\n",
            "8298 [ D loss: 0.138875, acc.: 95%] [G loss: 4.606671]\n",
            "8299 [ D loss: 0.262667, acc.: 90%] [G loss: 5.503180]\n",
            "8300 [ D loss: 0.096962, acc.: 98%] [G loss: 8.268763]\n",
            "8301 [ D loss: 0.177569, acc.: 94%] [G loss: 6.563204]\n",
            "8302 [ D loss: 0.136973, acc.: 94%] [G loss: 6.717596]\n",
            "8303 [ D loss: 0.250573, acc.: 91%] [G loss: 6.200799]\n",
            "8304 [ D loss: 0.222564, acc.: 91%] [G loss: 7.149441]\n",
            "8305 [ D loss: 0.156533, acc.: 94%] [G loss: 6.586453]\n",
            "8306 [ D loss: 0.099971, acc.: 97%] [G loss: 6.935584]\n",
            "8307 [ D loss: 0.183771, acc.: 91%] [G loss: 6.023963]\n",
            "8308 [ D loss: 0.146088, acc.: 94%] [G loss: 6.251102]\n",
            "8309 [ D loss: 0.128891, acc.: 96%] [G loss: 10.136164]\n",
            "8310 [ D loss: 0.105807, acc.: 98%] [G loss: 5.484425]\n",
            "8311 [ D loss: 0.082269, acc.: 97%] [G loss: 6.419696]\n",
            "8312 [ D loss: 0.129620, acc.: 97%] [G loss: 5.884090]\n",
            "8313 [ D loss: 0.122780, acc.: 97%] [G loss: 4.872025]\n",
            "8314 [ D loss: 0.052740, acc.: 98%] [G loss: 7.765056]\n",
            "8315 [ D loss: 0.079703, acc.: 99%] [G loss: 7.528881]\n",
            "8316 [ D loss: 0.165359, acc.: 94%] [G loss: 5.436138]\n",
            "8317 [ D loss: 0.095010, acc.: 98%] [G loss: 6.998124]\n",
            "8318 [ D loss: 0.113695, acc.: 96%] [G loss: 6.468435]\n",
            "8319 [ D loss: 0.095224, acc.: 97%] [G loss: 7.706123]\n",
            "8320 [ D loss: 0.089437, acc.: 97%] [G loss: 3.504937]\n",
            "8321 [ D loss: 0.128681, acc.: 95%] [G loss: 6.902926]\n",
            "8322 [ D loss: 0.160770, acc.: 95%] [G loss: 2.605726]\n",
            "8323 [ D loss: 0.150591, acc.: 97%] [G loss: 4.222429]\n",
            "8324 [ D loss: 0.127890, acc.: 95%] [G loss: 5.877584]\n",
            "8325 [ D loss: 0.208526, acc.: 94%] [G loss: 4.900756]\n",
            "8326 [ D loss: 0.182774, acc.: 95%] [G loss: 5.372779]\n",
            "8327 [ D loss: 0.199837, acc.: 93%] [G loss: 3.590590]\n",
            "8328 [ D loss: 0.156107, acc.: 95%] [G loss: 4.863779]\n",
            "8329 [ D loss: 0.156669, acc.: 96%] [G loss: 6.045554]\n",
            "8330 [ D loss: 0.222476, acc.: 91%] [G loss: 5.661220]\n",
            "8331 [ D loss: 0.132759, acc.: 98%] [G loss: 5.844868]\n",
            "8332 [ D loss: 0.154294, acc.: 94%] [G loss: 5.497542]\n",
            "8333 [ D loss: 0.112861, acc.: 97%] [G loss: 6.628471]\n",
            "8334 [ D loss: 0.066110, acc.: 100%] [G loss: 5.085715]\n",
            "8335 [ D loss: 0.200272, acc.: 92%] [G loss: 4.930241]\n",
            "8336 [ D loss: 0.123653, acc.: 96%] [G loss: 5.247576]\n",
            "8337 [ D loss: 0.207011, acc.: 92%] [G loss: 5.679016]\n",
            "8338 [ D loss: 0.136163, acc.: 97%] [G loss: 4.311084]\n",
            "8339 [ D loss: 0.203796, acc.: 91%] [G loss: 5.543489]\n",
            "8340 [ D loss: 0.154255, acc.: 93%] [G loss: 5.916879]\n",
            "8341 [ D loss: 0.138737, acc.: 94%] [G loss: 6.826294]\n",
            "8342 [ D loss: 0.104491, acc.: 98%] [G loss: 5.154696]\n",
            "8343 [ D loss: 0.130410, acc.: 95%] [G loss: 5.223041]\n",
            "8344 [ D loss: 0.085901, acc.: 98%] [G loss: 6.823311]\n",
            "8345 [ D loss: 0.118855, acc.: 98%] [G loss: 5.220444]\n",
            "8346 [ D loss: 0.097648, acc.: 97%] [G loss: 9.050640]\n",
            "8347 [ D loss: 0.053602, acc.: 99%] [G loss: 6.614335]\n",
            "8348 [ D loss: 0.202672, acc.: 91%] [G loss: 12.706413]\n",
            "8349 [ D loss: 0.109146, acc.: 96%] [G loss: 10.529400]\n",
            "8350 [ D loss: 0.130159, acc.: 94%] [G loss: 8.097746]\n",
            "8351 [ D loss: 0.187693, acc.: 92%] [G loss: 5.528085]\n",
            "8352 [ D loss: 0.123091, acc.: 97%] [G loss: 6.271011]\n",
            "8353 [ D loss: 0.145947, acc.: 95%] [G loss: 6.089267]\n",
            "8354 [ D loss: 0.097491, acc.: 96%] [G loss: 5.594318]\n",
            "8355 [ D loss: 0.240682, acc.: 91%] [G loss: 5.840094]\n",
            "8356 [ D loss: 0.200826, acc.: 93%] [G loss: 5.290973]\n",
            "8357 [ D loss: 0.117000, acc.: 97%] [G loss: 3.942890]\n",
            "8358 [ D loss: 0.291741, acc.: 88%] [G loss: 5.139828]\n",
            "8359 [ D loss: 0.199916, acc.: 93%] [G loss: 5.091533]\n",
            "8360 [ D loss: 0.156156, acc.: 95%] [G loss: 4.774647]\n",
            "8361 [ D loss: 0.193314, acc.: 92%] [G loss: 5.606262]\n",
            "8362 [ D loss: 0.141621, acc.: 96%] [G loss: 5.621443]\n",
            "8363 [ D loss: 0.161684, acc.: 95%] [G loss: 4.782701]\n",
            "8364 [ D loss: 0.085160, acc.: 97%] [G loss: 4.884542]\n",
            "8365 [ D loss: 0.135212, acc.: 95%] [G loss: 4.114231]\n",
            "8366 [ D loss: 0.111853, acc.: 98%] [G loss: 5.493242]\n",
            "8367 [ D loss: 0.121741, acc.: 96%] [G loss: 5.143461]\n",
            "8368 [ D loss: 0.222791, acc.: 88%] [G loss: 5.247249]\n",
            "8369 [ D loss: 0.153987, acc.: 93%] [G loss: 5.469491]\n",
            "8370 [ D loss: 0.274102, acc.: 87%] [G loss: 4.556152]\n",
            "8371 [ D loss: 0.148765, acc.: 95%] [G loss: 4.490851]\n",
            "8372 [ D loss: 0.069250, acc.: 98%] [G loss: 5.467060]\n",
            "8373 [ D loss: 0.144527, acc.: 95%] [G loss: 6.111418]\n",
            "8374 [ D loss: 0.138665, acc.: 95%] [G loss: 5.663640]\n",
            "8375 [ D loss: 0.103393, acc.: 96%] [G loss: 5.953571]\n",
            "8376 [ D loss: 0.165752, acc.: 97%] [G loss: 4.523172]\n",
            "8377 [ D loss: 0.071809, acc.: 98%] [G loss: 6.596124]\n",
            "8378 [ D loss: 0.160079, acc.: 93%] [G loss: 5.375592]\n",
            "8379 [ D loss: 0.133534, acc.: 95%] [G loss: 5.882577]\n",
            "8380 [ D loss: 0.120641, acc.: 96%] [G loss: 5.653080]\n",
            "8381 [ D loss: 0.226397, acc.: 92%] [G loss: 8.051028]\n",
            "8382 [ D loss: 0.185946, acc.: 91%] [G loss: 5.883961]\n",
            "8383 [ D loss: 0.076653, acc.: 98%] [G loss: 3.778182]\n",
            "8384 [ D loss: 0.156511, acc.: 95%] [G loss: 4.970291]\n",
            "8385 [ D loss: 0.182703, acc.: 94%] [G loss: 4.307977]\n",
            "8386 [ D loss: 0.152705, acc.: 94%] [G loss: 6.847861]\n",
            "8387 [ D loss: 0.113676, acc.: 96%] [G loss: 6.224653]\n",
            "8388 [ D loss: 0.276109, acc.: 90%] [G loss: 7.737084]\n",
            "8389 [ D loss: 0.242397, acc.: 87%] [G loss: 3.758457]\n",
            "8390 [ D loss: 0.188387, acc.: 91%] [G loss: 6.702934]\n",
            "8391 [ D loss: 0.362947, acc.: 85%] [G loss: 5.625532]\n",
            "8392 [ D loss: 0.347075, acc.: 83%] [G loss: 6.332483]\n",
            "8393 [ D loss: 0.136400, acc.: 95%] [G loss: 7.982089]\n",
            "8394 [ D loss: 0.162263, acc.: 92%] [G loss: 6.991326]\n",
            "8395 [ D loss: 0.243810, acc.: 89%] [G loss: 9.729292]\n",
            "8396 [ D loss: 0.114423, acc.: 97%] [G loss: 8.557289]\n",
            "8397 [ D loss: 0.195349, acc.: 92%] [G loss: 6.196001]\n",
            "8398 [ D loss: 0.079883, acc.: 97%] [G loss: 11.046412]\n",
            "8399 [ D loss: 0.086061, acc.: 98%] [G loss: 9.170328]\n",
            "8400 [ D loss: 0.075804, acc.: 98%] [G loss: 5.453901]\n",
            "8401 [ D loss: 0.081137, acc.: 98%] [G loss: 8.784639]\n",
            "8402 [ D loss: 0.108867, acc.: 95%] [G loss: 9.172190]\n",
            "8403 [ D loss: 0.088197, acc.: 98%] [G loss: 10.911304]\n",
            "8404 [ D loss: 0.123401, acc.: 93%] [G loss: 12.014714]\n",
            "8405 [ D loss: 0.062801, acc.: 98%] [G loss: 8.303923]\n",
            "8406 [ D loss: 0.111389, acc.: 96%] [G loss: 6.116771]\n",
            "8407 [ D loss: 0.106591, acc.: 98%] [G loss: 7.173107]\n",
            "8408 [ D loss: 0.109145, acc.: 96%] [G loss: 5.361030]\n",
            "8409 [ D loss: 0.082891, acc.: 98%] [G loss: 6.043576]\n",
            "8410 [ D loss: 0.161606, acc.: 95%] [G loss: 4.775814]\n",
            "8411 [ D loss: 0.120672, acc.: 96%] [G loss: 7.709959]\n",
            "8412 [ D loss: 0.180079, acc.: 94%] [G loss: 3.445135]\n",
            "8413 [ D loss: 0.068549, acc.: 98%] [G loss: 6.468724]\n",
            "8414 [ D loss: 0.196497, acc.: 90%] [G loss: 4.426656]\n",
            "8415 [ D loss: 0.283958, acc.: 89%] [G loss: 5.669479]\n",
            "8416 [ D loss: 0.232419, acc.: 88%] [G loss: 5.327858]\n",
            "8417 [ D loss: 0.073787, acc.: 98%] [G loss: 5.394302]\n",
            "8418 [ D loss: 0.323126, acc.: 86%] [G loss: 4.724789]\n",
            "8419 [ D loss: 0.064395, acc.: 98%] [G loss: 6.697628]\n",
            "8420 [ D loss: 0.316297, acc.: 85%] [G loss: 5.514127]\n",
            "8421 [ D loss: 0.195826, acc.: 91%] [G loss: 5.460914]\n",
            "8422 [ D loss: 0.186637, acc.: 92%] [G loss: 5.824877]\n",
            "8423 [ D loss: 0.110169, acc.: 96%] [G loss: 5.661699]\n",
            "8424 [ D loss: 0.211926, acc.: 91%] [G loss: 5.970634]\n",
            "8425 [ D loss: 0.131148, acc.: 96%] [G loss: 8.180887]\n",
            "8426 [ D loss: 0.072625, acc.: 98%] [G loss: 7.404459]\n",
            "8427 [ D loss: 0.182324, acc.: 92%] [G loss: 5.210482]\n",
            "8428 [ D loss: 0.395359, acc.: 80%] [G loss: 9.876686]\n",
            "8429 [ D loss: 0.268856, acc.: 91%] [G loss: 9.805592]\n",
            "8430 [ D loss: 0.328589, acc.: 85%] [G loss: 6.094418]\n",
            "8431 [ D loss: 0.143846, acc.: 95%] [G loss: 5.814396]\n",
            "8432 [ D loss: 0.215072, acc.: 92%] [G loss: 5.521211]\n",
            "8433 [ D loss: 0.160284, acc.: 94%] [G loss: 5.085407]\n",
            "8434 [ D loss: 0.224214, acc.: 89%] [G loss: 6.533966]\n",
            "8435 [ D loss: 0.128274, acc.: 96%] [G loss: 6.731019]\n",
            "8436 [ D loss: 0.088742, acc.: 97%] [G loss: 7.995066]\n",
            "8437 [ D loss: 0.170806, acc.: 95%] [G loss: 6.266732]\n",
            "8438 [ D loss: 0.121427, acc.: 96%] [G loss: 5.137526]\n",
            "8439 [ D loss: 0.172005, acc.: 91%] [G loss: 9.819956]\n",
            "8440 [ D loss: 0.182761, acc.: 91%] [G loss: 6.589020]\n",
            "8441 [ D loss: 0.058256, acc.: 98%] [G loss: 6.531991]\n",
            "8442 [ D loss: 0.209598, acc.: 91%] [G loss: 5.508850]\n",
            "8443 [ D loss: 0.223456, acc.: 91%] [G loss: 5.434875]\n",
            "8444 [ D loss: 0.173368, acc.: 94%] [G loss: 5.666689]\n",
            "8445 [ D loss: 0.103145, acc.: 95%] [G loss: 5.737104]\n",
            "8446 [ D loss: 0.201273, acc.: 91%] [G loss: 6.028312]\n",
            "8447 [ D loss: 0.276256, acc.: 89%] [G loss: 5.113298]\n",
            "8448 [ D loss: 0.218717, acc.: 90%] [G loss: 5.922374]\n",
            "8449 [ D loss: 0.102764, acc.: 97%] [G loss: 5.634130]\n",
            "8450 [ D loss: 0.203473, acc.: 90%] [G loss: 5.742622]\n",
            "8451 [ D loss: 0.109733, acc.: 97%] [G loss: 5.550707]\n",
            "8452 [ D loss: 0.170134, acc.: 93%] [G loss: 6.977840]\n",
            "8453 [ D loss: 0.139282, acc.: 95%] [G loss: 5.946040]\n",
            "8454 [ D loss: 0.173738, acc.: 93%] [G loss: 5.867158]\n",
            "8455 [ D loss: 0.130723, acc.: 93%] [G loss: 7.346827]\n",
            "8456 [ D loss: 0.086422, acc.: 98%] [G loss: 7.096500]\n",
            "8457 [ D loss: 0.103279, acc.: 97%] [G loss: 8.881660]\n",
            "8458 [ D loss: 0.058437, acc.: 98%] [G loss: 5.315715]\n",
            "8459 [ D loss: 0.044984, acc.: 99%] [G loss: 9.603915]\n",
            "8460 [ D loss: 0.079770, acc.: 98%] [G loss: 8.807943]\n",
            "8461 [ D loss: 0.133166, acc.: 94%] [G loss: 5.147030]\n",
            "8462 [ D loss: 0.183720, acc.: 94%] [G loss: 9.596190]\n",
            "8463 [ D loss: 0.076626, acc.: 98%] [G loss: 7.285445]\n",
            "8464 [ D loss: 0.049602, acc.: 98%] [G loss: 4.343906]\n",
            "8465 [ D loss: 0.104869, acc.: 97%] [G loss: 4.209410]\n",
            "8466 [ D loss: 0.183344, acc.: 94%] [G loss: 5.773187]\n",
            "8467 [ D loss: 0.286969, acc.: 87%] [G loss: 5.496854]\n",
            "8468 [ D loss: 0.227881, acc.: 90%] [G loss: 6.676784]\n",
            "8469 [ D loss: 0.117323, acc.: 95%] [G loss: 5.524820]\n",
            "8470 [ D loss: 0.122952, acc.: 97%] [G loss: 6.232915]\n",
            "8471 [ D loss: 0.166313, acc.: 94%] [G loss: 9.521238]\n",
            "8472 [ D loss: 0.128477, acc.: 95%] [G loss: 11.819973]\n",
            "8473 [ D loss: 0.076681, acc.: 97%] [G loss: 8.836535]\n",
            "8474 [ D loss: 0.136769, acc.: 94%] [G loss: 8.719970]\n",
            "8475 [ D loss: 0.199652, acc.: 92%] [G loss: 7.012016]\n",
            "8476 [ D loss: 0.117282, acc.: 96%] [G loss: 4.621906]\n",
            "8477 [ D loss: 0.303126, acc.: 84%] [G loss: 9.442705]\n",
            "8478 [ D loss: 0.231096, acc.: 91%] [G loss: 5.806888]\n",
            "8479 [ D loss: 0.130379, acc.: 94%] [G loss: 6.115083]\n",
            "8480 [ D loss: 0.106672, acc.: 96%] [G loss: 11.094176]\n",
            "8481 [ D loss: 0.167932, acc.: 96%] [G loss: 7.121783]\n",
            "8482 [ D loss: 0.049149, acc.: 99%] [G loss: 9.430315]\n",
            "8483 [ D loss: 0.131855, acc.: 93%] [G loss: 9.731955]\n",
            "8484 [ D loss: 0.136054, acc.: 95%] [G loss: 13.353790]\n",
            "8485 [ D loss: 0.085386, acc.: 98%] [G loss: 10.920647]\n",
            "8486 [ D loss: 0.121801, acc.: 95%] [G loss: 5.076083]\n",
            "8487 [ D loss: 0.064641, acc.: 97%] [G loss: 14.085308]\n",
            "8488 [ D loss: 0.030622, acc.: 99%] [G loss: 7.917377]\n",
            "8489 [ D loss: 0.084556, acc.: 96%] [G loss: 5.393950]\n",
            "8490 [ D loss: 0.091766, acc.: 97%] [G loss: 10.304411]\n",
            "8491 [ D loss: 0.070384, acc.: 100%] [G loss: 8.963556]\n",
            "8492 [ D loss: 0.182116, acc.: 92%] [G loss: 4.346611]\n",
            "8493 [ D loss: 0.102606, acc.: 95%] [G loss: 5.661859]\n",
            "8494 [ D loss: 0.149671, acc.: 95%] [G loss: 12.368479]\n",
            "8495 [ D loss: 0.254409, acc.: 87%] [G loss: 10.686943]\n",
            "8496 [ D loss: 0.105037, acc.: 97%] [G loss: 9.987398]\n",
            "8497 [ D loss: 0.072569, acc.: 98%] [G loss: 8.288173]\n",
            "8498 [ D loss: 0.090130, acc.: 95%] [G loss: 5.127284]\n",
            "8499 [ D loss: 0.083522, acc.: 98%] [G loss: 11.233781]\n",
            "8500 [ D loss: 0.116002, acc.: 94%] [G loss: 12.439137]\n",
            "8501 [ D loss: 0.030130, acc.: 100%] [G loss: 9.587405]\n",
            "8502 [ D loss: 0.097098, acc.: 97%] [G loss: 8.624532]\n",
            "8503 [ D loss: 0.059606, acc.: 100%] [G loss: 6.587464]\n",
            "8504 [ D loss: 0.140694, acc.: 95%] [G loss: 6.758980]\n",
            "8505 [ D loss: 0.051589, acc.: 100%] [G loss: 6.808176]\n",
            "8506 [ D loss: 0.131587, acc.: 92%] [G loss: 6.446790]\n",
            "8507 [ D loss: 0.074706, acc.: 98%] [G loss: 5.668450]\n",
            "8508 [ D loss: 0.084573, acc.: 98%] [G loss: 7.194385]\n",
            "8509 [ D loss: 0.111889, acc.: 96%] [G loss: 7.533180]\n",
            "8510 [ D loss: 0.105866, acc.: 97%] [G loss: 5.762638]\n",
            "8511 [ D loss: 0.144380, acc.: 95%] [G loss: 5.908315]\n",
            "8512 [ D loss: 0.096008, acc.: 96%] [G loss: 5.125869]\n",
            "8513 [ D loss: 0.175034, acc.: 94%] [G loss: 5.844163]\n",
            "8514 [ D loss: 0.165306, acc.: 96%] [G loss: 6.580795]\n",
            "8515 [ D loss: 0.128742, acc.: 95%] [G loss: 8.026197]\n",
            "8516 [ D loss: 0.164214, acc.: 97%] [G loss: 7.628525]\n",
            "8517 [ D loss: 0.351971, acc.: 85%] [G loss: 5.271216]\n",
            "8518 [ D loss: 0.096003, acc.: 98%] [G loss: 5.897063]\n",
            "8519 [ D loss: 0.175002, acc.: 93%] [G loss: 7.147130]\n",
            "8520 [ D loss: 0.182305, acc.: 92%] [G loss: 4.284064]\n",
            "8521 [ D loss: 0.124162, acc.: 97%] [G loss: 5.958771]\n",
            "8522 [ D loss: 0.185574, acc.: 94%] [G loss: 5.542497]\n",
            "8523 [ D loss: 0.131120, acc.: 95%] [G loss: 6.655901]\n",
            "8524 [ D loss: 0.070291, acc.: 98%] [G loss: 8.608632]\n",
            "8525 [ D loss: 0.070299, acc.: 98%] [G loss: 8.045823]\n",
            "8526 [ D loss: 0.200709, acc.: 91%] [G loss: 9.313364]\n",
            "8527 [ D loss: 0.210243, acc.: 92%] [G loss: 6.385417]\n",
            "8528 [ D loss: 0.164563, acc.: 95%] [G loss: 9.060246]\n",
            "8529 [ D loss: 0.069886, acc.: 97%] [G loss: 8.460590]\n",
            "8530 [ D loss: 0.133896, acc.: 94%] [G loss: 9.794092]\n",
            "8531 [ D loss: 0.138776, acc.: 94%] [G loss: 4.082958]\n",
            "8532 [ D loss: 0.142562, acc.: 95%] [G loss: 6.368390]\n",
            "8533 [ D loss: 0.093638, acc.: 97%] [G loss: 4.743645]\n",
            "8534 [ D loss: 0.147952, acc.: 95%] [G loss: 11.453193]\n",
            "8535 [ D loss: 0.177433, acc.: 92%] [G loss: 5.623140]\n",
            "8536 [ D loss: 0.146899, acc.: 94%] [G loss: 5.482913]\n",
            "8537 [ D loss: 0.150623, acc.: 95%] [G loss: 5.964020]\n",
            "8538 [ D loss: 0.103100, acc.: 96%] [G loss: 8.371788]\n",
            "8539 [ D loss: 0.213530, acc.: 89%] [G loss: 7.130656]\n",
            "8540 [ D loss: 0.102004, acc.: 95%] [G loss: 8.081612]\n",
            "8541 [ D loss: 0.239123, acc.: 94%] [G loss: 8.537468]\n",
            "8542 [ D loss: 0.172951, acc.: 92%] [G loss: 9.395138]\n",
            "8543 [ D loss: 0.093774, acc.: 97%] [G loss: 6.714301]\n",
            "8544 [ D loss: 0.053546, acc.: 100%] [G loss: 6.032835]\n",
            "8545 [ D loss: 0.117631, acc.: 98%] [G loss: 4.809824]\n",
            "8546 [ D loss: 0.155021, acc.: 97%] [G loss: 6.674530]\n",
            "8547 [ D loss: 0.244394, acc.: 88%] [G loss: 5.626791]\n",
            "8548 [ D loss: 0.109665, acc.: 96%] [G loss: 6.155291]\n",
            "8549 [ D loss: 0.332899, acc.: 83%] [G loss: 4.981969]\n",
            "8550 [ D loss: 0.215735, acc.: 91%] [G loss: 5.694110]\n",
            "8551 [ D loss: 0.075005, acc.: 99%] [G loss: 6.120014]\n",
            "8552 [ D loss: 0.250244, acc.: 91%] [G loss: 4.764192]\n",
            "8553 [ D loss: 0.083010, acc.: 98%] [G loss: 5.545090]\n",
            "8554 [ D loss: 0.063411, acc.: 98%] [G loss: 6.645845]\n",
            "8555 [ D loss: 0.259927, acc.: 91%] [G loss: 5.420520]\n",
            "8556 [ D loss: 0.112831, acc.: 97%] [G loss: 6.459946]\n",
            "8557 [ D loss: 0.153685, acc.: 94%] [G loss: 4.828223]\n",
            "8558 [ D loss: 0.136061, acc.: 95%] [G loss: 7.340492]\n",
            "8559 [ D loss: 0.114812, acc.: 96%] [G loss: 5.683403]\n",
            "8560 [ D loss: 0.131398, acc.: 98%] [G loss: 4.671412]\n",
            "8561 [ D loss: 0.261072, acc.: 90%] [G loss: 6.769235]\n",
            "8562 [ D loss: 0.189054, acc.: 93%] [G loss: 6.555431]\n",
            "8563 [ D loss: 0.128318, acc.: 95%] [G loss: 5.198778]\n",
            "8564 [ D loss: 0.164343, acc.: 95%] [G loss: 7.373503]\n",
            "8565 [ D loss: 0.145620, acc.: 93%] [G loss: 7.305349]\n",
            "8566 [ D loss: 0.102151, acc.: 97%] [G loss: 6.231619]\n",
            "8567 [ D loss: 0.116237, acc.: 96%] [G loss: 5.603808]\n",
            "8568 [ D loss: 0.062291, acc.: 98%] [G loss: 8.042807]\n",
            "8569 [ D loss: 0.121657, acc.: 96%] [G loss: 5.620386]\n",
            "8570 [ D loss: 0.088949, acc.: 98%] [G loss: 7.031562]\n",
            "8571 [ D loss: 0.094797, acc.: 96%] [G loss: 9.141563]\n",
            "8572 [ D loss: 0.046212, acc.: 98%] [G loss: 13.348534]\n",
            "8573 [ D loss: 0.027740, acc.: 98%] [G loss: 6.585261]\n",
            "8574 [ D loss: 0.070173, acc.: 98%] [G loss: 6.204161]\n",
            "8575 [ D loss: 0.166280, acc.: 93%] [G loss: 5.451027]\n",
            "8576 [ D loss: 0.148740, acc.: 95%] [G loss: 7.714594]\n",
            "8577 [ D loss: 0.106025, acc.: 97%] [G loss: 5.156633]\n",
            "8578 [ D loss: 0.105549, acc.: 95%] [G loss: 4.197078]\n",
            "8579 [ D loss: 0.205126, acc.: 92%] [G loss: 7.518867]\n",
            "8580 [ D loss: 0.216386, acc.: 91%] [G loss: 5.288126]\n",
            "8581 [ D loss: 0.093392, acc.: 98%] [G loss: 5.171941]\n",
            "8582 [ D loss: 0.207874, acc.: 91%] [G loss: 7.629309]\n",
            "8583 [ D loss: 0.121363, acc.: 95%] [G loss: 6.725497]\n",
            "8584 [ D loss: 0.111357, acc.: 96%] [G loss: 5.802217]\n",
            "8585 [ D loss: 0.104668, acc.: 97%] [G loss: 5.256205]\n",
            "8586 [ D loss: 0.105564, acc.: 96%] [G loss: 9.947536]\n",
            "8587 [ D loss: 0.108876, acc.: 95%] [G loss: 10.890144]\n",
            "8588 [ D loss: 0.117441, acc.: 95%] [G loss: 11.324585]\n",
            "8589 [ D loss: 0.154815, acc.: 93%] [G loss: 8.116871]\n",
            "8590 [ D loss: 0.110291, acc.: 97%] [G loss: 6.741702]\n",
            "8591 [ D loss: 0.092010, acc.: 97%] [G loss: 6.999548]\n",
            "8592 [ D loss: 0.134471, acc.: 92%] [G loss: 7.835386]\n",
            "8593 [ D loss: 0.090181, acc.: 98%] [G loss: 8.004939]\n",
            "8594 [ D loss: 0.050205, acc.: 98%] [G loss: 6.236829]\n",
            "8595 [ D loss: 0.094960, acc.: 97%] [G loss: 6.409388]\n",
            "8596 [ D loss: 0.174625, acc.: 94%] [G loss: 5.478824]\n",
            "8597 [ D loss: 0.169210, acc.: 94%] [G loss: 5.932854]\n",
            "8598 [ D loss: 0.094912, acc.: 98%] [G loss: 5.080279]\n",
            "8599 [ D loss: 0.142100, acc.: 94%] [G loss: 8.636326]\n",
            "8600 [ D loss: 0.142340, acc.: 95%] [G loss: 5.888831]\n",
            "8601 [ D loss: 0.111974, acc.: 95%] [G loss: 6.179771]\n",
            "8602 [ D loss: 0.173528, acc.: 93%] [G loss: 6.309448]\n",
            "8603 [ D loss: 0.217338, acc.: 92%] [G loss: 4.953562]\n",
            "8604 [ D loss: 0.114626, acc.: 97%] [G loss: 4.747870]\n",
            "8605 [ D loss: 0.117235, acc.: 96%] [G loss: 4.905609]\n",
            "8606 [ D loss: 0.163994, acc.: 93%] [G loss: 7.890891]\n",
            "8607 [ D loss: 0.153638, acc.: 94%] [G loss: 6.372285]\n",
            "8608 [ D loss: 0.141201, acc.: 96%] [G loss: 5.831130]\n",
            "8609 [ D loss: 0.184757, acc.: 93%] [G loss: 5.599122]\n",
            "8610 [ D loss: 0.158987, acc.: 95%] [G loss: 6.207048]\n",
            "8611 [ D loss: 0.117522, acc.: 96%] [G loss: 4.671332]\n",
            "8612 [ D loss: 0.115666, acc.: 97%] [G loss: 4.627354]\n",
            "8613 [ D loss: 0.300227, acc.: 88%] [G loss: 6.130794]\n",
            "8614 [ D loss: 0.159611, acc.: 94%] [G loss: 5.408581]\n",
            "8615 [ D loss: 0.188344, acc.: 95%] [G loss: 4.886163]\n",
            "8616 [ D loss: 0.240702, acc.: 91%] [G loss: 6.139027]\n",
            "8617 [ D loss: 0.292143, acc.: 86%] [G loss: 4.101321]\n",
            "8618 [ D loss: 0.261750, acc.: 88%] [G loss: 6.548993]\n",
            "8619 [ D loss: 0.199383, acc.: 91%] [G loss: 4.342595]\n",
            "8620 [ D loss: 0.173301, acc.: 92%] [G loss: 11.042739]\n",
            "8621 [ D loss: 0.188974, acc.: 93%] [G loss: 9.054083]\n",
            "8622 [ D loss: 0.133136, acc.: 96%] [G loss: 6.254586]\n",
            "8623 [ D loss: 0.098901, acc.: 95%] [G loss: 5.536393]\n",
            "8624 [ D loss: 0.091896, acc.: 97%] [G loss: 8.254622]\n",
            "8625 [ D loss: 0.068916, acc.: 98%] [G loss: 5.972432]\n",
            "8626 [ D loss: 0.158069, acc.: 94%] [G loss: 6.945630]\n",
            "8627 [ D loss: 0.063282, acc.: 98%] [G loss: 8.948603]\n",
            "8628 [ D loss: 0.122784, acc.: 95%] [G loss: 5.315508]\n",
            "8629 [ D loss: 0.132086, acc.: 95%] [G loss: 4.921718]\n",
            "8630 [ D loss: 0.157508, acc.: 94%] [G loss: 4.885394]\n",
            "8631 [ D loss: 0.163961, acc.: 95%] [G loss: 5.256989]\n",
            "8632 [ D loss: 0.247125, acc.: 91%] [G loss: 5.526110]\n",
            "8633 [ D loss: 0.454609, acc.: 83%] [G loss: 3.676490]\n",
            "8634 [ D loss: 0.190365, acc.: 91%] [G loss: 5.873814]\n",
            "8635 [ D loss: 0.198360, acc.: 92%] [G loss: 4.936475]\n",
            "8636 [ D loss: 0.115415, acc.: 98%] [G loss: 4.254103]\n",
            "8637 [ D loss: 0.115547, acc.: 98%] [G loss: 6.392553]\n",
            "8638 [ D loss: 0.133421, acc.: 95%] [G loss: 5.436583]\n",
            "8639 [ D loss: 0.156874, acc.: 94%] [G loss: 6.515946]\n",
            "8640 [ D loss: 0.059856, acc.: 98%] [G loss: 4.795261]\n",
            "8641 [ D loss: 0.141883, acc.: 95%] [G loss: 10.726267]\n",
            "8642 [ D loss: 0.128687, acc.: 95%] [G loss: 6.569029]\n",
            "8643 [ D loss: 0.073074, acc.: 98%] [G loss: 7.012231]\n",
            "8644 [ D loss: 0.071756, acc.: 97%] [G loss: 11.994224]\n",
            "8645 [ D loss: 0.100233, acc.: 97%] [G loss: 8.079117]\n",
            "8646 [ D loss: 0.091293, acc.: 96%] [G loss: 7.155639]\n",
            "8647 [ D loss: 0.124471, acc.: 95%] [G loss: 7.533421]\n",
            "8648 [ D loss: 0.111197, acc.: 98%] [G loss: 6.382907]\n",
            "8649 [ D loss: 0.141335, acc.: 94%] [G loss: 6.305541]\n",
            "8650 [ D loss: 0.131616, acc.: 97%] [G loss: 6.740169]\n",
            "8651 [ D loss: 0.096881, acc.: 95%] [G loss: 9.951141]\n",
            "8652 [ D loss: 0.101605, acc.: 98%] [G loss: 7.093546]\n",
            "8653 [ D loss: 0.154473, acc.: 93%] [G loss: 8.430586]\n",
            "8654 [ D loss: 0.145589, acc.: 95%] [G loss: 6.214671]\n",
            "8655 [ D loss: 0.195778, acc.: 91%] [G loss: 4.582009]\n",
            "8656 [ D loss: 0.091939, acc.: 98%] [G loss: 4.877009]\n",
            "8657 [ D loss: 0.291984, acc.: 88%] [G loss: 5.305933]\n",
            "8658 [ D loss: 0.111835, acc.: 97%] [G loss: 4.671076]\n",
            "8659 [ D loss: 0.094631, acc.: 97%] [G loss: 4.280518]\n",
            "8660 [ D loss: 0.139299, acc.: 94%] [G loss: 3.300399]\n",
            "8661 [ D loss: 0.140852, acc.: 94%] [G loss: 4.585375]\n",
            "8662 [ D loss: 0.157483, acc.: 95%] [G loss: 4.119481]\n",
            "8663 [ D loss: 0.227772, acc.: 91%] [G loss: 3.859801]\n",
            "8664 [ D loss: 0.176186, acc.: 94%] [G loss: 6.879972]\n",
            "8665 [ D loss: 0.574616, acc.: 78%] [G loss: 4.326777]\n",
            "8666 [ D loss: 0.390389, acc.: 79%] [G loss: 5.652342]\n",
            "8667 [ D loss: 0.098866, acc.: 97%] [G loss: 6.353957]\n",
            "8668 [ D loss: 0.113771, acc.: 95%] [G loss: 7.921104]\n",
            "8669 [ D loss: 0.188315, acc.: 91%] [G loss: 4.982400]\n",
            "8670 [ D loss: 0.085664, acc.: 98%] [G loss: 8.491323]\n",
            "8671 [ D loss: 0.229432, acc.: 89%] [G loss: 5.472217]\n",
            "8672 [ D loss: 0.210276, acc.: 92%] [G loss: 7.449772]\n",
            "8673 [ D loss: 0.134999, acc.: 94%] [G loss: 8.744945]\n",
            "8674 [ D loss: 0.104705, acc.: 95%] [G loss: 7.255138]\n",
            "8675 [ D loss: 0.128581, acc.: 94%] [G loss: 8.501253]\n",
            "8676 [ D loss: 0.078666, acc.: 98%] [G loss: 4.456259]\n",
            "8677 [ D loss: 0.123673, acc.: 96%] [G loss: 8.632888]\n",
            "8678 [ D loss: 0.109150, acc.: 98%] [G loss: 5.019282]\n",
            "8679 [ D loss: 0.083043, acc.: 97%] [G loss: 5.769587]\n",
            "8680 [ D loss: 0.098878, acc.: 97%] [G loss: 4.650484]\n",
            "8681 [ D loss: 0.118214, acc.: 96%] [G loss: 4.924760]\n",
            "8682 [ D loss: 0.239424, acc.: 89%] [G loss: 4.585697]\n",
            "8683 [ D loss: 0.105148, acc.: 96%] [G loss: 5.148566]\n",
            "8684 [ D loss: 0.246925, acc.: 90%] [G loss: 5.225532]\n",
            "8685 [ D loss: 0.305822, acc.: 88%] [G loss: 4.448382]\n",
            "8686 [ D loss: 0.201294, acc.: 91%] [G loss: 4.977709]\n",
            "8687 [ D loss: 0.126152, acc.: 95%] [G loss: 5.840310]\n",
            "8688 [ D loss: 0.153699, acc.: 94%] [G loss: 5.198074]\n",
            "8689 [ D loss: 0.077404, acc.: 98%] [G loss: 6.071312]\n",
            "8690 [ D loss: 0.076574, acc.: 98%] [G loss: 6.173300]\n",
            "8691 [ D loss: 0.060642, acc.: 99%] [G loss: 8.954092]\n",
            "8692 [ D loss: 0.140384, acc.: 92%] [G loss: 5.337403]\n",
            "8693 [ D loss: 0.149602, acc.: 93%] [G loss: 6.429955]\n",
            "8694 [ D loss: 0.112448, acc.: 97%] [G loss: 6.218556]\n",
            "8695 [ D loss: 0.126284, acc.: 95%] [G loss: 6.798126]\n",
            "8696 [ D loss: 0.076790, acc.: 98%] [G loss: 3.679268]\n",
            "8697 [ D loss: 0.047525, acc.: 98%] [G loss: 5.817743]\n",
            "8698 [ D loss: 0.118641, acc.: 95%] [G loss: 9.776148]\n",
            "8699 [ D loss: 0.131352, acc.: 96%] [G loss: 7.429773]\n",
            "8700 [ D loss: 0.131726, acc.: 94%] [G loss: 8.809537]\n",
            "8701 [ D loss: 0.194248, acc.: 91%] [G loss: 10.502474]\n",
            "8702 [ D loss: 0.230810, acc.: 91%] [G loss: 7.201848]\n",
            "8703 [ D loss: 0.144092, acc.: 93%] [G loss: 5.470878]\n",
            "8704 [ D loss: 0.174713, acc.: 95%] [G loss: 5.421133]\n",
            "8705 [ D loss: 0.322751, acc.: 87%] [G loss: 6.264239]\n",
            "8706 [ D loss: 0.113405, acc.: 95%] [G loss: 4.969489]\n",
            "8707 [ D loss: 0.078178, acc.: 98%] [G loss: 6.106819]\n",
            "8708 [ D loss: 0.258042, acc.: 90%] [G loss: 7.151389]\n",
            "8709 [ D loss: 0.245681, acc.: 88%] [G loss: 4.177461]\n",
            "8710 [ D loss: 0.133993, acc.: 95%] [G loss: 7.089408]\n",
            "8711 [ D loss: 0.111591, acc.: 96%] [G loss: 6.806273]\n",
            "8712 [ D loss: 0.114686, acc.: 98%] [G loss: 6.069015]\n",
            "8713 [ D loss: 0.063291, acc.: 98%] [G loss: 6.737230]\n",
            "8714 [ D loss: 0.093730, acc.: 97%] [G loss: 8.732382]\n",
            "8715 [ D loss: 0.058023, acc.: 98%] [G loss: 9.075069]\n",
            "8716 [ D loss: 0.051038, acc.: 99%] [G loss: 6.200766]\n",
            "8717 [ D loss: 0.099630, acc.: 97%] [G loss: 4.430721]\n",
            "8718 [ D loss: 0.079524, acc.: 98%] [G loss: 5.013247]\n",
            "8719 [ D loss: 0.077419, acc.: 98%] [G loss: 5.931756]\n",
            "8720 [ D loss: 0.111780, acc.: 97%] [G loss: 3.791121]\n",
            "8721 [ D loss: 0.124461, acc.: 95%] [G loss: 5.657922]\n",
            "8722 [ D loss: 0.200046, acc.: 91%] [G loss: 4.923620]\n",
            "8723 [ D loss: 0.178242, acc.: 93%] [G loss: 4.689595]\n",
            "8724 [ D loss: 0.104686, acc.: 98%] [G loss: 3.286675]\n",
            "8725 [ D loss: 0.200103, acc.: 91%] [G loss: 4.167358]\n",
            "8726 [ D loss: 0.212413, acc.: 92%] [G loss: 4.670751]\n",
            "8727 [ D loss: 0.140422, acc.: 96%] [G loss: 6.996140]\n",
            "8728 [ D loss: 0.127704, acc.: 95%] [G loss: 8.957848]\n",
            "8729 [ D loss: 0.118327, acc.: 96%] [G loss: 10.148990]\n",
            "8730 [ D loss: 0.089534, acc.: 97%] [G loss: 7.155310]\n",
            "8731 [ D loss: 0.042963, acc.: 98%] [G loss: 5.860669]\n",
            "8732 [ D loss: 0.110251, acc.: 96%] [G loss: 13.782018]\n",
            "8733 [ D loss: 0.072103, acc.: 98%] [G loss: 9.968361]\n",
            "8734 [ D loss: 0.094981, acc.: 95%] [G loss: 9.807443]\n",
            "8735 [ D loss: 0.080144, acc.: 98%] [G loss: 7.560379]\n",
            "8736 [ D loss: 0.098017, acc.: 96%] [G loss: 8.454811]\n",
            "8737 [ D loss: 0.186766, acc.: 93%] [G loss: 5.687249]\n",
            "8738 [ D loss: 0.131094, acc.: 95%] [G loss: 6.297715]\n",
            "8739 [ D loss: 0.072792, acc.: 98%] [G loss: 7.683336]\n",
            "8740 [ D loss: 0.089593, acc.: 98%] [G loss: 7.195606]\n",
            "8741 [ D loss: 0.112732, acc.: 95%] [G loss: 7.821006]\n",
            "8742 [ D loss: 0.122085, acc.: 96%] [G loss: 6.834303]\n",
            "8743 [ D loss: 0.094791, acc.: 96%] [G loss: 9.717181]\n",
            "8744 [ D loss: 0.138321, acc.: 97%] [G loss: 5.412844]\n",
            "8745 [ D loss: 0.169261, acc.: 93%] [G loss: 6.837710]\n",
            "8746 [ D loss: 0.147662, acc.: 92%] [G loss: 7.927877]\n",
            "8747 [ D loss: 0.094084, acc.: 97%] [G loss: 4.742689]\n",
            "8748 [ D loss: 0.134238, acc.: 95%] [G loss: 4.655756]\n",
            "8749 [ D loss: 0.085402, acc.: 98%] [G loss: 10.162140]\n",
            "8750 [ D loss: 0.100592, acc.: 98%] [G loss: 10.303366]\n",
            "8751 [ D loss: 0.074422, acc.: 97%] [G loss: 7.580530]\n",
            "8752 [ D loss: 0.111616, acc.: 96%] [G loss: 5.453041]\n",
            "8753 [ D loss: 0.118493, acc.: 95%] [G loss: 12.849375]\n",
            "8754 [ D loss: 0.148380, acc.: 95%] [G loss: 9.934790]\n",
            "8755 [ D loss: 0.113842, acc.: 95%] [G loss: 6.420896]\n",
            "8756 [ D loss: 0.104542, acc.: 96%] [G loss: 6.416908]\n",
            "8757 [ D loss: 0.052557, acc.: 99%] [G loss: 10.024364]\n",
            "8758 [ D loss: 0.118360, acc.: 95%] [G loss: 6.034657]\n",
            "8759 [ D loss: 0.035113, acc.: 100%] [G loss: 7.061641]\n",
            "8760 [ D loss: 0.141474, acc.: 95%] [G loss: 9.638238]\n",
            "8761 [ D loss: 0.110428, acc.: 96%] [G loss: 6.042477]\n",
            "8762 [ D loss: 0.131312, acc.: 95%] [G loss: 7.705952]\n",
            "8763 [ D loss: 0.133617, acc.: 95%] [G loss: 7.505758]\n",
            "8764 [ D loss: 0.180372, acc.: 94%] [G loss: 6.468299]\n",
            "8765 [ D loss: 0.223528, acc.: 89%] [G loss: 7.268351]\n",
            "8766 [ D loss: 0.096598, acc.: 98%] [G loss: 8.453144]\n",
            "8767 [ D loss: 0.138749, acc.: 95%] [G loss: 7.646299]\n",
            "8768 [ D loss: 0.141369, acc.: 95%] [G loss: 7.380023]\n",
            "8769 [ D loss: 0.126010, acc.: 92%] [G loss: 7.917153]\n",
            "8770 [ D loss: 0.081534, acc.: 96%] [G loss: 9.729733]\n",
            "8771 [ D loss: 0.087368, acc.: 97%] [G loss: 4.014984]\n",
            "8772 [ D loss: 0.194322, acc.: 92%] [G loss: 7.279912]\n",
            "8773 [ D loss: 0.162748, acc.: 92%] [G loss: 2.939894]\n",
            "8774 [ D loss: 0.151197, acc.: 95%] [G loss: 5.870714]\n",
            "8775 [ D loss: 0.215621, acc.: 92%] [G loss: 7.176298]\n",
            "8776 [ D loss: 0.208854, acc.: 91%] [G loss: 3.864019]\n",
            "8777 [ D loss: 0.072636, acc.: 98%] [G loss: 8.035213]\n",
            "8778 [ D loss: 0.220675, acc.: 91%] [G loss: 7.637995]\n",
            "8779 [ D loss: 0.364552, acc.: 85%] [G loss: 6.376938]\n",
            "8780 [ D loss: 0.263021, acc.: 86%] [G loss: 7.426772]\n",
            "8781 [ D loss: 0.281728, acc.: 86%] [G loss: 6.089309]\n",
            "8782 [ D loss: 0.174069, acc.: 93%] [G loss: 8.163658]\n",
            "8783 [ D loss: 0.214938, acc.: 93%] [G loss: 8.043072]\n",
            "8784 [ D loss: 0.064125, acc.: 99%] [G loss: 9.775314]\n",
            "8785 [ D loss: 0.109842, acc.: 97%] [G loss: 6.766659]\n",
            "8786 [ D loss: 0.033195, acc.: 99%] [G loss: 8.137025]\n",
            "8787 [ D loss: 0.106186, acc.: 97%] [G loss: 6.161551]\n",
            "8788 [ D loss: 0.054892, acc.: 98%] [G loss: 6.437104]\n",
            "8789 [ D loss: 0.098027, acc.: 95%] [G loss: 6.376723]\n",
            "8790 [ D loss: 0.095730, acc.: 98%] [G loss: 6.464912]\n",
            "8791 [ D loss: 0.168380, acc.: 92%] [G loss: 6.773654]\n",
            "8792 [ D loss: 0.139338, acc.: 95%] [G loss: 9.001593]\n",
            "8793 [ D loss: 0.125862, acc.: 98%] [G loss: 4.289886]\n",
            "8794 [ D loss: 0.135989, acc.: 96%] [G loss: 5.027856]\n",
            "8795 [ D loss: 0.119840, acc.: 96%] [G loss: 5.376481]\n",
            "8796 [ D loss: 0.156875, acc.: 94%] [G loss: 5.483965]\n",
            "8797 [ D loss: 0.126006, acc.: 95%] [G loss: 5.015342]\n",
            "8798 [ D loss: 0.203491, acc.: 92%] [G loss: 5.225324]\n",
            "8799 [ D loss: 0.276685, acc.: 89%] [G loss: 3.878426]\n",
            "8800 [ D loss: 0.198787, acc.: 93%] [G loss: 5.255459]\n",
            "8801 [ D loss: 0.131439, acc.: 97%] [G loss: 5.463929]\n",
            "8802 [ D loss: 0.207794, acc.: 92%] [G loss: 5.560431]\n",
            "8803 [ D loss: 0.139971, acc.: 97%] [G loss: 6.158980]\n",
            "8804 [ D loss: 0.170257, acc.: 94%] [G loss: 4.590800]\n",
            "8805 [ D loss: 0.142626, acc.: 95%] [G loss: 6.126180]\n",
            "8806 [ D loss: 0.136591, acc.: 95%] [G loss: 4.590158]\n",
            "8807 [ D loss: 0.150536, acc.: 92%] [G loss: 4.180010]\n",
            "8808 [ D loss: 0.182699, acc.: 93%] [G loss: 6.927062]\n",
            "8809 [ D loss: 0.174415, acc.: 94%] [G loss: 5.931876]\n",
            "8810 [ D loss: 0.148660, acc.: 94%] [G loss: 5.713822]\n",
            "8811 [ D loss: 0.133871, acc.: 95%] [G loss: 5.135120]\n",
            "8812 [ D loss: 0.290095, acc.: 88%] [G loss: 5.062631]\n",
            "8813 [ D loss: 0.070166, acc.: 98%] [G loss: 7.369027]\n",
            "8814 [ D loss: 0.141995, acc.: 93%] [G loss: 6.038866]\n",
            "8815 [ D loss: 0.169001, acc.: 92%] [G loss: 5.989828]\n",
            "8816 [ D loss: 0.191496, acc.: 92%] [G loss: 5.898051]\n",
            "8817 [ D loss: 0.096563, acc.: 96%] [G loss: 5.884462]\n",
            "8818 [ D loss: 0.161124, acc.: 91%] [G loss: 9.049964]\n",
            "8819 [ D loss: 0.067278, acc.: 98%] [G loss: 9.365927]\n",
            "8820 [ D loss: 0.131584, acc.: 95%] [G loss: 6.908886]\n",
            "8821 [ D loss: 0.153809, acc.: 91%] [G loss: 10.266592]\n",
            "8822 [ D loss: 0.141577, acc.: 93%] [G loss: 9.018499]\n",
            "8823 [ D loss: 0.092096, acc.: 97%] [G loss: 5.394545]\n",
            "8824 [ D loss: 0.074512, acc.: 98%] [G loss: 6.171662]\n",
            "8825 [ D loss: 0.323386, acc.: 88%] [G loss: 7.720405]\n",
            "8826 [ D loss: 0.104590, acc.: 97%] [G loss: 4.346138]\n",
            "8827 [ D loss: 0.215351, acc.: 89%] [G loss: 3.720897]\n",
            "8828 [ D loss: 0.204862, acc.: 89%] [G loss: 5.064155]\n",
            "8829 [ D loss: 0.370894, acc.: 84%] [G loss: 4.998032]\n",
            "8830 [ D loss: 0.100083, acc.: 96%] [G loss: 14.071751]\n",
            "8831 [ D loss: 0.208568, acc.: 92%] [G loss: 5.632314]\n",
            "8832 [ D loss: 0.078028, acc.: 98%] [G loss: 4.663695]\n",
            "8833 [ D loss: 0.118849, acc.: 95%] [G loss: 4.665177]\n",
            "8834 [ D loss: 0.094712, acc.: 95%] [G loss: 3.698371]\n",
            "8835 [ D loss: 0.059641, acc.: 98%] [G loss: 5.687752]\n",
            "8836 [ D loss: 0.265505, acc.: 88%] [G loss: 8.284854]\n",
            "8837 [ D loss: 0.272364, acc.: 88%] [G loss: 11.113859]\n",
            "8838 [ D loss: 0.243143, acc.: 91%] [G loss: 9.362553]\n",
            "8839 [ D loss: 0.213085, acc.: 91%] [G loss: 5.670710]\n",
            "8840 [ D loss: 0.061314, acc.: 98%] [G loss: 6.566984]\n",
            "8841 [ D loss: 0.133502, acc.: 96%] [G loss: 4.390523]\n",
            "8842 [ D loss: 0.176042, acc.: 92%] [G loss: 5.601992]\n",
            "8843 [ D loss: 0.215081, acc.: 92%] [G loss: 4.226269]\n",
            "8844 [ D loss: 0.119149, acc.: 95%] [G loss: 4.625472]\n",
            "8845 [ D loss: 0.138957, acc.: 97%] [G loss: 4.554916]\n",
            "8846 [ D loss: 0.170807, acc.: 92%] [G loss: 5.540930]\n",
            "8847 [ D loss: 0.153860, acc.: 94%] [G loss: 5.209045]\n",
            "8848 [ D loss: 0.144901, acc.: 95%] [G loss: 5.520207]\n",
            "8849 [ D loss: 0.127619, acc.: 95%] [G loss: 5.973463]\n",
            "8850 [ D loss: 0.123774, acc.: 95%] [G loss: 6.112731]\n",
            "8851 [ D loss: 0.109023, acc.: 97%] [G loss: 8.364720]\n",
            "8852 [ D loss: 0.093701, acc.: 98%] [G loss: 6.859342]\n",
            "8853 [ D loss: 0.104538, acc.: 96%] [G loss: 6.537706]\n",
            "8854 [ D loss: 0.080202, acc.: 97%] [G loss: 4.048896]\n",
            "8855 [ D loss: 0.123577, acc.: 95%] [G loss: 5.235693]\n",
            "8856 [ D loss: 0.114787, acc.: 94%] [G loss: 8.342134]\n",
            "8857 [ D loss: 0.139757, acc.: 98%] [G loss: 7.791061]\n",
            "8858 [ D loss: 0.254409, acc.: 89%] [G loss: 4.658900]\n",
            "8859 [ D loss: 0.183418, acc.: 94%] [G loss: 5.563637]\n",
            "8860 [ D loss: 0.208628, acc.: 93%] [G loss: 3.713992]\n",
            "8861 [ D loss: 0.210318, acc.: 91%] [G loss: 7.046320]\n",
            "8862 [ D loss: 0.158419, acc.: 93%] [G loss: 8.350507]\n",
            "8863 [ D loss: 0.045260, acc.: 100%] [G loss: 9.876503]\n",
            "8864 [ D loss: 0.115507, acc.: 95%] [G loss: 6.793180]\n",
            "8865 [ D loss: 0.041464, acc.: 99%] [G loss: 9.625579]\n",
            "8866 [ D loss: 0.080356, acc.: 98%] [G loss: 14.064682]\n",
            "8867 [ D loss: 0.148135, acc.: 95%] [G loss: 7.984170]\n",
            "8868 [ D loss: 0.093158, acc.: 98%] [G loss: 10.601346]\n",
            "8869 [ D loss: 0.099736, acc.: 95%] [G loss: 10.082668]\n",
            "8870 [ D loss: 0.153953, acc.: 95%] [G loss: 8.126747]\n",
            "8871 [ D loss: 0.123262, acc.: 95%] [G loss: 6.627907]\n",
            "8872 [ D loss: 0.117191, acc.: 95%] [G loss: 6.170650]\n",
            "8873 [ D loss: 0.137296, acc.: 95%] [G loss: 11.135859]\n",
            "8874 [ D loss: 0.065499, acc.: 100%] [G loss: 8.242432]\n",
            "8875 [ D loss: 0.120831, acc.: 95%] [G loss: 6.027801]\n",
            "8876 [ D loss: 0.080955, acc.: 97%] [G loss: 5.615705]\n",
            "8877 [ D loss: 0.156177, acc.: 95%] [G loss: 5.107646]\n",
            "8878 [ D loss: 0.123824, acc.: 96%] [G loss: 5.524502]\n",
            "8879 [ D loss: 0.154269, acc.: 95%] [G loss: 4.548120]\n",
            "8880 [ D loss: 0.133046, acc.: 96%] [G loss: 4.789200]\n",
            "8881 [ D loss: 0.140785, acc.: 95%] [G loss: 5.143426]\n",
            "8882 [ D loss: 0.227716, acc.: 91%] [G loss: 4.918898]\n",
            "8883 [ D loss: 0.142057, acc.: 94%] [G loss: 5.449803]\n",
            "8884 [ D loss: 0.189353, acc.: 93%] [G loss: 5.935604]\n",
            "8885 [ D loss: 0.096314, acc.: 98%] [G loss: 5.499978]\n",
            "8886 [ D loss: 0.106393, acc.: 98%] [G loss: 4.104650]\n",
            "8887 [ D loss: 0.217175, acc.: 91%] [G loss: 5.732185]\n",
            "8888 [ D loss: 0.178425, acc.: 90%] [G loss: 6.122432]\n",
            "8889 [ D loss: 0.127921, acc.: 95%] [G loss: 5.390981]\n",
            "8890 [ D loss: 0.145027, acc.: 95%] [G loss: 4.627847]\n",
            "8891 [ D loss: 0.180273, acc.: 93%] [G loss: 5.760836]\n",
            "8892 [ D loss: 0.125280, acc.: 95%] [G loss: 5.776612]\n",
            "8893 [ D loss: 0.132183, acc.: 97%] [G loss: 5.475042]\n",
            "8894 [ D loss: 0.096506, acc.: 95%] [G loss: 4.903323]\n",
            "8895 [ D loss: 0.151095, acc.: 94%] [G loss: 8.572731]\n",
            "8896 [ D loss: 0.087659, acc.: 97%] [G loss: 5.698991]\n",
            "8897 [ D loss: 0.202481, acc.: 89%] [G loss: 6.725965]\n",
            "8898 [ D loss: 0.105743, acc.: 96%] [G loss: 5.855606]\n",
            "8899 [ D loss: 0.135394, acc.: 96%] [G loss: 6.473859]\n",
            "8900 [ D loss: 0.162033, acc.: 95%] [G loss: 4.660658]\n",
            "8901 [ D loss: 0.114407, acc.: 96%] [G loss: 7.077414]\n",
            "8902 [ D loss: 0.154943, acc.: 95%] [G loss: 11.499409]\n",
            "8903 [ D loss: 0.062884, acc.: 98%] [G loss: 5.606672]\n",
            "8904 [ D loss: 0.071794, acc.: 98%] [G loss: 5.556404]\n",
            "8905 [ D loss: 0.033465, acc.: 100%] [G loss: 7.277900]\n",
            "8906 [ D loss: 0.097556, acc.: 97%] [G loss: 11.535758]\n",
            "8907 [ D loss: 0.061126, acc.: 97%] [G loss: 8.892300]\n",
            "8908 [ D loss: 0.101292, acc.: 98%] [G loss: 9.459366]\n",
            "8909 [ D loss: 0.199778, acc.: 94%] [G loss: 11.476286]\n",
            "8910 [ D loss: 0.049383, acc.: 99%] [G loss: 6.919923]\n",
            "8911 [ D loss: 0.135268, acc.: 94%] [G loss: 7.036500]\n",
            "8912 [ D loss: 0.109453, acc.: 97%] [G loss: 13.854346]\n",
            "8913 [ D loss: 0.118867, acc.: 96%] [G loss: 6.191255]\n",
            "8914 [ D loss: 0.197779, acc.: 91%] [G loss: 6.962166]\n",
            "8915 [ D loss: 0.128196, acc.: 95%] [G loss: 5.525633]\n",
            "8916 [ D loss: 0.133641, acc.: 95%] [G loss: 5.006470]\n",
            "8917 [ D loss: 0.138774, acc.: 95%] [G loss: 4.265128]\n",
            "8918 [ D loss: 0.182460, acc.: 93%] [G loss: 11.894747]\n",
            "8919 [ D loss: 0.093481, acc.: 98%] [G loss: 5.908828]\n",
            "8920 [ D loss: 0.078822, acc.: 98%] [G loss: 7.354638]\n",
            "8921 [ D loss: 0.087275, acc.: 98%] [G loss: 7.643986]\n",
            "8922 [ D loss: 0.054618, acc.: 99%] [G loss: 5.895054]\n",
            "8923 [ D loss: 0.126679, acc.: 95%] [G loss: 9.472727]\n",
            "8924 [ D loss: 0.198168, acc.: 91%] [G loss: 6.349916]\n",
            "8925 [ D loss: 0.120824, acc.: 96%] [G loss: 4.847603]\n",
            "8926 [ D loss: 0.056604, acc.: 98%] [G loss: 6.506896]\n",
            "8927 [ D loss: 0.150047, acc.: 93%] [G loss: 4.784503]\n",
            "8928 [ D loss: 0.181848, acc.: 91%] [G loss: 9.730661]\n",
            "8929 [ D loss: 0.163558, acc.: 93%] [G loss: 10.381432]\n",
            "8930 [ D loss: 0.110080, acc.: 98%] [G loss: 5.698090]\n",
            "8931 [ D loss: 0.118027, acc.: 97%] [G loss: 5.166997]\n",
            "8932 [ D loss: 0.184831, acc.: 94%] [G loss: 5.356931]\n",
            "8933 [ D loss: 0.116720, acc.: 96%] [G loss: 5.670827]\n",
            "8934 [ D loss: 0.094798, acc.: 97%] [G loss: 3.800937]\n",
            "8935 [ D loss: 0.155491, acc.: 95%] [G loss: 6.481566]\n",
            "8936 [ D loss: 0.161012, acc.: 94%] [G loss: 6.414349]\n",
            "8937 [ D loss: 0.138466, acc.: 96%] [G loss: 4.050344]\n",
            "8938 [ D loss: 0.151968, acc.: 95%] [G loss: 5.223700]\n",
            "8939 [ D loss: 0.099720, acc.: 96%] [G loss: 5.262731]\n",
            "8940 [ D loss: 0.218840, acc.: 92%] [G loss: 5.002459]\n",
            "8941 [ D loss: 0.207434, acc.: 94%] [G loss: 5.288380]\n",
            "8942 [ D loss: 0.264557, acc.: 91%] [G loss: 5.904735]\n",
            "8943 [ D loss: 0.131633, acc.: 95%] [G loss: 5.829733]\n",
            "8944 [ D loss: 0.167553, acc.: 93%] [G loss: 4.741523]\n",
            "8945 [ D loss: 0.159029, acc.: 96%] [G loss: 5.245295]\n",
            "8946 [ D loss: 0.052788, acc.: 99%] [G loss: 7.347982]\n",
            "8947 [ D loss: 0.171451, acc.: 92%] [G loss: 7.448256]\n",
            "8948 [ D loss: 0.136028, acc.: 94%] [G loss: 7.926913]\n",
            "8949 [ D loss: 0.132396, acc.: 95%] [G loss: 9.661017]\n",
            "8950 [ D loss: 0.085268, acc.: 98%] [G loss: 10.058011]\n",
            "8951 [ D loss: 0.051362, acc.: 100%] [G loss: 7.329622]\n",
            "8952 [ D loss: 0.134409, acc.: 95%] [G loss: 8.435243]\n",
            "8953 [ D loss: 0.093527, acc.: 98%] [G loss: 8.796108]\n",
            "8954 [ D loss: 0.140389, acc.: 95%] [G loss: 8.650457]\n",
            "8955 [ D loss: 0.135400, acc.: 95%] [G loss: 9.556439]\n",
            "8956 [ D loss: 0.074673, acc.: 98%] [G loss: 15.577375]\n",
            "8957 [ D loss: 0.067801, acc.: 98%] [G loss: 4.928717]\n",
            "8958 [ D loss: 0.035689, acc.: 98%] [G loss: 6.914895]\n",
            "8959 [ D loss: 0.186816, acc.: 91%] [G loss: 6.847899]\n",
            "8960 [ D loss: 0.117554, acc.: 96%] [G loss: 9.213132]\n",
            "8961 [ D loss: 0.261073, acc.: 88%] [G loss: 7.374561]\n",
            "8962 [ D loss: 0.071541, acc.: 99%] [G loss: 6.995298]\n",
            "8963 [ D loss: 0.128849, acc.: 95%] [G loss: 6.203561]\n",
            "8964 [ D loss: 0.100891, acc.: 95%] [G loss: 6.663498]\n",
            "8965 [ D loss: 0.160837, acc.: 92%] [G loss: 5.179160]\n",
            "8966 [ D loss: 0.101879, acc.: 96%] [G loss: 11.346375]\n",
            "8967 [ D loss: 0.127439, acc.: 96%] [G loss: 5.588061]\n",
            "8968 [ D loss: 0.163205, acc.: 96%] [G loss: 6.065100]\n",
            "8969 [ D loss: 0.208297, acc.: 94%] [G loss: 6.527597]\n",
            "8970 [ D loss: 0.235031, acc.: 93%] [G loss: 6.327790]\n",
            "8971 [ D loss: 0.093591, acc.: 96%] [G loss: 5.761949]\n",
            "8972 [ D loss: 0.135982, acc.: 94%] [G loss: 4.767776]\n",
            "8973 [ D loss: 0.166063, acc.: 94%] [G loss: 3.389678]\n",
            "8974 [ D loss: 0.182440, acc.: 92%] [G loss: 6.152601]\n",
            "8975 [ D loss: 0.122340, acc.: 95%] [G loss: 5.198894]\n",
            "8976 [ D loss: 0.144114, acc.: 96%] [G loss: 4.022609]\n",
            "8977 [ D loss: 0.177467, acc.: 94%] [G loss: 5.353385]\n",
            "8978 [ D loss: 0.198743, acc.: 91%] [G loss: 7.836796]\n",
            "8979 [ D loss: 0.174382, acc.: 92%] [G loss: 6.461664]\n",
            "8980 [ D loss: 0.159334, acc.: 95%] [G loss: 7.395727]\n",
            "8981 [ D loss: 0.166807, acc.: 95%] [G loss: 10.728876]\n",
            "8982 [ D loss: 0.147098, acc.: 94%] [G loss: 8.107499]\n",
            "8983 [ D loss: 0.098833, acc.: 96%] [G loss: 6.215912]\n",
            "8984 [ D loss: 0.164233, acc.: 95%] [G loss: 10.876062]\n",
            "8985 [ D loss: 0.065997, acc.: 98%] [G loss: 6.275416]\n",
            "8986 [ D loss: 0.154577, acc.: 94%] [G loss: 10.603221]\n",
            "8987 [ D loss: 0.149666, acc.: 94%] [G loss: 5.910170]\n",
            "8988 [ D loss: 0.102998, acc.: 98%] [G loss: 4.646074]\n",
            "8989 [ D loss: 0.230657, acc.: 91%] [G loss: 5.830840]\n",
            "8990 [ D loss: 0.227404, acc.: 92%] [G loss: 5.202489]\n",
            "8991 [ D loss: 0.145114, acc.: 95%] [G loss: 5.574234]\n",
            "8992 [ D loss: 0.110308, acc.: 96%] [G loss: 5.007465]\n",
            "8993 [ D loss: 0.179507, acc.: 94%] [G loss: 5.375329]\n",
            "8994 [ D loss: 0.130442, acc.: 96%] [G loss: 4.060346]\n",
            "8995 [ D loss: 0.083151, acc.: 97%] [G loss: 5.680991]\n",
            "8996 [ D loss: 0.110433, acc.: 96%] [G loss: 6.794133]\n",
            "8997 [ D loss: 0.079410, acc.: 98%] [G loss: 7.977768]\n",
            "8998 [ D loss: 0.086953, acc.: 97%] [G loss: 10.071663]\n",
            "8999 [ D loss: 0.077349, acc.: 99%] [G loss: 8.101110]\n",
            "9000 [ D loss: 0.132062, acc.: 96%] [G loss: 7.160136]\n",
            "9001 [ D loss: 0.336659, acc.: 85%] [G loss: 9.532143]\n",
            "9002 [ D loss: 0.159777, acc.: 93%] [G loss: 7.294146]\n",
            "9003 [ D loss: 0.313096, acc.: 84%] [G loss: 6.809596]\n",
            "9004 [ D loss: 0.161164, acc.: 93%] [G loss: 6.257755]\n",
            "9005 [ D loss: 0.150267, acc.: 94%] [G loss: 5.077415]\n",
            "9006 [ D loss: 0.098895, acc.: 98%] [G loss: 4.835332]\n",
            "9007 [ D loss: 0.123203, acc.: 96%] [G loss: 5.457034]\n",
            "9008 [ D loss: 0.135213, acc.: 95%] [G loss: 5.366473]\n",
            "9009 [ D loss: 0.152421, acc.: 95%] [G loss: 5.253011]\n",
            "9010 [ D loss: 0.133871, acc.: 96%] [G loss: 6.433220]\n",
            "9011 [ D loss: 0.195653, acc.: 93%] [G loss: 6.326592]\n",
            "9012 [ D loss: 0.075386, acc.: 99%] [G loss: 4.679309]\n",
            "9013 [ D loss: 0.192018, acc.: 92%] [G loss: 4.451943]\n",
            "9014 [ D loss: 0.119850, acc.: 96%] [G loss: 6.499948]\n",
            "9015 [ D loss: 0.068036, acc.: 98%] [G loss: 10.043073]\n",
            "9016 [ D loss: 0.094830, acc.: 98%] [G loss: 6.520282]\n",
            "9017 [ D loss: 0.097645, acc.: 97%] [G loss: 9.554232]\n",
            "9018 [ D loss: 0.111304, acc.: 97%] [G loss: 10.604540]\n",
            "9019 [ D loss: 0.149129, acc.: 93%] [G loss: 5.852727]\n",
            "9020 [ D loss: 0.075181, acc.: 98%] [G loss: 4.829525]\n",
            "9021 [ D loss: 0.147480, acc.: 93%] [G loss: 11.514709]\n",
            "9022 [ D loss: 0.091358, acc.: 97%] [G loss: 6.266523]\n",
            "9023 [ D loss: 0.053476, acc.: 98%] [G loss: 6.887995]\n",
            "9024 [ D loss: 0.077983, acc.: 98%] [G loss: 6.816361]\n",
            "9025 [ D loss: 0.157064, acc.: 93%] [G loss: 11.160959]\n",
            "9026 [ D loss: 0.094402, acc.: 96%] [G loss: 10.519291]\n",
            "9027 [ D loss: 0.079967, acc.: 98%] [G loss: 6.992493]\n",
            "9028 [ D loss: 0.095422, acc.: 96%] [G loss: 7.723871]\n",
            "9029 [ D loss: 0.155192, acc.: 91%] [G loss: 6.436495]\n",
            "9030 [ D loss: 0.136051, acc.: 95%] [G loss: 6.795836]\n",
            "9031 [ D loss: 0.174987, acc.: 93%] [G loss: 4.315371]\n",
            "9032 [ D loss: 0.124031, acc.: 97%] [G loss: 4.755279]\n",
            "9033 [ D loss: 0.110822, acc.: 96%] [G loss: 7.512271]\n",
            "9034 [ D loss: 0.099939, acc.: 95%] [G loss: 6.513292]\n",
            "9035 [ D loss: 0.141980, acc.: 95%] [G loss: 8.521285]\n",
            "9036 [ D loss: 0.098944, acc.: 98%] [G loss: 7.345871]\n",
            "9037 [ D loss: 0.087507, acc.: 98%] [G loss: 5.916014]\n",
            "9038 [ D loss: 0.156759, acc.: 95%] [G loss: 6.235669]\n",
            "9039 [ D loss: 0.186579, acc.: 91%] [G loss: 7.838162]\n",
            "9040 [ D loss: 0.117371, acc.: 98%] [G loss: 6.369496]\n",
            "9041 [ D loss: 0.113152, acc.: 98%] [G loss: 11.192976]\n",
            "9042 [ D loss: 0.234034, acc.: 92%] [G loss: 5.398652]\n",
            "9043 [ D loss: 0.090951, acc.: 97%] [G loss: 4.920536]\n",
            "9044 [ D loss: 0.103225, acc.: 96%] [G loss: 7.878276]\n",
            "9045 [ D loss: 0.196423, acc.: 93%] [G loss: 12.254541]\n",
            "9046 [ D loss: 0.076248, acc.: 98%] [G loss: 8.328962]\n",
            "9047 [ D loss: 0.185185, acc.: 91%] [G loss: 7.859741]\n",
            "9048 [ D loss: 0.165182, acc.: 95%] [G loss: 8.562101]\n",
            "9049 [ D loss: 0.193309, acc.: 91%] [G loss: 7.751705]\n",
            "9050 [ D loss: 0.171784, acc.: 92%] [G loss: 5.090955]\n",
            "9051 [ D loss: 0.154380, acc.: 93%] [G loss: 6.579256]\n",
            "9052 [ D loss: 0.199248, acc.: 93%] [G loss: 5.851986]\n",
            "9053 [ D loss: 0.195506, acc.: 93%] [G loss: 7.916751]\n",
            "9054 [ D loss: 0.106593, acc.: 95%] [G loss: 6.363567]\n",
            "9055 [ D loss: 0.189426, acc.: 93%] [G loss: 5.035982]\n",
            "9056 [ D loss: 0.188688, acc.: 92%] [G loss: 4.610089]\n",
            "9057 [ D loss: 0.103177, acc.: 96%] [G loss: 10.032640]\n",
            "9058 [ D loss: 0.220018, acc.: 88%] [G loss: 7.210670]\n",
            "9059 [ D loss: 0.220128, acc.: 93%] [G loss: 5.765620]\n",
            "9060 [ D loss: 0.316014, acc.: 85%] [G loss: 6.090230]\n",
            "9061 [ D loss: 0.096833, acc.: 96%] [G loss: 7.567328]\n",
            "9062 [ D loss: 0.331522, acc.: 85%] [G loss: 6.979277]\n",
            "9063 [ D loss: 0.222480, acc.: 89%] [G loss: 7.596826]\n",
            "9064 [ D loss: 0.099332, acc.: 97%] [G loss: 15.392647]\n",
            "9065 [ D loss: 0.097204, acc.: 97%] [G loss: 11.304914]\n",
            "9066 [ D loss: 0.086402, acc.: 98%] [G loss: 9.022419]\n",
            "9067 [ D loss: 0.083502, acc.: 97%] [G loss: 6.606498]\n",
            "9068 [ D loss: 0.136416, acc.: 95%] [G loss: 5.305680]\n",
            "9069 [ D loss: 0.096384, acc.: 97%] [G loss: 5.389878]\n",
            "9070 [ D loss: 0.108831, acc.: 95%] [G loss: 4.769530]\n",
            "9071 [ D loss: 0.144592, acc.: 94%] [G loss: 5.443260]\n",
            "9072 [ D loss: 0.081084, acc.: 98%] [G loss: 6.230389]\n",
            "9073 [ D loss: 0.195791, acc.: 90%] [G loss: 4.356472]\n",
            "9074 [ D loss: 0.085384, acc.: 98%] [G loss: 6.351954]\n",
            "9075 [ D loss: 0.147884, acc.: 94%] [G loss: 6.982377]\n",
            "9076 [ D loss: 0.154685, acc.: 96%] [G loss: 5.986237]\n",
            "9077 [ D loss: 0.162292, acc.: 96%] [G loss: 4.810705]\n",
            "9078 [ D loss: 0.135560, acc.: 94%] [G loss: 5.449353]\n",
            "9079 [ D loss: 0.107978, acc.: 97%] [G loss: 6.293776]\n",
            "9080 [ D loss: 0.107154, acc.: 98%] [G loss: 6.686446]\n",
            "9081 [ D loss: 0.180154, acc.: 94%] [G loss: 6.365337]\n",
            "9082 [ D loss: 0.128762, acc.: 94%] [G loss: 5.257537]\n",
            "9083 [ D loss: 0.093373, acc.: 98%] [G loss: 7.541372]\n",
            "9084 [ D loss: 0.062752, acc.: 99%] [G loss: 5.857748]\n",
            "9085 [ D loss: 0.069235, acc.: 97%] [G loss: 9.771040]\n",
            "9086 [ D loss: 0.119961, acc.: 98%] [G loss: 8.779728]\n",
            "9087 [ D loss: 0.105217, acc.: 96%] [G loss: 7.439985]\n",
            "9088 [ D loss: 0.094152, acc.: 98%] [G loss: 5.401088]\n",
            "9089 [ D loss: 0.076121, acc.: 97%] [G loss: 6.440570]\n",
            "9090 [ D loss: 0.069550, acc.: 98%] [G loss: 13.171906]\n",
            "9091 [ D loss: 0.048090, acc.: 99%] [G loss: 7.532568]\n",
            "9092 [ D loss: 0.156753, acc.: 94%] [G loss: 6.857957]\n",
            "9093 [ D loss: 0.183931, acc.: 93%] [G loss: 9.715469]\n",
            "9094 [ D loss: 0.094527, acc.: 99%] [G loss: 6.954752]\n",
            "9095 [ D loss: 0.066680, acc.: 98%] [G loss: 5.791612]\n",
            "9096 [ D loss: 0.105927, acc.: 97%] [G loss: 3.475982]\n",
            "9097 [ D loss: 0.155038, acc.: 96%] [G loss: 8.723331]\n",
            "9098 [ D loss: 0.192847, acc.: 93%] [G loss: 9.937840]\n",
            "9099 [ D loss: 0.125371, acc.: 95%] [G loss: 11.586393]\n",
            "9100 [ D loss: 0.052308, acc.: 99%] [G loss: 9.789448]\n",
            "9101 [ D loss: 0.092944, acc.: 98%] [G loss: 14.343338]\n",
            "9102 [ D loss: 0.193805, acc.: 95%] [G loss: 8.827611]\n",
            "9103 [ D loss: 0.089315, acc.: 98%] [G loss: 8.163290]\n",
            "9104 [ D loss: 0.124343, acc.: 96%] [G loss: 4.811290]\n",
            "9105 [ D loss: 0.133599, acc.: 94%] [G loss: 5.880883]\n",
            "9106 [ D loss: 0.080872, acc.: 98%] [G loss: 6.621153]\n",
            "9107 [ D loss: 0.107291, acc.: 96%] [G loss: 5.830322]\n",
            "9108 [ D loss: 0.162866, acc.: 95%] [G loss: 4.426122]\n",
            "9109 [ D loss: 0.163229, acc.: 94%] [G loss: 6.828903]\n",
            "9110 [ D loss: 0.173801, acc.: 95%] [G loss: 5.150339]\n",
            "9111 [ D loss: 0.189437, acc.: 95%] [G loss: 7.380206]\n",
            "9112 [ D loss: 0.143487, acc.: 95%] [G loss: 7.864273]\n",
            "9113 [ D loss: 0.064204, acc.: 97%] [G loss: 6.806628]\n",
            "9114 [ D loss: 0.049823, acc.: 98%] [G loss: 6.734700]\n",
            "9115 [ D loss: 0.107516, acc.: 97%] [G loss: 8.900356]\n",
            "9116 [ D loss: 0.106050, acc.: 96%] [G loss: 13.339809]\n",
            "9117 [ D loss: 0.053564, acc.: 99%] [G loss: 10.665007]\n",
            "9118 [ D loss: 0.080452, acc.: 97%] [G loss: 9.411727]\n",
            "9119 [ D loss: 0.070880, acc.: 98%] [G loss: 12.584499]\n",
            "9120 [ D loss: 0.102641, acc.: 96%] [G loss: 6.792020]\n",
            "9121 [ D loss: 0.148931, acc.: 94%] [G loss: 10.523888]\n",
            "9122 [ D loss: 0.090225, acc.: 95%] [G loss: 13.528016]\n",
            "9123 [ D loss: 0.085189, acc.: 98%] [G loss: 9.929882]\n",
            "9124 [ D loss: 0.066733, acc.: 99%] [G loss: 12.116504]\n",
            "9125 [ D loss: 0.073225, acc.: 98%] [G loss: 13.095813]\n",
            "9126 [ D loss: 0.079351, acc.: 96%] [G loss: 14.400383]\n",
            "9127 [ D loss: 0.045521, acc.: 99%] [G loss: 13.758301]\n",
            "9128 [ D loss: 0.036281, acc.: 99%] [G loss: 11.530611]\n",
            "9129 [ D loss: 0.051922, acc.: 97%] [G loss: 8.853820]\n",
            "9130 [ D loss: 0.057813, acc.: 99%] [G loss: 10.854154]\n",
            "9131 [ D loss: 0.044625, acc.: 98%] [G loss: 11.117469]\n",
            "9132 [ D loss: 0.063569, acc.: 97%] [G loss: 8.990980]\n",
            "9133 [ D loss: 0.119991, acc.: 96%] [G loss: 5.313289]\n",
            "9134 [ D loss: 0.077823, acc.: 98%] [G loss: 9.050713]\n",
            "9135 [ D loss: 0.100892, acc.: 95%] [G loss: 4.126943]\n",
            "9136 [ D loss: 0.080418, acc.: 97%] [G loss: 6.262344]\n",
            "9137 [ D loss: 0.167824, acc.: 95%] [G loss: 5.328122]\n",
            "9138 [ D loss: 0.131788, acc.: 96%] [G loss: 4.122158]\n",
            "9139 [ D loss: 0.263077, acc.: 91%] [G loss: 3.934036]\n",
            "9140 [ D loss: 0.200116, acc.: 91%] [G loss: 7.256690]\n",
            "9141 [ D loss: 0.118757, acc.: 95%] [G loss: 9.437635]\n",
            "9142 [ D loss: 0.234892, acc.: 90%] [G loss: 7.072766]\n",
            "9143 [ D loss: 0.129274, acc.: 95%] [G loss: 5.293223]\n",
            "9144 [ D loss: 0.088849, acc.: 97%] [G loss: 5.444430]\n",
            "9145 [ D loss: 0.102960, acc.: 95%] [G loss: 4.106529]\n",
            "9146 [ D loss: 0.090565, acc.: 98%] [G loss: 6.908994]\n",
            "9147 [ D loss: 0.179143, acc.: 91%] [G loss: 6.798860]\n",
            "9148 [ D loss: 0.149328, acc.: 95%] [G loss: 8.111469]\n",
            "9149 [ D loss: 0.120537, acc.: 95%] [G loss: 7.515213]\n",
            "9150 [ D loss: 0.143188, acc.: 96%] [G loss: 5.988795]\n",
            "9151 [ D loss: 0.159651, acc.: 95%] [G loss: 5.295366]\n",
            "9152 [ D loss: 0.123145, acc.: 96%] [G loss: 5.627780]\n",
            "9153 [ D loss: 0.127495, acc.: 95%] [G loss: 6.444725]\n",
            "9154 [ D loss: 0.159817, acc.: 91%] [G loss: 6.710064]\n",
            "9155 [ D loss: 0.130483, acc.: 95%] [G loss: 4.687031]\n",
            "9156 [ D loss: 0.176804, acc.: 94%] [G loss: 3.752576]\n",
            "9157 [ D loss: 0.212950, acc.: 91%] [G loss: 5.540216]\n",
            "9158 [ D loss: 0.086863, acc.: 96%] [G loss: 5.617028]\n",
            "9159 [ D loss: 0.229539, acc.: 91%] [G loss: 5.640438]\n",
            "9160 [ D loss: 0.123066, acc.: 97%] [G loss: 5.012161]\n",
            "9161 [ D loss: 0.116942, acc.: 95%] [G loss: 10.173254]\n",
            "9162 [ D loss: 0.134502, acc.: 95%] [G loss: 6.683329]\n",
            "9163 [ D loss: 0.148520, acc.: 92%] [G loss: 4.277199]\n",
            "9164 [ D loss: 0.086385, acc.: 96%] [G loss: 13.410883]\n",
            "9165 [ D loss: 0.088801, acc.: 97%] [G loss: 11.028319]\n",
            "9166 [ D loss: 0.050639, acc.: 98%] [G loss: 9.125112]\n",
            "9167 [ D loss: 0.085077, acc.: 96%] [G loss: 8.236352]\n",
            "9168 [ D loss: 0.116765, acc.: 94%] [G loss: 8.722095]\n",
            "9169 [ D loss: 0.172971, acc.: 91%] [G loss: 6.370878]\n",
            "9170 [ D loss: 0.134795, acc.: 95%] [G loss: 6.687939]\n",
            "9171 [ D loss: 0.114714, acc.: 96%] [G loss: 5.414548]\n",
            "9172 [ D loss: 0.129571, acc.: 95%] [G loss: 6.037921]\n",
            "9173 [ D loss: 0.168742, acc.: 93%] [G loss: 6.477125]\n",
            "9174 [ D loss: 0.106264, acc.: 97%] [G loss: 6.068903]\n",
            "9175 [ D loss: 0.109930, acc.: 97%] [G loss: 9.694729]\n",
            "9176 [ D loss: 0.076067, acc.: 98%] [G loss: 6.945055]\n",
            "9177 [ D loss: 0.063654, acc.: 98%] [G loss: 5.889612]\n",
            "9178 [ D loss: 0.059950, acc.: 97%] [G loss: 13.465824]\n",
            "9179 [ D loss: 0.087259, acc.: 98%] [G loss: 5.025668]\n",
            "9180 [ D loss: 0.075477, acc.: 98%] [G loss: 6.341626]\n",
            "9181 [ D loss: 0.070657, acc.: 98%] [G loss: 5.768767]\n",
            "9182 [ D loss: 0.164927, acc.: 92%] [G loss: 5.582980]\n",
            "9183 [ D loss: 0.109022, acc.: 95%] [G loss: 8.176029]\n",
            "9184 [ D loss: 0.131221, acc.: 96%] [G loss: 6.449362]\n",
            "9185 [ D loss: 0.125998, acc.: 94%] [G loss: 6.021693]\n",
            "9186 [ D loss: 0.100623, acc.: 98%] [G loss: 6.151317]\n",
            "9187 [ D loss: 0.156335, acc.: 95%] [G loss: 6.235855]\n",
            "9188 [ D loss: 0.051117, acc.: 98%] [G loss: 7.796789]\n",
            "9189 [ D loss: 0.166679, acc.: 94%] [G loss: 4.766522]\n",
            "9190 [ D loss: 0.149133, acc.: 94%] [G loss: 6.460377]\n",
            "9191 [ D loss: 0.263582, acc.: 91%] [G loss: 7.275311]\n",
            "9192 [ D loss: 0.087700, acc.: 98%] [G loss: 7.254292]\n",
            "9193 [ D loss: 0.091746, acc.: 98%] [G loss: 6.274646]\n",
            "9194 [ D loss: 0.088727, acc.: 97%] [G loss: 7.104647]\n",
            "9195 [ D loss: 0.096858, acc.: 98%] [G loss: 10.451923]\n",
            "9196 [ D loss: 0.079206, acc.: 98%] [G loss: 6.964853]\n",
            "9197 [ D loss: 0.041897, acc.: 98%] [G loss: 4.390413]\n",
            "9198 [ D loss: 0.116666, acc.: 95%] [G loss: 6.546106]\n",
            "9199 [ D loss: 0.179677, acc.: 95%] [G loss: 7.538640]\n",
            "9200 [ D loss: 0.105781, acc.: 95%] [G loss: 7.990401]\n",
            "9201 [ D loss: 0.127911, acc.: 95%] [G loss: 5.823615]\n",
            "9202 [ D loss: 0.082005, acc.: 99%] [G loss: 6.082327]\n",
            "9203 [ D loss: 0.034470, acc.: 100%] [G loss: 8.580854]\n",
            "9204 [ D loss: 0.060054, acc.: 98%] [G loss: 9.847687]\n",
            "9205 [ D loss: 0.079148, acc.: 96%] [G loss: 6.395227]\n",
            "9206 [ D loss: 0.075191, acc.: 97%] [G loss: 6.839388]\n",
            "9207 [ D loss: 0.089676, acc.: 98%] [G loss: 14.311371]\n",
            "9208 [ D loss: 0.133083, acc.: 95%] [G loss: 10.553507]\n",
            "9209 [ D loss: 0.117401, acc.: 95%] [G loss: 8.803040]\n",
            "9210 [ D loss: 0.126354, acc.: 94%] [G loss: 6.126297]\n",
            "9211 [ D loss: 0.172306, acc.: 93%] [G loss: 6.305406]\n",
            "9212 [ D loss: 0.084378, acc.: 96%] [G loss: 6.957924]\n",
            "9213 [ D loss: 0.228243, acc.: 92%] [G loss: 5.737467]\n",
            "9214 [ D loss: 0.207486, acc.: 91%] [G loss: 5.475674]\n",
            "9215 [ D loss: 0.087042, acc.: 98%] [G loss: 7.768732]\n",
            "9216 [ D loss: 0.144972, acc.: 95%] [G loss: 8.196376]\n",
            "9217 [ D loss: 0.162402, acc.: 91%] [G loss: 5.086907]\n",
            "9218 [ D loss: 0.102279, acc.: 98%] [G loss: 6.535354]\n",
            "9219 [ D loss: 0.256107, acc.: 88%] [G loss: 3.387619]\n",
            "9220 [ D loss: 0.197007, acc.: 93%] [G loss: 6.476698]\n",
            "9221 [ D loss: 0.323537, acc.: 87%] [G loss: 6.044008]\n",
            "9222 [ D loss: 0.107181, acc.: 98%] [G loss: 4.864127]\n",
            "9223 [ D loss: 0.176971, acc.: 94%] [G loss: 5.654861]\n",
            "9224 [ D loss: 0.078830, acc.: 96%] [G loss: 6.667420]\n",
            "9225 [ D loss: 0.090598, acc.: 96%] [G loss: 4.595928]\n",
            "9226 [ D loss: 0.111238, acc.: 95%] [G loss: 5.166575]\n",
            "9227 [ D loss: 0.053593, acc.: 98%] [G loss: 4.640987]\n",
            "9228 [ D loss: 0.131555, acc.: 95%] [G loss: 3.969572]\n",
            "9229 [ D loss: 0.123879, acc.: 97%] [G loss: 12.043083]\n",
            "9230 [ D loss: 0.072833, acc.: 98%] [G loss: 7.942964]\n",
            "9231 [ D loss: 0.049454, acc.: 98%] [G loss: 10.803701]\n",
            "9232 [ D loss: 0.056656, acc.: 98%] [G loss: 7.942252]\n",
            "9233 [ D loss: 0.041358, acc.: 100%] [G loss: 8.447464]\n",
            "9234 [ D loss: 0.087951, acc.: 96%] [G loss: 11.516353]\n",
            "9235 [ D loss: 0.056123, acc.: 98%] [G loss: 13.997524]\n",
            "9236 [ D loss: 0.106977, acc.: 97%] [G loss: 10.381604]\n",
            "9237 [ D loss: 0.169650, acc.: 91%] [G loss: 6.238411]\n",
            "9238 [ D loss: 0.061833, acc.: 98%] [G loss: 9.300652]\n",
            "9239 [ D loss: 0.122806, acc.: 98%] [G loss: 7.885843]\n",
            "9240 [ D loss: 0.118403, acc.: 97%] [G loss: 7.167619]\n",
            "9241 [ D loss: 0.116777, acc.: 95%] [G loss: 5.588239]\n",
            "9242 [ D loss: 0.124930, acc.: 97%] [G loss: 7.235063]\n",
            "9243 [ D loss: 0.158069, acc.: 94%] [G loss: 5.103671]\n",
            "9244 [ D loss: 0.076874, acc.: 98%] [G loss: 4.994786]\n",
            "9245 [ D loss: 0.089175, acc.: 98%] [G loss: 5.908222]\n",
            "9246 [ D loss: 0.210444, acc.: 91%] [G loss: 10.788198]\n",
            "9247 [ D loss: 0.109560, acc.: 95%] [G loss: 11.895932]\n",
            "9248 [ D loss: 0.113558, acc.: 96%] [G loss: 7.171700]\n",
            "9249 [ D loss: 0.069072, acc.: 98%] [G loss: 7.370940]\n",
            "9250 [ D loss: 0.161396, acc.: 95%] [G loss: 9.315863]\n",
            "9251 [ D loss: 0.130234, acc.: 94%] [G loss: 6.838134]\n",
            "9252 [ D loss: 0.096020, acc.: 96%] [G loss: 6.497855]\n",
            "9253 [ D loss: 0.074431, acc.: 97%] [G loss: 9.322151]\n",
            "9254 [ D loss: 0.098959, acc.: 96%] [G loss: 7.163841]\n",
            "9255 [ D loss: 0.087017, acc.: 96%] [G loss: 11.697032]\n",
            "9256 [ D loss: 0.091501, acc.: 96%] [G loss: 6.559445]\n",
            "9257 [ D loss: 0.134462, acc.: 96%] [G loss: 6.815471]\n",
            "9258 [ D loss: 0.116861, acc.: 95%] [G loss: 12.811808]\n",
            "9259 [ D loss: 0.120282, acc.: 95%] [G loss: 13.318352]\n",
            "9260 [ D loss: 0.186534, acc.: 93%] [G loss: 8.677340]\n",
            "9261 [ D loss: 0.072317, acc.: 97%] [G loss: 5.810225]\n",
            "9262 [ D loss: 0.074677, acc.: 99%] [G loss: 11.635921]\n",
            "9263 [ D loss: 0.048233, acc.: 99%] [G loss: 7.945523]\n",
            "9264 [ D loss: 0.161084, acc.: 96%] [G loss: 6.545187]\n",
            "9265 [ D loss: 0.094764, acc.: 97%] [G loss: 6.530655]\n",
            "9266 [ D loss: 0.054700, acc.: 98%] [G loss: 10.497890]\n",
            "9267 [ D loss: 0.153397, acc.: 94%] [G loss: 3.777237]\n",
            "9268 [ D loss: 0.092716, acc.: 98%] [G loss: 8.019922]\n",
            "9269 [ D loss: 0.253833, acc.: 88%] [G loss: 5.846222]\n",
            "9270 [ D loss: 0.176366, acc.: 92%] [G loss: 5.790616]\n",
            "9271 [ D loss: 0.133498, acc.: 96%] [G loss: 5.946726]\n",
            "9272 [ D loss: 0.121528, acc.: 98%] [G loss: 5.579461]\n",
            "9273 [ D loss: 0.085588, acc.: 98%] [G loss: 5.674051]\n",
            "9274 [ D loss: 0.104382, acc.: 97%] [G loss: 5.654450]\n",
            "9275 [ D loss: 0.198279, acc.: 91%] [G loss: 4.909218]\n",
            "9276 [ D loss: 0.075804, acc.: 96%] [G loss: 6.770628]\n",
            "9277 [ D loss: 0.230537, acc.: 90%] [G loss: 5.184242]\n",
            "9278 [ D loss: 0.077963, acc.: 98%] [G loss: 8.882926]\n",
            "9279 [ D loss: 0.345144, acc.: 83%] [G loss: 5.930071]\n",
            "9280 [ D loss: 0.104488, acc.: 97%] [G loss: 5.273086]\n",
            "9281 [ D loss: 0.170015, acc.: 95%] [G loss: 4.418583]\n",
            "9282 [ D loss: 0.152501, acc.: 95%] [G loss: 5.259312]\n",
            "9283 [ D loss: 0.177713, acc.: 95%] [G loss: 5.087430]\n",
            "9284 [ D loss: 0.228128, acc.: 92%] [G loss: 5.464783]\n",
            "9285 [ D loss: 0.083859, acc.: 98%] [G loss: 5.641892]\n",
            "9286 [ D loss: 0.197745, acc.: 95%] [G loss: 5.564530]\n",
            "9287 [ D loss: 0.168104, acc.: 93%] [G loss: 5.810295]\n",
            "9288 [ D loss: 0.134261, acc.: 96%] [G loss: 6.464509]\n",
            "9289 [ D loss: 0.150926, acc.: 95%] [G loss: 5.112620]\n",
            "9290 [ D loss: 0.096292, acc.: 98%] [G loss: 5.063842]\n",
            "9291 [ D loss: 0.227718, acc.: 91%] [G loss: 5.357020]\n",
            "9292 [ D loss: 0.070081, acc.: 100%] [G loss: 8.765941]\n",
            "9293 [ D loss: 0.165085, acc.: 91%] [G loss: 7.445876]\n",
            "9294 [ D loss: 0.137941, acc.: 93%] [G loss: 11.264080]\n",
            "9295 [ D loss: 0.087337, acc.: 98%] [G loss: 10.540802]\n",
            "9296 [ D loss: 0.061609, acc.: 98%] [G loss: 11.745213]\n",
            "9297 [ D loss: 0.161745, acc.: 95%] [G loss: 7.855891]\n",
            "9298 [ D loss: 0.126095, acc.: 95%] [G loss: 5.657288]\n",
            "9299 [ D loss: 0.126965, acc.: 95%] [G loss: 8.996392]\n",
            "9300 [ D loss: 0.057353, acc.: 98%] [G loss: 7.121835]\n",
            "9301 [ D loss: 0.060145, acc.: 98%] [G loss: 15.486360]\n",
            "9302 [ D loss: 0.040154, acc.: 98%] [G loss: 9.257032]\n",
            "9303 [ D loss: 0.101903, acc.: 97%] [G loss: 5.874834]\n",
            "9304 [ D loss: 0.117439, acc.: 95%] [G loss: 7.362539]\n",
            "9305 [ D loss: 0.071712, acc.: 99%] [G loss: 8.206979]\n",
            "9306 [ D loss: 0.107504, acc.: 96%] [G loss: 12.803810]\n",
            "9307 [ D loss: 0.128063, acc.: 95%] [G loss: 7.064141]\n",
            "9308 [ D loss: 0.060251, acc.: 97%] [G loss: 6.315849]\n",
            "9309 [ D loss: 0.075011, acc.: 98%] [G loss: 5.499846]\n",
            "9310 [ D loss: 0.142202, acc.: 93%] [G loss: 8.163563]\n",
            "9311 [ D loss: 0.097900, acc.: 98%] [G loss: 5.851348]\n",
            "9312 [ D loss: 0.128900, acc.: 97%] [G loss: 6.711048]\n",
            "9313 [ D loss: 0.188577, acc.: 94%] [G loss: 5.434093]\n",
            "9314 [ D loss: 0.158006, acc.: 92%] [G loss: 5.920718]\n",
            "9315 [ D loss: 0.144194, acc.: 96%] [G loss: 4.607894]\n",
            "9316 [ D loss: 0.295996, acc.: 88%] [G loss: 6.941095]\n",
            "9317 [ D loss: 0.197395, acc.: 93%] [G loss: 3.955875]\n",
            "9318 [ D loss: 0.133233, acc.: 97%] [G loss: 7.739566]\n",
            "9319 [ D loss: 0.114577, acc.: 97%] [G loss: 7.119074]\n",
            "9320 [ D loss: 0.203957, acc.: 91%] [G loss: 7.620134]\n",
            "9321 [ D loss: 0.043138, acc.: 99%] [G loss: 6.282721]\n",
            "9322 [ D loss: 0.100522, acc.: 96%] [G loss: 9.534388]\n",
            "9323 [ D loss: 0.169105, acc.: 91%] [G loss: 10.493711]\n",
            "9324 [ D loss: 0.078042, acc.: 98%] [G loss: 8.596841]\n",
            "9325 [ D loss: 0.063203, acc.: 99%] [G loss: 9.415471]\n",
            "9326 [ D loss: 0.072989, acc.: 96%] [G loss: 8.508649]\n",
            "9327 [ D loss: 0.087069, acc.: 96%] [G loss: 8.454925]\n",
            "9328 [ D loss: 0.139421, acc.: 95%] [G loss: 13.259134]\n",
            "9329 [ D loss: 0.053711, acc.: 99%] [G loss: 5.900654]\n",
            "9330 [ D loss: 0.109510, acc.: 96%] [G loss: 6.692553]\n",
            "9331 [ D loss: 0.085843, acc.: 98%] [G loss: 5.798137]\n",
            "9332 [ D loss: 0.094742, acc.: 98%] [G loss: 5.572880]\n",
            "9333 [ D loss: 0.136457, acc.: 97%] [G loss: 4.545535]\n",
            "9334 [ D loss: 0.185586, acc.: 93%] [G loss: 7.635992]\n",
            "9335 [ D loss: 0.104164, acc.: 97%] [G loss: 8.745533]\n",
            "9336 [ D loss: 0.058831, acc.: 99%] [G loss: 6.447202]\n",
            "9337 [ D loss: 0.088560, acc.: 97%] [G loss: 9.420379]\n",
            "9338 [ D loss: 0.064806, acc.: 97%] [G loss: 7.936203]\n",
            "9339 [ D loss: 0.113084, acc.: 94%] [G loss: 7.938065]\n",
            "9340 [ D loss: 0.180440, acc.: 94%] [G loss: 6.298655]\n",
            "9341 [ D loss: 0.075442, acc.: 97%] [G loss: 5.671487]\n",
            "9342 [ D loss: 0.154803, acc.: 93%] [G loss: 8.055252]\n",
            "9343 [ D loss: 0.077458, acc.: 99%] [G loss: 6.272112]\n",
            "9344 [ D loss: 0.130488, acc.: 95%] [G loss: 6.715312]\n",
            "9345 [ D loss: 0.157768, acc.: 93%] [G loss: 6.592423]\n",
            "9346 [ D loss: 0.100114, acc.: 95%] [G loss: 7.036636]\n",
            "9347 [ D loss: 0.141745, acc.: 96%] [G loss: 5.939712]\n",
            "9348 [ D loss: 0.147656, acc.: 95%] [G loss: 7.863000]\n",
            "9349 [ D loss: 0.117664, acc.: 97%] [G loss: 7.589315]\n",
            "9350 [ D loss: 0.170443, acc.: 92%] [G loss: 9.838163]\n",
            "9351 [ D loss: 0.112660, acc.: 95%] [G loss: 8.441031]\n",
            "9352 [ D loss: 0.099447, acc.: 96%] [G loss: 12.421080]\n",
            "9353 [ D loss: 0.092120, acc.: 96%] [G loss: 6.570014]\n",
            "9354 [ D loss: 0.184187, acc.: 93%] [G loss: 6.362942]\n",
            "9355 [ D loss: 0.100470, acc.: 95%] [G loss: 5.527910]\n",
            "9356 [ D loss: 0.220115, acc.: 91%] [G loss: 5.655287]\n",
            "9357 [ D loss: 0.132965, acc.: 95%] [G loss: 6.323563]\n",
            "9358 [ D loss: 0.221953, acc.: 91%] [G loss: 4.988280]\n",
            "9359 [ D loss: 0.176871, acc.: 93%] [G loss: 5.668363]\n",
            "9360 [ D loss: 0.085144, acc.: 98%] [G loss: 5.093795]\n",
            "9361 [ D loss: 0.118120, acc.: 95%] [G loss: 5.049130]\n",
            "9362 [ D loss: 0.090268, acc.: 98%] [G loss: 7.858826]\n",
            "9363 [ D loss: 0.070996, acc.: 98%] [G loss: 7.600178]\n",
            "9364 [ D loss: 0.120049, acc.: 97%] [G loss: 8.328002]\n",
            "9365 [ D loss: 0.147037, acc.: 91%] [G loss: 6.237734]\n",
            "9366 [ D loss: 0.102854, acc.: 97%] [G loss: 7.721631]\n",
            "9367 [ D loss: 0.062554, acc.: 98%] [G loss: 8.868546]\n",
            "9368 [ D loss: 0.107882, acc.: 98%] [G loss: 6.095259]\n",
            "9369 [ D loss: 0.046814, acc.: 99%] [G loss: 5.536263]\n",
            "9370 [ D loss: 0.133114, acc.: 96%] [G loss: 12.778383]\n",
            "9371 [ D loss: 0.036572, acc.: 99%] [G loss: 6.666771]\n",
            "9372 [ D loss: 0.074641, acc.: 97%] [G loss: 9.984322]\n",
            "9373 [ D loss: 0.178920, acc.: 91%] [G loss: 7.390870]\n",
            "9374 [ D loss: 0.136473, acc.: 96%] [G loss: 5.450040]\n",
            "9375 [ D loss: 0.089275, acc.: 96%] [G loss: 3.930568]\n",
            "9376 [ D loss: 0.047836, acc.: 98%] [G loss: 4.690757]\n",
            "9377 [ D loss: 0.118197, acc.: 95%] [G loss: 5.801726]\n",
            "9378 [ D loss: 0.133737, acc.: 95%] [G loss: 5.091594]\n",
            "9379 [ D loss: 0.151281, acc.: 93%] [G loss: 8.035015]\n",
            "9380 [ D loss: 0.180840, acc.: 92%] [G loss: 6.681303]\n",
            "9381 [ D loss: 0.167686, acc.: 93%] [G loss: 7.168893]\n",
            "9382 [ D loss: 0.148287, acc.: 95%] [G loss: 5.647411]\n",
            "9383 [ D loss: 0.230538, acc.: 90%] [G loss: 4.342710]\n",
            "9384 [ D loss: 0.182141, acc.: 92%] [G loss: 7.786908]\n",
            "9385 [ D loss: 0.190083, acc.: 92%] [G loss: 5.040437]\n",
            "9386 [ D loss: 0.109700, acc.: 97%] [G loss: 12.553109]\n",
            "9387 [ D loss: 0.151915, acc.: 95%] [G loss: 7.721853]\n",
            "9388 [ D loss: 0.142588, acc.: 94%] [G loss: 10.014136]\n",
            "9389 [ D loss: 0.100244, acc.: 96%] [G loss: 7.915504]\n",
            "9390 [ D loss: 0.104412, acc.: 97%] [G loss: 6.907131]\n",
            "9391 [ D loss: 0.077700, acc.: 97%] [G loss: 8.613535]\n",
            "9392 [ D loss: 0.093309, acc.: 97%] [G loss: 5.522360]\n",
            "9393 [ D loss: 0.101497, acc.: 96%] [G loss: 11.950556]\n",
            "9394 [ D loss: 0.091559, acc.: 98%] [G loss: 6.009111]\n",
            "9395 [ D loss: 0.105674, acc.: 96%] [G loss: 9.142632]\n",
            "9396 [ D loss: 0.069381, acc.: 100%] [G loss: 6.526233]\n",
            "9397 [ D loss: 0.078050, acc.: 100%] [G loss: 5.362728]\n",
            "9398 [ D loss: 0.116981, acc.: 94%] [G loss: 6.095461]\n",
            "9399 [ D loss: 0.091611, acc.: 96%] [G loss: 5.409623]\n",
            "9400 [ D loss: 0.404366, acc.: 86%] [G loss: 6.190291]\n",
            "9401 [ D loss: 0.128288, acc.: 94%] [G loss: 5.365349]\n",
            "9402 [ D loss: 0.081734, acc.: 98%] [G loss: 5.388396]\n",
            "9403 [ D loss: 0.226149, acc.: 92%] [G loss: 6.280948]\n",
            "9404 [ D loss: 0.180334, acc.: 91%] [G loss: 6.259701]\n",
            "9405 [ D loss: 0.137611, acc.: 95%] [G loss: 6.101984]\n",
            "9406 [ D loss: 0.067691, acc.: 98%] [G loss: 6.513827]\n",
            "9407 [ D loss: 0.174068, acc.: 93%] [G loss: 5.835576]\n",
            "9408 [ D loss: 0.118752, acc.: 97%] [G loss: 6.231207]\n",
            "9409 [ D loss: 0.302166, acc.: 88%] [G loss: 6.851627]\n",
            "9410 [ D loss: 0.109444, acc.: 95%] [G loss: 7.116476]\n",
            "9411 [ D loss: 0.149370, acc.: 97%] [G loss: 5.452995]\n",
            "9412 [ D loss: 0.228998, acc.: 90%] [G loss: 4.982810]\n",
            "9413 [ D loss: 0.064337, acc.: 99%] [G loss: 6.125307]\n",
            "9414 [ D loss: 0.351231, acc.: 85%] [G loss: 6.009442]\n",
            "9415 [ D loss: 0.195854, acc.: 91%] [G loss: 5.606284]\n",
            "9416 [ D loss: 0.181043, acc.: 94%] [G loss: 7.260795]\n",
            "9417 [ D loss: 0.171386, acc.: 96%] [G loss: 7.202421]\n",
            "9418 [ D loss: 0.168872, acc.: 95%] [G loss: 5.552845]\n",
            "9419 [ D loss: 0.147488, acc.: 96%] [G loss: 7.238876]\n",
            "9420 [ D loss: 0.154697, acc.: 95%] [G loss: 5.703945]\n",
            "9421 [ D loss: 0.144033, acc.: 95%] [G loss: 5.240521]\n",
            "9422 [ D loss: 0.121627, acc.: 97%] [G loss: 4.084451]\n",
            "9423 [ D loss: 0.092717, acc.: 97%] [G loss: 5.457883]\n",
            "9424 [ D loss: 0.246608, acc.: 90%] [G loss: 12.062129]\n",
            "9425 [ D loss: 0.141471, acc.: 96%] [G loss: 7.491801]\n",
            "9426 [ D loss: 0.115664, acc.: 97%] [G loss: 6.004206]\n",
            "9427 [ D loss: 0.153756, acc.: 97%] [G loss: 6.629638]\n",
            "9428 [ D loss: 0.113019, acc.: 95%] [G loss: 8.329006]\n",
            "9429 [ D loss: 0.096856, acc.: 98%] [G loss: 8.933160]\n",
            "9430 [ D loss: 0.055693, acc.: 98%] [G loss: 13.990315]\n",
            "9431 [ D loss: 0.058724, acc.: 97%] [G loss: 11.841300]\n",
            "9432 [ D loss: 0.053570, acc.: 98%] [G loss: 13.425446]\n",
            "9433 [ D loss: 0.081031, acc.: 97%] [G loss: 10.893913]\n",
            "9434 [ D loss: 0.087085, acc.: 96%] [G loss: 9.503588]\n",
            "9435 [ D loss: 0.067790, acc.: 98%] [G loss: 7.893094]\n",
            "9436 [ D loss: 0.095453, acc.: 97%] [G loss: 6.243570]\n",
            "9437 [ D loss: 0.102385, acc.: 98%] [G loss: 7.156718]\n",
            "9438 [ D loss: 0.221331, acc.: 88%] [G loss: 3.462627]\n",
            "9439 [ D loss: 0.081964, acc.: 97%] [G loss: 4.477492]\n",
            "9440 [ D loss: 0.244457, acc.: 90%] [G loss: 5.545407]\n",
            "9441 [ D loss: 0.236624, acc.: 92%] [G loss: 5.183300]\n",
            "9442 [ D loss: 0.208836, acc.: 91%] [G loss: 7.021100]\n",
            "9443 [ D loss: 0.276969, acc.: 88%] [G loss: 8.323420]\n",
            "9444 [ D loss: 0.186365, acc.: 92%] [G loss: 6.329794]\n",
            "9445 [ D loss: 0.087019, acc.: 96%] [G loss: 5.452831]\n",
            "9446 [ D loss: 0.143721, acc.: 91%] [G loss: 6.262026]\n",
            "9447 [ D loss: 0.090926, acc.: 97%] [G loss: 5.618860]\n",
            "9448 [ D loss: 0.140622, acc.: 95%] [G loss: 7.952341]\n",
            "9449 [ D loss: 0.028837, acc.: 100%] [G loss: 11.717698]\n",
            "9450 [ D loss: 0.090904, acc.: 98%] [G loss: 11.473948]\n",
            "9451 [ D loss: 0.109964, acc.: 97%] [G loss: 7.427003]\n",
            "9452 [ D loss: 0.088801, acc.: 96%] [G loss: 7.579823]\n",
            "9453 [ D loss: 0.103042, acc.: 98%] [G loss: 6.214305]\n",
            "9454 [ D loss: 0.126278, acc.: 95%] [G loss: 5.710904]\n",
            "9455 [ D loss: 0.164837, acc.: 95%] [G loss: 5.901083]\n",
            "9456 [ D loss: 0.207612, acc.: 93%] [G loss: 6.252113]\n",
            "9457 [ D loss: 0.130622, acc.: 96%] [G loss: 5.828372]\n",
            "9458 [ D loss: 0.115131, acc.: 98%] [G loss: 3.534854]\n",
            "9459 [ D loss: 0.121788, acc.: 97%] [G loss: 6.051007]\n",
            "9460 [ D loss: 0.085737, acc.: 98%] [G loss: 5.206316]\n",
            "9461 [ D loss: 0.040815, acc.: 98%] [G loss: 7.867939]\n",
            "9462 [ D loss: 0.045012, acc.: 98%] [G loss: 14.528168]\n",
            "9463 [ D loss: 0.021754, acc.: 100%] [G loss: 11.868223]\n",
            "9464 [ D loss: 0.059701, acc.: 97%] [G loss: 14.972696]\n",
            "9465 [ D loss: 0.026097, acc.: 99%] [G loss: 11.679142]\n",
            "9466 [ D loss: 0.063593, acc.: 98%] [G loss: 10.482702]\n",
            "9467 [ D loss: 0.134378, acc.: 95%] [G loss: 11.770593]\n",
            "9468 [ D loss: 0.073824, acc.: 97%] [G loss: 10.481082]\n",
            "9469 [ D loss: 0.154150, acc.: 95%] [G loss: 8.078572]\n",
            "9470 [ D loss: 0.078956, acc.: 96%] [G loss: 6.603682]\n",
            "9471 [ D loss: 0.062056, acc.: 98%] [G loss: 8.452810]\n",
            "9472 [ D loss: 0.077095, acc.: 98%] [G loss: 5.530288]\n",
            "9473 [ D loss: 0.194063, acc.: 95%] [G loss: 14.101315]\n",
            "9474 [ D loss: 0.111277, acc.: 95%] [G loss: 9.149590]\n",
            "9475 [ D loss: 0.054140, acc.: 98%] [G loss: 7.916944]\n",
            "9476 [ D loss: 0.184191, acc.: 90%] [G loss: 9.716406]\n",
            "9477 [ D loss: 0.068038, acc.: 98%] [G loss: 9.121563]\n",
            "9478 [ D loss: 0.164827, acc.: 92%] [G loss: 7.648243]\n",
            "9479 [ D loss: 0.102808, acc.: 97%] [G loss: 7.869976]\n",
            "9480 [ D loss: 0.059827, acc.: 98%] [G loss: 7.961352]\n",
            "9481 [ D loss: 0.177328, acc.: 92%] [G loss: 9.066612]\n",
            "9482 [ D loss: 0.131797, acc.: 95%] [G loss: 6.000059]\n",
            "9483 [ D loss: 0.154554, acc.: 95%] [G loss: 8.588819]\n",
            "9484 [ D loss: 0.068357, acc.: 98%] [G loss: 12.863905]\n",
            "9485 [ D loss: 0.092865, acc.: 97%] [G loss: 7.789775]\n",
            "9486 [ D loss: 0.111193, acc.: 96%] [G loss: 6.138075]\n",
            "9487 [ D loss: 0.095225, acc.: 97%] [G loss: 13.925999]\n",
            "9488 [ D loss: 0.039015, acc.: 100%] [G loss: 7.618320]\n",
            "9489 [ D loss: 0.151295, acc.: 94%] [G loss: 8.845959]\n",
            "9490 [ D loss: 0.107145, acc.: 95%] [G loss: 7.206515]\n",
            "9491 [ D loss: 0.137382, acc.: 94%] [G loss: 6.755542]\n",
            "9492 [ D loss: 0.106181, acc.: 95%] [G loss: 6.039572]\n",
            "9493 [ D loss: 0.127324, acc.: 95%] [G loss: 5.373831]\n",
            "9494 [ D loss: 0.127239, acc.: 95%] [G loss: 5.990946]\n",
            "9495 [ D loss: 0.094052, acc.: 95%] [G loss: 8.052489]\n",
            "9496 [ D loss: 0.124944, acc.: 95%] [G loss: 6.899967]\n",
            "9497 [ D loss: 0.075560, acc.: 97%] [G loss: 7.933898]\n",
            "9498 [ D loss: 0.097822, acc.: 98%] [G loss: 7.762996]\n",
            "9499 [ D loss: 0.148555, acc.: 95%] [G loss: 11.020012]\n",
            "9500 [ D loss: 0.085760, acc.: 97%] [G loss: 7.244420]\n",
            "9501 [ D loss: 0.147092, acc.: 94%] [G loss: 7.705435]\n",
            "9502 [ D loss: 0.080864, acc.: 98%] [G loss: 8.472847]\n",
            "9503 [ D loss: 0.097552, acc.: 97%] [G loss: 6.299360]\n",
            "9504 [ D loss: 0.124969, acc.: 96%] [G loss: 6.411767]\n",
            "9505 [ D loss: 0.118952, acc.: 97%] [G loss: 7.559302]\n",
            "9506 [ D loss: 0.107201, acc.: 97%] [G loss: 6.239078]\n",
            "9507 [ D loss: 0.112980, acc.: 97%] [G loss: 4.650934]\n",
            "9508 [ D loss: 0.125876, acc.: 96%] [G loss: 4.280210]\n",
            "9509 [ D loss: 0.183137, acc.: 91%] [G loss: 5.565829]\n",
            "9510 [ D loss: 0.291083, acc.: 85%] [G loss: 5.972524]\n",
            "9511 [ D loss: 0.141245, acc.: 95%] [G loss: 8.187553]\n",
            "9512 [ D loss: 0.097636, acc.: 98%] [G loss: 7.933743]\n",
            "9513 [ D loss: 0.101640, acc.: 95%] [G loss: 6.026235]\n",
            "9514 [ D loss: 0.093669, acc.: 97%] [G loss: 7.185298]\n",
            "9515 [ D loss: 0.064770, acc.: 98%] [G loss: 8.797324]\n",
            "9516 [ D loss: 0.121668, acc.: 95%] [G loss: 7.603897]\n",
            "9517 [ D loss: 0.190302, acc.: 94%] [G loss: 7.253714]\n",
            "9518 [ D loss: 0.154410, acc.: 92%] [G loss: 4.863354]\n",
            "9519 [ D loss: 0.055013, acc.: 99%] [G loss: 3.882718]\n",
            "9520 [ D loss: 0.054406, acc.: 100%] [G loss: 7.740170]\n",
            "9521 [ D loss: 0.043690, acc.: 98%] [G loss: 10.401884]\n",
            "9522 [ D loss: 0.141225, acc.: 96%] [G loss: 6.733274]\n",
            "9523 [ D loss: 0.188451, acc.: 91%] [G loss: 7.655316]\n",
            "9524 [ D loss: 0.112329, acc.: 97%] [G loss: 6.718421]\n",
            "9525 [ D loss: 0.217810, acc.: 91%] [G loss: 7.698235]\n",
            "9526 [ D loss: 0.202471, acc.: 91%] [G loss: 5.321203]\n",
            "9527 [ D loss: 0.132984, acc.: 95%] [G loss: 10.321276]\n",
            "9528 [ D loss: 0.076625, acc.: 98%] [G loss: 5.516271]\n",
            "9529 [ D loss: 0.055214, acc.: 98%] [G loss: 8.354394]\n",
            "9530 [ D loss: 0.168177, acc.: 94%] [G loss: 9.266844]\n",
            "9531 [ D loss: 0.087132, acc.: 96%] [G loss: 11.886569]\n",
            "9532 [ D loss: 0.102316, acc.: 96%] [G loss: 9.207521]\n",
            "9533 [ D loss: 0.062936, acc.: 98%] [G loss: 9.358658]\n",
            "9534 [ D loss: 0.056126, acc.: 97%] [G loss: 11.393091]\n",
            "9535 [ D loss: 0.051995, acc.: 98%] [G loss: 3.990707]\n",
            "9536 [ D loss: 0.036242, acc.: 98%] [G loss: 6.442344]\n",
            "9537 [ D loss: 0.125081, acc.: 95%] [G loss: 10.219552]\n",
            "9538 [ D loss: 0.087523, acc.: 98%] [G loss: 7.195908]\n",
            "9539 [ D loss: 0.225529, acc.: 89%] [G loss: 10.698007]\n",
            "9540 [ D loss: 0.223430, acc.: 89%] [G loss: 8.691754]\n",
            "9541 [ D loss: 0.086539, acc.: 96%] [G loss: 9.794246]\n",
            "9542 [ D loss: 0.086451, acc.: 98%] [G loss: 6.003618]\n",
            "9543 [ D loss: 0.065979, acc.: 98%] [G loss: 6.307220]\n",
            "9544 [ D loss: 0.118033, acc.: 95%] [G loss: 7.111557]\n",
            "9545 [ D loss: 0.102601, acc.: 95%] [G loss: 5.244348]\n",
            "9546 [ D loss: 0.107105, acc.: 96%] [G loss: 5.805749]\n",
            "9547 [ D loss: 0.110273, acc.: 97%] [G loss: 5.809153]\n",
            "9548 [ D loss: 0.057973, acc.: 98%] [G loss: 7.464355]\n",
            "9549 [ D loss: 0.134336, acc.: 95%] [G loss: 4.551795]\n",
            "9550 [ D loss: 0.106052, acc.: 95%] [G loss: 8.174370]\n",
            "9551 [ D loss: 0.100675, acc.: 95%] [G loss: 6.035673]\n",
            "9552 [ D loss: 0.174441, acc.: 91%] [G loss: 8.170454]\n",
            "9553 [ D loss: 0.160150, acc.: 95%] [G loss: 6.485619]\n",
            "9554 [ D loss: 0.182595, acc.: 94%] [G loss: 4.747067]\n",
            "9555 [ D loss: 0.138087, acc.: 97%] [G loss: 6.578249]\n",
            "9556 [ D loss: 0.211035, acc.: 92%] [G loss: 4.340301]\n",
            "9557 [ D loss: 0.427463, acc.: 82%] [G loss: 6.565997]\n",
            "9558 [ D loss: 0.222425, acc.: 92%] [G loss: 5.335407]\n",
            "9559 [ D loss: 0.236843, acc.: 91%] [G loss: 5.900150]\n",
            "9560 [ D loss: 0.092054, acc.: 98%] [G loss: 7.945013]\n",
            "9561 [ D loss: 0.126739, acc.: 95%] [G loss: 5.475988]\n",
            "9562 [ D loss: 0.124269, acc.: 95%] [G loss: 6.360800]\n",
            "9563 [ D loss: 0.154221, acc.: 93%] [G loss: 5.073390]\n",
            "9564 [ D loss: 0.105766, acc.: 96%] [G loss: 5.204193]\n",
            "9565 [ D loss: 0.076344, acc.: 98%] [G loss: 6.205892]\n",
            "9566 [ D loss: 0.076519, acc.: 98%] [G loss: 4.947128]\n",
            "9567 [ D loss: 0.124801, acc.: 95%] [G loss: 8.339884]\n",
            "9568 [ D loss: 0.154247, acc.: 92%] [G loss: 6.360350]\n",
            "9569 [ D loss: 0.093220, acc.: 95%] [G loss: 12.069172]\n",
            "9570 [ D loss: 0.162640, acc.: 94%] [G loss: 9.131685]\n",
            "9571 [ D loss: 0.145449, acc.: 95%] [G loss: 8.883532]\n",
            "9572 [ D loss: 0.069484, acc.: 98%] [G loss: 4.998536]\n",
            "9573 [ D loss: 0.084070, acc.: 97%] [G loss: 9.720502]\n",
            "9574 [ D loss: 0.152537, acc.: 95%] [G loss: 8.569332]\n",
            "9575 [ D loss: 0.142828, acc.: 93%] [G loss: 9.401620]\n",
            "9576 [ D loss: 0.109890, acc.: 97%] [G loss: 6.732314]\n",
            "9577 [ D loss: 0.128862, acc.: 95%] [G loss: 7.850215]\n",
            "9578 [ D loss: 0.078712, acc.: 98%] [G loss: 5.350350]\n",
            "9579 [ D loss: 0.207291, acc.: 91%] [G loss: 5.241700]\n",
            "9580 [ D loss: 0.136806, acc.: 92%] [G loss: 5.306857]\n",
            "9581 [ D loss: 0.162384, acc.: 91%] [G loss: 12.421854]\n",
            "9582 [ D loss: 0.074690, acc.: 98%] [G loss: 7.486600]\n",
            "9583 [ D loss: 0.111679, acc.: 97%] [G loss: 7.354513]\n",
            "9584 [ D loss: 0.074699, acc.: 99%] [G loss: 4.270854]\n",
            "9585 [ D loss: 0.069537, acc.: 98%] [G loss: 6.468575]\n",
            "9586 [ D loss: 0.144657, acc.: 96%] [G loss: 10.542433]\n",
            "9587 [ D loss: 0.103890, acc.: 95%] [G loss: 12.090541]\n",
            "9588 [ D loss: 0.047057, acc.: 99%] [G loss: 8.380704]\n",
            "9589 [ D loss: 0.133100, acc.: 95%] [G loss: 9.995874]\n",
            "9590 [ D loss: 0.091081, acc.: 97%] [G loss: 8.743942]\n",
            "9591 [ D loss: 0.141203, acc.: 93%] [G loss: 6.266803]\n",
            "9592 [ D loss: 0.113375, acc.: 95%] [G loss: 5.490274]\n",
            "9593 [ D loss: 0.144350, acc.: 95%] [G loss: 7.972388]\n",
            "9594 [ D loss: 0.152524, acc.: 93%] [G loss: 6.994180]\n",
            "9595 [ D loss: 0.112323, acc.: 96%] [G loss: 6.282922]\n",
            "9596 [ D loss: 0.082853, acc.: 98%] [G loss: 6.222185]\n",
            "9597 [ D loss: 0.096160, acc.: 96%] [G loss: 8.764924]\n",
            "9598 [ D loss: 0.083917, acc.: 96%] [G loss: 7.194754]\n",
            "9599 [ D loss: 0.089733, acc.: 97%] [G loss: 9.259629]\n",
            "9600 [ D loss: 0.208682, acc.: 90%] [G loss: 5.257859]\n",
            "9601 [ D loss: 0.061172, acc.: 98%] [G loss: 8.891864]\n",
            "9602 [ D loss: 0.056157, acc.: 98%] [G loss: 6.633980]\n",
            "9603 [ D loss: 0.068673, acc.: 98%] [G loss: 8.943607]\n",
            "9604 [ D loss: 0.178715, acc.: 95%] [G loss: 11.553977]\n",
            "9605 [ D loss: 0.104875, acc.: 97%] [G loss: 7.768892]\n",
            "9606 [ D loss: 0.133863, acc.: 95%] [G loss: 10.157078]\n",
            "9607 [ D loss: 0.064086, acc.: 98%] [G loss: 10.263005]\n",
            "9608 [ D loss: 0.085012, acc.: 98%] [G loss: 6.444416]\n",
            "9609 [ D loss: 0.219880, acc.: 91%] [G loss: 4.830284]\n",
            "9610 [ D loss: 0.169161, acc.: 93%] [G loss: 6.095955]\n",
            "9611 [ D loss: 0.126346, acc.: 95%] [G loss: 4.833431]\n",
            "9612 [ D loss: 0.217210, acc.: 90%] [G loss: 5.724341]\n",
            "9613 [ D loss: 0.182790, acc.: 94%] [G loss: 5.879904]\n",
            "9614 [ D loss: 0.231139, acc.: 90%] [G loss: 5.654988]\n",
            "9615 [ D loss: 0.094019, acc.: 97%] [G loss: 6.199392]\n",
            "9616 [ D loss: 0.152886, acc.: 95%] [G loss: 5.173018]\n",
            "9617 [ D loss: 0.067133, acc.: 98%] [G loss: 4.983625]\n",
            "9618 [ D loss: 0.105776, acc.: 95%] [G loss: 7.041700]\n",
            "9619 [ D loss: 0.094525, acc.: 97%] [G loss: 9.238163]\n",
            "9620 [ D loss: 0.086721, acc.: 97%] [G loss: 6.834388]\n",
            "9621 [ D loss: 0.137717, acc.: 94%] [G loss: 8.864940]\n",
            "9622 [ D loss: 0.245764, acc.: 90%] [G loss: 12.866622]\n",
            "9623 [ D loss: 0.242684, acc.: 89%] [G loss: 5.511208]\n",
            "9624 [ D loss: 0.186588, acc.: 94%] [G loss: 11.123867]\n",
            "9625 [ D loss: 0.170077, acc.: 93%] [G loss: 7.193317]\n",
            "9626 [ D loss: 0.251315, acc.: 90%] [G loss: 5.171112]\n",
            "9627 [ D loss: 0.212026, acc.: 91%] [G loss: 6.780835]\n",
            "9628 [ D loss: 0.102455, acc.: 96%] [G loss: 8.095890]\n",
            "9629 [ D loss: 0.202987, acc.: 91%] [G loss: 5.601278]\n",
            "9630 [ D loss: 0.192651, acc.: 93%] [G loss: 6.052496]\n",
            "9631 [ D loss: 0.140921, acc.: 93%] [G loss: 7.309444]\n",
            "9632 [ D loss: 0.268098, acc.: 89%] [G loss: 5.082286]\n",
            "9633 [ D loss: 0.108117, acc.: 97%] [G loss: 6.273324]\n",
            "9634 [ D loss: 0.148866, acc.: 95%] [G loss: 6.536106]\n",
            "9635 [ D loss: 0.143099, acc.: 95%] [G loss: 5.888573]\n",
            "9636 [ D loss: 0.115860, acc.: 96%] [G loss: 4.476239]\n",
            "9637 [ D loss: 0.046497, acc.: 98%] [G loss: 5.427512]\n",
            "9638 [ D loss: 0.126740, acc.: 96%] [G loss: 6.424401]\n",
            "9639 [ D loss: 0.171912, acc.: 92%] [G loss: 7.220040]\n",
            "9640 [ D loss: 0.212696, acc.: 92%] [G loss: 6.950362]\n",
            "9641 [ D loss: 0.110440, acc.: 97%] [G loss: 7.125385]\n",
            "9642 [ D loss: 0.112212, acc.: 95%] [G loss: 5.948332]\n",
            "9643 [ D loss: 0.116511, acc.: 95%] [G loss: 6.658346]\n",
            "9644 [ D loss: 0.129237, acc.: 92%] [G loss: 4.370001]\n",
            "9645 [ D loss: 0.078442, acc.: 98%] [G loss: 7.333820]\n",
            "9646 [ D loss: 0.058287, acc.: 98%] [G loss: 5.415374]\n",
            "9647 [ D loss: 0.094402, acc.: 95%] [G loss: 6.039628]\n",
            "9648 [ D loss: 0.099855, acc.: 98%] [G loss: 6.951103]\n",
            "9649 [ D loss: 0.162505, acc.: 94%] [G loss: 5.502043]\n",
            "9650 [ D loss: 0.100347, acc.: 96%] [G loss: 4.825739]\n",
            "9651 [ D loss: 0.202417, acc.: 93%] [G loss: 5.060195]\n",
            "9652 [ D loss: 0.246197, acc.: 91%] [G loss: 5.489994]\n",
            "9653 [ D loss: 0.102337, acc.: 95%] [G loss: 7.998903]\n",
            "9654 [ D loss: 0.191210, acc.: 93%] [G loss: 9.492641]\n",
            "9655 [ D loss: 0.194914, acc.: 91%] [G loss: 6.755806]\n",
            "9656 [ D loss: 0.069458, acc.: 98%] [G loss: 5.742584]\n",
            "9657 [ D loss: 0.194589, acc.: 94%] [G loss: 5.579428]\n",
            "9658 [ D loss: 0.110924, acc.: 97%] [G loss: 6.281781]\n",
            "9659 [ D loss: 0.099465, acc.: 97%] [G loss: 6.054555]\n",
            "9660 [ D loss: 0.245949, acc.: 91%] [G loss: 7.754121]\n",
            "9661 [ D loss: 0.217627, acc.: 91%] [G loss: 7.768555]\n",
            "9662 [ D loss: 0.056424, acc.: 98%] [G loss: 4.906439]\n",
            "9663 [ D loss: 0.059372, acc.: 99%] [G loss: 8.788376]\n",
            "9664 [ D loss: 0.052507, acc.: 98%] [G loss: 12.663506]\n",
            "9665 [ D loss: 0.037147, acc.: 100%] [G loss: 7.480865]\n",
            "9666 [ D loss: 0.080103, acc.: 96%] [G loss: 9.926766]\n",
            "9667 [ D loss: 0.138112, acc.: 95%] [G loss: 9.238858]\n",
            "9668 [ D loss: 0.060406, acc.: 99%] [G loss: 7.989955]\n",
            "9669 [ D loss: 0.099666, acc.: 96%] [G loss: 8.237554]\n",
            "9670 [ D loss: 0.095291, acc.: 96%] [G loss: 10.356812]\n",
            "9671 [ D loss: 0.077603, acc.: 97%] [G loss: 7.160463]\n",
            "9672 [ D loss: 0.182212, acc.: 94%] [G loss: 12.499321]\n",
            "9673 [ D loss: 0.100727, acc.: 97%] [G loss: 7.064200]\n",
            "9674 [ D loss: 0.149833, acc.: 95%] [G loss: 7.438884]\n",
            "9675 [ D loss: 0.083305, acc.: 98%] [G loss: 11.276620]\n",
            "9676 [ D loss: 0.090232, acc.: 98%] [G loss: 6.253881]\n",
            "9677 [ D loss: 0.042317, acc.: 100%] [G loss: 7.025054]\n",
            "9678 [ D loss: 0.054091, acc.: 99%] [G loss: 12.240829]\n",
            "9679 [ D loss: 0.080927, acc.: 97%] [G loss: 7.583020]\n",
            "9680 [ D loss: 0.158036, acc.: 94%] [G loss: 11.641088]\n",
            "9681 [ D loss: 0.049487, acc.: 99%] [G loss: 7.145799]\n",
            "9682 [ D loss: 0.072929, acc.: 98%] [G loss: 7.976635]\n",
            "9683 [ D loss: 0.101749, acc.: 98%] [G loss: 6.891801]\n",
            "9684 [ D loss: 0.122894, acc.: 97%] [G loss: 5.190117]\n",
            "9685 [ D loss: 0.061243, acc.: 98%] [G loss: 5.687687]\n",
            "9686 [ D loss: 0.127405, acc.: 97%] [G loss: 7.881373]\n",
            "9687 [ D loss: 0.211851, acc.: 90%] [G loss: 6.151599]\n",
            "9688 [ D loss: 0.098387, acc.: 98%] [G loss: 8.592796]\n",
            "9689 [ D loss: 0.164929, acc.: 93%] [G loss: 5.659004]\n",
            "9690 [ D loss: 0.165018, acc.: 93%] [G loss: 8.603123]\n",
            "9691 [ D loss: 0.074994, acc.: 98%] [G loss: 5.756419]\n",
            "9692 [ D loss: 0.142155, acc.: 96%] [G loss: 6.505399]\n",
            "9693 [ D loss: 0.208222, acc.: 91%] [G loss: 5.536654]\n",
            "9694 [ D loss: 0.137231, acc.: 96%] [G loss: 5.332780]\n",
            "9695 [ D loss: 0.076046, acc.: 99%] [G loss: 5.191386]\n",
            "9696 [ D loss: 0.156998, acc.: 95%] [G loss: 5.438504]\n",
            "9697 [ D loss: 0.147110, acc.: 95%] [G loss: 4.566557]\n",
            "9698 [ D loss: 0.116040, acc.: 98%] [G loss: 5.492456]\n",
            "9699 [ D loss: 0.111357, acc.: 95%] [G loss: 5.983944]\n",
            "9700 [ D loss: 0.118461, acc.: 96%] [G loss: 6.667425]\n",
            "9701 [ D loss: 0.157655, acc.: 93%] [G loss: 6.681072]\n",
            "9702 [ D loss: 0.185284, acc.: 92%] [G loss: 6.548747]\n",
            "9703 [ D loss: 0.113429, acc.: 95%] [G loss: 12.045616]\n",
            "9704 [ D loss: 0.095768, acc.: 96%] [G loss: 6.277329]\n",
            "9705 [ D loss: 0.209424, acc.: 91%] [G loss: 7.286827]\n",
            "9706 [ D loss: 0.184480, acc.: 91%] [G loss: 7.126079]\n",
            "9707 [ D loss: 0.123228, acc.: 96%] [G loss: 10.402840]\n",
            "9708 [ D loss: 0.062345, acc.: 98%] [G loss: 7.581072]\n",
            "9709 [ D loss: 0.072797, acc.: 98%] [G loss: 6.409247]\n",
            "9710 [ D loss: 0.069080, acc.: 98%] [G loss: 5.931290]\n",
            "9711 [ D loss: 0.141450, acc.: 96%] [G loss: 11.142406]\n",
            "9712 [ D loss: 0.066313, acc.: 98%] [G loss: 6.263516]\n",
            "9713 [ D loss: 0.055799, acc.: 99%] [G loss: 12.356434]\n",
            "9714 [ D loss: 0.037035, acc.: 99%] [G loss: 12.865310]\n",
            "9715 [ D loss: 0.072856, acc.: 98%] [G loss: 11.021132]\n",
            "9716 [ D loss: 0.059806, acc.: 98%] [G loss: 12.718699]\n",
            "9717 [ D loss: 0.036492, acc.: 100%] [G loss: 9.914288]\n",
            "9718 [ D loss: 0.035354, acc.: 100%] [G loss: 8.847038]\n",
            "9719 [ D loss: 0.029551, acc.: 100%] [G loss: 10.481352]\n",
            "9720 [ D loss: 0.060958, acc.: 98%] [G loss: 7.975640]\n",
            "9721 [ D loss: 0.071614, acc.: 99%] [G loss: 5.040114]\n",
            "9722 [ D loss: 0.050390, acc.: 98%] [G loss: 11.416766]\n",
            "9723 [ D loss: 0.094543, acc.: 96%] [G loss: 11.501310]\n",
            "9724 [ D loss: 0.075520, acc.: 98%] [G loss: 8.216986]\n",
            "9725 [ D loss: 0.145870, acc.: 97%] [G loss: 7.358544]\n",
            "9726 [ D loss: 0.216032, acc.: 91%] [G loss: 6.115204]\n",
            "9727 [ D loss: 0.177421, acc.: 92%] [G loss: 10.744903]\n",
            "9728 [ D loss: 0.120999, acc.: 96%] [G loss: 10.286861]\n",
            "9729 [ D loss: 0.064650, acc.: 97%] [G loss: 7.294871]\n",
            "9730 [ D loss: 0.062920, acc.: 98%] [G loss: 7.703981]\n",
            "9731 [ D loss: 0.052943, acc.: 99%] [G loss: 8.264145]\n",
            "9732 [ D loss: 0.409360, acc.: 82%] [G loss: 8.427217]\n",
            "9733 [ D loss: 0.327563, acc.: 84%] [G loss: 4.005308]\n",
            "9734 [ D loss: 0.077378, acc.: 97%] [G loss: 5.449263]\n",
            "9735 [ D loss: 0.145913, acc.: 95%] [G loss: 6.002347]\n",
            "9736 [ D loss: 0.146139, acc.: 92%] [G loss: 8.304811]\n",
            "9737 [ D loss: 0.109818, acc.: 95%] [G loss: 8.168385]\n",
            "9738 [ D loss: 0.144082, acc.: 95%] [G loss: 5.892082]\n",
            "9739 [ D loss: 0.124697, acc.: 95%] [G loss: 6.238767]\n",
            "9740 [ D loss: 0.092814, acc.: 96%] [G loss: 8.268903]\n",
            "9741 [ D loss: 0.124534, acc.: 96%] [G loss: 5.372369]\n",
            "9742 [ D loss: 0.123795, acc.: 97%] [G loss: 6.022038]\n",
            "9743 [ D loss: 0.062758, acc.: 98%] [G loss: 6.662861]\n",
            "9744 [ D loss: 0.137481, acc.: 96%] [G loss: 7.260406]\n",
            "9745 [ D loss: 0.065574, acc.: 98%] [G loss: 12.655804]\n",
            "9746 [ D loss: 0.089285, acc.: 98%] [G loss: 7.103319]\n",
            "9747 [ D loss: 0.033139, acc.: 99%] [G loss: 5.102913]\n",
            "9748 [ D loss: 0.065927, acc.: 98%] [G loss: 7.264063]\n",
            "9749 [ D loss: 0.108173, acc.: 96%] [G loss: 8.675950]\n",
            "9750 [ D loss: 0.055666, acc.: 98%] [G loss: 7.874345]\n",
            "9751 [ D loss: 0.054628, acc.: 98%] [G loss: 6.869888]\n",
            "9752 [ D loss: 0.107916, acc.: 97%] [G loss: 5.870439]\n",
            "9753 [ D loss: 0.072954, acc.: 97%] [G loss: 9.771078]\n",
            "9754 [ D loss: 0.130202, acc.: 95%] [G loss: 5.769782]\n",
            "9755 [ D loss: 0.106890, acc.: 98%] [G loss: 5.594121]\n",
            "9756 [ D loss: 0.149719, acc.: 95%] [G loss: 4.320766]\n",
            "9757 [ D loss: 0.071123, acc.: 99%] [G loss: 6.037057]\n",
            "9758 [ D loss: 0.081358, acc.: 97%] [G loss: 6.722865]\n",
            "9759 [ D loss: 0.191589, acc.: 91%] [G loss: 4.862509]\n",
            "9760 [ D loss: 0.072941, acc.: 98%] [G loss: 7.365652]\n",
            "9761 [ D loss: 0.135708, acc.: 95%] [G loss: 10.240566]\n",
            "9762 [ D loss: 0.148664, acc.: 94%] [G loss: 5.722124]\n",
            "9763 [ D loss: 0.054498, acc.: 98%] [G loss: 7.760319]\n",
            "9764 [ D loss: 0.133540, acc.: 96%] [G loss: 6.292614]\n",
            "9765 [ D loss: 0.131616, acc.: 95%] [G loss: 10.475948]\n",
            "9766 [ D loss: 0.196378, acc.: 93%] [G loss: 5.694278]\n",
            "9767 [ D loss: 0.130573, acc.: 96%] [G loss: 4.120603]\n",
            "9768 [ D loss: 0.053670, acc.: 99%] [G loss: 4.659976]\n",
            "9769 [ D loss: 0.171612, acc.: 95%] [G loss: 8.811749]\n",
            "9770 [ D loss: 0.092038, acc.: 96%] [G loss: 6.027175]\n",
            "9771 [ D loss: 0.084165, acc.: 97%] [G loss: 12.529099]\n",
            "9772 [ D loss: 0.084834, acc.: 98%] [G loss: 10.195147]\n",
            "9773 [ D loss: 0.073471, acc.: 97%] [G loss: 8.751999]\n",
            "9774 [ D loss: 0.137286, acc.: 95%] [G loss: 6.653874]\n",
            "9775 [ D loss: 0.118551, acc.: 95%] [G loss: 11.667706]\n",
            "9776 [ D loss: 0.112991, acc.: 95%] [G loss: 7.082662]\n",
            "9777 [ D loss: 0.059128, acc.: 98%] [G loss: 8.999989]\n",
            "9778 [ D loss: 0.063065, acc.: 99%] [G loss: 10.060149]\n",
            "9779 [ D loss: 0.148239, acc.: 93%] [G loss: 7.744957]\n",
            "9780 [ D loss: 0.085990, acc.: 97%] [G loss: 5.900795]\n",
            "9781 [ D loss: 0.046278, acc.: 99%] [G loss: 11.458310]\n",
            "9782 [ D loss: 0.082621, acc.: 98%] [G loss: 6.910012]\n",
            "9783 [ D loss: 0.141939, acc.: 95%] [G loss: 8.809568]\n",
            "9784 [ D loss: 0.057673, acc.: 99%] [G loss: 4.622422]\n",
            "9785 [ D loss: 0.157909, acc.: 93%] [G loss: 7.142089]\n",
            "9786 [ D loss: 0.266339, acc.: 87%] [G loss: 5.472619]\n",
            "9787 [ D loss: 0.155130, acc.: 91%] [G loss: 5.722292]\n",
            "9788 [ D loss: 0.230454, acc.: 93%] [G loss: 9.494551]\n",
            "9789 [ D loss: 0.165404, acc.: 93%] [G loss: 10.861067]\n",
            "9790 [ D loss: 0.073926, acc.: 98%] [G loss: 8.282580]\n",
            "9791 [ D loss: 0.194413, acc.: 95%] [G loss: 7.181277]\n",
            "9792 [ D loss: 0.126720, acc.: 95%] [G loss: 5.660920]\n",
            "9793 [ D loss: 0.057436, acc.: 99%] [G loss: 6.368452]\n",
            "9794 [ D loss: 0.183965, acc.: 91%] [G loss: 5.319423]\n",
            "9795 [ D loss: 0.083005, acc.: 97%] [G loss: 7.486627]\n",
            "9796 [ D loss: 0.068242, acc.: 99%] [G loss: 8.653210]\n",
            "9797 [ D loss: 0.167060, acc.: 94%] [G loss: 6.376530]\n",
            "9798 [ D loss: 0.098973, acc.: 96%] [G loss: 5.097671]\n",
            "9799 [ D loss: 0.103530, acc.: 95%] [G loss: 12.973778]\n",
            "9800 [ D loss: 0.051206, acc.: 98%] [G loss: 9.125391]\n",
            "9801 [ D loss: 0.134949, acc.: 95%] [G loss: 11.157133]\n",
            "9802 [ D loss: 0.120379, acc.: 95%] [G loss: 11.472893]\n",
            "9803 [ D loss: 0.059585, acc.: 98%] [G loss: 8.912209]\n",
            "9804 [ D loss: 0.080880, acc.: 98%] [G loss: 8.453265]\n",
            "9805 [ D loss: 0.106768, acc.: 95%] [G loss: 16.054495]\n",
            "9806 [ D loss: 0.058734, acc.: 97%] [G loss: 11.683079]\n",
            "9807 [ D loss: 0.085655, acc.: 98%] [G loss: 9.667677]\n",
            "9808 [ D loss: 0.104461, acc.: 96%] [G loss: 7.071689]\n",
            "9809 [ D loss: 0.073592, acc.: 98%] [G loss: 15.334447]\n",
            "9810 [ D loss: 0.068630, acc.: 97%] [G loss: 9.279057]\n",
            "9811 [ D loss: 0.033990, acc.: 100%] [G loss: 9.456029]\n",
            "9812 [ D loss: 0.051586, acc.: 98%] [G loss: 9.443550]\n",
            "9813 [ D loss: 0.109122, acc.: 95%] [G loss: 8.800169]\n",
            "9814 [ D loss: 0.083538, acc.: 98%] [G loss: 6.026177]\n",
            "9815 [ D loss: 0.043543, acc.: 99%] [G loss: 6.571677]\n",
            "9816 [ D loss: 0.158613, acc.: 94%] [G loss: 11.715220]\n",
            "9817 [ D loss: 0.085197, acc.: 99%] [G loss: 5.445695]\n",
            "9818 [ D loss: 0.142906, acc.: 96%] [G loss: 4.460742]\n",
            "9819 [ D loss: 0.149316, acc.: 95%] [G loss: 7.004675]\n",
            "9820 [ D loss: 0.257650, acc.: 92%] [G loss: 8.010667]\n",
            "9821 [ D loss: 0.234301, acc.: 90%] [G loss: 6.595347]\n",
            "9822 [ D loss: 0.135250, acc.: 93%] [G loss: 5.366076]\n",
            "9823 [ D loss: 0.168977, acc.: 94%] [G loss: 5.117640]\n",
            "9824 [ D loss: 0.198532, acc.: 91%] [G loss: 5.340872]\n",
            "9825 [ D loss: 0.095793, acc.: 98%] [G loss: 9.958957]\n",
            "9826 [ D loss: 0.181569, acc.: 94%] [G loss: 7.530545]\n",
            "9827 [ D loss: 0.089497, acc.: 98%] [G loss: 5.663535]\n",
            "9828 [ D loss: 0.168209, acc.: 93%] [G loss: 9.452713]\n",
            "9829 [ D loss: 0.121030, acc.: 96%] [G loss: 7.340000]\n",
            "9830 [ D loss: 0.101399, acc.: 98%] [G loss: 7.913915]\n",
            "9831 [ D loss: 0.141545, acc.: 96%] [G loss: 5.725498]\n",
            "9832 [ D loss: 0.160483, acc.: 94%] [G loss: 5.188319]\n",
            "9833 [ D loss: 0.103099, acc.: 97%] [G loss: 6.121952]\n",
            "9834 [ D loss: 0.139203, acc.: 95%] [G loss: 8.247101]\n",
            "9835 [ D loss: 0.097646, acc.: 95%] [G loss: 5.232790]\n",
            "9836 [ D loss: 0.070970, acc.: 97%] [G loss: 14.254681]\n",
            "9837 [ D loss: 0.083011, acc.: 97%] [G loss: 12.233861]\n",
            "9838 [ D loss: 0.105941, acc.: 95%] [G loss: 8.436892]\n",
            "9839 [ D loss: 0.038136, acc.: 98%] [G loss: 4.608237]\n",
            "9840 [ D loss: 0.133795, acc.: 94%] [G loss: 2.746656]\n",
            "9841 [ D loss: 0.080107, acc.: 97%] [G loss: 4.930707]\n",
            "9842 [ D loss: 0.161530, acc.: 92%] [G loss: 14.877341]\n",
            "9843 [ D loss: 0.572536, acc.: 74%] [G loss: 13.811251]\n",
            "9844 [ D loss: 0.977340, acc.: 73%] [G loss: 8.347748]\n",
            "9845 [ D loss: 0.066804, acc.: 98%] [G loss: 12.554001]\n",
            "9846 [ D loss: 0.098394, acc.: 95%] [G loss: 11.014614]\n",
            "9847 [ D loss: 0.110117, acc.: 96%] [G loss: 9.566545]\n",
            "9848 [ D loss: 0.122288, acc.: 95%] [G loss: 11.815959]\n",
            "9849 [ D loss: 0.102045, acc.: 97%] [G loss: 8.307930]\n",
            "9850 [ D loss: 0.107277, acc.: 97%] [G loss: 4.558091]\n",
            "9851 [ D loss: 0.162174, acc.: 93%] [G loss: 5.309538]\n",
            "9852 [ D loss: 0.126952, acc.: 95%] [G loss: 5.498439]\n",
            "9853 [ D loss: 0.166546, acc.: 92%] [G loss: 6.169374]\n",
            "9854 [ D loss: 0.171457, acc.: 92%] [G loss: 6.034373]\n",
            "9855 [ D loss: 0.058500, acc.: 98%] [G loss: 8.003218]\n",
            "9856 [ D loss: 0.105815, acc.: 96%] [G loss: 6.727692]\n",
            "9857 [ D loss: 0.168214, acc.: 91%] [G loss: 5.730695]\n",
            "9858 [ D loss: 0.095244, acc.: 95%] [G loss: 5.301245]\n",
            "9859 [ D loss: 0.145169, acc.: 96%] [G loss: 7.151166]\n",
            "9860 [ D loss: 0.071086, acc.: 98%] [G loss: 6.505923]\n",
            "9861 [ D loss: 0.081996, acc.: 97%] [G loss: 6.771681]\n",
            "9862 [ D loss: 0.152517, acc.: 95%] [G loss: 5.728887]\n",
            "9863 [ D loss: 0.073036, acc.: 98%] [G loss: 5.755531]\n",
            "9864 [ D loss: 0.147290, acc.: 94%] [G loss: 7.408885]\n",
            "9865 [ D loss: 0.156592, acc.: 95%] [G loss: 7.668549]\n",
            "9866 [ D loss: 0.115525, acc.: 95%] [G loss: 6.028086]\n",
            "9867 [ D loss: 0.107342, acc.: 96%] [G loss: 7.509614]\n",
            "9868 [ D loss: 0.069835, acc.: 98%] [G loss: 8.138752]\n",
            "9869 [ D loss: 0.115327, acc.: 95%] [G loss: 10.245934]\n",
            "9870 [ D loss: 0.053890, acc.: 98%] [G loss: 7.722511]\n",
            "9871 [ D loss: 0.098535, acc.: 96%] [G loss: 10.403337]\n",
            "9872 [ D loss: 0.073570, acc.: 99%] [G loss: 9.810877]\n",
            "9873 [ D loss: 0.075183, acc.: 98%] [G loss: 6.890606]\n",
            "9874 [ D loss: 0.118769, acc.: 95%] [G loss: 10.286625]\n",
            "9875 [ D loss: 0.064666, acc.: 97%] [G loss: 10.326223]\n",
            "9876 [ D loss: 0.094670, acc.: 96%] [G loss: 11.779272]\n",
            "9877 [ D loss: 0.133343, acc.: 95%] [G loss: 7.611210]\n",
            "9878 [ D loss: 0.082840, acc.: 98%] [G loss: 7.285488]\n",
            "9879 [ D loss: 0.141432, acc.: 95%] [G loss: 9.078889]\n",
            "9880 [ D loss: 0.156193, acc.: 93%] [G loss: 5.830229]\n",
            "9881 [ D loss: 0.215277, acc.: 94%] [G loss: 4.935899]\n",
            "9882 [ D loss: 0.160155, acc.: 95%] [G loss: 7.594975]\n",
            "9883 [ D loss: 0.138433, acc.: 94%] [G loss: 6.782648]\n",
            "9884 [ D loss: 0.054831, acc.: 99%] [G loss: 5.609330]\n",
            "9885 [ D loss: 0.099081, acc.: 97%] [G loss: 6.195643]\n",
            "9886 [ D loss: 0.080113, acc.: 98%] [G loss: 5.953145]\n",
            "9887 [ D loss: 0.081695, acc.: 96%] [G loss: 4.521978]\n",
            "9888 [ D loss: 0.191198, acc.: 93%] [G loss: 7.535758]\n",
            "9889 [ D loss: 0.089900, acc.: 96%] [G loss: 7.923639]\n",
            "9890 [ D loss: 0.122272, acc.: 95%] [G loss: 7.971123]\n",
            "9891 [ D loss: 0.107343, acc.: 97%] [G loss: 6.290697]\n",
            "9892 [ D loss: 0.107457, acc.: 96%] [G loss: 9.634220]\n",
            "9893 [ D loss: 0.053990, acc.: 99%] [G loss: 6.862565]\n",
            "9894 [ D loss: 0.056891, acc.: 98%] [G loss: 6.092196]\n",
            "9895 [ D loss: 0.094964, acc.: 98%] [G loss: 7.789120]\n",
            "9896 [ D loss: 0.197415, acc.: 93%] [G loss: 5.687621]\n",
            "9897 [ D loss: 0.089279, acc.: 98%] [G loss: 6.617879]\n",
            "9898 [ D loss: 0.179783, acc.: 93%] [G loss: 6.492839]\n",
            "9899 [ D loss: 0.076565, acc.: 99%] [G loss: 4.961448]\n",
            "9900 [ D loss: 0.189446, acc.: 93%] [G loss: 6.368062]\n",
            "9901 [ D loss: 0.149365, acc.: 94%] [G loss: 7.709699]\n",
            "9902 [ D loss: 0.090737, acc.: 96%] [G loss: 7.096274]\n",
            "9903 [ D loss: 0.051351, acc.: 98%] [G loss: 5.214552]\n",
            "9904 [ D loss: 0.048143, acc.: 98%] [G loss: 14.919014]\n",
            "9905 [ D loss: 0.067503, acc.: 98%] [G loss: 10.296623]\n",
            "9906 [ D loss: 0.076923, acc.: 98%] [G loss: 9.998741]\n",
            "9907 [ D loss: 0.200769, acc.: 91%] [G loss: 8.212365]\n",
            "9908 [ D loss: 0.095283, acc.: 96%] [G loss: 7.653978]\n",
            "9909 [ D loss: 0.114873, acc.: 98%] [G loss: 11.510410]\n",
            "9910 [ D loss: 0.110138, acc.: 95%] [G loss: 7.816584]\n",
            "9911 [ D loss: 0.084649, acc.: 98%] [G loss: 4.502460]\n",
            "9912 [ D loss: 0.061950, acc.: 98%] [G loss: 6.037557]\n",
            "9913 [ D loss: 0.116725, acc.: 95%] [G loss: 7.219090]\n",
            "9914 [ D loss: 0.096824, acc.: 97%] [G loss: 7.847913]\n",
            "9915 [ D loss: 0.106668, acc.: 96%] [G loss: 9.535441]\n",
            "9916 [ D loss: 0.103779, acc.: 97%] [G loss: 7.220251]\n",
            "9917 [ D loss: 0.200109, acc.: 92%] [G loss: 5.959032]\n",
            "9918 [ D loss: 0.117769, acc.: 97%] [G loss: 7.049326]\n",
            "9919 [ D loss: 0.109467, acc.: 96%] [G loss: 7.526814]\n",
            "9920 [ D loss: 0.207570, acc.: 89%] [G loss: 9.403079]\n",
            "9921 [ D loss: 0.192839, acc.: 91%] [G loss: 5.808810]\n",
            "9922 [ D loss: 0.083504, acc.: 97%] [G loss: 6.370472]\n",
            "9923 [ D loss: 0.149283, acc.: 95%] [G loss: 6.460753]\n",
            "9924 [ D loss: 0.088287, acc.: 97%] [G loss: 6.860631]\n",
            "9925 [ D loss: 0.171660, acc.: 94%] [G loss: 9.620184]\n",
            "9926 [ D loss: 0.077525, acc.: 98%] [G loss: 9.433456]\n",
            "9927 [ D loss: 0.171482, acc.: 95%] [G loss: 10.730324]\n",
            "9928 [ D loss: 0.101094, acc.: 96%] [G loss: 6.231800]\n",
            "9929 [ D loss: 0.076006, acc.: 98%] [G loss: 7.639924]\n",
            "9930 [ D loss: 0.173728, acc.: 94%] [G loss: 4.147880]\n",
            "9931 [ D loss: 0.153582, acc.: 96%] [G loss: 7.093356]\n",
            "9932 [ D loss: 0.227020, acc.: 91%] [G loss: 5.646818]\n",
            "9933 [ D loss: 0.253742, acc.: 89%] [G loss: 6.514825]\n",
            "9934 [ D loss: 0.331744, acc.: 88%] [G loss: 6.387940]\n",
            "9935 [ D loss: 0.202400, acc.: 91%] [G loss: 6.726282]\n",
            "9936 [ D loss: 0.145539, acc.: 95%] [G loss: 5.770825]\n",
            "9937 [ D loss: 0.061745, acc.: 98%] [G loss: 6.978255]\n",
            "9938 [ D loss: 0.175475, acc.: 94%] [G loss: 7.822973]\n",
            "9939 [ D loss: 0.153686, acc.: 93%] [G loss: 6.634881]\n",
            "9940 [ D loss: 0.059921, acc.: 98%] [G loss: 7.099305]\n",
            "9941 [ D loss: 0.125160, acc.: 97%] [G loss: 7.300136]\n",
            "9942 [ D loss: 0.383873, acc.: 86%] [G loss: 8.406011]\n",
            "9943 [ D loss: 0.144495, acc.: 95%] [G loss: 8.923477]\n",
            "9944 [ D loss: 0.111805, acc.: 95%] [G loss: 6.251073]\n",
            "9945 [ D loss: 0.151684, acc.: 95%] [G loss: 7.085175]\n",
            "9946 [ D loss: 0.132176, acc.: 95%] [G loss: 6.064746]\n",
            "9947 [ D loss: 0.181723, acc.: 95%] [G loss: 5.339147]\n",
            "9948 [ D loss: 0.206384, acc.: 95%] [G loss: 6.223803]\n",
            "9949 [ D loss: 0.105284, acc.: 95%] [G loss: 5.625851]\n",
            "9950 [ D loss: 0.259504, acc.: 88%] [G loss: 6.325172]\n",
            "9951 [ D loss: 0.218807, acc.: 90%] [G loss: 5.136779]\n",
            "9952 [ D loss: 0.110672, acc.: 97%] [G loss: 5.593351]\n",
            "9953 [ D loss: 0.084765, acc.: 98%] [G loss: 5.957794]\n",
            "9954 [ D loss: 0.112202, acc.: 97%] [G loss: 6.881958]\n",
            "9955 [ D loss: 0.112403, acc.: 95%] [G loss: 5.801240]\n",
            "9956 [ D loss: 0.120500, acc.: 95%] [G loss: 7.502251]\n",
            "9957 [ D loss: 0.153286, acc.: 93%] [G loss: 6.381029]\n",
            "9958 [ D loss: 0.122679, acc.: 95%] [G loss: 8.022722]\n",
            "9959 [ D loss: 0.076708, acc.: 98%] [G loss: 10.581015]\n",
            "9960 [ D loss: 0.128207, acc.: 95%] [G loss: 6.647739]\n",
            "9961 [ D loss: 0.047463, acc.: 98%] [G loss: 9.649868]\n",
            "9962 [ D loss: 0.063163, acc.: 98%] [G loss: 11.426897]\n",
            "9963 [ D loss: 0.037352, acc.: 99%] [G loss: 7.399537]\n",
            "9964 [ D loss: 0.086412, acc.: 97%] [G loss: 10.854490]\n",
            "9965 [ D loss: 0.061957, acc.: 97%] [G loss: 7.383569]\n",
            "9966 [ D loss: 0.127801, acc.: 95%] [G loss: 10.685723]\n",
            "9967 [ D loss: 0.101794, acc.: 98%] [G loss: 11.088484]\n",
            "9968 [ D loss: 0.122555, acc.: 95%] [G loss: 6.248209]\n",
            "9969 [ D loss: 0.088862, acc.: 98%] [G loss: 15.012074]\n",
            "9970 [ D loss: 0.048439, acc.: 98%] [G loss: 7.533867]\n",
            "9971 [ D loss: 0.111036, acc.: 96%] [G loss: 6.548681]\n",
            "9972 [ D loss: 0.114088, acc.: 95%] [G loss: 6.038859]\n",
            "9973 [ D loss: 0.106030, acc.: 97%] [G loss: 6.439063]\n",
            "9974 [ D loss: 0.251434, acc.: 90%] [G loss: 5.816046]\n",
            "9975 [ D loss: 0.206536, acc.: 92%] [G loss: 6.686056]\n",
            "9976 [ D loss: 0.192466, acc.: 94%] [G loss: 5.420804]\n",
            "9977 [ D loss: 0.118621, acc.: 96%] [G loss: 7.781593]\n",
            "9978 [ D loss: 0.159285, acc.: 93%] [G loss: 3.486542]\n",
            "9979 [ D loss: 0.111397, acc.: 96%] [G loss: 7.737749]\n",
            "9980 [ D loss: 0.091434, acc.: 96%] [G loss: 8.882196]\n",
            "9981 [ D loss: 0.227650, acc.: 88%] [G loss: 4.738133]\n",
            "9982 [ D loss: 0.017318, acc.: 100%] [G loss: 8.509996]\n",
            "9983 [ D loss: 0.173727, acc.: 92%] [G loss: 11.179716]\n",
            "9984 [ D loss: 0.210963, acc.: 91%] [G loss: 10.947453]\n",
            "9985 [ D loss: 0.114355, acc.: 97%] [G loss: 9.866494]\n",
            "9986 [ D loss: 0.064074, acc.: 98%] [G loss: 15.133686]\n",
            "9987 [ D loss: 0.045127, acc.: 98%] [G loss: 12.032722]\n",
            "9988 [ D loss: 0.095203, acc.: 97%] [G loss: 8.505714]\n",
            "9989 [ D loss: 0.059619, acc.: 97%] [G loss: 13.634659]\n",
            "9990 [ D loss: 0.072590, acc.: 98%] [G loss: 9.696588]\n",
            "9991 [ D loss: 0.055964, acc.: 98%] [G loss: 7.869611]\n",
            "9992 [ D loss: 0.150671, acc.: 95%] [G loss: 6.844591]\n",
            "9993 [ D loss: 0.189270, acc.: 92%] [G loss: 7.476777]\n",
            "9994 [ D loss: 0.097574, acc.: 96%] [G loss: 5.697572]\n",
            "9995 [ D loss: 0.130660, acc.: 96%] [G loss: 5.741905]\n",
            "9996 [ D loss: 0.107802, acc.: 96%] [G loss: 5.423842]\n",
            "9997 [ D loss: 0.153988, acc.: 94%] [G loss: 4.571220]\n",
            "9998 [ D loss: 0.115751, acc.: 97%] [G loss: 5.236550]\n",
            "9999 [ D loss: 0.118611, acc.: 98%] [G loss: 8.060760]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "baYaEugl-J72",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "26bd0104-f3ac-42bd-f705-4f6049c209f3"
      },
      "cell_type": "code",
      "source": [
        "# 10000 iteration\n",
        "generated_img = model.generator.predict(np.random.normal(0, 1, (10, 100)))\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 2))\n",
        "n =10\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(1, n, i + 1)\n",
        "    plt.imshow(np.squeeze(generated_img[i]))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAABsCAYAAAAyoVQIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f186899c9b0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "jMTsO59l-MI4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61866
        },
        "outputId": "719813ab-7396-4210-e90b-b54a4ac06411"
      },
      "cell_type": "code",
      "source": [
        "model = GAN()\n",
        "model.train(epochs=15000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_19 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_125 (Dense)            (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_91 (LeakyReLU)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_126 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_92 (LeakyReLU)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_127 (Dense)            (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 533,505\n",
            "Trainable params: 533,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_128 (Dense)            (None, 256)               25856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_93 (LeakyReLU)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_55 (Batc (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_129 (Dense)            (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_94 (LeakyReLU)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_56 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_130 (Dense)            (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_95 (LeakyReLU)   (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_57 (Batc (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense_131 (Dense)            (None, 784)               803600    \n",
            "_________________________________________________________________\n",
            "reshape_17 (Reshape)         (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 1,493,520\n",
            "Trainable params: 1,489,936\n",
            "Non-trainable params: 3,584\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 [ D loss: 0.674030, acc.: 64%] [G loss: 0.763732]\n",
            "1 [ D loss: 0.643622, acc.: 66%] [G loss: 0.785033]\n",
            "2 [ D loss: 0.535455, acc.: 75%] [G loss: 0.933655]\n",
            "3 [ D loss: 0.453901, acc.: 84%] [G loss: 1.041255]\n",
            "4 [ D loss: 0.379486, acc.: 94%] [G loss: 1.158961]\n",
            "5 [ D loss: 0.310738, acc.: 98%] [G loss: 1.264643]\n",
            "6 [ D loss: 0.322920, acc.: 93%] [G loss: 1.361583]\n",
            "7 [ D loss: 0.273678, acc.: 99%] [G loss: 1.487244]\n",
            "8 [ D loss: 0.251398, acc.: 98%] [G loss: 1.546515]\n",
            "9 [ D loss: 0.227439, acc.: 100%] [G loss: 1.651034]\n",
            "10 [ D loss: 0.202317, acc.: 99%] [G loss: 1.714586]\n",
            "11 [ D loss: 0.171925, acc.: 100%] [G loss: 1.747761]\n",
            "12 [ D loss: 0.168401, acc.: 99%] [G loss: 1.845441]\n",
            "13 [ D loss: 0.174812, acc.: 100%] [G loss: 1.890058]\n",
            "14 [ D loss: 0.142267, acc.: 100%] [G loss: 1.992876]\n",
            "15 [ D loss: 0.133130, acc.: 100%] [G loss: 2.071599]\n",
            "16 [ D loss: 0.129158, acc.: 100%] [G loss: 2.097140]\n",
            "17 [ D loss: 0.136553, acc.: 100%] [G loss: 2.162015]\n",
            "18 [ D loss: 0.124745, acc.: 100%] [G loss: 2.272797]\n",
            "19 [ D loss: 0.117679, acc.: 100%] [G loss: 2.344188]\n",
            "20 [ D loss: 0.114964, acc.: 100%] [G loss: 2.477071]\n",
            "21 [ D loss: 0.111242, acc.: 100%] [G loss: 2.514660]\n",
            "22 [ D loss: 0.097375, acc.: 100%] [G loss: 2.579413]\n",
            "23 [ D loss: 0.090707, acc.: 100%] [G loss: 2.627368]\n",
            "24 [ D loss: 0.080699, acc.: 99%] [G loss: 2.759684]\n",
            "25 [ D loss: 0.090407, acc.: 100%] [G loss: 2.729344]\n",
            "26 [ D loss: 0.092475, acc.: 100%] [G loss: 2.736762]\n",
            "27 [ D loss: 0.082020, acc.: 100%] [G loss: 2.832583]\n",
            "28 [ D loss: 0.080741, acc.: 100%] [G loss: 2.937438]\n",
            "29 [ D loss: 0.081731, acc.: 100%] [G loss: 2.861509]\n",
            "30 [ D loss: 0.080694, acc.: 100%] [G loss: 2.925503]\n",
            "31 [ D loss: 0.066227, acc.: 100%] [G loss: 2.987871]\n",
            "32 [ D loss: 0.067281, acc.: 100%] [G loss: 3.040753]\n",
            "33 [ D loss: 0.073666, acc.: 99%] [G loss: 3.131557]\n",
            "34 [ D loss: 0.062631, acc.: 100%] [G loss: 3.148160]\n",
            "35 [ D loss: 0.081671, acc.: 99%] [G loss: 3.171624]\n",
            "36 [ D loss: 0.076240, acc.: 99%] [G loss: 3.207664]\n",
            "37 [ D loss: 0.077014, acc.: 100%] [G loss: 3.189346]\n",
            "38 [ D loss: 0.088726, acc.: 99%] [G loss: 3.264603]\n",
            "39 [ D loss: 0.067512, acc.: 99%] [G loss: 3.418331]\n",
            "40 [ D loss: 0.122796, acc.: 97%] [G loss: 3.458558]\n",
            "41 [ D loss: 0.070467, acc.: 100%] [G loss: 3.506169]\n",
            "42 [ D loss: 0.093912, acc.: 98%] [G loss: 3.527331]\n",
            "43 [ D loss: 0.099533, acc.: 99%] [G loss: 3.606994]\n",
            "44 [ D loss: 0.100852, acc.: 98%] [G loss: 3.552050]\n",
            "45 [ D loss: 0.109044, acc.: 98%] [G loss: 3.607286]\n",
            "46 [ D loss: 0.150681, acc.: 98%] [G loss: 3.718144]\n",
            "47 [ D loss: 0.114904, acc.: 97%] [G loss: 3.903610]\n",
            "48 [ D loss: 0.159635, acc.: 98%] [G loss: 3.669239]\n",
            "49 [ D loss: 0.178168, acc.: 95%] [G loss: 3.893299]\n",
            "50 [ D loss: 0.149993, acc.: 97%] [G loss: 3.854106]\n",
            "51 [ D loss: 0.149321, acc.: 96%] [G loss: 3.701548]\n",
            "52 [ D loss: 0.196713, acc.: 95%] [G loss: 3.933257]\n",
            "53 [ D loss: 0.190494, acc.: 95%] [G loss: 3.771595]\n",
            "54 [ D loss: 0.191092, acc.: 95%] [G loss: 3.573091]\n",
            "55 [ D loss: 0.203562, acc.: 92%] [G loss: 3.579447]\n",
            "56 [ D loss: 0.190784, acc.: 94%] [G loss: 3.520512]\n",
            "57 [ D loss: 0.273782, acc.: 90%] [G loss: 3.600428]\n",
            "58 [ D loss: 0.257236, acc.: 91%] [G loss: 3.520530]\n",
            "59 [ D loss: 0.190838, acc.: 95%] [G loss: 3.342492]\n",
            "60 [ D loss: 0.301542, acc.: 88%] [G loss: 3.348137]\n",
            "61 [ D loss: 0.234048, acc.: 90%] [G loss: 3.656624]\n",
            "62 [ D loss: 0.366871, acc.: 85%] [G loss: 3.699655]\n",
            "63 [ D loss: 0.303560, acc.: 91%] [G loss: 3.526846]\n",
            "64 [ D loss: 0.268649, acc.: 88%] [G loss: 3.253708]\n",
            "65 [ D loss: 0.283570, acc.: 88%] [G loss: 3.140485]\n",
            "66 [ D loss: 0.254242, acc.: 90%] [G loss: 3.144083]\n",
            "67 [ D loss: 0.398859, acc.: 84%] [G loss: 3.200352]\n",
            "68 [ D loss: 0.524973, acc.: 75%] [G loss: 3.453368]\n",
            "69 [ D loss: 0.344323, acc.: 85%] [G loss: 3.143537]\n",
            "70 [ D loss: 0.372364, acc.: 87%] [G loss: 2.844411]\n",
            "71 [ D loss: 0.433388, acc.: 81%] [G loss: 2.993870]\n",
            "72 [ D loss: 0.279830, acc.: 91%] [G loss: 2.825823]\n",
            "73 [ D loss: 0.375451, acc.: 82%] [G loss: 2.876554]\n",
            "74 [ D loss: 0.358774, acc.: 83%] [G loss: 2.868984]\n",
            "75 [ D loss: 0.478108, acc.: 84%] [G loss: 3.133958]\n",
            "76 [ D loss: 0.655882, acc.: 63%] [G loss: 2.979213]\n",
            "77 [ D loss: 0.418365, acc.: 84%] [G loss: 3.003266]\n",
            "78 [ D loss: 0.415042, acc.: 82%] [G loss: 2.744958]\n",
            "79 [ D loss: 0.390840, acc.: 83%] [G loss: 2.852279]\n",
            "80 [ D loss: 0.388585, acc.: 83%] [G loss: 2.636464]\n",
            "81 [ D loss: 0.330520, acc.: 88%] [G loss: 2.608401]\n",
            "82 [ D loss: 0.507479, acc.: 74%] [G loss: 2.925732]\n",
            "83 [ D loss: 0.331457, acc.: 84%] [G loss: 2.670430]\n",
            "84 [ D loss: 0.385838, acc.: 82%] [G loss: 2.265637]\n",
            "85 [ D loss: 0.328905, acc.: 88%] [G loss: 2.267921]\n",
            "86 [ D loss: 0.451184, acc.: 76%] [G loss: 2.713868]\n",
            "87 [ D loss: 0.391975, acc.: 82%] [G loss: 2.709726]\n",
            "88 [ D loss: 0.595899, acc.: 67%] [G loss: 2.623681]\n",
            "89 [ D loss: 0.353432, acc.: 88%] [G loss: 2.734587]\n",
            "90 [ D loss: 0.392244, acc.: 85%] [G loss: 2.590200]\n",
            "91 [ D loss: 0.376080, acc.: 84%] [G loss: 2.678761]\n",
            "92 [ D loss: 0.386484, acc.: 85%] [G loss: 2.738455]\n",
            "93 [ D loss: 0.440464, acc.: 81%] [G loss: 2.758288]\n",
            "94 [ D loss: 0.380712, acc.: 81%] [G loss: 2.669237]\n",
            "95 [ D loss: 0.491451, acc.: 75%] [G loss: 2.716033]\n",
            "96 [ D loss: 0.375659, acc.: 82%] [G loss: 2.738125]\n",
            "97 [ D loss: 0.342693, acc.: 88%] [G loss: 2.574764]\n",
            "98 [ D loss: 0.406170, acc.: 78%] [G loss: 2.733174]\n",
            "99 [ D loss: 0.425631, acc.: 82%] [G loss: 2.887985]\n",
            "100 [ D loss: 0.391640, acc.: 79%] [G loss: 2.745490]\n",
            "101 [ D loss: 0.494771, acc.: 75%] [G loss: 2.763699]\n",
            "102 [ D loss: 0.603814, acc.: 68%] [G loss: 3.038697]\n",
            "103 [ D loss: 0.527370, acc.: 70%] [G loss: 3.045063]\n",
            "104 [ D loss: 0.572025, acc.: 70%] [G loss: 2.914543]\n",
            "105 [ D loss: 0.395048, acc.: 80%] [G loss: 2.493840]\n",
            "106 [ D loss: 0.482885, acc.: 77%] [G loss: 2.363611]\n",
            "107 [ D loss: 0.488972, acc.: 78%] [G loss: 2.542280]\n",
            "108 [ D loss: 0.383675, acc.: 90%] [G loss: 2.818811]\n",
            "109 [ D loss: 0.452151, acc.: 77%] [G loss: 2.786931]\n",
            "110 [ D loss: 0.472625, acc.: 77%] [G loss: 2.833032]\n",
            "111 [ D loss: 0.442567, acc.: 80%] [G loss: 2.513528]\n",
            "112 [ D loss: 0.402359, acc.: 80%] [G loss: 2.564406]\n",
            "113 [ D loss: 0.403417, acc.: 82%] [G loss: 2.647317]\n",
            "114 [ D loss: 0.461213, acc.: 77%] [G loss: 2.770809]\n",
            "115 [ D loss: 0.393277, acc.: 87%] [G loss: 2.835906]\n",
            "116 [ D loss: 0.493119, acc.: 73%] [G loss: 2.527960]\n",
            "117 [ D loss: 0.398019, acc.: 84%] [G loss: 2.526814]\n",
            "118 [ D loss: 0.396390, acc.: 84%] [G loss: 2.377140]\n",
            "119 [ D loss: 0.445989, acc.: 80%] [G loss: 2.471116]\n",
            "120 [ D loss: 0.456102, acc.: 79%] [G loss: 2.778257]\n",
            "121 [ D loss: 0.400666, acc.: 81%] [G loss: 2.826480]\n",
            "122 [ D loss: 0.506101, acc.: 73%] [G loss: 2.618818]\n",
            "123 [ D loss: 0.384759, acc.: 83%] [G loss: 2.551315]\n",
            "124 [ D loss: 0.491008, acc.: 77%] [G loss: 2.741395]\n",
            "125 [ D loss: 0.429029, acc.: 81%] [G loss: 2.654593]\n",
            "126 [ D loss: 0.415203, acc.: 84%] [G loss: 2.681507]\n",
            "127 [ D loss: 0.413448, acc.: 82%] [G loss: 2.665925]\n",
            "128 [ D loss: 0.381148, acc.: 86%] [G loss: 2.795516]\n",
            "129 [ D loss: 0.394296, acc.: 85%] [G loss: 2.859110]\n",
            "130 [ D loss: 0.408595, acc.: 78%] [G loss: 2.855901]\n",
            "131 [ D loss: 0.485640, acc.: 74%] [G loss: 2.644258]\n",
            "132 [ D loss: 0.386092, acc.: 85%] [G loss: 2.382458]\n",
            "133 [ D loss: 0.441928, acc.: 84%] [G loss: 2.739445]\n",
            "134 [ D loss: 0.430049, acc.: 81%] [G loss: 2.536811]\n",
            "135 [ D loss: 0.351412, acc.: 88%] [G loss: 2.642664]\n",
            "136 [ D loss: 0.457455, acc.: 78%] [G loss: 2.796606]\n",
            "137 [ D loss: 0.543178, acc.: 70%] [G loss: 3.186056]\n",
            "138 [ D loss: 0.420420, acc.: 82%] [G loss: 3.106059]\n",
            "139 [ D loss: 0.423249, acc.: 84%] [G loss: 2.774683]\n",
            "140 [ D loss: 0.387561, acc.: 86%] [G loss: 2.747287]\n",
            "141 [ D loss: 0.411600, acc.: 83%] [G loss: 3.057138]\n",
            "142 [ D loss: 0.409290, acc.: 81%] [G loss: 2.970086]\n",
            "143 [ D loss: 0.459599, acc.: 77%] [G loss: 3.083459]\n",
            "144 [ D loss: 0.461363, acc.: 76%] [G loss: 2.881045]\n",
            "145 [ D loss: 0.461274, acc.: 75%] [G loss: 2.764674]\n",
            "146 [ D loss: 0.393362, acc.: 82%] [G loss: 3.055053]\n",
            "147 [ D loss: 0.453773, acc.: 80%] [G loss: 3.164912]\n",
            "148 [ D loss: 0.359631, acc.: 86%] [G loss: 3.036067]\n",
            "149 [ D loss: 0.456945, acc.: 80%] [G loss: 3.004850]\n",
            "150 [ D loss: 0.413086, acc.: 80%] [G loss: 3.011084]\n",
            "151 [ D loss: 0.418440, acc.: 82%] [G loss: 3.054772]\n",
            "152 [ D loss: 0.417051, acc.: 82%] [G loss: 2.898231]\n",
            "153 [ D loss: 0.422495, acc.: 80%] [G loss: 2.673452]\n",
            "154 [ D loss: 0.448990, acc.: 76%] [G loss: 2.929092]\n",
            "155 [ D loss: 0.417982, acc.: 84%] [G loss: 3.106920]\n",
            "156 [ D loss: 0.340527, acc.: 90%] [G loss: 2.976266]\n",
            "157 [ D loss: 0.378448, acc.: 84%] [G loss: 2.463437]\n",
            "158 [ D loss: 0.401601, acc.: 84%] [G loss: 2.899173]\n",
            "159 [ D loss: 0.353812, acc.: 88%] [G loss: 2.951904]\n",
            "160 [ D loss: 0.335044, acc.: 87%] [G loss: 3.006239]\n",
            "161 [ D loss: 0.359170, acc.: 82%] [G loss: 2.859949]\n",
            "162 [ D loss: 0.378796, acc.: 87%] [G loss: 3.001648]\n",
            "163 [ D loss: 0.376860, acc.: 83%] [G loss: 2.969818]\n",
            "164 [ D loss: 0.343383, acc.: 87%] [G loss: 2.791567]\n",
            "165 [ D loss: 0.437314, acc.: 77%] [G loss: 2.998265]\n",
            "166 [ D loss: 0.341135, acc.: 87%] [G loss: 3.172405]\n",
            "167 [ D loss: 0.386389, acc.: 84%] [G loss: 3.182045]\n",
            "168 [ D loss: 0.380429, acc.: 81%] [G loss: 2.829573]\n",
            "169 [ D loss: 0.343589, acc.: 88%] [G loss: 2.764441]\n",
            "170 [ D loss: 0.394946, acc.: 88%] [G loss: 3.117594]\n",
            "171 [ D loss: 0.397510, acc.: 85%] [G loss: 3.345906]\n",
            "172 [ D loss: 0.402873, acc.: 81%] [G loss: 3.529071]\n",
            "173 [ D loss: 0.388803, acc.: 84%] [G loss: 3.314977]\n",
            "174 [ D loss: 0.375362, acc.: 83%] [G loss: 3.285408]\n",
            "175 [ D loss: 0.372017, acc.: 83%] [G loss: 3.045820]\n",
            "176 [ D loss: 0.376441, acc.: 80%] [G loss: 3.130840]\n",
            "177 [ D loss: 0.486088, acc.: 77%] [G loss: 3.213364]\n",
            "178 [ D loss: 0.382833, acc.: 84%] [G loss: 3.187516]\n",
            "179 [ D loss: 0.389337, acc.: 86%] [G loss: 2.872092]\n",
            "180 [ D loss: 0.526615, acc.: 79%] [G loss: 2.737572]\n",
            "181 [ D loss: 0.346978, acc.: 87%] [G loss: 3.013978]\n",
            "182 [ D loss: 0.511673, acc.: 75%] [G loss: 3.077056]\n",
            "183 [ D loss: 0.486455, acc.: 78%] [G loss: 3.300614]\n",
            "184 [ D loss: 0.407924, acc.: 80%] [G loss: 3.234053]\n",
            "185 [ D loss: 0.443460, acc.: 79%] [G loss: 3.065436]\n",
            "186 [ D loss: 0.531925, acc.: 73%] [G loss: 3.176437]\n",
            "187 [ D loss: 0.407821, acc.: 84%] [G loss: 2.948859]\n",
            "188 [ D loss: 0.553038, acc.: 73%] [G loss: 3.137507]\n",
            "189 [ D loss: 0.516271, acc.: 73%] [G loss: 3.194326]\n",
            "190 [ D loss: 0.517316, acc.: 74%] [G loss: 3.102673]\n",
            "191 [ D loss: 0.530845, acc.: 73%] [G loss: 2.888868]\n",
            "192 [ D loss: 0.550855, acc.: 73%] [G loss: 3.089658]\n",
            "193 [ D loss: 0.505862, acc.: 77%] [G loss: 3.112785]\n",
            "194 [ D loss: 0.462026, acc.: 75%] [G loss: 3.020288]\n",
            "195 [ D loss: 0.472853, acc.: 79%] [G loss: 2.875860]\n",
            "196 [ D loss: 0.489249, acc.: 73%] [G loss: 2.970906]\n",
            "197 [ D loss: 0.464380, acc.: 76%] [G loss: 3.379105]\n",
            "198 [ D loss: 0.427943, acc.: 77%] [G loss: 2.987293]\n",
            "199 [ D loss: 0.492382, acc.: 73%] [G loss: 3.178822]\n",
            "200 [ D loss: 0.438524, acc.: 78%] [G loss: 3.015651]\n",
            "201 [ D loss: 0.513851, acc.: 71%] [G loss: 3.370407]\n",
            "202 [ D loss: 0.495490, acc.: 73%] [G loss: 3.333395]\n",
            "203 [ D loss: 0.518022, acc.: 72%] [G loss: 3.196991]\n",
            "204 [ D loss: 0.488690, acc.: 72%] [G loss: 2.951707]\n",
            "205 [ D loss: 0.545349, acc.: 72%] [G loss: 3.058146]\n",
            "206 [ D loss: 0.510610, acc.: 77%] [G loss: 3.264596]\n",
            "207 [ D loss: 0.490523, acc.: 70%] [G loss: 2.952811]\n",
            "208 [ D loss: 0.507892, acc.: 78%] [G loss: 2.820734]\n",
            "209 [ D loss: 0.448361, acc.: 78%] [G loss: 3.033838]\n",
            "210 [ D loss: 0.463539, acc.: 76%] [G loss: 2.854841]\n",
            "211 [ D loss: 0.500265, acc.: 76%] [G loss: 2.654641]\n",
            "212 [ D loss: 0.463647, acc.: 77%] [G loss: 3.364722]\n",
            "213 [ D loss: 0.490057, acc.: 74%] [G loss: 3.088418]\n",
            "214 [ D loss: 0.544044, acc.: 68%] [G loss: 2.716752]\n",
            "215 [ D loss: 0.458572, acc.: 82%] [G loss: 2.962249]\n",
            "216 [ D loss: 0.523056, acc.: 73%] [G loss: 3.034408]\n",
            "217 [ D loss: 0.516768, acc.: 70%] [G loss: 3.272669]\n",
            "218 [ D loss: 0.523273, acc.: 73%] [G loss: 2.691928]\n",
            "219 [ D loss: 0.553228, acc.: 70%] [G loss: 3.093401]\n",
            "220 [ D loss: 0.457754, acc.: 77%] [G loss: 2.984040]\n",
            "221 [ D loss: 0.457985, acc.: 80%] [G loss: 2.685794]\n",
            "222 [ D loss: 0.526424, acc.: 77%] [G loss: 2.824644]\n",
            "223 [ D loss: 0.546852, acc.: 71%] [G loss: 3.176931]\n",
            "224 [ D loss: 0.497657, acc.: 70%] [G loss: 2.903866]\n",
            "225 [ D loss: 0.575451, acc.: 64%] [G loss: 2.732114]\n",
            "226 [ D loss: 0.531665, acc.: 71%] [G loss: 2.843327]\n",
            "227 [ D loss: 0.534332, acc.: 70%] [G loss: 2.835709]\n",
            "228 [ D loss: 0.641751, acc.: 53%] [G loss: 3.052036]\n",
            "229 [ D loss: 0.553065, acc.: 62%] [G loss: 2.709082]\n",
            "230 [ D loss: 0.560364, acc.: 66%] [G loss: 2.900373]\n",
            "231 [ D loss: 0.626492, acc.: 59%] [G loss: 3.247129]\n",
            "232 [ D loss: 0.529899, acc.: 69%] [G loss: 3.078449]\n",
            "233 [ D loss: 0.591904, acc.: 65%] [G loss: 2.912856]\n",
            "234 [ D loss: 0.575310, acc.: 66%] [G loss: 2.925764]\n",
            "235 [ D loss: 0.615539, acc.: 66%] [G loss: 2.745293]\n",
            "236 [ D loss: 0.600035, acc.: 72%] [G loss: 2.791407]\n",
            "237 [ D loss: 0.617929, acc.: 64%] [G loss: 3.156253]\n",
            "238 [ D loss: 0.537767, acc.: 66%] [G loss: 2.915518]\n",
            "239 [ D loss: 0.642591, acc.: 59%] [G loss: 2.647604]\n",
            "240 [ D loss: 0.653962, acc.: 59%] [G loss: 3.045264]\n",
            "241 [ D loss: 0.568504, acc.: 64%] [G loss: 2.670588]\n",
            "242 [ D loss: 0.616654, acc.: 63%] [G loss: 2.950462]\n",
            "243 [ D loss: 0.605062, acc.: 60%] [G loss: 2.736760]\n",
            "244 [ D loss: 0.623981, acc.: 63%] [G loss: 2.750490]\n",
            "245 [ D loss: 0.632666, acc.: 62%] [G loss: 2.507985]\n",
            "246 [ D loss: 0.555055, acc.: 70%] [G loss: 2.428577]\n",
            "247 [ D loss: 0.546168, acc.: 66%] [G loss: 2.488784]\n",
            "248 [ D loss: 0.587683, acc.: 65%] [G loss: 2.555649]\n",
            "249 [ D loss: 0.527565, acc.: 69%] [G loss: 2.708706]\n",
            "250 [ D loss: 0.579298, acc.: 61%] [G loss: 2.514173]\n",
            "251 [ D loss: 0.596928, acc.: 69%] [G loss: 3.033694]\n",
            "252 [ D loss: 0.608477, acc.: 61%] [G loss: 2.652656]\n",
            "253 [ D loss: 0.671073, acc.: 54%] [G loss: 2.715715]\n",
            "254 [ D loss: 0.629056, acc.: 62%] [G loss: 2.562007]\n",
            "255 [ D loss: 0.584619, acc.: 63%] [G loss: 2.582847]\n",
            "256 [ D loss: 0.564373, acc.: 64%] [G loss: 2.410559]\n",
            "257 [ D loss: 0.604863, acc.: 63%] [G loss: 2.508950]\n",
            "258 [ D loss: 0.510266, acc.: 77%] [G loss: 2.462422]\n",
            "259 [ D loss: 0.528061, acc.: 69%] [G loss: 2.311296]\n",
            "260 [ D loss: 0.564781, acc.: 65%] [G loss: 2.584559]\n",
            "261 [ D loss: 0.488861, acc.: 72%] [G loss: 2.523857]\n",
            "262 [ D loss: 0.537511, acc.: 68%] [G loss: 2.493587]\n",
            "263 [ D loss: 0.563844, acc.: 65%] [G loss: 2.384507]\n",
            "264 [ D loss: 0.547579, acc.: 71%] [G loss: 2.428082]\n",
            "265 [ D loss: 0.500471, acc.: 74%] [G loss: 2.522249]\n",
            "266 [ D loss: 0.509700, acc.: 73%] [G loss: 2.556842]\n",
            "267 [ D loss: 0.528916, acc.: 77%] [G loss: 2.604452]\n",
            "268 [ D loss: 0.567629, acc.: 62%] [G loss: 2.150571]\n",
            "269 [ D loss: 0.594455, acc.: 72%] [G loss: 2.288573]\n",
            "270 [ D loss: 0.580285, acc.: 70%] [G loss: 2.401801]\n",
            "271 [ D loss: 0.594445, acc.: 69%] [G loss: 2.375848]\n",
            "272 [ D loss: 0.630644, acc.: 64%] [G loss: 2.216068]\n",
            "273 [ D loss: 0.629163, acc.: 60%] [G loss: 2.207037]\n",
            "274 [ D loss: 0.576940, acc.: 66%] [G loss: 1.943014]\n",
            "275 [ D loss: 0.649632, acc.: 62%] [G loss: 2.268879]\n",
            "276 [ D loss: 0.572817, acc.: 70%] [G loss: 2.423200]\n",
            "277 [ D loss: 0.641404, acc.: 59%] [G loss: 2.084225]\n",
            "278 [ D loss: 0.635982, acc.: 54%] [G loss: 2.034386]\n",
            "279 [ D loss: 0.637060, acc.: 59%] [G loss: 2.089134]\n",
            "280 [ D loss: 0.601236, acc.: 65%] [G loss: 2.268675]\n",
            "281 [ D loss: 0.608041, acc.: 65%] [G loss: 2.184419]\n",
            "282 [ D loss: 0.584133, acc.: 69%] [G loss: 2.155532]\n",
            "283 [ D loss: 0.589782, acc.: 66%] [G loss: 2.123311]\n",
            "284 [ D loss: 0.583009, acc.: 66%] [G loss: 2.191054]\n",
            "285 [ D loss: 0.552540, acc.: 72%] [G loss: 2.172499]\n",
            "286 [ D loss: 0.598233, acc.: 64%] [G loss: 2.127400]\n",
            "287 [ D loss: 0.607775, acc.: 61%] [G loss: 2.148888]\n",
            "288 [ D loss: 0.553384, acc.: 70%] [G loss: 2.150985]\n",
            "289 [ D loss: 0.570746, acc.: 70%] [G loss: 2.213687]\n",
            "290 [ D loss: 0.565616, acc.: 70%] [G loss: 2.133742]\n",
            "291 [ D loss: 0.602766, acc.: 66%] [G loss: 2.176792]\n",
            "292 [ D loss: 0.591748, acc.: 62%] [G loss: 2.070666]\n",
            "293 [ D loss: 0.583335, acc.: 67%] [G loss: 2.006328]\n",
            "294 [ D loss: 0.580440, acc.: 64%] [G loss: 1.958960]\n",
            "295 [ D loss: 0.555722, acc.: 73%] [G loss: 2.134026]\n",
            "296 [ D loss: 0.574468, acc.: 63%] [G loss: 1.877099]\n",
            "297 [ D loss: 0.603553, acc.: 60%] [G loss: 2.192946]\n",
            "298 [ D loss: 0.527329, acc.: 72%] [G loss: 2.262596]\n",
            "299 [ D loss: 0.578110, acc.: 69%] [G loss: 2.137617]\n",
            "300 [ D loss: 0.560914, acc.: 68%] [G loss: 2.119072]\n",
            "301 [ D loss: 0.591419, acc.: 64%] [G loss: 1.987693]\n",
            "302 [ D loss: 0.585567, acc.: 69%] [G loss: 1.988389]\n",
            "303 [ D loss: 0.606294, acc.: 62%] [G loss: 1.995116]\n",
            "304 [ D loss: 0.682456, acc.: 53%] [G loss: 1.990632]\n",
            "305 [ D loss: 0.601320, acc.: 65%] [G loss: 1.886780]\n",
            "306 [ D loss: 0.616323, acc.: 67%] [G loss: 1.992941]\n",
            "307 [ D loss: 0.606271, acc.: 68%] [G loss: 2.070689]\n",
            "308 [ D loss: 0.629000, acc.: 61%] [G loss: 1.912792]\n",
            "309 [ D loss: 0.592181, acc.: 64%] [G loss: 1.996302]\n",
            "310 [ D loss: 0.578059, acc.: 65%] [G loss: 2.020011]\n",
            "311 [ D loss: 0.620792, acc.: 62%] [G loss: 1.925700]\n",
            "312 [ D loss: 0.579802, acc.: 61%] [G loss: 1.819078]\n",
            "313 [ D loss: 0.601458, acc.: 59%] [G loss: 1.773764]\n",
            "314 [ D loss: 0.574340, acc.: 63%] [G loss: 1.948561]\n",
            "315 [ D loss: 0.601481, acc.: 61%] [G loss: 2.002468]\n",
            "316 [ D loss: 0.586069, acc.: 63%] [G loss: 2.087668]\n",
            "317 [ D loss: 0.623458, acc.: 55%] [G loss: 1.959661]\n",
            "318 [ D loss: 0.606721, acc.: 60%] [G loss: 1.937266]\n",
            "319 [ D loss: 0.568369, acc.: 69%] [G loss: 1.933572]\n",
            "320 [ D loss: 0.598159, acc.: 61%] [G loss: 1.833935]\n",
            "321 [ D loss: 0.658212, acc.: 57%] [G loss: 1.975335]\n",
            "322 [ D loss: 0.649766, acc.: 55%] [G loss: 1.907198]\n",
            "323 [ D loss: 0.621694, acc.: 57%] [G loss: 1.845314]\n",
            "324 [ D loss: 0.659959, acc.: 50%] [G loss: 1.819350]\n",
            "325 [ D loss: 0.687992, acc.: 50%] [G loss: 1.842706]\n",
            "326 [ D loss: 0.611104, acc.: 62%] [G loss: 1.790606]\n",
            "327 [ D loss: 0.603808, acc.: 62%] [G loss: 1.765636]\n",
            "328 [ D loss: 0.624086, acc.: 53%] [G loss: 1.734053]\n",
            "329 [ D loss: 0.657162, acc.: 51%] [G loss: 1.638113]\n",
            "330 [ D loss: 0.656574, acc.: 51%] [G loss: 1.698004]\n",
            "331 [ D loss: 0.642751, acc.: 55%] [G loss: 1.750905]\n",
            "332 [ D loss: 0.600523, acc.: 58%] [G loss: 1.749272]\n",
            "333 [ D loss: 0.600427, acc.: 57%] [G loss: 1.751444]\n",
            "334 [ D loss: 0.632518, acc.: 55%] [G loss: 1.698436]\n",
            "335 [ D loss: 0.610714, acc.: 59%] [G loss: 1.765414]\n",
            "336 [ D loss: 0.622693, acc.: 56%] [G loss: 1.674686]\n",
            "337 [ D loss: 0.603475, acc.: 59%] [G loss: 1.693629]\n",
            "338 [ D loss: 0.581910, acc.: 63%] [G loss: 1.679457]\n",
            "339 [ D loss: 0.574537, acc.: 66%] [G loss: 1.686888]\n",
            "340 [ D loss: 0.608527, acc.: 60%] [G loss: 1.667050]\n",
            "341 [ D loss: 0.545990, acc.: 69%] [G loss: 1.695175]\n",
            "342 [ D loss: 0.571632, acc.: 64%] [G loss: 1.716507]\n",
            "343 [ D loss: 0.616774, acc.: 61%] [G loss: 1.743947]\n",
            "344 [ D loss: 0.553623, acc.: 67%] [G loss: 1.654892]\n",
            "345 [ D loss: 0.579538, acc.: 66%] [G loss: 1.597674]\n",
            "346 [ D loss: 0.613439, acc.: 61%] [G loss: 1.654117]\n",
            "347 [ D loss: 0.635123, acc.: 58%] [G loss: 1.776627]\n",
            "348 [ D loss: 0.606346, acc.: 61%] [G loss: 1.749901]\n",
            "349 [ D loss: 0.658152, acc.: 53%] [G loss: 1.696364]\n",
            "350 [ D loss: 0.605524, acc.: 66%] [G loss: 1.629388]\n",
            "351 [ D loss: 0.605978, acc.: 63%] [G loss: 1.624393]\n",
            "352 [ D loss: 0.606990, acc.: 60%] [G loss: 1.666924]\n",
            "353 [ D loss: 0.594011, acc.: 59%] [G loss: 1.631547]\n",
            "354 [ D loss: 0.616662, acc.: 60%] [G loss: 1.714228]\n",
            "355 [ D loss: 0.580088, acc.: 62%] [G loss: 1.717680]\n",
            "356 [ D loss: 0.607787, acc.: 61%] [G loss: 1.739436]\n",
            "357 [ D loss: 0.626523, acc.: 59%] [G loss: 1.748748]\n",
            "358 [ D loss: 0.580816, acc.: 62%] [G loss: 1.710123]\n",
            "359 [ D loss: 0.632160, acc.: 58%] [G loss: 1.617215]\n",
            "360 [ D loss: 0.604378, acc.: 63%] [G loss: 1.572167]\n",
            "361 [ D loss: 0.632697, acc.: 61%] [G loss: 1.514565]\n",
            "362 [ D loss: 0.606070, acc.: 64%] [G loss: 1.639042]\n",
            "363 [ D loss: 0.616539, acc.: 55%] [G loss: 1.617933]\n",
            "364 [ D loss: 0.609403, acc.: 60%] [G loss: 1.606240]\n",
            "365 [ D loss: 0.590995, acc.: 64%] [G loss: 1.660643]\n",
            "366 [ D loss: 0.555887, acc.: 68%] [G loss: 1.587125]\n",
            "367 [ D loss: 0.590631, acc.: 62%] [G loss: 1.644437]\n",
            "368 [ D loss: 0.620053, acc.: 59%] [G loss: 1.607317]\n",
            "369 [ D loss: 0.602981, acc.: 59%] [G loss: 1.536159]\n",
            "370 [ D loss: 0.620984, acc.: 59%] [G loss: 1.564672]\n",
            "371 [ D loss: 0.570231, acc.: 66%] [G loss: 1.681242]\n",
            "372 [ D loss: 0.590203, acc.: 62%] [G loss: 1.628400]\n",
            "373 [ D loss: 0.587214, acc.: 61%] [G loss: 1.547433]\n",
            "374 [ D loss: 0.634116, acc.: 52%] [G loss: 1.632747]\n",
            "375 [ D loss: 0.587830, acc.: 62%] [G loss: 1.655467]\n",
            "376 [ D loss: 0.573833, acc.: 66%] [G loss: 1.626326]\n",
            "377 [ D loss: 0.583170, acc.: 70%] [G loss: 1.650648]\n",
            "378 [ D loss: 0.594432, acc.: 63%] [G loss: 1.649071]\n",
            "379 [ D loss: 0.610572, acc.: 58%] [G loss: 1.595601]\n",
            "380 [ D loss: 0.628400, acc.: 55%] [G loss: 1.581142]\n",
            "381 [ D loss: 0.574558, acc.: 71%] [G loss: 1.570575]\n",
            "382 [ D loss: 0.581477, acc.: 65%] [G loss: 1.605243]\n",
            "383 [ D loss: 0.597599, acc.: 63%] [G loss: 1.669240]\n",
            "384 [ D loss: 0.609458, acc.: 61%] [G loss: 1.559386]\n",
            "385 [ D loss: 0.607310, acc.: 63%] [G loss: 1.514688]\n",
            "386 [ D loss: 0.586118, acc.: 64%] [G loss: 1.609763]\n",
            "387 [ D loss: 0.618582, acc.: 59%] [G loss: 1.599941]\n",
            "388 [ D loss: 0.632455, acc.: 60%] [G loss: 1.646511]\n",
            "389 [ D loss: 0.581607, acc.: 68%] [G loss: 1.617596]\n",
            "390 [ D loss: 0.608024, acc.: 59%] [G loss: 1.528468]\n",
            "391 [ D loss: 0.589763, acc.: 60%] [G loss: 1.477521]\n",
            "392 [ D loss: 0.620769, acc.: 63%] [G loss: 1.541436]\n",
            "393 [ D loss: 0.600338, acc.: 62%] [G loss: 1.551696]\n",
            "394 [ D loss: 0.640181, acc.: 60%] [G loss: 1.614071]\n",
            "395 [ D loss: 0.644598, acc.: 55%] [G loss: 1.491177]\n",
            "396 [ D loss: 0.609173, acc.: 66%] [G loss: 1.471788]\n",
            "397 [ D loss: 0.598629, acc.: 66%] [G loss: 1.468460]\n",
            "398 [ D loss: 0.628268, acc.: 55%] [G loss: 1.519321]\n",
            "399 [ D loss: 0.599947, acc.: 61%] [G loss: 1.526289]\n",
            "400 [ D loss: 0.579041, acc.: 66%] [G loss: 1.533570]\n",
            "401 [ D loss: 0.635657, acc.: 56%] [G loss: 1.441815]\n",
            "402 [ D loss: 0.609784, acc.: 66%] [G loss: 1.470300]\n",
            "403 [ D loss: 0.639522, acc.: 52%] [G loss: 1.485815]\n",
            "404 [ D loss: 0.610605, acc.: 61%] [G loss: 1.470788]\n",
            "405 [ D loss: 0.625394, acc.: 55%] [G loss: 1.496644]\n",
            "406 [ D loss: 0.599098, acc.: 63%] [G loss: 1.557900]\n",
            "407 [ D loss: 0.592768, acc.: 62%] [G loss: 1.478076]\n",
            "408 [ D loss: 0.608434, acc.: 67%] [G loss: 1.511481]\n",
            "409 [ D loss: 0.629766, acc.: 56%] [G loss: 1.477757]\n",
            "410 [ D loss: 0.613061, acc.: 59%] [G loss: 1.564888]\n",
            "411 [ D loss: 0.626716, acc.: 62%] [G loss: 1.473774]\n",
            "412 [ D loss: 0.599949, acc.: 67%] [G loss: 1.448959]\n",
            "413 [ D loss: 0.584649, acc.: 72%] [G loss: 1.517506]\n",
            "414 [ D loss: 0.579022, acc.: 67%] [G loss: 1.519565]\n",
            "415 [ D loss: 0.609061, acc.: 63%] [G loss: 1.518928]\n",
            "416 [ D loss: 0.593975, acc.: 66%] [G loss: 1.405033]\n",
            "417 [ D loss: 0.609480, acc.: 67%] [G loss: 1.497502]\n",
            "418 [ D loss: 0.628449, acc.: 62%] [G loss: 1.515909]\n",
            "419 [ D loss: 0.640859, acc.: 64%] [G loss: 1.476169]\n",
            "420 [ D loss: 0.582593, acc.: 70%] [G loss: 1.514850]\n",
            "421 [ D loss: 0.580974, acc.: 67%] [G loss: 1.588228]\n",
            "422 [ D loss: 0.628290, acc.: 55%] [G loss: 1.403309]\n",
            "423 [ D loss: 0.608249, acc.: 61%] [G loss: 1.364322]\n",
            "424 [ D loss: 0.589667, acc.: 68%] [G loss: 1.452716]\n",
            "425 [ D loss: 0.592657, acc.: 64%] [G loss: 1.488409]\n",
            "426 [ D loss: 0.595097, acc.: 67%] [G loss: 1.504012]\n",
            "427 [ D loss: 0.658814, acc.: 62%] [G loss: 1.373176]\n",
            "428 [ D loss: 0.628030, acc.: 62%] [G loss: 1.447027]\n",
            "429 [ D loss: 0.600596, acc.: 70%] [G loss: 1.517115]\n",
            "430 [ D loss: 0.625974, acc.: 63%] [G loss: 1.469440]\n",
            "431 [ D loss: 0.595453, acc.: 73%] [G loss: 1.424748]\n",
            "432 [ D loss: 0.617854, acc.: 63%] [G loss: 1.465215]\n",
            "433 [ D loss: 0.617311, acc.: 70%] [G loss: 1.558450]\n",
            "434 [ D loss: 0.615232, acc.: 64%] [G loss: 1.595984]\n",
            "435 [ D loss: 0.643809, acc.: 57%] [G loss: 1.452904]\n",
            "436 [ D loss: 0.630229, acc.: 62%] [G loss: 1.477552]\n",
            "437 [ D loss: 0.633498, acc.: 66%] [G loss: 1.463237]\n",
            "438 [ D loss: 0.615676, acc.: 74%] [G loss: 1.521428]\n",
            "439 [ D loss: 0.648286, acc.: 61%] [G loss: 1.500736]\n",
            "440 [ D loss: 0.600734, acc.: 68%] [G loss: 1.447574]\n",
            "441 [ D loss: 0.617907, acc.: 68%] [G loss: 1.384813]\n",
            "442 [ D loss: 0.672191, acc.: 59%] [G loss: 1.329581]\n",
            "443 [ D loss: 0.608421, acc.: 67%] [G loss: 1.444839]\n",
            "444 [ D loss: 0.615176, acc.: 63%] [G loss: 1.473833]\n",
            "445 [ D loss: 0.599970, acc.: 66%] [G loss: 1.449316]\n",
            "446 [ D loss: 0.636491, acc.: 61%] [G loss: 1.391414]\n",
            "447 [ D loss: 0.616454, acc.: 70%] [G loss: 1.472436]\n",
            "448 [ D loss: 0.581583, acc.: 76%] [G loss: 1.541155]\n",
            "449 [ D loss: 0.584289, acc.: 70%] [G loss: 1.485154]\n",
            "450 [ D loss: 0.589893, acc.: 73%] [G loss: 1.429988]\n",
            "451 [ D loss: 0.625548, acc.: 64%] [G loss: 1.507814]\n",
            "452 [ D loss: 0.601869, acc.: 67%] [G loss: 1.456774]\n",
            "453 [ D loss: 0.584457, acc.: 70%] [G loss: 1.419588]\n",
            "454 [ D loss: 0.611881, acc.: 70%] [G loss: 1.388947]\n",
            "455 [ D loss: 0.607225, acc.: 71%] [G loss: 1.456900]\n",
            "456 [ D loss: 0.613823, acc.: 71%] [G loss: 1.442388]\n",
            "457 [ D loss: 0.604323, acc.: 73%] [G loss: 1.332203]\n",
            "458 [ D loss: 0.622702, acc.: 69%] [G loss: 1.363394]\n",
            "459 [ D loss: 0.615746, acc.: 66%] [G loss: 1.341381]\n",
            "460 [ D loss: 0.623208, acc.: 65%] [G loss: 1.467295]\n",
            "461 [ D loss: 0.622366, acc.: 68%] [G loss: 1.333221]\n",
            "462 [ D loss: 0.649731, acc.: 62%] [G loss: 1.340976]\n",
            "463 [ D loss: 0.606473, acc.: 77%] [G loss: 1.346167]\n",
            "464 [ D loss: 0.587848, acc.: 70%] [G loss: 1.439241]\n",
            "465 [ D loss: 0.609354, acc.: 64%] [G loss: 1.404882]\n",
            "466 [ D loss: 0.657070, acc.: 59%] [G loss: 1.398996]\n",
            "467 [ D loss: 0.573953, acc.: 70%] [G loss: 1.394401]\n",
            "468 [ D loss: 0.587380, acc.: 64%] [G loss: 1.404746]\n",
            "469 [ D loss: 0.614658, acc.: 62%] [G loss: 1.291937]\n",
            "470 [ D loss: 0.635884, acc.: 66%] [G loss: 1.353549]\n",
            "471 [ D loss: 0.613381, acc.: 69%] [G loss: 1.454586]\n",
            "472 [ D loss: 0.656330, acc.: 52%] [G loss: 1.411288]\n",
            "473 [ D loss: 0.612528, acc.: 65%] [G loss: 1.396928]\n",
            "474 [ D loss: 0.598478, acc.: 66%] [G loss: 1.482625]\n",
            "475 [ D loss: 0.553740, acc.: 69%] [G loss: 1.446358]\n",
            "476 [ D loss: 0.587669, acc.: 71%] [G loss: 1.633796]\n",
            "477 [ D loss: 0.585692, acc.: 68%] [G loss: 1.618751]\n",
            "478 [ D loss: 0.592600, acc.: 74%] [G loss: 1.455758]\n",
            "479 [ D loss: 0.633923, acc.: 63%] [G loss: 1.441761]\n",
            "480 [ D loss: 0.589071, acc.: 73%] [G loss: 1.499776]\n",
            "481 [ D loss: 0.604981, acc.: 65%] [G loss: 1.562280]\n",
            "482 [ D loss: 0.592005, acc.: 71%] [G loss: 1.526023]\n",
            "483 [ D loss: 0.593026, acc.: 66%] [G loss: 1.448014]\n",
            "484 [ D loss: 0.609841, acc.: 66%] [G loss: 1.444721]\n",
            "485 [ D loss: 0.593742, acc.: 70%] [G loss: 1.529976]\n",
            "486 [ D loss: 0.546510, acc.: 81%] [G loss: 1.527069]\n",
            "487 [ D loss: 0.564440, acc.: 75%] [G loss: 1.630951]\n",
            "488 [ D loss: 0.559814, acc.: 73%] [G loss: 1.599025]\n",
            "489 [ D loss: 0.583566, acc.: 71%] [G loss: 1.537141]\n",
            "490 [ D loss: 0.605277, acc.: 69%] [G loss: 1.445420]\n",
            "491 [ D loss: 0.571438, acc.: 77%] [G loss: 1.503715]\n",
            "492 [ D loss: 0.556512, acc.: 78%] [G loss: 1.548263]\n",
            "493 [ D loss: 0.634743, acc.: 62%] [G loss: 1.375188]\n",
            "494 [ D loss: 0.601001, acc.: 67%] [G loss: 1.438279]\n",
            "495 [ D loss: 0.578932, acc.: 64%] [G loss: 1.437060]\n",
            "496 [ D loss: 0.555348, acc.: 70%] [G loss: 1.470329]\n",
            "497 [ D loss: 0.567288, acc.: 70%] [G loss: 1.542718]\n",
            "498 [ D loss: 0.587489, acc.: 66%] [G loss: 1.380457]\n",
            "499 [ D loss: 0.572951, acc.: 71%] [G loss: 1.552220]\n",
            "500 [ D loss: 0.553975, acc.: 73%] [G loss: 1.520788]\n",
            "501 [ D loss: 0.579708, acc.: 71%] [G loss: 1.482399]\n",
            "502 [ D loss: 0.544637, acc.: 76%] [G loss: 1.635816]\n",
            "503 [ D loss: 0.554779, acc.: 76%] [G loss: 1.650105]\n",
            "504 [ D loss: 0.561085, acc.: 71%] [G loss: 1.528962]\n",
            "505 [ D loss: 0.614016, acc.: 66%] [G loss: 1.370734]\n",
            "506 [ D loss: 0.590818, acc.: 73%] [G loss: 1.515571]\n",
            "507 [ D loss: 0.575241, acc.: 66%] [G loss: 1.590802]\n",
            "508 [ D loss: 0.570621, acc.: 71%] [G loss: 1.572800]\n",
            "509 [ D loss: 0.621227, acc.: 61%] [G loss: 1.478938]\n",
            "510 [ D loss: 0.584567, acc.: 71%] [G loss: 1.422707]\n",
            "511 [ D loss: 0.589306, acc.: 73%] [G loss: 1.528404]\n",
            "512 [ D loss: 0.597971, acc.: 72%] [G loss: 1.567172]\n",
            "513 [ D loss: 0.561022, acc.: 77%] [G loss: 1.519380]\n",
            "514 [ D loss: 0.537621, acc.: 79%] [G loss: 1.676941]\n",
            "515 [ D loss: 0.575323, acc.: 67%] [G loss: 1.552531]\n",
            "516 [ D loss: 0.552124, acc.: 75%] [G loss: 1.524457]\n",
            "517 [ D loss: 0.549375, acc.: 84%] [G loss: 1.538825]\n",
            "518 [ D loss: 0.612777, acc.: 71%] [G loss: 1.481036]\n",
            "519 [ D loss: 0.634413, acc.: 67%] [G loss: 1.403740]\n",
            "520 [ D loss: 0.601677, acc.: 72%] [G loss: 1.469117]\n",
            "521 [ D loss: 0.623413, acc.: 62%] [G loss: 1.499977]\n",
            "522 [ D loss: 0.627936, acc.: 68%] [G loss: 1.428760]\n",
            "523 [ D loss: 0.638330, acc.: 64%] [G loss: 1.440387]\n",
            "524 [ D loss: 0.577921, acc.: 73%] [G loss: 1.559783]\n",
            "525 [ D loss: 0.542515, acc.: 80%] [G loss: 1.582785]\n",
            "526 [ D loss: 0.556996, acc.: 71%] [G loss: 1.555666]\n",
            "527 [ D loss: 0.621655, acc.: 64%] [G loss: 1.394374]\n",
            "528 [ D loss: 0.627018, acc.: 66%] [G loss: 1.384082]\n",
            "529 [ D loss: 0.608458, acc.: 68%] [G loss: 1.448496]\n",
            "530 [ D loss: 0.591611, acc.: 69%] [G loss: 1.511712]\n",
            "531 [ D loss: 0.588940, acc.: 70%] [G loss: 1.404678]\n",
            "532 [ D loss: 0.598812, acc.: 69%] [G loss: 1.350871]\n",
            "533 [ D loss: 0.573666, acc.: 72%] [G loss: 1.451421]\n",
            "534 [ D loss: 0.601135, acc.: 67%] [G loss: 1.500363]\n",
            "535 [ D loss: 0.556956, acc.: 70%] [G loss: 1.614105]\n",
            "536 [ D loss: 0.547559, acc.: 70%] [G loss: 1.604130]\n",
            "537 [ D loss: 0.557641, acc.: 67%] [G loss: 1.570469]\n",
            "538 [ D loss: 0.606776, acc.: 70%] [G loss: 1.379220]\n",
            "539 [ D loss: 0.582576, acc.: 78%] [G loss: 1.419617]\n",
            "540 [ D loss: 0.608448, acc.: 73%] [G loss: 1.453178]\n",
            "541 [ D loss: 0.609339, acc.: 69%] [G loss: 1.448640]\n",
            "542 [ D loss: 0.604140, acc.: 66%] [G loss: 1.448643]\n",
            "543 [ D loss: 0.596365, acc.: 70%] [G loss: 1.395442]\n",
            "544 [ D loss: 0.610947, acc.: 67%] [G loss: 1.528642]\n",
            "545 [ D loss: 0.584751, acc.: 70%] [G loss: 1.562963]\n",
            "546 [ D loss: 0.569129, acc.: 73%] [G loss: 1.508636]\n",
            "547 [ D loss: 0.595811, acc.: 77%] [G loss: 1.492559]\n",
            "548 [ D loss: 0.624338, acc.: 67%] [G loss: 1.410443]\n",
            "549 [ D loss: 0.615909, acc.: 67%] [G loss: 1.518814]\n",
            "550 [ D loss: 0.583837, acc.: 69%] [G loss: 1.629509]\n",
            "551 [ D loss: 0.660645, acc.: 55%] [G loss: 1.516297]\n",
            "552 [ D loss: 0.607446, acc.: 66%] [G loss: 1.513903]\n",
            "553 [ D loss: 0.554540, acc.: 75%] [G loss: 1.555001]\n",
            "554 [ D loss: 0.541704, acc.: 78%] [G loss: 1.419713]\n",
            "555 [ D loss: 0.633389, acc.: 64%] [G loss: 1.465813]\n",
            "556 [ D loss: 0.600075, acc.: 70%] [G loss: 1.501436]\n",
            "557 [ D loss: 0.608507, acc.: 66%] [G loss: 1.445946]\n",
            "558 [ D loss: 0.570293, acc.: 72%] [G loss: 1.435002]\n",
            "559 [ D loss: 0.558916, acc.: 73%] [G loss: 1.566102]\n",
            "560 [ D loss: 0.555441, acc.: 73%] [G loss: 1.621780]\n",
            "561 [ D loss: 0.564370, acc.: 77%] [G loss: 1.533151]\n",
            "562 [ D loss: 0.588452, acc.: 75%] [G loss: 1.449738]\n",
            "563 [ D loss: 0.576642, acc.: 74%] [G loss: 1.449597]\n",
            "564 [ D loss: 0.600518, acc.: 70%] [G loss: 1.515074]\n",
            "565 [ D loss: 0.592103, acc.: 67%] [G loss: 1.584960]\n",
            "566 [ D loss: 0.599598, acc.: 62%] [G loss: 1.488551]\n",
            "567 [ D loss: 0.565727, acc.: 73%] [G loss: 1.429458]\n",
            "568 [ D loss: 0.572766, acc.: 74%] [G loss: 1.512529]\n",
            "569 [ D loss: 0.586876, acc.: 65%] [G loss: 1.537512]\n",
            "570 [ D loss: 0.561162, acc.: 71%] [G loss: 1.530229]\n",
            "571 [ D loss: 0.590297, acc.: 70%] [G loss: 1.646396]\n",
            "572 [ D loss: 0.508476, acc.: 84%] [G loss: 1.568549]\n",
            "573 [ D loss: 0.607774, acc.: 65%] [G loss: 1.473413]\n",
            "574 [ D loss: 0.586877, acc.: 72%] [G loss: 1.503436]\n",
            "575 [ D loss: 0.616557, acc.: 62%] [G loss: 1.537485]\n",
            "576 [ D loss: 0.527217, acc.: 84%] [G loss: 1.542106]\n",
            "577 [ D loss: 0.591414, acc.: 72%] [G loss: 1.573984]\n",
            "578 [ D loss: 0.594362, acc.: 68%] [G loss: 1.584947]\n",
            "579 [ D loss: 0.541842, acc.: 72%] [G loss: 1.689200]\n",
            "580 [ D loss: 0.526773, acc.: 75%] [G loss: 1.673842]\n",
            "581 [ D loss: 0.601029, acc.: 62%] [G loss: 1.442459]\n",
            "582 [ D loss: 0.618398, acc.: 62%] [G loss: 1.519573]\n",
            "583 [ D loss: 0.575259, acc.: 71%] [G loss: 1.609381]\n",
            "584 [ D loss: 0.545387, acc.: 72%] [G loss: 1.785808]\n",
            "585 [ D loss: 0.534008, acc.: 75%] [G loss: 1.793353]\n",
            "586 [ D loss: 0.539008, acc.: 81%] [G loss: 1.453198]\n",
            "587 [ D loss: 0.605286, acc.: 73%] [G loss: 1.405023]\n",
            "588 [ D loss: 0.556081, acc.: 76%] [G loss: 1.562423]\n",
            "589 [ D loss: 0.576896, acc.: 66%] [G loss: 1.682553]\n",
            "590 [ D loss: 0.556770, acc.: 71%] [G loss: 1.719641]\n",
            "591 [ D loss: 0.541731, acc.: 73%] [G loss: 1.741191]\n",
            "592 [ D loss: 0.535776, acc.: 80%] [G loss: 1.546795]\n",
            "593 [ D loss: 0.567737, acc.: 74%] [G loss: 1.559660]\n",
            "594 [ D loss: 0.571036, acc.: 75%] [G loss: 1.604484]\n",
            "595 [ D loss: 0.567602, acc.: 73%] [G loss: 1.562783]\n",
            "596 [ D loss: 0.598072, acc.: 66%] [G loss: 1.659642]\n",
            "597 [ D loss: 0.532080, acc.: 66%] [G loss: 1.868178]\n",
            "598 [ D loss: 0.514239, acc.: 78%] [G loss: 1.748453]\n",
            "599 [ D loss: 0.527350, acc.: 84%] [G loss: 1.652234]\n",
            "600 [ D loss: 0.573042, acc.: 74%] [G loss: 1.402571]\n",
            "601 [ D loss: 0.579579, acc.: 73%] [G loss: 1.351825]\n",
            "602 [ D loss: 0.618604, acc.: 66%] [G loss: 1.580396]\n",
            "603 [ D loss: 0.554178, acc.: 72%] [G loss: 1.858680]\n",
            "604 [ D loss: 0.485648, acc.: 74%] [G loss: 2.132586]\n",
            "605 [ D loss: 0.495831, acc.: 80%] [G loss: 1.840218]\n",
            "606 [ D loss: 0.548680, acc.: 75%] [G loss: 1.437813]\n",
            "607 [ D loss: 0.582665, acc.: 74%] [G loss: 1.302391]\n",
            "608 [ D loss: 0.540601, acc.: 74%] [G loss: 1.754256]\n",
            "609 [ D loss: 0.524209, acc.: 78%] [G loss: 1.767581]\n",
            "610 [ D loss: 0.541709, acc.: 77%] [G loss: 1.669821]\n",
            "611 [ D loss: 0.585594, acc.: 65%] [G loss: 1.683718]\n",
            "612 [ D loss: 0.557849, acc.: 73%] [G loss: 1.669630]\n",
            "613 [ D loss: 0.507987, acc.: 79%] [G loss: 1.649222]\n",
            "614 [ D loss: 0.541260, acc.: 77%] [G loss: 1.831647]\n",
            "615 [ D loss: 0.488423, acc.: 74%] [G loss: 2.036740]\n",
            "616 [ D loss: 0.466467, acc.: 82%] [G loss: 2.253329]\n",
            "617 [ D loss: 0.459032, acc.: 80%] [G loss: 1.996185]\n",
            "618 [ D loss: 0.563491, acc.: 69%] [G loss: 1.569305]\n",
            "619 [ D loss: 0.554362, acc.: 76%] [G loss: 1.611039]\n",
            "620 [ D loss: 0.525147, acc.: 74%] [G loss: 1.945791]\n",
            "621 [ D loss: 0.522621, acc.: 74%] [G loss: 2.033446]\n",
            "622 [ D loss: 0.494286, acc.: 80%] [G loss: 1.818611]\n",
            "623 [ D loss: 0.531155, acc.: 80%] [G loss: 1.627234]\n",
            "624 [ D loss: 0.526101, acc.: 79%] [G loss: 1.880909]\n",
            "625 [ D loss: 0.529205, acc.: 72%] [G loss: 1.884749]\n",
            "626 [ D loss: 0.545790, acc.: 74%] [G loss: 1.920190]\n",
            "627 [ D loss: 0.492947, acc.: 83%] [G loss: 1.762106]\n",
            "628 [ D loss: 0.523595, acc.: 80%] [G loss: 1.742210]\n",
            "629 [ D loss: 0.562700, acc.: 70%] [G loss: 1.585971]\n",
            "630 [ D loss: 0.558928, acc.: 71%] [G loss: 1.650273]\n",
            "631 [ D loss: 0.548450, acc.: 73%] [G loss: 1.757308]\n",
            "632 [ D loss: 0.469502, acc.: 82%] [G loss: 1.856784]\n",
            "633 [ D loss: 0.492666, acc.: 75%] [G loss: 1.668654]\n",
            "634 [ D loss: 0.517753, acc.: 83%] [G loss: 1.668147]\n",
            "635 [ D loss: 0.557489, acc.: 77%] [G loss: 1.635372]\n",
            "636 [ D loss: 0.548498, acc.: 72%] [G loss: 1.731884]\n",
            "637 [ D loss: 0.527581, acc.: 71%] [G loss: 1.857738]\n",
            "638 [ D loss: 0.495484, acc.: 78%] [G loss: 2.107050]\n",
            "639 [ D loss: 0.463541, acc.: 84%] [G loss: 2.061323]\n",
            "640 [ D loss: 0.544429, acc.: 77%] [G loss: 1.537226]\n",
            "641 [ D loss: 0.569408, acc.: 72%] [G loss: 1.938280]\n",
            "642 [ D loss: 0.485113, acc.: 76%] [G loss: 2.301400]\n",
            "643 [ D loss: 0.595524, acc.: 72%] [G loss: 1.653719]\n",
            "644 [ D loss: 0.547614, acc.: 75%] [G loss: 1.808386]\n",
            "645 [ D loss: 0.525367, acc.: 74%] [G loss: 2.074650]\n",
            "646 [ D loss: 0.505340, acc.: 77%] [G loss: 1.697073]\n",
            "647 [ D loss: 0.656278, acc.: 62%] [G loss: 1.594942]\n",
            "648 [ D loss: 0.517369, acc.: 81%] [G loss: 1.799800]\n",
            "649 [ D loss: 0.511009, acc.: 73%] [G loss: 2.116549]\n",
            "650 [ D loss: 0.504460, acc.: 74%] [G loss: 2.049064]\n",
            "651 [ D loss: 0.554371, acc.: 71%] [G loss: 1.656874]\n",
            "652 [ D loss: 0.537287, acc.: 77%] [G loss: 1.678453]\n",
            "653 [ D loss: 0.481539, acc.: 78%] [G loss: 2.051334]\n",
            "654 [ D loss: 0.484857, acc.: 78%] [G loss: 2.065955]\n",
            "655 [ D loss: 0.494569, acc.: 80%] [G loss: 1.901020]\n",
            "656 [ D loss: 0.578999, acc.: 71%] [G loss: 1.482988]\n",
            "657 [ D loss: 0.521446, acc.: 78%] [G loss: 1.825484]\n",
            "658 [ D loss: 0.477273, acc.: 75%] [G loss: 2.246527]\n",
            "659 [ D loss: 0.476348, acc.: 78%] [G loss: 2.056960]\n",
            "660 [ D loss: 0.462026, acc.: 81%] [G loss: 1.893582]\n",
            "661 [ D loss: 0.494374, acc.: 82%] [G loss: 1.788621]\n",
            "662 [ D loss: 0.454167, acc.: 82%] [G loss: 1.997730]\n",
            "663 [ D loss: 0.500143, acc.: 83%] [G loss: 1.774046]\n",
            "664 [ D loss: 0.621932, acc.: 66%] [G loss: 1.630407]\n",
            "665 [ D loss: 0.530965, acc.: 80%] [G loss: 1.668256]\n",
            "666 [ D loss: 0.554852, acc.: 70%] [G loss: 1.914927]\n",
            "667 [ D loss: 0.470064, acc.: 79%] [G loss: 2.243828]\n",
            "668 [ D loss: 0.446317, acc.: 82%] [G loss: 1.861335]\n",
            "669 [ D loss: 0.462353, acc.: 84%] [G loss: 1.834574]\n",
            "670 [ D loss: 0.461311, acc.: 86%] [G loss: 1.748207]\n",
            "671 [ D loss: 0.536846, acc.: 83%] [G loss: 1.932377]\n",
            "672 [ D loss: 0.456034, acc.: 84%] [G loss: 2.092987]\n",
            "673 [ D loss: 0.486476, acc.: 76%] [G loss: 2.043886]\n",
            "674 [ D loss: 0.457543, acc.: 79%] [G loss: 2.113810]\n",
            "675 [ D loss: 0.471538, acc.: 83%] [G loss: 1.963068]\n",
            "676 [ D loss: 0.425377, acc.: 91%] [G loss: 2.007037]\n",
            "677 [ D loss: 0.456721, acc.: 84%] [G loss: 2.241171]\n",
            "678 [ D loss: 0.444227, acc.: 86%] [G loss: 2.192338]\n",
            "679 [ D loss: 0.594167, acc.: 68%] [G loss: 1.773665]\n",
            "680 [ D loss: 0.535302, acc.: 76%] [G loss: 1.842891]\n",
            "681 [ D loss: 0.473232, acc.: 84%] [G loss: 1.976780]\n",
            "682 [ D loss: 0.553140, acc.: 72%] [G loss: 2.022643]\n",
            "683 [ D loss: 0.472674, acc.: 73%] [G loss: 2.794101]\n",
            "684 [ D loss: 0.419994, acc.: 88%] [G loss: 2.289351]\n",
            "685 [ D loss: 0.446999, acc.: 82%] [G loss: 2.114769]\n",
            "686 [ D loss: 0.525113, acc.: 80%] [G loss: 1.643988]\n",
            "687 [ D loss: 0.578768, acc.: 71%] [G loss: 1.893630]\n",
            "688 [ D loss: 0.537252, acc.: 72%] [G loss: 2.041147]\n",
            "689 [ D loss: 0.488707, acc.: 76%] [G loss: 2.489112]\n",
            "690 [ D loss: 0.440133, acc.: 85%] [G loss: 2.511051]\n",
            "691 [ D loss: 0.510008, acc.: 83%] [G loss: 1.597734]\n",
            "692 [ D loss: 0.548457, acc.: 84%] [G loss: 1.779259]\n",
            "693 [ D loss: 0.541341, acc.: 73%] [G loss: 1.964954]\n",
            "694 [ D loss: 0.543337, acc.: 71%] [G loss: 1.775114]\n",
            "695 [ D loss: 0.466060, acc.: 84%] [G loss: 1.975088]\n",
            "696 [ D loss: 0.421256, acc.: 81%] [G loss: 2.301704]\n",
            "697 [ D loss: 0.434680, acc.: 85%] [G loss: 2.050914]\n",
            "698 [ D loss: 0.549187, acc.: 74%] [G loss: 1.537218]\n",
            "699 [ D loss: 0.489346, acc.: 80%] [G loss: 1.912850]\n",
            "700 [ D loss: 0.411774, acc.: 88%] [G loss: 2.104515]\n",
            "701 [ D loss: 0.444475, acc.: 83%] [G loss: 2.322241]\n",
            "702 [ D loss: 0.452821, acc.: 84%] [G loss: 2.454690]\n",
            "703 [ D loss: 0.475502, acc.: 77%] [G loss: 2.340482]\n",
            "704 [ D loss: 0.358116, acc.: 91%] [G loss: 2.618624]\n",
            "705 [ D loss: 0.535500, acc.: 73%] [G loss: 1.974578]\n",
            "706 [ D loss: 0.427687, acc.: 89%] [G loss: 2.323182]\n",
            "707 [ D loss: 0.469692, acc.: 78%] [G loss: 2.162831]\n",
            "708 [ D loss: 0.513192, acc.: 76%] [G loss: 1.967936]\n",
            "709 [ D loss: 0.471573, acc.: 77%] [G loss: 2.374884]\n",
            "710 [ D loss: 0.445096, acc.: 82%] [G loss: 2.144124]\n",
            "711 [ D loss: 0.481433, acc.: 79%] [G loss: 2.043058]\n",
            "712 [ D loss: 0.426992, acc.: 88%] [G loss: 2.229971]\n",
            "713 [ D loss: 0.434033, acc.: 83%] [G loss: 2.624806]\n",
            "714 [ D loss: 0.414258, acc.: 86%] [G loss: 2.779654]\n",
            "715 [ D loss: 0.570587, acc.: 73%] [G loss: 1.999165]\n",
            "716 [ D loss: 0.452593, acc.: 83%] [G loss: 2.316752]\n",
            "717 [ D loss: 0.462006, acc.: 82%] [G loss: 1.936274]\n",
            "718 [ D loss: 0.544296, acc.: 77%] [G loss: 1.985161]\n",
            "719 [ D loss: 0.478462, acc.: 80%] [G loss: 2.137599]\n",
            "720 [ D loss: 0.400259, acc.: 87%] [G loss: 2.522368]\n",
            "721 [ D loss: 0.460036, acc.: 78%] [G loss: 2.568075]\n",
            "722 [ D loss: 0.413864, acc.: 90%] [G loss: 1.905815]\n",
            "723 [ D loss: 0.507840, acc.: 80%] [G loss: 2.063445]\n",
            "724 [ D loss: 0.473132, acc.: 80%] [G loss: 2.135769]\n",
            "725 [ D loss: 0.534412, acc.: 69%] [G loss: 2.211628]\n",
            "726 [ D loss: 0.481200, acc.: 80%] [G loss: 2.094296]\n",
            "727 [ D loss: 0.428932, acc.: 88%] [G loss: 1.967907]\n",
            "728 [ D loss: 0.481072, acc.: 82%] [G loss: 2.035951]\n",
            "729 [ D loss: 0.456250, acc.: 82%] [G loss: 2.095526]\n",
            "730 [ D loss: 0.448215, acc.: 80%] [G loss: 2.272411]\n",
            "731 [ D loss: 0.443964, acc.: 80%] [G loss: 2.418414]\n",
            "732 [ D loss: 0.437299, acc.: 84%] [G loss: 2.384227]\n",
            "733 [ D loss: 0.376771, acc.: 92%] [G loss: 2.355384]\n",
            "734 [ D loss: 0.488162, acc.: 84%] [G loss: 1.931937]\n",
            "735 [ D loss: 0.479732, acc.: 80%] [G loss: 2.170002]\n",
            "736 [ D loss: 0.388676, acc.: 84%] [G loss: 2.792619]\n",
            "737 [ D loss: 0.414598, acc.: 84%] [G loss: 2.642179]\n",
            "738 [ D loss: 0.576844, acc.: 73%] [G loss: 1.759744]\n",
            "739 [ D loss: 0.356433, acc.: 97%] [G loss: 2.097847]\n",
            "740 [ D loss: 0.410358, acc.: 84%] [G loss: 2.202176]\n",
            "741 [ D loss: 0.421876, acc.: 80%] [G loss: 2.734127]\n",
            "742 [ D loss: 0.378290, acc.: 88%] [G loss: 2.765015]\n",
            "743 [ D loss: 0.368446, acc.: 88%] [G loss: 2.405686]\n",
            "744 [ D loss: 0.425224, acc.: 85%] [G loss: 1.859399]\n",
            "745 [ D loss: 0.481087, acc.: 79%] [G loss: 1.910070]\n",
            "746 [ D loss: 0.493577, acc.: 75%] [G loss: 2.188686]\n",
            "747 [ D loss: 0.450208, acc.: 83%] [G loss: 1.989294]\n",
            "748 [ D loss: 0.430210, acc.: 80%] [G loss: 2.348435]\n",
            "749 [ D loss: 0.367925, acc.: 86%] [G loss: 3.033020]\n",
            "750 [ D loss: 0.338252, acc.: 98%] [G loss: 2.260984]\n",
            "751 [ D loss: 0.452721, acc.: 80%] [G loss: 2.072731]\n",
            "752 [ D loss: 0.452925, acc.: 81%] [G loss: 2.831276]\n",
            "753 [ D loss: 0.470013, acc.: 79%] [G loss: 2.585666]\n",
            "754 [ D loss: 0.431965, acc.: 90%] [G loss: 2.378382]\n",
            "755 [ D loss: 0.368621, acc.: 93%] [G loss: 2.147263]\n",
            "756 [ D loss: 0.508110, acc.: 80%] [G loss: 1.813889]\n",
            "757 [ D loss: 0.443659, acc.: 88%] [G loss: 2.177978]\n",
            "758 [ D loss: 0.410156, acc.: 87%] [G loss: 1.904797]\n",
            "759 [ D loss: 0.469945, acc.: 82%] [G loss: 2.214584]\n",
            "760 [ D loss: 0.398919, acc.: 87%] [G loss: 2.097099]\n",
            "761 [ D loss: 0.521369, acc.: 76%] [G loss: 2.224936]\n",
            "762 [ D loss: 0.407475, acc.: 85%] [G loss: 2.665593]\n",
            "763 [ D loss: 0.375837, acc.: 86%] [G loss: 2.881517]\n",
            "764 [ D loss: 0.451901, acc.: 84%] [G loss: 1.920627]\n",
            "765 [ D loss: 0.496425, acc.: 72%] [G loss: 2.279832]\n",
            "766 [ D loss: 0.425908, acc.: 83%] [G loss: 2.258702]\n",
            "767 [ D loss: 0.433128, acc.: 85%] [G loss: 2.222559]\n",
            "768 [ D loss: 0.445192, acc.: 80%] [G loss: 2.889681]\n",
            "769 [ D loss: 0.370013, acc.: 89%] [G loss: 2.652521]\n",
            "770 [ D loss: 0.552033, acc.: 76%] [G loss: 1.874810]\n",
            "771 [ D loss: 0.471180, acc.: 78%] [G loss: 1.997880]\n",
            "772 [ D loss: 0.439839, acc.: 89%] [G loss: 2.372387]\n",
            "773 [ D loss: 0.349985, acc.: 89%] [G loss: 2.829020]\n",
            "774 [ D loss: 0.462012, acc.: 80%] [G loss: 2.162302]\n",
            "775 [ D loss: 0.445156, acc.: 84%] [G loss: 2.006531]\n",
            "776 [ D loss: 0.356262, acc.: 96%] [G loss: 2.358420]\n",
            "777 [ D loss: 0.373176, acc.: 94%] [G loss: 2.113362]\n",
            "778 [ D loss: 0.388800, acc.: 91%] [G loss: 2.574090]\n",
            "779 [ D loss: 0.406807, acc.: 89%] [G loss: 2.255245]\n",
            "780 [ D loss: 0.563585, acc.: 73%] [G loss: 2.207297]\n",
            "781 [ D loss: 0.339166, acc.: 95%] [G loss: 2.368161]\n",
            "782 [ D loss: 0.388619, acc.: 93%] [G loss: 2.173092]\n",
            "783 [ D loss: 0.332467, acc.: 93%] [G loss: 2.620643]\n",
            "784 [ D loss: 0.450635, acc.: 80%] [G loss: 2.229987]\n",
            "785 [ D loss: 0.504867, acc.: 78%] [G loss: 2.546068]\n",
            "786 [ D loss: 0.302391, acc.: 95%] [G loss: 3.281696]\n",
            "787 [ D loss: 0.428634, acc.: 88%] [G loss: 2.128921]\n",
            "788 [ D loss: 0.491429, acc.: 77%] [G loss: 2.048360]\n",
            "789 [ D loss: 0.427234, acc.: 83%] [G loss: 2.100833]\n",
            "790 [ D loss: 0.368306, acc.: 86%] [G loss: 2.291934]\n",
            "791 [ D loss: 0.430205, acc.: 84%] [G loss: 2.358835]\n",
            "792 [ D loss: 0.361178, acc.: 91%] [G loss: 3.089642]\n",
            "793 [ D loss: 0.530588, acc.: 74%] [G loss: 2.303380]\n",
            "794 [ D loss: 0.404222, acc.: 82%] [G loss: 2.591209]\n",
            "795 [ D loss: 0.378923, acc.: 88%] [G loss: 2.989312]\n",
            "796 [ D loss: 0.319919, acc.: 91%] [G loss: 2.715065]\n",
            "797 [ D loss: 0.441820, acc.: 79%] [G loss: 2.465636]\n",
            "798 [ D loss: 0.330689, acc.: 89%] [G loss: 2.439593]\n",
            "799 [ D loss: 0.523522, acc.: 68%] [G loss: 2.652912]\n",
            "800 [ D loss: 0.343207, acc.: 88%] [G loss: 2.915747]\n",
            "801 [ D loss: 0.353121, acc.: 95%] [G loss: 2.347219]\n",
            "802 [ D loss: 0.385795, acc.: 89%] [G loss: 2.324350]\n",
            "803 [ D loss: 0.381192, acc.: 91%] [G loss: 2.361576]\n",
            "804 [ D loss: 0.358611, acc.: 89%] [G loss: 2.332036]\n",
            "805 [ D loss: 0.433134, acc.: 79%] [G loss: 2.762712]\n",
            "806 [ D loss: 0.330134, acc.: 91%] [G loss: 3.218926]\n",
            "807 [ D loss: 0.364836, acc.: 88%] [G loss: 2.221351]\n",
            "808 [ D loss: 0.366352, acc.: 91%] [G loss: 2.120462]\n",
            "809 [ D loss: 0.290619, acc.: 95%] [G loss: 2.819031]\n",
            "810 [ D loss: 0.275437, acc.: 92%] [G loss: 3.180074]\n",
            "811 [ D loss: 0.421053, acc.: 82%] [G loss: 3.354268]\n",
            "812 [ D loss: 0.539430, acc.: 71%] [G loss: 2.297984]\n",
            "813 [ D loss: 0.430119, acc.: 90%] [G loss: 2.266812]\n",
            "814 [ D loss: 0.463326, acc.: 75%] [G loss: 3.054347]\n",
            "815 [ D loss: 0.425725, acc.: 82%] [G loss: 2.791926]\n",
            "816 [ D loss: 0.317263, acc.: 94%] [G loss: 2.934052]\n",
            "817 [ D loss: 0.232937, acc.: 98%] [G loss: 3.085937]\n",
            "818 [ D loss: 0.458307, acc.: 79%] [G loss: 3.120961]\n",
            "819 [ D loss: 0.393522, acc.: 83%] [G loss: 2.600189]\n",
            "820 [ D loss: 0.363493, acc.: 95%] [G loss: 2.407471]\n",
            "821 [ D loss: 0.290419, acc.: 94%] [G loss: 3.026112]\n",
            "822 [ D loss: 0.273254, acc.: 95%] [G loss: 3.474165]\n",
            "823 [ D loss: 0.479922, acc.: 77%] [G loss: 2.478732]\n",
            "824 [ D loss: 0.413650, acc.: 87%] [G loss: 2.222027]\n",
            "825 [ D loss: 0.340835, acc.: 92%] [G loss: 2.707719]\n",
            "826 [ D loss: 0.246708, acc.: 97%] [G loss: 2.853580]\n",
            "827 [ D loss: 0.362451, acc.: 86%] [G loss: 2.304646]\n",
            "828 [ D loss: 0.385469, acc.: 80%] [G loss: 2.901201]\n",
            "829 [ D loss: 0.319930, acc.: 87%] [G loss: 3.879726]\n",
            "830 [ D loss: 0.300706, acc.: 94%] [G loss: 2.811829]\n",
            "831 [ D loss: 0.355087, acc.: 90%] [G loss: 3.367602]\n",
            "832 [ D loss: 0.218036, acc.: 98%] [G loss: 3.819299]\n",
            "833 [ D loss: 0.407888, acc.: 77%] [G loss: 2.153240]\n",
            "834 [ D loss: 0.427541, acc.: 80%] [G loss: 2.790656]\n",
            "835 [ D loss: 0.292227, acc.: 88%] [G loss: 3.655747]\n",
            "836 [ D loss: 0.388675, acc.: 82%] [G loss: 2.599240]\n",
            "837 [ D loss: 0.282944, acc.: 98%] [G loss: 3.472615]\n",
            "838 [ D loss: 0.221979, acc.: 98%] [G loss: 4.776741]\n",
            "839 [ D loss: 0.432796, acc.: 82%] [G loss: 2.468124]\n",
            "840 [ D loss: 0.301971, acc.: 94%] [G loss: 3.238093]\n",
            "841 [ D loss: 0.364710, acc.: 86%] [G loss: 3.231141]\n",
            "842 [ D loss: 0.290924, acc.: 98%] [G loss: 3.546270]\n",
            "843 [ D loss: 0.212816, acc.: 98%] [G loss: 4.192020]\n",
            "844 [ D loss: 0.491865, acc.: 75%] [G loss: 2.289377]\n",
            "845 [ D loss: 0.366441, acc.: 89%] [G loss: 2.762148]\n",
            "846 [ D loss: 0.211472, acc.: 99%] [G loss: 3.615795]\n",
            "847 [ D loss: 0.241794, acc.: 97%] [G loss: 3.192389]\n",
            "848 [ D loss: 0.203382, acc.: 100%] [G loss: 2.620590]\n",
            "849 [ D loss: 0.362331, acc.: 89%] [G loss: 2.839184]\n",
            "850 [ D loss: 0.262833, acc.: 96%] [G loss: 3.497473]\n",
            "851 [ D loss: 0.404434, acc.: 84%] [G loss: 2.717869]\n",
            "852 [ D loss: 0.326826, acc.: 97%] [G loss: 2.572584]\n",
            "853 [ D loss: 0.336084, acc.: 92%] [G loss: 2.683414]\n",
            "854 [ D loss: 0.239051, acc.: 95%] [G loss: 4.638641]\n",
            "855 [ D loss: 0.219110, acc.: 98%] [G loss: 3.047351]\n",
            "856 [ D loss: 0.305395, acc.: 91%] [G loss: 3.298002]\n",
            "857 [ D loss: 0.532317, acc.: 76%] [G loss: 3.555037]\n",
            "858 [ D loss: 0.272542, acc.: 99%] [G loss: 3.211187]\n",
            "859 [ D loss: 0.260186, acc.: 94%] [G loss: 4.473804]\n",
            "860 [ D loss: 0.358115, acc.: 89%] [G loss: 3.259995]\n",
            "861 [ D loss: 0.432755, acc.: 76%] [G loss: 3.214565]\n",
            "862 [ D loss: 0.267385, acc.: 98%] [G loss: 3.662108]\n",
            "863 [ D loss: 0.320710, acc.: 91%] [G loss: 3.443739]\n",
            "864 [ D loss: 0.356013, acc.: 91%] [G loss: 2.979039]\n",
            "865 [ D loss: 0.240101, acc.: 97%] [G loss: 3.331067]\n",
            "866 [ D loss: 0.246764, acc.: 92%] [G loss: 2.609125]\n",
            "867 [ D loss: 0.337830, acc.: 91%] [G loss: 2.520103]\n",
            "868 [ D loss: 0.459772, acc.: 80%] [G loss: 2.298198]\n",
            "869 [ D loss: 0.298917, acc.: 94%] [G loss: 2.966465]\n",
            "870 [ D loss: 0.245507, acc.: 95%] [G loss: 3.449682]\n",
            "871 [ D loss: 0.312208, acc.: 92%] [G loss: 3.395940]\n",
            "872 [ D loss: 0.377583, acc.: 84%] [G loss: 3.196232]\n",
            "873 [ D loss: 0.371441, acc.: 84%] [G loss: 3.504868]\n",
            "874 [ D loss: 0.365327, acc.: 89%] [G loss: 3.820058]\n",
            "875 [ D loss: 0.353679, acc.: 88%] [G loss: 2.900049]\n",
            "876 [ D loss: 0.362288, acc.: 88%] [G loss: 2.990286]\n",
            "877 [ D loss: 0.235254, acc.: 98%] [G loss: 3.781222]\n",
            "878 [ D loss: 0.363468, acc.: 89%] [G loss: 2.581081]\n",
            "879 [ D loss: 0.630249, acc.: 73%] [G loss: 2.515950]\n",
            "880 [ D loss: 0.438880, acc.: 80%] [G loss: 2.985053]\n",
            "881 [ D loss: 0.305188, acc.: 91%] [G loss: 3.615291]\n",
            "882 [ D loss: 0.222064, acc.: 98%] [G loss: 4.450059]\n",
            "883 [ D loss: 0.713677, acc.: 71%] [G loss: 2.435043]\n",
            "884 [ D loss: 0.235146, acc.: 95%] [G loss: 4.967607]\n",
            "885 [ D loss: 0.427114, acc.: 82%] [G loss: 2.712352]\n",
            "886 [ D loss: 0.412741, acc.: 80%] [G loss: 3.072561]\n",
            "887 [ D loss: 0.284105, acc.: 95%] [G loss: 3.100440]\n",
            "888 [ D loss: 0.295586, acc.: 97%] [G loss: 3.674948]\n",
            "889 [ D loss: 0.254846, acc.: 100%] [G loss: 3.552894]\n",
            "890 [ D loss: 0.395934, acc.: 79%] [G loss: 2.986970]\n",
            "891 [ D loss: 0.324804, acc.: 96%] [G loss: 2.581926]\n",
            "892 [ D loss: 0.345604, acc.: 91%] [G loss: 2.589386]\n",
            "893 [ D loss: 0.354587, acc.: 94%] [G loss: 2.879736]\n",
            "894 [ D loss: 0.240131, acc.: 94%] [G loss: 3.602077]\n",
            "895 [ D loss: 0.296666, acc.: 95%] [G loss: 2.606612]\n",
            "896 [ D loss: 0.232484, acc.: 96%] [G loss: 4.179454]\n",
            "897 [ D loss: 0.614073, acc.: 73%] [G loss: 2.378697]\n",
            "898 [ D loss: 0.243446, acc.: 98%] [G loss: 5.186424]\n",
            "899 [ D loss: 0.186647, acc.: 97%] [G loss: 4.665832]\n",
            "900 [ D loss: 0.457821, acc.: 77%] [G loss: 3.507664]\n",
            "901 [ D loss: 0.223726, acc.: 98%] [G loss: 3.695233]\n",
            "902 [ D loss: 0.416907, acc.: 87%] [G loss: 2.985957]\n",
            "903 [ D loss: 0.263058, acc.: 95%] [G loss: 3.731394]\n",
            "904 [ D loss: 0.201158, acc.: 95%] [G loss: 4.241360]\n",
            "905 [ D loss: 0.328481, acc.: 92%] [G loss: 2.553549]\n",
            "906 [ D loss: 0.477721, acc.: 75%] [G loss: 2.736253]\n",
            "907 [ D loss: 0.255076, acc.: 93%] [G loss: 3.977100]\n",
            "908 [ D loss: 0.207186, acc.: 97%] [G loss: 4.351052]\n",
            "909 [ D loss: 0.245449, acc.: 93%] [G loss: 3.387190]\n",
            "910 [ D loss: 0.459526, acc.: 73%] [G loss: 2.665914]\n",
            "911 [ D loss: 0.263901, acc.: 98%] [G loss: 3.469378]\n",
            "912 [ D loss: 0.248070, acc.: 95%] [G loss: 3.259062]\n",
            "913 [ D loss: 0.472476, acc.: 74%] [G loss: 2.695097]\n",
            "914 [ D loss: 0.243962, acc.: 94%] [G loss: 4.314148]\n",
            "915 [ D loss: 0.250717, acc.: 95%] [G loss: 3.119852]\n",
            "916 [ D loss: 0.233131, acc.: 98%] [G loss: 4.073886]\n",
            "917 [ D loss: 0.364337, acc.: 88%] [G loss: 3.071652]\n",
            "918 [ D loss: 0.385540, acc.: 77%] [G loss: 2.571532]\n",
            "919 [ D loss: 0.283286, acc.: 97%] [G loss: 3.490887]\n",
            "920 [ D loss: 0.325562, acc.: 93%] [G loss: 3.656414]\n",
            "921 [ D loss: 0.310100, acc.: 96%] [G loss: 2.933703]\n",
            "922 [ D loss: 0.207768, acc.: 97%] [G loss: 4.429509]\n",
            "923 [ D loss: 0.436539, acc.: 77%] [G loss: 2.499339]\n",
            "924 [ D loss: 0.308026, acc.: 95%] [G loss: 3.165974]\n",
            "925 [ D loss: 0.238171, acc.: 95%] [G loss: 3.276643]\n",
            "926 [ D loss: 0.247634, acc.: 93%] [G loss: 3.729945]\n",
            "927 [ D loss: 0.400808, acc.: 77%] [G loss: 3.529310]\n",
            "928 [ D loss: 0.266060, acc.: 93%] [G loss: 4.996567]\n",
            "929 [ D loss: 0.282520, acc.: 93%] [G loss: 4.225355]\n",
            "930 [ D loss: 0.197577, acc.: 99%] [G loss: 2.712529]\n",
            "931 [ D loss: 0.479420, acc.: 71%] [G loss: 3.085975]\n",
            "932 [ D loss: 0.226821, acc.: 96%] [G loss: 3.258221]\n",
            "933 [ D loss: 0.352945, acc.: 91%] [G loss: 2.988728]\n",
            "934 [ D loss: 0.213825, acc.: 97%] [G loss: 4.003628]\n",
            "935 [ D loss: 0.428675, acc.: 77%] [G loss: 2.454955]\n",
            "936 [ D loss: 0.295540, acc.: 98%] [G loss: 3.025255]\n",
            "937 [ D loss: 0.270760, acc.: 91%] [G loss: 4.415584]\n",
            "938 [ D loss: 0.221535, acc.: 94%] [G loss: 4.508128]\n",
            "939 [ D loss: 0.465190, acc.: 68%] [G loss: 3.049481]\n",
            "940 [ D loss: 0.218445, acc.: 98%] [G loss: 3.705452]\n",
            "941 [ D loss: 0.312601, acc.: 93%] [G loss: 3.027168]\n",
            "942 [ D loss: 0.229207, acc.: 98%] [G loss: 3.122393]\n",
            "943 [ D loss: 0.323869, acc.: 97%] [G loss: 2.802500]\n",
            "944 [ D loss: 0.235363, acc.: 99%] [G loss: 2.637301]\n",
            "945 [ D loss: 0.252016, acc.: 97%] [G loss: 3.344951]\n",
            "946 [ D loss: 0.207377, acc.: 95%] [G loss: 4.463833]\n",
            "947 [ D loss: 0.296690, acc.: 94%] [G loss: 3.423237]\n",
            "948 [ D loss: 0.408513, acc.: 77%] [G loss: 3.521125]\n",
            "949 [ D loss: 0.302295, acc.: 94%] [G loss: 3.605307]\n",
            "950 [ D loss: 0.315731, acc.: 93%] [G loss: 3.237051]\n",
            "951 [ D loss: 0.279432, acc.: 95%] [G loss: 2.921490]\n",
            "952 [ D loss: 0.264856, acc.: 94%] [G loss: 3.174982]\n",
            "953 [ D loss: 0.333284, acc.: 94%] [G loss: 3.013053]\n",
            "954 [ D loss: 0.294602, acc.: 91%] [G loss: 2.995800]\n",
            "955 [ D loss: 0.381850, acc.: 84%] [G loss: 3.345955]\n",
            "956 [ D loss: 0.384201, acc.: 83%] [G loss: 4.130445]\n",
            "957 [ D loss: 0.323176, acc.: 88%] [G loss: 3.722608]\n",
            "958 [ D loss: 0.327059, acc.: 96%] [G loss: 2.804761]\n",
            "959 [ D loss: 0.369946, acc.: 86%] [G loss: 3.233122]\n",
            "960 [ D loss: 0.245921, acc.: 95%] [G loss: 3.522422]\n",
            "961 [ D loss: 0.260576, acc.: 96%] [G loss: 3.174234]\n",
            "962 [ D loss: 0.295694, acc.: 98%] [G loss: 3.084315]\n",
            "963 [ D loss: 0.443361, acc.: 77%] [G loss: 3.264093]\n",
            "964 [ D loss: 0.271421, acc.: 95%] [G loss: 3.348152]\n",
            "965 [ D loss: 0.292788, acc.: 92%] [G loss: 3.598998]\n",
            "966 [ D loss: 0.251704, acc.: 95%] [G loss: 3.311022]\n",
            "967 [ D loss: 0.420261, acc.: 77%] [G loss: 2.818937]\n",
            "968 [ D loss: 0.483627, acc.: 77%] [G loss: 3.409824]\n",
            "969 [ D loss: 0.339036, acc.: 91%] [G loss: 3.327442]\n",
            "970 [ D loss: 0.256744, acc.: 95%] [G loss: 3.863420]\n",
            "971 [ D loss: 0.172314, acc.: 100%] [G loss: 5.238321]\n",
            "972 [ D loss: 0.505987, acc.: 74%] [G loss: 2.547549]\n",
            "973 [ D loss: 0.435841, acc.: 77%] [G loss: 2.838550]\n",
            "974 [ D loss: 0.267539, acc.: 89%] [G loss: 4.408328]\n",
            "975 [ D loss: 0.257629, acc.: 95%] [G loss: 3.210502]\n",
            "976 [ D loss: 0.309379, acc.: 92%] [G loss: 2.576755]\n",
            "977 [ D loss: 0.515943, acc.: 79%] [G loss: 3.660769]\n",
            "978 [ D loss: 0.331155, acc.: 91%] [G loss: 4.728507]\n",
            "979 [ D loss: 0.313525, acc.: 95%] [G loss: 3.151936]\n",
            "980 [ D loss: 0.205433, acc.: 94%] [G loss: 3.538363]\n",
            "981 [ D loss: 0.250437, acc.: 96%] [G loss: 3.449262]\n",
            "982 [ D loss: 0.305967, acc.: 91%] [G loss: 3.198093]\n",
            "983 [ D loss: 0.448416, acc.: 77%] [G loss: 2.811905]\n",
            "984 [ D loss: 0.319048, acc.: 92%] [G loss: 3.344356]\n",
            "985 [ D loss: 0.242601, acc.: 97%] [G loss: 2.946337]\n",
            "986 [ D loss: 0.325555, acc.: 95%] [G loss: 3.023922]\n",
            "987 [ D loss: 0.188438, acc.: 98%] [G loss: 4.255314]\n",
            "988 [ D loss: 0.275891, acc.: 96%] [G loss: 4.372007]\n",
            "989 [ D loss: 0.465331, acc.: 76%] [G loss: 2.683442]\n",
            "990 [ D loss: 0.375424, acc.: 83%] [G loss: 3.444624]\n",
            "991 [ D loss: 0.214129, acc.: 97%] [G loss: 4.896195]\n",
            "992 [ D loss: 0.400409, acc.: 80%] [G loss: 5.407656]\n",
            "993 [ D loss: 0.368470, acc.: 87%] [G loss: 3.053489]\n",
            "994 [ D loss: 0.257994, acc.: 90%] [G loss: 3.791527]\n",
            "995 [ D loss: 0.201833, acc.: 98%] [G loss: 4.560773]\n",
            "996 [ D loss: 0.453074, acc.: 76%] [G loss: 3.930758]\n",
            "997 [ D loss: 0.406107, acc.: 85%] [G loss: 3.033145]\n",
            "998 [ D loss: 0.218187, acc.: 98%] [G loss: 4.216221]\n",
            "999 [ D loss: 0.327173, acc.: 89%] [G loss: 3.725009]\n",
            "1000 [ D loss: 0.377784, acc.: 83%] [G loss: 3.989464]\n",
            "1001 [ D loss: 0.531308, acc.: 66%] [G loss: 3.280964]\n",
            "1002 [ D loss: 0.195284, acc.: 98%] [G loss: 6.823911]\n",
            "1003 [ D loss: 0.461335, acc.: 76%] [G loss: 4.012225]\n",
            "1004 [ D loss: 0.369921, acc.: 88%] [G loss: 2.908257]\n",
            "1005 [ D loss: 0.300546, acc.: 93%] [G loss: 5.118618]\n",
            "1006 [ D loss: 0.269299, acc.: 97%] [G loss: 3.518358]\n",
            "1007 [ D loss: 0.228891, acc.: 98%] [G loss: 3.140203]\n",
            "1008 [ D loss: 0.330812, acc.: 94%] [G loss: 3.384722]\n",
            "1009 [ D loss: 0.195091, acc.: 99%] [G loss: 4.244143]\n",
            "1010 [ D loss: 0.386114, acc.: 83%] [G loss: 3.109834]\n",
            "1011 [ D loss: 0.410201, acc.: 79%] [G loss: 3.943759]\n",
            "1012 [ D loss: 0.334686, acc.: 92%] [G loss: 4.067135]\n",
            "1013 [ D loss: 0.234730, acc.: 96%] [G loss: 3.596554]\n",
            "1014 [ D loss: 0.239095, acc.: 97%] [G loss: 3.369360]\n",
            "1015 [ D loss: 0.202950, acc.: 97%] [G loss: 4.440687]\n",
            "1016 [ D loss: 0.629045, acc.: 70%] [G loss: 2.544452]\n",
            "1017 [ D loss: 0.261004, acc.: 91%] [G loss: 4.208212]\n",
            "1018 [ D loss: 0.209651, acc.: 96%] [G loss: 4.667460]\n",
            "1019 [ D loss: 0.438333, acc.: 77%] [G loss: 3.199603]\n",
            "1020 [ D loss: 0.279882, acc.: 89%] [G loss: 5.007300]\n",
            "1021 [ D loss: 0.231344, acc.: 98%] [G loss: 2.531848]\n",
            "1022 [ D loss: 0.224695, acc.: 97%] [G loss: 4.511630]\n",
            "1023 [ D loss: 0.553563, acc.: 64%] [G loss: 2.094060]\n",
            "1024 [ D loss: 0.338356, acc.: 88%] [G loss: 3.270429]\n",
            "1025 [ D loss: 0.267452, acc.: 93%] [G loss: 3.753230]\n",
            "1026 [ D loss: 0.159647, acc.: 99%] [G loss: 3.460393]\n",
            "1027 [ D loss: 0.511609, acc.: 74%] [G loss: 2.226544]\n",
            "1028 [ D loss: 0.524368, acc.: 72%] [G loss: 2.176791]\n",
            "1029 [ D loss: 0.281461, acc.: 95%] [G loss: 3.332156]\n",
            "1030 [ D loss: 0.197021, acc.: 97%] [G loss: 5.226424]\n",
            "1031 [ D loss: 0.182866, acc.: 97%] [G loss: 3.490026]\n",
            "1032 [ D loss: 0.538710, acc.: 73%] [G loss: 3.795677]\n",
            "1033 [ D loss: 0.249258, acc.: 98%] [G loss: 2.764779]\n",
            "1034 [ D loss: 0.410312, acc.: 77%] [G loss: 3.812312]\n",
            "1035 [ D loss: 0.294903, acc.: 95%] [G loss: 3.617597]\n",
            "1036 [ D loss: 0.259141, acc.: 95%] [G loss: 4.003940]\n",
            "1037 [ D loss: 0.372226, acc.: 84%] [G loss: 3.061440]\n",
            "1038 [ D loss: 0.274093, acc.: 95%] [G loss: 3.244490]\n",
            "1039 [ D loss: 0.228973, acc.: 96%] [G loss: 4.282513]\n",
            "1040 [ D loss: 0.226604, acc.: 97%] [G loss: 4.057313]\n",
            "1041 [ D loss: 0.234961, acc.: 96%] [G loss: 3.218464]\n",
            "1042 [ D loss: 0.556049, acc.: 69%] [G loss: 3.311074]\n",
            "1043 [ D loss: 0.259703, acc.: 92%] [G loss: 3.373020]\n",
            "1044 [ D loss: 0.410809, acc.: 72%] [G loss: 3.671192]\n",
            "1045 [ D loss: 0.300382, acc.: 94%] [G loss: 4.345289]\n",
            "1046 [ D loss: 0.222996, acc.: 95%] [G loss: 4.655073]\n",
            "1047 [ D loss: 0.288676, acc.: 93%] [G loss: 4.065998]\n",
            "1048 [ D loss: 0.191412, acc.: 99%] [G loss: 3.223898]\n",
            "1049 [ D loss: 0.412633, acc.: 77%] [G loss: 2.691261]\n",
            "1050 [ D loss: 0.417401, acc.: 72%] [G loss: 2.702937]\n",
            "1051 [ D loss: 0.299269, acc.: 88%] [G loss: 3.501634]\n",
            "1052 [ D loss: 0.228235, acc.: 95%] [G loss: 3.318917]\n",
            "1053 [ D loss: 0.142002, acc.: 99%] [G loss: 5.589110]\n",
            "1054 [ D loss: 0.429120, acc.: 80%] [G loss: 2.610630]\n",
            "1055 [ D loss: 0.406242, acc.: 75%] [G loss: 2.353402]\n",
            "1056 [ D loss: 0.423181, acc.: 78%] [G loss: 3.459434]\n",
            "1057 [ D loss: 0.388008, acc.: 85%] [G loss: 2.783482]\n",
            "1058 [ D loss: 0.321046, acc.: 88%] [G loss: 2.822421]\n",
            "1059 [ D loss: 0.377822, acc.: 87%] [G loss: 2.634758]\n",
            "1060 [ D loss: 0.175232, acc.: 95%] [G loss: 6.817559]\n",
            "1061 [ D loss: 0.483825, acc.: 70%] [G loss: 2.101486]\n",
            "1062 [ D loss: 0.168446, acc.: 100%] [G loss: 7.029043]\n",
            "1063 [ D loss: 0.728693, acc.: 63%] [G loss: 2.711737]\n",
            "1064 [ D loss: 0.225707, acc.: 93%] [G loss: 5.043466]\n",
            "1065 [ D loss: 0.333136, acc.: 88%] [G loss: 3.831390]\n",
            "1066 [ D loss: 0.345067, acc.: 85%] [G loss: 4.286223]\n",
            "1067 [ D loss: 0.488413, acc.: 72%] [G loss: 2.746197]\n",
            "1068 [ D loss: 0.267113, acc.: 96%] [G loss: 3.062029]\n",
            "1069 [ D loss: 0.260668, acc.: 94%] [G loss: 3.572994]\n",
            "1070 [ D loss: 0.349563, acc.: 91%] [G loss: 4.117035]\n",
            "1071 [ D loss: 0.430408, acc.: 78%] [G loss: 3.389729]\n",
            "1072 [ D loss: 0.368438, acc.: 87%] [G loss: 3.541842]\n",
            "1073 [ D loss: 0.286387, acc.: 94%] [G loss: 2.546257]\n",
            "1074 [ D loss: 0.410239, acc.: 87%] [G loss: 2.791735]\n",
            "1075 [ D loss: 0.456814, acc.: 75%] [G loss: 2.735773]\n",
            "1076 [ D loss: 0.501177, acc.: 73%] [G loss: 3.991393]\n",
            "1077 [ D loss: 0.395597, acc.: 81%] [G loss: 3.107243]\n",
            "1078 [ D loss: 0.465989, acc.: 77%] [G loss: 3.688945]\n",
            "1079 [ D loss: 0.430378, acc.: 86%] [G loss: 2.373923]\n",
            "1080 [ D loss: 0.246881, acc.: 96%] [G loss: 3.082562]\n",
            "1081 [ D loss: 0.193555, acc.: 98%] [G loss: 4.262494]\n",
            "1082 [ D loss: 0.669050, acc.: 68%] [G loss: 3.331836]\n",
            "1083 [ D loss: 0.609144, acc.: 67%] [G loss: 3.235398]\n",
            "1084 [ D loss: 0.504967, acc.: 71%] [G loss: 2.616457]\n",
            "1085 [ D loss: 0.351656, acc.: 88%] [G loss: 3.924617]\n",
            "1086 [ D loss: 0.208926, acc.: 96%] [G loss: 6.016617]\n",
            "1087 [ D loss: 0.505228, acc.: 76%] [G loss: 3.729222]\n",
            "1088 [ D loss: 0.730510, acc.: 64%] [G loss: 2.301236]\n",
            "1089 [ D loss: 0.407615, acc.: 81%] [G loss: 4.318110]\n",
            "1090 [ D loss: 0.395911, acc.: 84%] [G loss: 3.249064]\n",
            "1091 [ D loss: 0.278840, acc.: 93%] [G loss: 5.064417]\n",
            "1092 [ D loss: 0.440830, acc.: 80%] [G loss: 2.354074]\n",
            "1093 [ D loss: 0.664292, acc.: 66%] [G loss: 2.832856]\n",
            "1094 [ D loss: 0.316315, acc.: 91%] [G loss: 5.106145]\n",
            "1095 [ D loss: 0.258020, acc.: 95%] [G loss: 4.339322]\n",
            "1096 [ D loss: 0.601725, acc.: 73%] [G loss: 3.473380]\n",
            "1097 [ D loss: 0.563107, acc.: 70%] [G loss: 3.610405]\n",
            "1098 [ D loss: 0.321171, acc.: 88%] [G loss: 4.953737]\n",
            "1099 [ D loss: 0.455894, acc.: 76%] [G loss: 3.580922]\n",
            "1100 [ D loss: 0.472793, acc.: 72%] [G loss: 2.517515]\n",
            "1101 [ D loss: 0.406367, acc.: 84%] [G loss: 2.732833]\n",
            "1102 [ D loss: 0.399559, acc.: 77%] [G loss: 4.517968]\n",
            "1103 [ D loss: 0.169807, acc.: 98%] [G loss: 5.109386]\n",
            "1104 [ D loss: 0.263351, acc.: 95%] [G loss: 3.103352]\n",
            "1105 [ D loss: 0.378942, acc.: 85%] [G loss: 2.286880]\n",
            "1106 [ D loss: 0.636948, acc.: 63%] [G loss: 2.448220]\n",
            "1107 [ D loss: 0.451590, acc.: 77%] [G loss: 3.469337]\n",
            "1108 [ D loss: 0.347455, acc.: 95%] [G loss: 2.398102]\n",
            "1109 [ D loss: 0.232345, acc.: 98%] [G loss: 4.549099]\n",
            "1110 [ D loss: 0.253966, acc.: 91%] [G loss: 5.116927]\n",
            "1111 [ D loss: 0.421593, acc.: 84%] [G loss: 3.053389]\n",
            "1112 [ D loss: 0.355333, acc.: 86%] [G loss: 2.672634]\n",
            "1113 [ D loss: 0.664118, acc.: 64%] [G loss: 2.118989]\n",
            "1114 [ D loss: 0.435378, acc.: 77%] [G loss: 3.564078]\n",
            "1115 [ D loss: 0.463447, acc.: 74%] [G loss: 4.302399]\n",
            "1116 [ D loss: 0.293664, acc.: 94%] [G loss: 4.241436]\n",
            "1117 [ D loss: 0.197816, acc.: 95%] [G loss: 7.151734]\n",
            "1118 [ D loss: 0.367264, acc.: 82%] [G loss: 3.936272]\n",
            "1119 [ D loss: 0.460325, acc.: 77%] [G loss: 4.049324]\n",
            "1120 [ D loss: 0.361159, acc.: 86%] [G loss: 3.560140]\n",
            "1121 [ D loss: 0.582534, acc.: 70%] [G loss: 2.972764]\n",
            "1122 [ D loss: 0.504307, acc.: 70%] [G loss: 2.912298]\n",
            "1123 [ D loss: 0.317574, acc.: 88%] [G loss: 4.397661]\n",
            "1124 [ D loss: 0.396470, acc.: 81%] [G loss: 3.173217]\n",
            "1125 [ D loss: 0.398942, acc.: 81%] [G loss: 3.564238]\n",
            "1126 [ D loss: 0.280886, acc.: 92%] [G loss: 3.959384]\n",
            "1127 [ D loss: 0.187974, acc.: 98%] [G loss: 4.471447]\n",
            "1128 [ D loss: 0.444280, acc.: 81%] [G loss: 3.937427]\n",
            "1129 [ D loss: 0.388954, acc.: 84%] [G loss: 4.267234]\n",
            "1130 [ D loss: 0.283486, acc.: 95%] [G loss: 4.221360]\n",
            "1131 [ D loss: 0.308296, acc.: 88%] [G loss: 5.621661]\n",
            "1132 [ D loss: 0.555902, acc.: 73%] [G loss: 3.623986]\n",
            "1133 [ D loss: 0.446088, acc.: 74%] [G loss: 2.589422]\n",
            "1134 [ D loss: 0.493372, acc.: 73%] [G loss: 4.518280]\n",
            "1135 [ D loss: 0.582162, acc.: 65%] [G loss: 2.375902]\n",
            "1136 [ D loss: 0.214140, acc.: 95%] [G loss: 5.597754]\n",
            "1137 [ D loss: 0.232062, acc.: 93%] [G loss: 3.558291]\n",
            "1138 [ D loss: 0.632821, acc.: 66%] [G loss: 2.290203]\n",
            "1139 [ D loss: 0.420724, acc.: 73%] [G loss: 3.082683]\n",
            "1140 [ D loss: 0.540891, acc.: 63%] [G loss: 2.584779]\n",
            "1141 [ D loss: 0.460698, acc.: 73%] [G loss: 2.782393]\n",
            "1142 [ D loss: 0.453297, acc.: 77%] [G loss: 2.336202]\n",
            "1143 [ D loss: 0.400866, acc.: 88%] [G loss: 2.740030]\n",
            "1144 [ D loss: 0.228327, acc.: 95%] [G loss: 7.286662]\n",
            "1145 [ D loss: 0.725491, acc.: 59%] [G loss: 1.415840]\n",
            "1146 [ D loss: 0.218068, acc.: 95%] [G loss: 3.057942]\n",
            "1147 [ D loss: 0.174778, acc.: 98%] [G loss: 6.213144]\n",
            "1148 [ D loss: 0.409442, acc.: 80%] [G loss: 2.891094]\n",
            "1149 [ D loss: 0.494193, acc.: 77%] [G loss: 1.832723]\n",
            "1150 [ D loss: 0.326341, acc.: 92%] [G loss: 2.978341]\n",
            "1151 [ D loss: 0.144674, acc.: 100%] [G loss: 6.757030]\n",
            "1152 [ D loss: 0.273329, acc.: 93%] [G loss: 3.124660]\n",
            "1153 [ D loss: 0.669348, acc.: 67%] [G loss: 1.848285]\n",
            "1154 [ D loss: 0.610950, acc.: 65%] [G loss: 1.784469]\n",
            "1155 [ D loss: 0.295325, acc.: 97%] [G loss: 3.141465]\n",
            "1156 [ D loss: 0.187664, acc.: 98%] [G loss: 7.901656]\n",
            "1157 [ D loss: 0.307889, acc.: 88%] [G loss: 3.821185]\n",
            "1158 [ D loss: 0.509786, acc.: 75%] [G loss: 4.719893]\n",
            "1159 [ D loss: 0.592292, acc.: 66%] [G loss: 3.330036]\n",
            "1160 [ D loss: 0.550589, acc.: 69%] [G loss: 2.154656]\n",
            "1161 [ D loss: 0.365093, acc.: 84%] [G loss: 2.758319]\n",
            "1162 [ D loss: 0.259642, acc.: 94%] [G loss: 3.625751]\n",
            "1163 [ D loss: 0.161361, acc.: 96%] [G loss: 6.112585]\n",
            "1164 [ D loss: 0.236950, acc.: 93%] [G loss: 3.999296]\n",
            "1165 [ D loss: 0.317006, acc.: 89%] [G loss: 3.362195]\n",
            "1166 [ D loss: 0.510646, acc.: 72%] [G loss: 2.587407]\n",
            "1167 [ D loss: 0.503319, acc.: 74%] [G loss: 3.441524]\n",
            "1168 [ D loss: 0.405564, acc.: 79%] [G loss: 3.454710]\n",
            "1169 [ D loss: 0.398104, acc.: 84%] [G loss: 4.118758]\n",
            "1170 [ D loss: 0.242255, acc.: 92%] [G loss: 5.461841]\n",
            "1171 [ D loss: 0.468575, acc.: 75%] [G loss: 2.537698]\n",
            "1172 [ D loss: 0.240767, acc.: 95%] [G loss: 3.378541]\n",
            "1173 [ D loss: 0.175485, acc.: 95%] [G loss: 5.611501]\n",
            "1174 [ D loss: 0.663496, acc.: 66%] [G loss: 1.827819]\n",
            "1175 [ D loss: 0.162331, acc.: 98%] [G loss: 4.937267]\n",
            "1176 [ D loss: 0.174195, acc.: 97%] [G loss: 4.507598]\n",
            "1177 [ D loss: 0.703073, acc.: 62%] [G loss: 2.186393]\n",
            "1178 [ D loss: 0.602291, acc.: 64%] [G loss: 2.736765]\n",
            "1179 [ D loss: 0.509569, acc.: 69%] [G loss: 2.007324]\n",
            "1180 [ D loss: 0.487119, acc.: 70%] [G loss: 1.837184]\n",
            "1181 [ D loss: 0.326720, acc.: 88%] [G loss: 4.438909]\n",
            "1182 [ D loss: 0.178652, acc.: 97%] [G loss: 5.007758]\n",
            "1183 [ D loss: 0.251808, acc.: 95%] [G loss: 2.701804]\n",
            "1184 [ D loss: 0.396260, acc.: 82%] [G loss: 2.817621]\n",
            "1185 [ D loss: 0.185892, acc.: 97%] [G loss: 4.018370]\n",
            "1186 [ D loss: 0.184903, acc.: 98%] [G loss: 3.779830]\n",
            "1187 [ D loss: 0.224699, acc.: 98%] [G loss: 2.869483]\n",
            "1188 [ D loss: 0.364785, acc.: 88%] [G loss: 2.373615]\n",
            "1189 [ D loss: 0.445724, acc.: 77%] [G loss: 2.258718]\n",
            "1190 [ D loss: 0.335889, acc.: 94%] [G loss: 2.968286]\n",
            "1191 [ D loss: 0.201860, acc.: 97%] [G loss: 5.584515]\n",
            "1192 [ D loss: 0.375125, acc.: 85%] [G loss: 3.859876]\n",
            "1193 [ D loss: 0.269937, acc.: 96%] [G loss: 3.044594]\n",
            "1194 [ D loss: 0.618536, acc.: 63%] [G loss: 2.721356]\n",
            "1195 [ D loss: 0.243933, acc.: 94%] [G loss: 4.362306]\n",
            "1196 [ D loss: 0.212098, acc.: 95%] [G loss: 4.336271]\n",
            "1197 [ D loss: 0.157558, acc.: 98%] [G loss: 5.661051]\n",
            "1198 [ D loss: 0.291895, acc.: 91%] [G loss: 3.759883]\n",
            "1199 [ D loss: 0.618919, acc.: 59%] [G loss: 1.897683]\n",
            "1200 [ D loss: 0.345551, acc.: 90%] [G loss: 3.668784]\n",
            "1201 [ D loss: 0.206168, acc.: 96%] [G loss: 6.331934]\n",
            "1202 [ D loss: 0.308602, acc.: 89%] [G loss: 3.042268]\n",
            "1203 [ D loss: 0.194520, acc.: 96%] [G loss: 4.578730]\n",
            "1204 [ D loss: 0.151202, acc.: 97%] [G loss: 4.360782]\n",
            "1205 [ D loss: 0.552070, acc.: 72%] [G loss: 3.545661]\n",
            "1206 [ D loss: 0.576555, acc.: 66%] [G loss: 3.304716]\n",
            "1207 [ D loss: 0.372980, acc.: 82%] [G loss: 3.437206]\n",
            "1208 [ D loss: 0.250080, acc.: 95%] [G loss: 2.848691]\n",
            "1209 [ D loss: 0.259696, acc.: 96%] [G loss: 3.050033]\n",
            "1210 [ D loss: 0.171065, acc.: 96%] [G loss: 5.089409]\n",
            "1211 [ D loss: 0.272576, acc.: 93%] [G loss: 2.231173]\n",
            "1212 [ D loss: 0.338231, acc.: 89%] [G loss: 2.722645]\n",
            "1213 [ D loss: 0.233997, acc.: 95%] [G loss: 3.142453]\n",
            "1214 [ D loss: 0.163076, acc.: 98%] [G loss: 5.876001]\n",
            "1215 [ D loss: 0.231610, acc.: 98%] [G loss: 2.600804]\n",
            "1216 [ D loss: 0.509563, acc.: 73%] [G loss: 2.186045]\n",
            "1217 [ D loss: 0.286776, acc.: 96%] [G loss: 3.484706]\n",
            "1218 [ D loss: 0.171557, acc.: 98%] [G loss: 6.194941]\n",
            "1219 [ D loss: 0.643712, acc.: 62%] [G loss: 2.971885]\n",
            "1220 [ D loss: 0.669540, acc.: 59%] [G loss: 1.830139]\n",
            "1221 [ D loss: 0.381761, acc.: 89%] [G loss: 2.878774]\n",
            "1222 [ D loss: 0.253061, acc.: 95%] [G loss: 3.941418]\n",
            "1223 [ D loss: 0.186101, acc.: 95%] [G loss: 6.196050]\n",
            "1224 [ D loss: 0.277720, acc.: 95%] [G loss: 4.642976]\n",
            "1225 [ D loss: 0.170500, acc.: 96%] [G loss: 4.328040]\n",
            "1226 [ D loss: 0.378823, acc.: 87%] [G loss: 3.455699]\n",
            "1227 [ D loss: 0.379266, acc.: 83%] [G loss: 3.149304]\n",
            "1228 [ D loss: 0.316045, acc.: 95%] [G loss: 2.621031]\n",
            "1229 [ D loss: 0.456482, acc.: 77%] [G loss: 2.851578]\n",
            "1230 [ D loss: 0.347856, acc.: 88%] [G loss: 3.559629]\n",
            "1231 [ D loss: 0.189066, acc.: 98%] [G loss: 5.491898]\n",
            "1232 [ D loss: 0.319100, acc.: 90%] [G loss: 3.773914]\n",
            "1233 [ D loss: 0.411903, acc.: 80%] [G loss: 3.746890]\n",
            "1234 [ D loss: 0.186990, acc.: 98%] [G loss: 4.825774]\n",
            "1235 [ D loss: 0.232469, acc.: 95%] [G loss: 3.281335]\n",
            "1236 [ D loss: 0.408616, acc.: 84%] [G loss: 2.994693]\n",
            "1237 [ D loss: 0.333417, acc.: 86%] [G loss: 4.537305]\n",
            "1238 [ D loss: 0.403730, acc.: 84%] [G loss: 2.615557]\n",
            "1239 [ D loss: 0.255890, acc.: 95%] [G loss: 3.150674]\n",
            "1240 [ D loss: 0.203274, acc.: 95%] [G loss: 4.884120]\n",
            "1241 [ D loss: 0.352969, acc.: 89%] [G loss: 2.356857]\n",
            "1242 [ D loss: 0.654238, acc.: 62%] [G loss: 1.726772]\n",
            "1243 [ D loss: 0.431598, acc.: 80%] [G loss: 2.178854]\n",
            "1244 [ D loss: 0.165735, acc.: 98%] [G loss: 5.081597]\n",
            "1245 [ D loss: 0.155788, acc.: 98%] [G loss: 5.143478]\n",
            "1246 [ D loss: 0.235578, acc.: 91%] [G loss: 3.076786]\n",
            "1247 [ D loss: 0.224211, acc.: 95%] [G loss: 2.561137]\n",
            "1248 [ D loss: 0.548852, acc.: 67%] [G loss: 2.646393]\n",
            "1249 [ D loss: 0.350046, acc.: 86%] [G loss: 3.143658]\n",
            "1250 [ D loss: 0.334540, acc.: 90%] [G loss: 3.214931]\n",
            "1251 [ D loss: 0.366086, acc.: 87%] [G loss: 2.600764]\n",
            "1252 [ D loss: 0.172272, acc.: 97%] [G loss: 6.105464]\n",
            "1253 [ D loss: 0.569273, acc.: 65%] [G loss: 3.315420]\n",
            "1254 [ D loss: 0.324075, acc.: 86%] [G loss: 3.840508]\n",
            "1255 [ D loss: 0.350838, acc.: 88%] [G loss: 2.518676]\n",
            "1256 [ D loss: 0.543164, acc.: 66%] [G loss: 2.626779]\n",
            "1257 [ D loss: 0.163441, acc.: 98%] [G loss: 3.575867]\n",
            "1258 [ D loss: 0.298587, acc.: 89%] [G loss: 5.021836]\n",
            "1259 [ D loss: 0.281576, acc.: 94%] [G loss: 3.349451]\n",
            "1260 [ D loss: 0.178220, acc.: 98%] [G loss: 3.492610]\n",
            "1261 [ D loss: 0.238862, acc.: 91%] [G loss: 5.210876]\n",
            "1262 [ D loss: 0.606369, acc.: 65%] [G loss: 2.884369]\n",
            "1263 [ D loss: 0.159648, acc.: 98%] [G loss: 4.483745]\n",
            "1264 [ D loss: 0.192302, acc.: 95%] [G loss: 3.138527]\n",
            "1265 [ D loss: 0.498522, acc.: 71%] [G loss: 1.925556]\n",
            "1266 [ D loss: 0.687355, acc.: 59%] [G loss: 1.563739]\n",
            "1267 [ D loss: 0.383866, acc.: 88%] [G loss: 2.835538]\n",
            "1268 [ D loss: 0.616458, acc.: 59%] [G loss: 1.811020]\n",
            "1269 [ D loss: 0.617730, acc.: 59%] [G loss: 1.979168]\n",
            "1270 [ D loss: 0.287701, acc.: 94%] [G loss: 3.154288]\n",
            "1271 [ D loss: 0.166299, acc.: 98%] [G loss: 7.838099]\n",
            "1272 [ D loss: 0.473204, acc.: 74%] [G loss: 2.483361]\n",
            "1273 [ D loss: 0.154059, acc.: 99%] [G loss: 6.008907]\n",
            "1274 [ D loss: 0.149874, acc.: 98%] [G loss: 7.259123]\n",
            "1275 [ D loss: 0.465509, acc.: 70%] [G loss: 1.924232]\n",
            "1276 [ D loss: 0.192028, acc.: 96%] [G loss: 6.566617]\n",
            "1277 [ D loss: 0.292034, acc.: 91%] [G loss: 3.000876]\n",
            "1278 [ D loss: 0.588342, acc.: 67%] [G loss: 2.747196]\n",
            "1279 [ D loss: 0.554486, acc.: 70%] [G loss: 2.835414]\n",
            "1280 [ D loss: 0.651498, acc.: 62%] [G loss: 1.951974]\n",
            "1281 [ D loss: 0.504601, acc.: 72%] [G loss: 2.448487]\n",
            "1282 [ D loss: 0.500183, acc.: 74%] [G loss: 1.931353]\n",
            "1283 [ D loss: 0.272502, acc.: 94%] [G loss: 3.589130]\n",
            "1284 [ D loss: 0.189754, acc.: 96%] [G loss: 5.275236]\n",
            "1285 [ D loss: 0.378483, acc.: 84%] [G loss: 2.074319]\n",
            "1286 [ D loss: 0.418185, acc.: 84%] [G loss: 2.347818]\n",
            "1287 [ D loss: 0.387489, acc.: 83%] [G loss: 1.744681]\n",
            "1288 [ D loss: 0.540903, acc.: 63%] [G loss: 1.512849]\n",
            "1289 [ D loss: 0.401750, acc.: 88%] [G loss: 3.038331]\n",
            "1290 [ D loss: 0.233919, acc.: 95%] [G loss: 4.948055]\n",
            "1291 [ D loss: 0.524255, acc.: 63%] [G loss: 1.723423]\n",
            "1292 [ D loss: 0.603111, acc.: 65%] [G loss: 1.738061]\n",
            "1293 [ D loss: 0.342167, acc.: 87%] [G loss: 3.490829]\n",
            "1294 [ D loss: 0.319805, acc.: 95%] [G loss: 3.632038]\n",
            "1295 [ D loss: 0.213081, acc.: 96%] [G loss: 4.029328]\n",
            "1296 [ D loss: 0.355081, acc.: 87%] [G loss: 2.093554]\n",
            "1297 [ D loss: 0.444414, acc.: 78%] [G loss: 3.723065]\n",
            "1298 [ D loss: 0.528898, acc.: 69%] [G loss: 2.239073]\n",
            "1299 [ D loss: 0.361764, acc.: 88%] [G loss: 2.943512]\n",
            "1300 [ D loss: 0.181369, acc.: 96%] [G loss: 5.492321]\n",
            "1301 [ D loss: 0.626972, acc.: 67%] [G loss: 2.951653]\n",
            "1302 [ D loss: 0.206524, acc.: 95%] [G loss: 2.944808]\n",
            "1303 [ D loss: 0.339994, acc.: 88%] [G loss: 2.778954]\n",
            "1304 [ D loss: 0.570482, acc.: 66%] [G loss: 1.352155]\n",
            "1305 [ D loss: 0.621139, acc.: 56%] [G loss: 1.944433]\n",
            "1306 [ D loss: 0.307448, acc.: 91%] [G loss: 3.280818]\n",
            "1307 [ D loss: 0.488871, acc.: 79%] [G loss: 1.948974]\n",
            "1308 [ D loss: 0.296122, acc.: 93%] [G loss: 2.670318]\n",
            "1309 [ D loss: 0.197750, acc.: 98%] [G loss: 3.580939]\n",
            "1310 [ D loss: 0.346313, acc.: 88%] [G loss: 2.713283]\n",
            "1311 [ D loss: 0.650844, acc.: 62%] [G loss: 1.102198]\n",
            "1312 [ D loss: 0.644008, acc.: 58%] [G loss: 1.347733]\n",
            "1313 [ D loss: 0.537471, acc.: 68%] [G loss: 2.110288]\n",
            "1314 [ D loss: 0.287690, acc.: 92%] [G loss: 3.523171]\n",
            "1315 [ D loss: 0.278986, acc.: 96%] [G loss: 3.258038]\n",
            "1316 [ D loss: 0.281072, acc.: 89%] [G loss: 4.245533]\n",
            "1317 [ D loss: 0.349753, acc.: 86%] [G loss: 4.251324]\n",
            "1318 [ D loss: 0.224855, acc.: 93%] [G loss: 4.379276]\n",
            "1319 [ D loss: 0.191119, acc.: 96%] [G loss: 3.863172]\n",
            "1320 [ D loss: 0.606551, acc.: 59%] [G loss: 2.147987]\n",
            "1321 [ D loss: 0.672223, acc.: 59%] [G loss: 1.476691]\n",
            "1322 [ D loss: 0.522536, acc.: 73%] [G loss: 1.645473]\n",
            "1323 [ D loss: 0.339740, acc.: 92%] [G loss: 2.710493]\n",
            "1324 [ D loss: 0.248303, acc.: 96%] [G loss: 2.795959]\n",
            "1325 [ D loss: 0.310679, acc.: 97%] [G loss: 2.332954]\n",
            "1326 [ D loss: 0.226748, acc.: 96%] [G loss: 3.313351]\n",
            "1327 [ D loss: 0.502223, acc.: 67%] [G loss: 2.368910]\n",
            "1328 [ D loss: 0.385903, acc.: 80%] [G loss: 1.451496]\n",
            "1329 [ D loss: 0.280354, acc.: 91%] [G loss: 2.965897]\n",
            "1330 [ D loss: 0.498042, acc.: 65%] [G loss: 1.510947]\n",
            "1331 [ D loss: 0.474370, acc.: 73%] [G loss: 2.459176]\n",
            "1332 [ D loss: 0.566148, acc.: 60%] [G loss: 1.468685]\n",
            "1333 [ D loss: 0.463007, acc.: 77%] [G loss: 1.870419]\n",
            "1334 [ D loss: 0.190061, acc.: 96%] [G loss: 5.614727]\n",
            "1335 [ D loss: 0.324821, acc.: 90%] [G loss: 2.881166]\n",
            "1336 [ D loss: 0.257175, acc.: 95%] [G loss: 2.722782]\n",
            "1337 [ D loss: 0.306980, acc.: 89%] [G loss: 3.180317]\n",
            "1338 [ D loss: 0.170796, acc.: 97%] [G loss: 5.306137]\n",
            "1339 [ D loss: 0.321974, acc.: 91%] [G loss: 2.178109]\n",
            "1340 [ D loss: 0.685116, acc.: 59%] [G loss: 1.650044]\n",
            "1341 [ D loss: 0.650372, acc.: 63%] [G loss: 1.341343]\n",
            "1342 [ D loss: 0.511636, acc.: 68%] [G loss: 2.091843]\n",
            "1343 [ D loss: 0.249578, acc.: 97%] [G loss: 2.335181]\n",
            "1344 [ D loss: 0.317199, acc.: 95%] [G loss: 3.478588]\n",
            "1345 [ D loss: 0.240378, acc.: 94%] [G loss: 4.584297]\n",
            "1346 [ D loss: 0.495825, acc.: 69%] [G loss: 2.531030]\n",
            "1347 [ D loss: 0.634067, acc.: 63%] [G loss: 1.348646]\n",
            "1348 [ D loss: 0.539897, acc.: 68%] [G loss: 1.896804]\n",
            "1349 [ D loss: 0.271634, acc.: 95%] [G loss: 2.460807]\n",
            "1350 [ D loss: 0.199221, acc.: 95%] [G loss: 5.565380]\n",
            "1351 [ D loss: 0.259964, acc.: 92%] [G loss: 2.844166]\n",
            "1352 [ D loss: 0.409712, acc.: 77%] [G loss: 2.853470]\n",
            "1353 [ D loss: 0.406618, acc.: 80%] [G loss: 3.012880]\n",
            "1354 [ D loss: 0.294503, acc.: 91%] [G loss: 2.495638]\n",
            "1355 [ D loss: 0.484059, acc.: 70%] [G loss: 1.879939]\n",
            "1356 [ D loss: 0.614114, acc.: 60%] [G loss: 1.329632]\n",
            "1357 [ D loss: 0.731594, acc.: 53%] [G loss: 1.213872]\n",
            "1358 [ D loss: 0.375117, acc.: 88%] [G loss: 2.173413]\n",
            "1359 [ D loss: 0.276614, acc.: 91%] [G loss: 3.865136]\n",
            "1360 [ D loss: 0.227574, acc.: 94%] [G loss: 4.725412]\n",
            "1361 [ D loss: 0.228989, acc.: 97%] [G loss: 3.552417]\n",
            "1362 [ D loss: 0.312554, acc.: 92%] [G loss: 3.058035]\n",
            "1363 [ D loss: 0.457931, acc.: 65%] [G loss: 2.192281]\n",
            "1364 [ D loss: 0.375310, acc.: 84%] [G loss: 3.007562]\n",
            "1365 [ D loss: 0.352273, acc.: 87%] [G loss: 3.696168]\n",
            "1366 [ D loss: 0.604221, acc.: 63%] [G loss: 1.658241]\n",
            "1367 [ D loss: 0.215396, acc.: 96%] [G loss: 4.976001]\n",
            "1368 [ D loss: 0.160528, acc.: 97%] [G loss: 7.305886]\n",
            "1369 [ D loss: 0.679765, acc.: 60%] [G loss: 1.545347]\n",
            "1370 [ D loss: 0.302621, acc.: 92%] [G loss: 1.948361]\n",
            "1371 [ D loss: 0.243098, acc.: 92%] [G loss: 3.317382]\n",
            "1372 [ D loss: 0.545164, acc.: 63%] [G loss: 1.650511]\n",
            "1373 [ D loss: 0.257515, acc.: 96%] [G loss: 2.942874]\n",
            "1374 [ D loss: 0.422993, acc.: 83%] [G loss: 2.224028]\n",
            "1375 [ D loss: 0.622262, acc.: 59%] [G loss: 1.680177]\n",
            "1376 [ D loss: 0.490593, acc.: 73%] [G loss: 2.201937]\n",
            "1377 [ D loss: 0.300936, acc.: 96%] [G loss: 2.231542]\n",
            "1378 [ D loss: 0.256122, acc.: 95%] [G loss: 2.933160]\n",
            "1379 [ D loss: 0.159219, acc.: 98%] [G loss: 4.744729]\n",
            "1380 [ D loss: 0.384228, acc.: 84%] [G loss: 3.267000]\n",
            "1381 [ D loss: 0.452991, acc.: 72%] [G loss: 2.285560]\n",
            "1382 [ D loss: 0.442736, acc.: 77%] [G loss: 1.990978]\n",
            "1383 [ D loss: 0.522016, acc.: 66%] [G loss: 1.549929]\n",
            "1384 [ D loss: 0.515152, acc.: 70%] [G loss: 2.060654]\n",
            "1385 [ D loss: 0.353086, acc.: 88%] [G loss: 2.851201]\n",
            "1386 [ D loss: 0.201197, acc.: 100%] [G loss: 3.650831]\n",
            "1387 [ D loss: 0.181895, acc.: 97%] [G loss: 3.990320]\n",
            "1388 [ D loss: 0.377813, acc.: 84%] [G loss: 3.322922]\n",
            "1389 [ D loss: 0.469615, acc.: 70%] [G loss: 5.327496]\n",
            "1390 [ D loss: 0.244946, acc.: 89%] [G loss: 4.206745]\n",
            "1391 [ D loss: 0.289414, acc.: 91%] [G loss: 3.665704]\n",
            "1392 [ D loss: 0.527850, acc.: 67%] [G loss: 1.592057]\n",
            "1393 [ D loss: 0.317711, acc.: 89%] [G loss: 2.651021]\n",
            "1394 [ D loss: 0.190630, acc.: 98%] [G loss: 2.919487]\n",
            "1395 [ D loss: 0.304282, acc.: 94%] [G loss: 2.091000]\n",
            "1396 [ D loss: 0.365766, acc.: 86%] [G loss: 2.215683]\n",
            "1397 [ D loss: 0.578852, acc.: 60%] [G loss: 2.368544]\n",
            "1398 [ D loss: 0.405419, acc.: 78%] [G loss: 1.897036]\n",
            "1399 [ D loss: 0.360019, acc.: 88%] [G loss: 2.787528]\n",
            "1400 [ D loss: 0.204417, acc.: 98%] [G loss: 3.444274]\n",
            "1401 [ D loss: 0.176933, acc.: 98%] [G loss: 6.247379]\n",
            "1402 [ D loss: 0.243349, acc.: 96%] [G loss: 2.813364]\n",
            "1403 [ D loss: 0.471962, acc.: 77%] [G loss: 2.623069]\n",
            "1404 [ D loss: 0.183450, acc.: 96%] [G loss: 4.400486]\n",
            "1405 [ D loss: 0.343855, acc.: 89%] [G loss: 3.107535]\n",
            "1406 [ D loss: 0.378848, acc.: 84%] [G loss: 1.796411]\n",
            "1407 [ D loss: 0.511881, acc.: 67%] [G loss: 1.933831]\n",
            "1408 [ D loss: 0.627197, acc.: 59%] [G loss: 1.558582]\n",
            "1409 [ D loss: 0.282274, acc.: 96%] [G loss: 3.238686]\n",
            "1410 [ D loss: 0.204491, acc.: 95%] [G loss: 6.174840]\n",
            "1411 [ D loss: 0.577309, acc.: 61%] [G loss: 1.852781]\n",
            "1412 [ D loss: 0.197598, acc.: 94%] [G loss: 3.756078]\n",
            "1413 [ D loss: 0.248501, acc.: 95%] [G loss: 2.656271]\n",
            "1414 [ D loss: 0.646389, acc.: 53%] [G loss: 1.349144]\n",
            "1415 [ D loss: 0.688451, acc.: 58%] [G loss: 1.636343]\n",
            "1416 [ D loss: 0.494565, acc.: 68%] [G loss: 2.493317]\n",
            "1417 [ D loss: 0.365092, acc.: 89%] [G loss: 2.355823]\n",
            "1418 [ D loss: 0.243384, acc.: 93%] [G loss: 3.931178]\n",
            "1419 [ D loss: 0.317202, acc.: 91%] [G loss: 3.545911]\n",
            "1420 [ D loss: 0.261369, acc.: 96%] [G loss: 2.495219]\n",
            "1421 [ D loss: 0.522525, acc.: 71%] [G loss: 2.728353]\n",
            "1422 [ D loss: 0.552336, acc.: 66%] [G loss: 1.440961]\n",
            "1423 [ D loss: 0.408181, acc.: 84%] [G loss: 2.795348]\n",
            "1424 [ D loss: 0.240702, acc.: 94%] [G loss: 4.968838]\n",
            "1425 [ D loss: 0.320439, acc.: 95%] [G loss: 2.432884]\n",
            "1426 [ D loss: 0.536519, acc.: 58%] [G loss: 1.552503]\n",
            "1427 [ D loss: 0.559163, acc.: 62%] [G loss: 1.518880]\n",
            "1428 [ D loss: 0.325354, acc.: 91%] [G loss: 2.171225]\n",
            "1429 [ D loss: 0.225678, acc.: 95%] [G loss: 3.485509]\n",
            "1430 [ D loss: 0.375100, acc.: 87%] [G loss: 2.993703]\n",
            "1431 [ D loss: 0.279534, acc.: 91%] [G loss: 4.146821]\n",
            "1432 [ D loss: 0.452383, acc.: 77%] [G loss: 2.220746]\n",
            "1433 [ D loss: 0.406469, acc.: 84%] [G loss: 2.550267]\n",
            "1434 [ D loss: 0.408025, acc.: 83%] [G loss: 1.941643]\n",
            "1435 [ D loss: 0.373667, acc.: 91%] [G loss: 3.041674]\n",
            "1436 [ D loss: 0.400781, acc.: 86%] [G loss: 2.403933]\n",
            "1437 [ D loss: 0.250030, acc.: 97%] [G loss: 2.663401]\n",
            "1438 [ D loss: 0.248285, acc.: 95%] [G loss: 2.675326]\n",
            "1439 [ D loss: 0.341178, acc.: 87%] [G loss: 1.595543]\n",
            "1440 [ D loss: 0.604925, acc.: 60%] [G loss: 1.954372]\n",
            "1441 [ D loss: 0.350285, acc.: 92%] [G loss: 2.453385]\n",
            "1442 [ D loss: 0.311071, acc.: 91%] [G loss: 4.280974]\n",
            "1443 [ D loss: 0.353655, acc.: 88%] [G loss: 2.201510]\n",
            "1444 [ D loss: 0.585235, acc.: 63%] [G loss: 3.210149]\n",
            "1445 [ D loss: 0.210457, acc.: 95%] [G loss: 5.436932]\n",
            "1446 [ D loss: 0.526959, acc.: 73%] [G loss: 1.725216]\n",
            "1447 [ D loss: 0.217059, acc.: 95%] [G loss: 4.137448]\n",
            "1448 [ D loss: 0.488995, acc.: 70%] [G loss: 2.230177]\n",
            "1449 [ D loss: 0.622760, acc.: 67%] [G loss: 2.084685]\n",
            "1450 [ D loss: 0.274093, acc.: 95%] [G loss: 3.267132]\n",
            "1451 [ D loss: 0.295702, acc.: 89%] [G loss: 3.432471]\n",
            "1452 [ D loss: 0.735017, acc.: 57%] [G loss: 2.760033]\n",
            "1453 [ D loss: 0.697923, acc.: 57%] [G loss: 2.080584]\n",
            "1454 [ D loss: 0.535939, acc.: 70%] [G loss: 3.155809]\n",
            "1455 [ D loss: 0.275394, acc.: 92%] [G loss: 5.935543]\n",
            "1456 [ D loss: 0.569099, acc.: 67%] [G loss: 1.990783]\n",
            "1457 [ D loss: 0.215590, acc.: 95%] [G loss: 3.373872]\n",
            "1458 [ D loss: 0.276467, acc.: 91%] [G loss: 4.185467]\n",
            "1459 [ D loss: 0.489194, acc.: 77%] [G loss: 1.955808]\n",
            "1460 [ D loss: 0.653541, acc.: 54%] [G loss: 2.176694]\n",
            "1461 [ D loss: 0.210455, acc.: 98%] [G loss: 4.465702]\n",
            "1462 [ D loss: 0.332896, acc.: 92%] [G loss: 2.452562]\n",
            "1463 [ D loss: 0.675969, acc.: 59%] [G loss: 1.765084]\n",
            "1464 [ D loss: 0.496358, acc.: 70%] [G loss: 1.983488]\n",
            "1465 [ D loss: 0.400037, acc.: 83%] [G loss: 2.934504]\n",
            "1466 [ D loss: 0.272071, acc.: 96%] [G loss: 2.520709]\n",
            "1467 [ D loss: 0.353301, acc.: 84%] [G loss: 2.634867]\n",
            "1468 [ D loss: 0.306529, acc.: 91%] [G loss: 2.801482]\n",
            "1469 [ D loss: 0.646103, acc.: 59%] [G loss: 1.749592]\n",
            "1470 [ D loss: 0.307279, acc.: 90%] [G loss: 2.197905]\n",
            "1471 [ D loss: 0.363945, acc.: 86%] [G loss: 2.755356]\n",
            "1472 [ D loss: 0.336085, acc.: 88%] [G loss: 3.948778]\n",
            "1473 [ D loss: 0.521095, acc.: 71%] [G loss: 1.804395]\n",
            "1474 [ D loss: 0.462658, acc.: 77%] [G loss: 5.163305]\n",
            "1475 [ D loss: 0.184282, acc.: 98%] [G loss: 5.088633]\n",
            "1476 [ D loss: 0.382519, acc.: 84%] [G loss: 2.707249]\n",
            "1477 [ D loss: 0.520818, acc.: 67%] [G loss: 1.782283]\n",
            "1478 [ D loss: 0.320086, acc.: 90%] [G loss: 2.857566]\n",
            "1479 [ D loss: 0.198902, acc.: 95%] [G loss: 3.991935]\n",
            "1480 [ D loss: 0.552644, acc.: 64%] [G loss: 2.665329]\n",
            "1481 [ D loss: 0.217706, acc.: 93%] [G loss: 3.717794]\n",
            "1482 [ D loss: 0.366893, acc.: 85%] [G loss: 3.189395]\n",
            "1483 [ D loss: 0.180292, acc.: 96%] [G loss: 3.950601]\n",
            "1484 [ D loss: 0.248215, acc.: 91%] [G loss: 2.857090]\n",
            "1485 [ D loss: 0.465787, acc.: 77%] [G loss: 2.642304]\n",
            "1486 [ D loss: 0.623532, acc.: 56%] [G loss: 2.201158]\n",
            "1487 [ D loss: 0.365701, acc.: 84%] [G loss: 2.345919]\n",
            "1488 [ D loss: 0.338850, acc.: 84%] [G loss: 3.173759]\n",
            "1489 [ D loss: 0.490197, acc.: 76%] [G loss: 2.459358]\n",
            "1490 [ D loss: 0.341104, acc.: 91%] [G loss: 2.051073]\n",
            "1491 [ D loss: 0.507558, acc.: 73%] [G loss: 2.934927]\n",
            "1492 [ D loss: 0.385754, acc.: 90%] [G loss: 2.199050]\n",
            "1493 [ D loss: 0.459154, acc.: 80%] [G loss: 2.813013]\n",
            "1494 [ D loss: 0.428588, acc.: 88%] [G loss: 2.313930]\n",
            "1495 [ D loss: 0.398399, acc.: 85%] [G loss: 2.275355]\n",
            "1496 [ D loss: 0.248585, acc.: 94%] [G loss: 4.024799]\n",
            "1497 [ D loss: 0.260887, acc.: 94%] [G loss: 4.098576]\n",
            "1498 [ D loss: 0.615315, acc.: 62%] [G loss: 2.090596]\n",
            "1499 [ D loss: 0.385224, acc.: 82%] [G loss: 2.218165]\n",
            "1500 [ D loss: 0.484637, acc.: 71%] [G loss: 3.100338]\n",
            "1501 [ D loss: 0.304348, acc.: 85%] [G loss: 4.125627]\n",
            "1502 [ D loss: 0.550467, acc.: 68%] [G loss: 3.160023]\n",
            "1503 [ D loss: 0.478040, acc.: 75%] [G loss: 2.369226]\n",
            "1504 [ D loss: 0.302515, acc.: 91%] [G loss: 3.934757]\n",
            "1505 [ D loss: 0.212367, acc.: 96%] [G loss: 3.343643]\n",
            "1506 [ D loss: 0.536665, acc.: 71%] [G loss: 2.159823]\n",
            "1507 [ D loss: 0.278045, acc.: 91%] [G loss: 2.885943]\n",
            "1508 [ D loss: 0.266328, acc.: 90%] [G loss: 4.080963]\n",
            "1509 [ D loss: 0.368603, acc.: 83%] [G loss: 2.963858]\n",
            "1510 [ D loss: 0.283588, acc.: 94%] [G loss: 2.970841]\n",
            "1511 [ D loss: 0.307776, acc.: 91%] [G loss: 2.742997]\n",
            "1512 [ D loss: 0.361700, acc.: 88%] [G loss: 2.021024]\n",
            "1513 [ D loss: 0.594029, acc.: 65%] [G loss: 1.792369]\n",
            "1514 [ D loss: 0.496842, acc.: 74%] [G loss: 1.942339]\n",
            "1515 [ D loss: 0.454167, acc.: 79%] [G loss: 2.298034]\n",
            "1516 [ D loss: 0.287292, acc.: 92%] [G loss: 3.020161]\n",
            "1517 [ D loss: 0.469169, acc.: 70%] [G loss: 1.913191]\n",
            "1518 [ D loss: 0.556534, acc.: 63%] [G loss: 2.308782]\n",
            "1519 [ D loss: 0.408802, acc.: 83%] [G loss: 2.978144]\n",
            "1520 [ D loss: 0.498661, acc.: 73%] [G loss: 3.579281]\n",
            "1521 [ D loss: 0.320946, acc.: 88%] [G loss: 6.390103]\n",
            "1522 [ D loss: 0.407778, acc.: 81%] [G loss: 2.588203]\n",
            "1523 [ D loss: 0.544505, acc.: 68%] [G loss: 1.927303]\n",
            "1524 [ D loss: 0.601064, acc.: 61%] [G loss: 1.815006]\n",
            "1525 [ D loss: 0.649116, acc.: 54%] [G loss: 1.501675]\n",
            "1526 [ D loss: 0.585829, acc.: 66%] [G loss: 1.997570]\n",
            "1527 [ D loss: 0.252041, acc.: 96%] [G loss: 3.202718]\n",
            "1528 [ D loss: 0.226895, acc.: 95%] [G loss: 3.125988]\n",
            "1529 [ D loss: 0.628454, acc.: 59%] [G loss: 2.223697]\n",
            "1530 [ D loss: 0.515982, acc.: 70%] [G loss: 1.577268]\n",
            "1531 [ D loss: 0.437889, acc.: 77%] [G loss: 1.503460]\n",
            "1532 [ D loss: 0.582559, acc.: 69%] [G loss: 2.009702]\n",
            "1533 [ D loss: 0.274822, acc.: 91%] [G loss: 3.763833]\n",
            "1534 [ D loss: 0.454249, acc.: 78%] [G loss: 2.242338]\n",
            "1535 [ D loss: 0.444129, acc.: 78%] [G loss: 2.738152]\n",
            "1536 [ D loss: 0.278728, acc.: 95%] [G loss: 2.820089]\n",
            "1537 [ D loss: 0.373123, acc.: 85%] [G loss: 2.296402]\n",
            "1538 [ D loss: 0.671714, acc.: 55%] [G loss: 1.459223]\n",
            "1539 [ D loss: 0.508500, acc.: 70%] [G loss: 2.095282]\n",
            "1540 [ D loss: 0.301467, acc.: 93%] [G loss: 2.698912]\n",
            "1541 [ D loss: 0.581433, acc.: 67%] [G loss: 2.572277]\n",
            "1542 [ D loss: 0.403920, acc.: 85%] [G loss: 2.981294]\n",
            "1543 [ D loss: 0.238034, acc.: 96%] [G loss: 3.118181]\n",
            "1544 [ D loss: 0.363203, acc.: 84%] [G loss: 2.447374]\n",
            "1545 [ D loss: 0.416691, acc.: 81%] [G loss: 1.607736]\n",
            "1546 [ D loss: 0.624863, acc.: 62%] [G loss: 1.929405]\n",
            "1547 [ D loss: 0.529452, acc.: 71%] [G loss: 2.093957]\n",
            "1548 [ D loss: 0.338608, acc.: 86%] [G loss: 3.757338]\n",
            "1549 [ D loss: 0.503349, acc.: 74%] [G loss: 1.836857]\n",
            "1550 [ D loss: 0.577954, acc.: 60%] [G loss: 1.580560]\n",
            "1551 [ D loss: 0.552512, acc.: 70%] [G loss: 2.807854]\n",
            "1552 [ D loss: 0.423355, acc.: 81%] [G loss: 2.529208]\n",
            "1553 [ D loss: 0.631605, acc.: 64%] [G loss: 2.158664]\n",
            "1554 [ D loss: 0.425801, acc.: 77%] [G loss: 2.402473]\n",
            "1555 [ D loss: 0.510254, acc.: 68%] [G loss: 3.058396]\n",
            "1556 [ D loss: 0.212246, acc.: 95%] [G loss: 4.043016]\n",
            "1557 [ D loss: 0.387270, acc.: 84%] [G loss: 3.217230]\n",
            "1558 [ D loss: 0.268291, acc.: 92%] [G loss: 4.715640]\n",
            "1559 [ D loss: 0.189858, acc.: 95%] [G loss: 4.289501]\n",
            "1560 [ D loss: 0.228054, acc.: 96%] [G loss: 2.560879]\n",
            "1561 [ D loss: 0.167041, acc.: 97%] [G loss: 2.031698]\n",
            "1562 [ D loss: 0.409525, acc.: 77%] [G loss: 1.606855]\n",
            "1563 [ D loss: 0.595912, acc.: 68%] [G loss: 3.389464]\n",
            "1564 [ D loss: 0.488314, acc.: 70%] [G loss: 1.912553]\n",
            "1565 [ D loss: 0.365626, acc.: 86%] [G loss: 3.213484]\n",
            "1566 [ D loss: 0.297679, acc.: 94%] [G loss: 2.496719]\n",
            "1567 [ D loss: 0.589745, acc.: 57%] [G loss: 2.853849]\n",
            "1568 [ D loss: 0.406906, acc.: 84%] [G loss: 4.473244]\n",
            "1569 [ D loss: 0.447867, acc.: 77%] [G loss: 2.735425]\n",
            "1570 [ D loss: 0.474320, acc.: 72%] [G loss: 2.893163]\n",
            "1571 [ D loss: 0.243199, acc.: 95%] [G loss: 3.185704]\n",
            "1572 [ D loss: 0.677778, acc.: 59%] [G loss: 2.588793]\n",
            "1573 [ D loss: 0.523400, acc.: 69%] [G loss: 2.179874]\n",
            "1574 [ D loss: 0.334600, acc.: 88%] [G loss: 2.971054]\n",
            "1575 [ D loss: 0.288948, acc.: 95%] [G loss: 2.559381]\n",
            "1576 [ D loss: 0.377268, acc.: 84%] [G loss: 3.157325]\n",
            "1577 [ D loss: 0.534360, acc.: 69%] [G loss: 1.288056]\n",
            "1578 [ D loss: 0.361085, acc.: 84%] [G loss: 2.815111]\n",
            "1579 [ D loss: 0.469072, acc.: 80%] [G loss: 2.693555]\n",
            "1580 [ D loss: 0.442088, acc.: 80%] [G loss: 2.093977]\n",
            "1581 [ D loss: 0.470389, acc.: 77%] [G loss: 1.881391]\n",
            "1582 [ D loss: 0.615850, acc.: 60%] [G loss: 1.722548]\n",
            "1583 [ D loss: 0.306550, acc.: 91%] [G loss: 3.275882]\n",
            "1584 [ D loss: 0.368662, acc.: 88%] [G loss: 1.894917]\n",
            "1585 [ D loss: 0.666240, acc.: 55%] [G loss: 1.188179]\n",
            "1586 [ D loss: 0.367542, acc.: 93%] [G loss: 3.980299]\n",
            "1587 [ D loss: 0.565579, acc.: 69%] [G loss: 3.172111]\n",
            "1588 [ D loss: 0.356170, acc.: 85%] [G loss: 6.101727]\n",
            "1589 [ D loss: 0.311026, acc.: 88%] [G loss: 4.319823]\n",
            "1590 [ D loss: 0.451511, acc.: 76%] [G loss: 3.327753]\n",
            "1591 [ D loss: 0.304808, acc.: 91%] [G loss: 2.940055]\n",
            "1592 [ D loss: 0.290587, acc.: 89%] [G loss: 3.027923]\n",
            "1593 [ D loss: 0.417761, acc.: 78%] [G loss: 2.336720]\n",
            "1594 [ D loss: 0.578969, acc.: 62%] [G loss: 1.581162]\n",
            "1595 [ D loss: 0.357741, acc.: 85%] [G loss: 2.503593]\n",
            "1596 [ D loss: 0.364336, acc.: 85%] [G loss: 3.048867]\n",
            "1597 [ D loss: 0.428375, acc.: 80%] [G loss: 5.543037]\n",
            "1598 [ D loss: 0.334005, acc.: 84%] [G loss: 4.594029]\n",
            "1599 [ D loss: 0.416941, acc.: 73%] [G loss: 1.800323]\n",
            "1600 [ D loss: 0.446123, acc.: 71%] [G loss: 2.826416]\n",
            "1601 [ D loss: 0.253129, acc.: 95%] [G loss: 3.400246]\n",
            "1602 [ D loss: 0.372181, acc.: 83%] [G loss: 2.881158]\n",
            "1603 [ D loss: 0.535624, acc.: 66%] [G loss: 2.417997]\n",
            "1604 [ D loss: 0.502740, acc.: 71%] [G loss: 2.175956]\n",
            "1605 [ D loss: 0.292306, acc.: 92%] [G loss: 2.800978]\n",
            "1606 [ D loss: 0.263219, acc.: 93%] [G loss: 3.438602]\n",
            "1607 [ D loss: 0.236087, acc.: 95%] [G loss: 1.834776]\n",
            "1608 [ D loss: 0.543674, acc.: 62%] [G loss: 2.728792]\n",
            "1609 [ D loss: 0.211448, acc.: 94%] [G loss: 4.699549]\n",
            "1610 [ D loss: 0.500743, acc.: 66%] [G loss: 1.395835]\n",
            "1611 [ D loss: 0.255170, acc.: 91%] [G loss: 4.709134]\n",
            "1612 [ D loss: 0.670897, acc.: 61%] [G loss: 1.510888]\n",
            "1613 [ D loss: 0.267033, acc.: 97%] [G loss: 2.560448]\n",
            "1614 [ D loss: 0.250285, acc.: 94%] [G loss: 3.930251]\n",
            "1615 [ D loss: 0.541930, acc.: 70%] [G loss: 2.215215]\n",
            "1616 [ D loss: 0.623554, acc.: 60%] [G loss: 1.378701]\n",
            "1617 [ D loss: 0.420643, acc.: 83%] [G loss: 2.563881]\n",
            "1618 [ D loss: 0.514558, acc.: 78%] [G loss: 4.419201]\n",
            "1619 [ D loss: 0.501514, acc.: 73%] [G loss: 2.671130]\n",
            "1620 [ D loss: 0.395071, acc.: 76%] [G loss: 2.444157]\n",
            "1621 [ D loss: 0.329084, acc.: 86%] [G loss: 2.408527]\n",
            "1622 [ D loss: 0.521075, acc.: 70%] [G loss: 1.730919]\n",
            "1623 [ D loss: 0.505351, acc.: 70%] [G loss: 2.078064]\n",
            "1624 [ D loss: 0.451371, acc.: 77%] [G loss: 2.072288]\n",
            "1625 [ D loss: 0.349591, acc.: 87%] [G loss: 3.479583]\n",
            "1626 [ D loss: 0.492602, acc.: 77%] [G loss: 3.058131]\n",
            "1627 [ D loss: 0.215092, acc.: 96%] [G loss: 3.495321]\n",
            "1628 [ D loss: 0.245499, acc.: 94%] [G loss: 3.486176]\n",
            "1629 [ D loss: 0.504172, acc.: 71%] [G loss: 3.294843]\n",
            "1630 [ D loss: 0.252380, acc.: 92%] [G loss: 6.550976]\n",
            "1631 [ D loss: 0.539027, acc.: 70%] [G loss: 3.149417]\n",
            "1632 [ D loss: 0.228677, acc.: 93%] [G loss: 3.342998]\n",
            "1633 [ D loss: 0.287800, acc.: 91%] [G loss: 3.209738]\n",
            "1634 [ D loss: 0.465545, acc.: 80%] [G loss: 3.237190]\n",
            "1635 [ D loss: 0.526867, acc.: 69%] [G loss: 1.998775]\n",
            "1636 [ D loss: 0.583662, acc.: 60%] [G loss: 1.325040]\n",
            "1637 [ D loss: 0.542121, acc.: 65%] [G loss: 2.479828]\n",
            "1638 [ D loss: 0.608770, acc.: 56%] [G loss: 1.978447]\n",
            "1639 [ D loss: 0.470732, acc.: 73%] [G loss: 2.039849]\n",
            "1640 [ D loss: 0.533294, acc.: 80%] [G loss: 1.718930]\n",
            "1641 [ D loss: 0.510295, acc.: 72%] [G loss: 2.358061]\n",
            "1642 [ D loss: 0.313601, acc.: 94%] [G loss: 2.452674]\n",
            "1643 [ D loss: 0.297497, acc.: 91%] [G loss: 3.015219]\n",
            "1644 [ D loss: 0.342599, acc.: 88%] [G loss: 2.579993]\n",
            "1645 [ D loss: 0.642169, acc.: 55%] [G loss: 1.020786]\n",
            "1646 [ D loss: 0.508392, acc.: 76%] [G loss: 1.420609]\n",
            "1647 [ D loss: 0.442083, acc.: 84%] [G loss: 2.280007]\n",
            "1648 [ D loss: 0.460676, acc.: 75%] [G loss: 4.448635]\n",
            "1649 [ D loss: 0.469783, acc.: 76%] [G loss: 1.878239]\n",
            "1650 [ D loss: 0.654309, acc.: 52%] [G loss: 1.327646]\n",
            "1651 [ D loss: 0.563318, acc.: 69%] [G loss: 1.886025]\n",
            "1652 [ D loss: 0.510654, acc.: 67%] [G loss: 1.804334]\n",
            "1653 [ D loss: 0.466688, acc.: 77%] [G loss: 2.454404]\n",
            "1654 [ D loss: 0.380018, acc.: 88%] [G loss: 2.200378]\n",
            "1655 [ D loss: 0.471407, acc.: 78%] [G loss: 3.484090]\n",
            "1656 [ D loss: 0.306777, acc.: 88%] [G loss: 2.851314]\n",
            "1657 [ D loss: 0.485857, acc.: 68%] [G loss: 2.103954]\n",
            "1658 [ D loss: 0.263546, acc.: 96%] [G loss: 3.583713]\n",
            "1659 [ D loss: 0.429065, acc.: 79%] [G loss: 1.994187]\n",
            "1660 [ D loss: 0.541544, acc.: 66%] [G loss: 1.793040]\n",
            "1661 [ D loss: 0.384882, acc.: 84%] [G loss: 2.765901]\n",
            "1662 [ D loss: 0.328169, acc.: 91%] [G loss: 4.615902]\n",
            "1663 [ D loss: 0.359690, acc.: 87%] [G loss: 1.965476]\n",
            "1664 [ D loss: 0.561673, acc.: 62%] [G loss: 1.455776]\n",
            "1665 [ D loss: 0.350425, acc.: 84%] [G loss: 2.312709]\n",
            "1666 [ D loss: 0.613781, acc.: 61%] [G loss: 1.389617]\n",
            "1667 [ D loss: 0.556222, acc.: 62%] [G loss: 1.911115]\n",
            "1668 [ D loss: 0.387736, acc.: 92%] [G loss: 2.665931]\n",
            "1669 [ D loss: 0.514296, acc.: 77%] [G loss: 2.717960]\n",
            "1670 [ D loss: 0.605464, acc.: 60%] [G loss: 1.620303]\n",
            "1671 [ D loss: 0.566817, acc.: 59%] [G loss: 1.793949]\n",
            "1672 [ D loss: 0.531966, acc.: 64%] [G loss: 1.501184]\n",
            "1673 [ D loss: 0.492056, acc.: 81%] [G loss: 2.570656]\n",
            "1674 [ D loss: 0.593942, acc.: 67%] [G loss: 2.763582]\n",
            "1675 [ D loss: 0.607940, acc.: 69%] [G loss: 1.929907]\n",
            "1676 [ D loss: 0.424437, acc.: 78%] [G loss: 3.457569]\n",
            "1677 [ D loss: 0.415756, acc.: 79%] [G loss: 1.701578]\n",
            "1678 [ D loss: 0.514364, acc.: 73%] [G loss: 3.037093]\n",
            "1679 [ D loss: 0.419567, acc.: 80%] [G loss: 3.714638]\n",
            "1680 [ D loss: 0.514339, acc.: 77%] [G loss: 2.756029]\n",
            "1681 [ D loss: 0.425757, acc.: 82%] [G loss: 3.722680]\n",
            "1682 [ D loss: 0.402937, acc.: 86%] [G loss: 2.593114]\n",
            "1683 [ D loss: 0.515474, acc.: 69%] [G loss: 1.610013]\n",
            "1684 [ D loss: 0.606582, acc.: 58%] [G loss: 1.549568]\n",
            "1685 [ D loss: 0.330071, acc.: 88%] [G loss: 3.226967]\n",
            "1686 [ D loss: 0.367580, acc.: 83%] [G loss: 1.239584]\n",
            "1687 [ D loss: 0.285625, acc.: 91%] [G loss: 3.649616]\n",
            "1688 [ D loss: 0.439189, acc.: 77%] [G loss: 3.181707]\n",
            "1689 [ D loss: 0.550687, acc.: 68%] [G loss: 2.532508]\n",
            "1690 [ D loss: 0.214496, acc.: 98%] [G loss: 4.697692]\n",
            "1691 [ D loss: 0.548234, acc.: 63%] [G loss: 4.718345]\n",
            "1692 [ D loss: 0.353294, acc.: 88%] [G loss: 4.097045]\n",
            "1693 [ D loss: 0.565162, acc.: 66%] [G loss: 2.998044]\n",
            "1694 [ D loss: 0.384615, acc.: 82%] [G loss: 3.455340]\n",
            "1695 [ D loss: 0.413558, acc.: 82%] [G loss: 2.481839]\n",
            "1696 [ D loss: 0.459246, acc.: 74%] [G loss: 3.328146]\n",
            "1697 [ D loss: 0.340056, acc.: 86%] [G loss: 3.754779]\n",
            "1698 [ D loss: 0.312007, acc.: 87%] [G loss: 4.047618]\n",
            "1699 [ D loss: 0.404771, acc.: 80%] [G loss: 3.269630]\n",
            "1700 [ D loss: 0.362214, acc.: 84%] [G loss: 3.244418]\n",
            "1701 [ D loss: 0.261332, acc.: 95%] [G loss: 3.626911]\n",
            "1702 [ D loss: 0.234184, acc.: 95%] [G loss: 4.025656]\n",
            "1703 [ D loss: 0.674183, acc.: 55%] [G loss: 2.216809]\n",
            "1704 [ D loss: 0.450311, acc.: 79%] [G loss: 2.783821]\n",
            "1705 [ D loss: 0.320149, acc.: 89%] [G loss: 4.443876]\n",
            "1706 [ D loss: 0.420678, acc.: 83%] [G loss: 2.171865]\n",
            "1707 [ D loss: 0.423604, acc.: 80%] [G loss: 2.216074]\n",
            "1708 [ D loss: 0.351271, acc.: 91%] [G loss: 3.174208]\n",
            "1709 [ D loss: 0.498483, acc.: 73%] [G loss: 2.368218]\n",
            "1710 [ D loss: 0.350323, acc.: 85%] [G loss: 1.999369]\n",
            "1711 [ D loss: 0.555850, acc.: 64%] [G loss: 1.590698]\n",
            "1712 [ D loss: 0.574296, acc.: 65%] [G loss: 2.292367]\n",
            "1713 [ D loss: 0.572719, acc.: 68%] [G loss: 2.496697]\n",
            "1714 [ D loss: 0.283123, acc.: 90%] [G loss: 3.271908]\n",
            "1715 [ D loss: 0.656560, acc.: 55%] [G loss: 1.720636]\n",
            "1716 [ D loss: 0.319372, acc.: 92%] [G loss: 2.587816]\n",
            "1717 [ D loss: 0.404482, acc.: 82%] [G loss: 3.882629]\n",
            "1718 [ D loss: 0.388864, acc.: 84%] [G loss: 1.568332]\n",
            "1719 [ D loss: 0.434178, acc.: 81%] [G loss: 2.903036]\n",
            "1720 [ D loss: 0.364691, acc.: 88%] [G loss: 3.161400]\n",
            "1721 [ D loss: 0.461131, acc.: 73%] [G loss: 2.108773]\n",
            "1722 [ D loss: 0.352890, acc.: 87%] [G loss: 2.354444]\n",
            "1723 [ D loss: 0.393283, acc.: 80%] [G loss: 2.565888]\n",
            "1724 [ D loss: 0.325016, acc.: 88%] [G loss: 3.700253]\n",
            "1725 [ D loss: 0.537925, acc.: 69%] [G loss: 2.726725]\n",
            "1726 [ D loss: 0.431894, acc.: 75%] [G loss: 2.069689]\n",
            "1727 [ D loss: 0.439934, acc.: 81%] [G loss: 2.952411]\n",
            "1728 [ D loss: 0.410112, acc.: 81%] [G loss: 3.599759]\n",
            "1729 [ D loss: 0.393347, acc.: 82%] [G loss: 3.971337]\n",
            "1730 [ D loss: 0.470055, acc.: 73%] [G loss: 2.423773]\n",
            "1731 [ D loss: 0.283000, acc.: 91%] [G loss: 2.329787]\n",
            "1732 [ D loss: 0.405217, acc.: 77%] [G loss: 3.537253]\n",
            "1733 [ D loss: 0.271689, acc.: 95%] [G loss: 3.510827]\n",
            "1734 [ D loss: 0.460215, acc.: 75%] [G loss: 5.235023]\n",
            "1735 [ D loss: 0.273176, acc.: 88%] [G loss: 4.941248]\n",
            "1736 [ D loss: 0.363978, acc.: 84%] [G loss: 5.984585]\n",
            "1737 [ D loss: 0.431893, acc.: 77%] [G loss: 3.303554]\n",
            "1738 [ D loss: 0.528637, acc.: 68%] [G loss: 4.214371]\n",
            "1739 [ D loss: 0.479355, acc.: 74%] [G loss: 2.594764]\n",
            "1740 [ D loss: 0.431873, acc.: 84%] [G loss: 2.761173]\n",
            "1741 [ D loss: 0.368632, acc.: 87%] [G loss: 3.769290]\n",
            "1742 [ D loss: 0.464717, acc.: 77%] [G loss: 4.153047]\n",
            "1743 [ D loss: 0.489995, acc.: 73%] [G loss: 2.175335]\n",
            "1744 [ D loss: 0.577873, acc.: 63%] [G loss: 2.244378]\n",
            "1745 [ D loss: 0.431442, acc.: 77%] [G loss: 2.763447]\n",
            "1746 [ D loss: 0.438023, acc.: 74%] [G loss: 2.239687]\n",
            "1747 [ D loss: 0.294475, acc.: 95%] [G loss: 3.136408]\n",
            "1748 [ D loss: 0.445023, acc.: 80%] [G loss: 2.072646]\n",
            "1749 [ D loss: 0.406322, acc.: 81%] [G loss: 2.491141]\n",
            "1750 [ D loss: 0.355123, acc.: 88%] [G loss: 2.701440]\n",
            "1751 [ D loss: 0.560845, acc.: 64%] [G loss: 1.979900]\n",
            "1752 [ D loss: 0.600306, acc.: 54%] [G loss: 1.691271]\n",
            "1753 [ D loss: 0.568805, acc.: 63%] [G loss: 1.926051]\n",
            "1754 [ D loss: 0.465980, acc.: 77%] [G loss: 1.932899]\n",
            "1755 [ D loss: 0.576443, acc.: 62%] [G loss: 1.860708]\n",
            "1756 [ D loss: 0.546208, acc.: 66%] [G loss: 2.107470]\n",
            "1757 [ D loss: 0.439742, acc.: 84%] [G loss: 2.873396]\n",
            "1758 [ D loss: 0.463399, acc.: 78%] [G loss: 1.903325]\n",
            "1759 [ D loss: 0.420529, acc.: 80%] [G loss: 1.847248]\n",
            "1760 [ D loss: 0.398032, acc.: 80%] [G loss: 3.196157]\n",
            "1761 [ D loss: 0.488059, acc.: 73%] [G loss: 2.518453]\n",
            "1762 [ D loss: 0.285480, acc.: 91%] [G loss: 3.898998]\n",
            "1763 [ D loss: 0.323834, acc.: 89%] [G loss: 2.467193]\n",
            "1764 [ D loss: 0.605693, acc.: 55%] [G loss: 1.502042]\n",
            "1765 [ D loss: 0.416834, acc.: 82%] [G loss: 2.036305]\n",
            "1766 [ D loss: 0.490351, acc.: 77%] [G loss: 3.289634]\n",
            "1767 [ D loss: 0.373975, acc.: 84%] [G loss: 6.568857]\n",
            "1768 [ D loss: 0.333405, acc.: 85%] [G loss: 5.169142]\n",
            "1769 [ D loss: 0.452675, acc.: 73%] [G loss: 4.712928]\n",
            "1770 [ D loss: 0.237444, acc.: 94%] [G loss: 4.743542]\n",
            "1771 [ D loss: 0.418480, acc.: 82%] [G loss: 4.089531]\n",
            "1772 [ D loss: 0.281969, acc.: 90%] [G loss: 3.598729]\n",
            "1773 [ D loss: 0.338389, acc.: 88%] [G loss: 3.423277]\n",
            "1774 [ D loss: 0.400736, acc.: 80%] [G loss: 1.926623]\n",
            "1775 [ D loss: 0.301574, acc.: 92%] [G loss: 3.416012]\n",
            "1776 [ D loss: 0.316610, acc.: 85%] [G loss: 3.143212]\n",
            "1777 [ D loss: 0.540441, acc.: 68%] [G loss: 1.938985]\n",
            "1778 [ D loss: 0.300016, acc.: 91%] [G loss: 3.931942]\n",
            "1779 [ D loss: 0.405866, acc.: 79%] [G loss: 1.867144]\n",
            "1780 [ D loss: 0.637898, acc.: 59%] [G loss: 1.450107]\n",
            "1781 [ D loss: 0.510225, acc.: 73%] [G loss: 2.861903]\n",
            "1782 [ D loss: 0.390422, acc.: 87%] [G loss: 3.010222]\n",
            "1783 [ D loss: 0.523087, acc.: 67%] [G loss: 3.704352]\n",
            "1784 [ D loss: 0.238841, acc.: 95%] [G loss: 2.132081]\n",
            "1785 [ D loss: 0.558924, acc.: 64%] [G loss: 1.861082]\n",
            "1786 [ D loss: 0.262021, acc.: 94%] [G loss: 5.076722]\n",
            "1787 [ D loss: 0.553314, acc.: 59%] [G loss: 2.078174]\n",
            "1788 [ D loss: 0.267424, acc.: 91%] [G loss: 3.607020]\n",
            "1789 [ D loss: 0.476279, acc.: 73%] [G loss: 1.983359]\n",
            "1790 [ D loss: 0.370778, acc.: 82%] [G loss: 1.944162]\n",
            "1791 [ D loss: 0.424211, acc.: 83%] [G loss: 2.620322]\n",
            "1792 [ D loss: 0.535408, acc.: 68%] [G loss: 2.388003]\n",
            "1793 [ D loss: 0.604441, acc.: 70%] [G loss: 3.694627]\n",
            "1794 [ D loss: 0.730549, acc.: 52%] [G loss: 1.826568]\n",
            "1795 [ D loss: 0.586779, acc.: 62%] [G loss: 1.510680]\n",
            "1796 [ D loss: 0.373821, acc.: 82%] [G loss: 1.911563]\n",
            "1797 [ D loss: 0.499411, acc.: 77%] [G loss: 1.974631]\n",
            "1798 [ D loss: 0.395716, acc.: 84%] [G loss: 2.866886]\n",
            "1799 [ D loss: 0.352120, acc.: 84%] [G loss: 2.294526]\n",
            "1800 [ D loss: 0.415030, acc.: 84%] [G loss: 3.754427]\n",
            "1801 [ D loss: 0.363673, acc.: 86%] [G loss: 3.806010]\n",
            "1802 [ D loss: 0.321007, acc.: 87%] [G loss: 2.312959]\n",
            "1803 [ D loss: 0.259045, acc.: 93%] [G loss: 2.540132]\n",
            "1804 [ D loss: 0.400757, acc.: 80%] [G loss: 3.144126]\n",
            "1805 [ D loss: 0.407124, acc.: 80%] [G loss: 2.847260]\n",
            "1806 [ D loss: 0.341774, acc.: 91%] [G loss: 3.055791]\n",
            "1807 [ D loss: 0.460644, acc.: 72%] [G loss: 2.119735]\n",
            "1808 [ D loss: 0.342919, acc.: 88%] [G loss: 3.196027]\n",
            "1809 [ D loss: 0.404228, acc.: 77%] [G loss: 3.109777]\n",
            "1810 [ D loss: 0.421293, acc.: 77%] [G loss: 2.533278]\n",
            "1811 [ D loss: 0.451784, acc.: 73%] [G loss: 2.675174]\n",
            "1812 [ D loss: 0.414700, acc.: 78%] [G loss: 1.911349]\n",
            "1813 [ D loss: 0.383296, acc.: 80%] [G loss: 2.767018]\n",
            "1814 [ D loss: 0.417315, acc.: 79%] [G loss: 2.213583]\n",
            "1815 [ D loss: 0.550513, acc.: 65%] [G loss: 2.362812]\n",
            "1816 [ D loss: 0.521085, acc.: 66%] [G loss: 2.418484]\n",
            "1817 [ D loss: 0.556452, acc.: 66%] [G loss: 2.160805]\n",
            "1818 [ D loss: 0.409706, acc.: 82%] [G loss: 2.680250]\n",
            "1819 [ D loss: 0.479731, acc.: 74%] [G loss: 2.205364]\n",
            "1820 [ D loss: 0.577551, acc.: 59%] [G loss: 1.885863]\n",
            "1821 [ D loss: 0.428928, acc.: 80%] [G loss: 3.586840]\n",
            "1822 [ D loss: 0.341723, acc.: 88%] [G loss: 5.745493]\n",
            "1823 [ D loss: 0.356034, acc.: 87%] [G loss: 5.054899]\n",
            "1824 [ D loss: 0.360993, acc.: 85%] [G loss: 2.532790]\n",
            "1825 [ D loss: 0.370881, acc.: 86%] [G loss: 2.242497]\n",
            "1826 [ D loss: 0.629070, acc.: 57%] [G loss: 1.160278]\n",
            "1827 [ D loss: 0.366774, acc.: 88%] [G loss: 2.857355]\n",
            "1828 [ D loss: 0.417882, acc.: 77%] [G loss: 3.602612]\n",
            "1829 [ D loss: 0.483166, acc.: 71%] [G loss: 2.924806]\n",
            "1830 [ D loss: 0.558870, acc.: 62%] [G loss: 1.846961]\n",
            "1831 [ D loss: 0.456242, acc.: 75%] [G loss: 2.206783]\n",
            "1832 [ D loss: 0.623758, acc.: 55%] [G loss: 1.974232]\n",
            "1833 [ D loss: 0.354519, acc.: 84%] [G loss: 2.966019]\n",
            "1834 [ D loss: 0.404599, acc.: 88%] [G loss: 3.833508]\n",
            "1835 [ D loss: 0.460420, acc.: 77%] [G loss: 2.821182]\n",
            "1836 [ D loss: 0.577924, acc.: 66%] [G loss: 3.402009]\n",
            "1837 [ D loss: 0.344741, acc.: 88%] [G loss: 2.370924]\n",
            "1838 [ D loss: 0.479605, acc.: 73%] [G loss: 1.507748]\n",
            "1839 [ D loss: 0.514696, acc.: 69%] [G loss: 2.130147]\n",
            "1840 [ D loss: 0.358834, acc.: 87%] [G loss: 2.023055]\n",
            "1841 [ D loss: 0.591876, acc.: 66%] [G loss: 3.419511]\n",
            "1842 [ D loss: 0.291934, acc.: 94%] [G loss: 3.893855]\n",
            "1843 [ D loss: 0.354077, acc.: 85%] [G loss: 4.616931]\n",
            "1844 [ D loss: 0.516765, acc.: 69%] [G loss: 1.299398]\n",
            "1845 [ D loss: 0.440219, acc.: 78%] [G loss: 2.916275]\n",
            "1846 [ D loss: 0.555814, acc.: 74%] [G loss: 2.923945]\n",
            "1847 [ D loss: 0.451958, acc.: 80%] [G loss: 2.156111]\n",
            "1848 [ D loss: 0.370440, acc.: 85%] [G loss: 3.402437]\n",
            "1849 [ D loss: 0.581165, acc.: 59%] [G loss: 2.175631]\n",
            "1850 [ D loss: 0.568152, acc.: 58%] [G loss: 1.600908]\n",
            "1851 [ D loss: 0.450150, acc.: 77%] [G loss: 2.611583]\n",
            "1852 [ D loss: 0.353583, acc.: 91%] [G loss: 2.626956]\n",
            "1853 [ D loss: 0.371287, acc.: 89%] [G loss: 3.016995]\n",
            "1854 [ D loss: 0.560067, acc.: 66%] [G loss: 1.852521]\n",
            "1855 [ D loss: 0.565864, acc.: 66%] [G loss: 1.905319]\n",
            "1856 [ D loss: 0.544529, acc.: 65%] [G loss: 1.868096]\n",
            "1857 [ D loss: 0.497909, acc.: 80%] [G loss: 1.970915]\n",
            "1858 [ D loss: 0.395365, acc.: 84%] [G loss: 2.675419]\n",
            "1859 [ D loss: 0.551395, acc.: 66%] [G loss: 3.011952]\n",
            "1860 [ D loss: 0.227215, acc.: 99%] [G loss: 2.827388]\n",
            "1861 [ D loss: 0.383078, acc.: 84%] [G loss: 5.796173]\n",
            "1862 [ D loss: 0.267576, acc.: 92%] [G loss: 4.668510]\n",
            "1863 [ D loss: 0.261621, acc.: 89%] [G loss: 3.893009]\n",
            "1864 [ D loss: 0.401500, acc.: 80%] [G loss: 2.303252]\n",
            "1865 [ D loss: 0.450863, acc.: 74%] [G loss: 3.427200]\n",
            "1866 [ D loss: 0.277566, acc.: 91%] [G loss: 3.648819]\n",
            "1867 [ D loss: 0.411872, acc.: 79%] [G loss: 3.324556]\n",
            "1868 [ D loss: 0.330337, acc.: 83%] [G loss: 3.113028]\n",
            "1869 [ D loss: 0.498812, acc.: 73%] [G loss: 3.659880]\n",
            "1870 [ D loss: 0.408241, acc.: 80%] [G loss: 3.441295]\n",
            "1871 [ D loss: 0.604683, acc.: 59%] [G loss: 1.813209]\n",
            "1872 [ D loss: 0.280530, acc.: 95%] [G loss: 4.429590]\n",
            "1873 [ D loss: 0.404824, acc.: 79%] [G loss: 2.806125]\n",
            "1874 [ D loss: 0.512273, acc.: 67%] [G loss: 2.396187]\n",
            "1875 [ D loss: 0.453878, acc.: 77%] [G loss: 2.318667]\n",
            "1876 [ D loss: 0.278701, acc.: 95%] [G loss: 2.501402]\n",
            "1877 [ D loss: 0.493905, acc.: 70%] [G loss: 2.247077]\n",
            "1878 [ D loss: 0.536399, acc.: 68%] [G loss: 2.049492]\n",
            "1879 [ D loss: 0.536372, acc.: 65%] [G loss: 1.357846]\n",
            "1880 [ D loss: 0.482530, acc.: 73%] [G loss: 2.008957]\n",
            "1881 [ D loss: 0.461801, acc.: 76%] [G loss: 1.388505]\n",
            "1882 [ D loss: 0.453580, acc.: 81%] [G loss: 4.482387]\n",
            "1883 [ D loss: 0.299053, acc.: 93%] [G loss: 3.985412]\n",
            "1884 [ D loss: 0.292767, acc.: 87%] [G loss: 6.584969]\n",
            "1885 [ D loss: 0.300492, acc.: 90%] [G loss: 2.304497]\n",
            "1886 [ D loss: 0.414720, acc.: 79%] [G loss: 3.942011]\n",
            "1887 [ D loss: 0.444557, acc.: 74%] [G loss: 2.390201]\n",
            "1888 [ D loss: 0.407327, acc.: 79%] [G loss: 4.630402]\n",
            "1889 [ D loss: 0.390054, acc.: 80%] [G loss: 2.210427]\n",
            "1890 [ D loss: 0.444670, acc.: 74%] [G loss: 1.486872]\n",
            "1891 [ D loss: 0.479752, acc.: 70%] [G loss: 1.251593]\n",
            "1892 [ D loss: 0.565590, acc.: 60%] [G loss: 1.601674]\n",
            "1893 [ D loss: 0.359949, acc.: 84%] [G loss: 2.577542]\n",
            "1894 [ D loss: 0.551936, acc.: 67%] [G loss: 1.859930]\n",
            "1895 [ D loss: 0.535865, acc.: 65%] [G loss: 1.610893]\n",
            "1896 [ D loss: 0.573335, acc.: 63%] [G loss: 1.577730]\n",
            "1897 [ D loss: 0.461902, acc.: 77%] [G loss: 3.125911]\n",
            "1898 [ D loss: 0.357006, acc.: 94%] [G loss: 2.678159]\n",
            "1899 [ D loss: 0.419857, acc.: 85%] [G loss: 3.328046]\n",
            "1900 [ D loss: 0.587698, acc.: 66%] [G loss: 2.778069]\n",
            "1901 [ D loss: 0.532623, acc.: 70%] [G loss: 1.872030]\n",
            "1902 [ D loss: 0.463367, acc.: 75%] [G loss: 2.166206]\n",
            "1903 [ D loss: 0.428380, acc.: 77%] [G loss: 2.494070]\n",
            "1904 [ D loss: 0.485905, acc.: 66%] [G loss: 1.884506]\n",
            "1905 [ D loss: 0.575526, acc.: 60%] [G loss: 1.874801]\n",
            "1906 [ D loss: 0.472318, acc.: 73%] [G loss: 1.810622]\n",
            "1907 [ D loss: 0.432086, acc.: 80%] [G loss: 2.094023]\n",
            "1908 [ D loss: 0.445668, acc.: 81%] [G loss: 1.891044]\n",
            "1909 [ D loss: 0.439470, acc.: 86%] [G loss: 2.903847]\n",
            "1910 [ D loss: 0.505935, acc.: 74%] [G loss: 1.510437]\n",
            "1911 [ D loss: 0.431822, acc.: 83%] [G loss: 1.292350]\n",
            "1912 [ D loss: 0.584495, acc.: 64%] [G loss: 1.872757]\n",
            "1913 [ D loss: 0.457320, acc.: 78%] [G loss: 2.502241]\n",
            "1914 [ D loss: 0.361178, acc.: 89%] [G loss: 2.689417]\n",
            "1915 [ D loss: 0.605035, acc.: 66%] [G loss: 1.959321]\n",
            "1916 [ D loss: 0.363337, acc.: 84%] [G loss: 2.909880]\n",
            "1917 [ D loss: 0.499444, acc.: 71%] [G loss: 3.365266]\n",
            "1918 [ D loss: 0.319958, acc.: 91%] [G loss: 3.333001]\n",
            "1919 [ D loss: 0.320691, acc.: 91%] [G loss: 2.558292]\n",
            "1920 [ D loss: 0.328800, acc.: 93%] [G loss: 3.498846]\n",
            "1921 [ D loss: 0.284987, acc.: 95%] [G loss: 4.575311]\n",
            "1922 [ D loss: 0.522846, acc.: 69%] [G loss: 1.801210]\n",
            "1923 [ D loss: 0.310942, acc.: 95%] [G loss: 3.851696]\n",
            "1924 [ D loss: 0.341375, acc.: 86%] [G loss: 2.537497]\n",
            "1925 [ D loss: 0.442745, acc.: 80%] [G loss: 2.449406]\n",
            "1926 [ D loss: 0.507854, acc.: 72%] [G loss: 2.946140]\n",
            "1927 [ D loss: 0.388680, acc.: 80%] [G loss: 2.355551]\n",
            "1928 [ D loss: 0.596957, acc.: 63%] [G loss: 2.088185]\n",
            "1929 [ D loss: 0.371850, acc.: 86%] [G loss: 3.604731]\n",
            "1930 [ D loss: 0.458407, acc.: 80%] [G loss: 2.378956]\n",
            "1931 [ D loss: 0.437690, acc.: 76%] [G loss: 3.090562]\n",
            "1932 [ D loss: 0.379707, acc.: 84%] [G loss: 2.823540]\n",
            "1933 [ D loss: 0.374521, acc.: 83%] [G loss: 3.696500]\n",
            "1934 [ D loss: 0.571726, acc.: 65%] [G loss: 5.285710]\n",
            "1935 [ D loss: 0.275191, acc.: 91%] [G loss: 4.264589]\n",
            "1936 [ D loss: 0.454055, acc.: 78%] [G loss: 1.857875]\n",
            "1937 [ D loss: 0.453683, acc.: 80%] [G loss: 1.948909]\n",
            "1938 [ D loss: 0.446226, acc.: 77%] [G loss: 2.053205]\n",
            "1939 [ D loss: 0.484973, acc.: 71%] [G loss: 2.225308]\n",
            "1940 [ D loss: 0.370512, acc.: 87%] [G loss: 1.759330]\n",
            "1941 [ D loss: 0.481956, acc.: 70%] [G loss: 1.711797]\n",
            "1942 [ D loss: 0.483147, acc.: 77%] [G loss: 2.166727]\n",
            "1943 [ D loss: 0.426723, acc.: 81%] [G loss: 2.995655]\n",
            "1944 [ D loss: 0.443076, acc.: 75%] [G loss: 2.145217]\n",
            "1945 [ D loss: 0.432278, acc.: 78%] [G loss: 2.191118]\n",
            "1946 [ D loss: 0.554951, acc.: 62%] [G loss: 1.853828]\n",
            "1947 [ D loss: 0.468805, acc.: 76%] [G loss: 2.103981]\n",
            "1948 [ D loss: 0.379806, acc.: 92%] [G loss: 2.563448]\n",
            "1949 [ D loss: 0.413294, acc.: 80%] [G loss: 3.111765]\n",
            "1950 [ D loss: 0.421493, acc.: 77%] [G loss: 1.833937]\n",
            "1951 [ D loss: 0.319736, acc.: 87%] [G loss: 2.455897]\n",
            "1952 [ D loss: 0.425543, acc.: 77%] [G loss: 2.829068]\n",
            "1953 [ D loss: 0.406477, acc.: 77%] [G loss: 2.866642]\n",
            "1954 [ D loss: 0.470125, acc.: 73%] [G loss: 2.800614]\n",
            "1955 [ D loss: 0.401149, acc.: 80%] [G loss: 2.769999]\n",
            "1956 [ D loss: 0.212313, acc.: 97%] [G loss: 6.091262]\n",
            "1957 [ D loss: 0.310945, acc.: 93%] [G loss: 2.865704]\n",
            "1958 [ D loss: 0.360146, acc.: 81%] [G loss: 3.005400]\n",
            "1959 [ D loss: 0.367037, acc.: 80%] [G loss: 2.032925]\n",
            "1960 [ D loss: 0.487709, acc.: 69%] [G loss: 1.756360]\n",
            "1961 [ D loss: 0.466773, acc.: 75%] [G loss: 2.078911]\n",
            "1962 [ D loss: 0.531132, acc.: 72%] [G loss: 1.735300]\n",
            "1963 [ D loss: 0.428802, acc.: 83%] [G loss: 2.648748]\n",
            "1964 [ D loss: 0.537543, acc.: 70%] [G loss: 2.104568]\n",
            "1965 [ D loss: 0.496508, acc.: 72%] [G loss: 3.310596]\n",
            "1966 [ D loss: 0.482824, acc.: 76%] [G loss: 2.266517]\n",
            "1967 [ D loss: 0.398317, acc.: 80%] [G loss: 2.552721]\n",
            "1968 [ D loss: 0.270662, acc.: 91%] [G loss: 4.464569]\n",
            "1969 [ D loss: 0.368131, acc.: 83%] [G loss: 2.213264]\n",
            "1970 [ D loss: 0.271130, acc.: 93%] [G loss: 3.323937]\n",
            "1971 [ D loss: 0.451510, acc.: 77%] [G loss: 2.350864]\n",
            "1972 [ D loss: 0.360041, acc.: 82%] [G loss: 2.770702]\n",
            "1973 [ D loss: 0.301993, acc.: 89%] [G loss: 2.602862]\n",
            "1974 [ D loss: 0.539532, acc.: 68%] [G loss: 2.562840]\n",
            "1975 [ D loss: 0.407964, acc.: 77%] [G loss: 4.838899]\n",
            "1976 [ D loss: 0.529032, acc.: 64%] [G loss: 2.221387]\n",
            "1977 [ D loss: 0.235682, acc.: 97%] [G loss: 4.001992]\n",
            "1978 [ D loss: 0.409443, acc.: 77%] [G loss: 2.347497]\n",
            "1979 [ D loss: 0.293548, acc.: 95%] [G loss: 3.499729]\n",
            "1980 [ D loss: 0.391055, acc.: 81%] [G loss: 1.921254]\n",
            "1981 [ D loss: 0.495552, acc.: 69%] [G loss: 2.060208]\n",
            "1982 [ D loss: 0.384862, acc.: 85%] [G loss: 2.871500]\n",
            "1983 [ D loss: 0.314832, acc.: 91%] [G loss: 3.350804]\n",
            "1984 [ D loss: 0.315910, acc.: 88%] [G loss: 2.674877]\n",
            "1985 [ D loss: 0.559029, acc.: 63%] [G loss: 5.695272]\n",
            "1986 [ D loss: 0.251258, acc.: 92%] [G loss: 4.798809]\n",
            "1987 [ D loss: 0.368074, acc.: 84%] [G loss: 2.898103]\n",
            "1988 [ D loss: 0.248651, acc.: 89%] [G loss: 4.828393]\n",
            "1989 [ D loss: 0.214495, acc.: 94%] [G loss: 4.042205]\n",
            "1990 [ D loss: 0.310717, acc.: 86%] [G loss: 2.874507]\n",
            "1991 [ D loss: 0.391831, acc.: 80%] [G loss: 3.170592]\n",
            "1992 [ D loss: 0.309856, acc.: 88%] [G loss: 2.321026]\n",
            "1993 [ D loss: 0.556594, acc.: 64%] [G loss: 1.669912]\n",
            "1994 [ D loss: 0.477811, acc.: 74%] [G loss: 2.826954]\n",
            "1995 [ D loss: 0.269313, acc.: 95%] [G loss: 4.009545]\n",
            "1996 [ D loss: 0.313089, acc.: 90%] [G loss: 4.810673]\n",
            "1997 [ D loss: 0.423245, acc.: 80%] [G loss: 3.237225]\n",
            "1998 [ D loss: 0.409323, acc.: 79%] [G loss: 3.620137]\n",
            "1999 [ D loss: 0.238406, acc.: 93%] [G loss: 4.156526]\n",
            "2000 [ D loss: 0.300681, acc.: 88%] [G loss: 3.943694]\n",
            "2001 [ D loss: 0.193430, acc.: 96%] [G loss: 5.801440]\n",
            "2002 [ D loss: 0.248971, acc.: 90%] [G loss: 6.751984]\n",
            "2003 [ D loss: 0.271395, acc.: 91%] [G loss: 5.629222]\n",
            "2004 [ D loss: 0.248748, acc.: 89%] [G loss: 4.956253]\n",
            "2005 [ D loss: 0.342698, acc.: 80%] [G loss: 2.845434]\n",
            "2006 [ D loss: 0.432805, acc.: 76%] [G loss: 1.828518]\n",
            "2007 [ D loss: 0.331899, acc.: 91%] [G loss: 2.835621]\n",
            "2008 [ D loss: 0.397103, acc.: 86%] [G loss: 3.111093]\n",
            "2009 [ D loss: 0.375673, acc.: 86%] [G loss: 3.100624]\n",
            "2010 [ D loss: 0.330331, acc.: 84%] [G loss: 2.538810]\n",
            "2011 [ D loss: 0.336716, acc.: 84%] [G loss: 3.007489]\n",
            "2012 [ D loss: 0.309417, acc.: 91%] [G loss: 2.746325]\n",
            "2013 [ D loss: 0.456001, acc.: 74%] [G loss: 2.302522]\n",
            "2014 [ D loss: 0.291404, acc.: 94%] [G loss: 3.242206]\n",
            "2015 [ D loss: 0.276485, acc.: 93%] [G loss: 2.975890]\n",
            "2016 [ D loss: 0.384127, acc.: 83%] [G loss: 2.504823]\n",
            "2017 [ D loss: 0.364191, acc.: 84%] [G loss: 2.692157]\n",
            "2018 [ D loss: 0.326151, acc.: 91%] [G loss: 3.777969]\n",
            "2019 [ D loss: 0.373759, acc.: 80%] [G loss: 3.056910]\n",
            "2020 [ D loss: 0.413463, acc.: 81%] [G loss: 3.011819]\n",
            "2021 [ D loss: 0.269096, acc.: 95%] [G loss: 3.191910]\n",
            "2022 [ D loss: 0.486249, acc.: 74%] [G loss: 2.655320]\n",
            "2023 [ D loss: 0.394776, acc.: 80%] [G loss: 2.547927]\n",
            "2024 [ D loss: 0.395840, acc.: 78%] [G loss: 2.642931]\n",
            "2025 [ D loss: 0.371979, acc.: 84%] [G loss: 2.933162]\n",
            "2026 [ D loss: 0.354770, acc.: 91%] [G loss: 2.365291]\n",
            "2027 [ D loss: 0.301471, acc.: 97%] [G loss: 2.474628]\n",
            "2028 [ D loss: 0.379088, acc.: 80%] [G loss: 1.916065]\n",
            "2029 [ D loss: 0.403491, acc.: 82%] [G loss: 2.379458]\n",
            "2030 [ D loss: 0.356458, acc.: 84%] [G loss: 3.669062]\n",
            "2031 [ D loss: 0.313057, acc.: 91%] [G loss: 2.430013]\n",
            "2032 [ D loss: 0.487060, acc.: 70%] [G loss: 2.002555]\n",
            "2033 [ D loss: 0.393755, acc.: 91%] [G loss: 2.401155]\n",
            "2034 [ D loss: 0.582377, acc.: 62%] [G loss: 2.403153]\n",
            "2035 [ D loss: 0.636311, acc.: 53%] [G loss: 1.700786]\n",
            "2036 [ D loss: 0.489205, acc.: 77%] [G loss: 1.596804]\n",
            "2037 [ D loss: 0.509286, acc.: 73%] [G loss: 2.824716]\n",
            "2038 [ D loss: 0.409501, acc.: 88%] [G loss: 2.575822]\n",
            "2039 [ D loss: 0.355853, acc.: 88%] [G loss: 4.001155]\n",
            "2040 [ D loss: 0.401208, acc.: 80%] [G loss: 2.815522]\n",
            "2041 [ D loss: 0.484941, acc.: 72%] [G loss: 2.610609]\n",
            "2042 [ D loss: 0.295510, acc.: 91%] [G loss: 4.359542]\n",
            "2043 [ D loss: 0.287146, acc.: 91%] [G loss: 4.147331]\n",
            "2044 [ D loss: 0.307713, acc.: 91%] [G loss: 2.908180]\n",
            "2045 [ D loss: 0.355964, acc.: 90%] [G loss: 3.196087]\n",
            "2046 [ D loss: 0.349620, acc.: 88%] [G loss: 4.024857]\n",
            "2047 [ D loss: 0.291063, acc.: 88%] [G loss: 5.505626]\n",
            "2048 [ D loss: 0.335775, acc.: 87%] [G loss: 3.251523]\n",
            "2049 [ D loss: 0.265045, acc.: 91%] [G loss: 4.529054]\n",
            "2050 [ D loss: 0.279572, acc.: 88%] [G loss: 2.111064]\n",
            "2051 [ D loss: 0.181396, acc.: 95%] [G loss: 2.588213]\n",
            "2052 [ D loss: 0.198119, acc.: 96%] [G loss: 8.598740]\n",
            "2053 [ D loss: 0.360764, acc.: 78%] [G loss: 3.205902]\n",
            "2054 [ D loss: 0.276308, acc.: 86%] [G loss: 4.959520]\n",
            "2055 [ D loss: 0.377827, acc.: 78%] [G loss: 3.968970]\n",
            "2056 [ D loss: 0.399661, acc.: 79%] [G loss: 3.395277]\n",
            "2057 [ D loss: 0.266948, acc.: 88%] [G loss: 3.929783]\n",
            "2058 [ D loss: 0.458323, acc.: 73%] [G loss: 3.286411]\n",
            "2059 [ D loss: 0.316933, acc.: 90%] [G loss: 2.706936]\n",
            "2060 [ D loss: 0.388855, acc.: 84%] [G loss: 3.107151]\n",
            "2061 [ D loss: 0.298111, acc.: 93%] [G loss: 3.569485]\n",
            "2062 [ D loss: 0.325871, acc.: 91%] [G loss: 2.815830]\n",
            "2063 [ D loss: 0.374982, acc.: 84%] [G loss: 2.007560]\n",
            "2064 [ D loss: 0.391730, acc.: 84%] [G loss: 1.917238]\n",
            "2065 [ D loss: 0.422576, acc.: 81%] [G loss: 1.737344]\n",
            "2066 [ D loss: 0.377018, acc.: 88%] [G loss: 2.767100]\n",
            "2067 [ D loss: 0.315865, acc.: 91%] [G loss: 2.868420]\n",
            "2068 [ D loss: 0.395144, acc.: 83%] [G loss: 2.388172]\n",
            "2069 [ D loss: 0.406480, acc.: 86%] [G loss: 3.585847]\n",
            "2070 [ D loss: 0.401747, acc.: 82%] [G loss: 4.061419]\n",
            "2071 [ D loss: 0.379940, acc.: 84%] [G loss: 2.947859]\n",
            "2072 [ D loss: 0.200558, acc.: 97%] [G loss: 4.136680]\n",
            "2073 [ D loss: 0.268136, acc.: 93%] [G loss: 2.833603]\n",
            "2074 [ D loss: 0.371930, acc.: 79%] [G loss: 3.113660]\n",
            "2075 [ D loss: 0.221367, acc.: 93%] [G loss: 2.865798]\n",
            "2076 [ D loss: 0.364575, acc.: 82%] [G loss: 2.738152]\n",
            "2077 [ D loss: 0.297882, acc.: 94%] [G loss: 2.666887]\n",
            "2078 [ D loss: 0.463863, acc.: 78%] [G loss: 3.340860]\n",
            "2079 [ D loss: 0.343539, acc.: 88%] [G loss: 5.475485]\n",
            "2080 [ D loss: 0.445644, acc.: 82%] [G loss: 3.035358]\n",
            "2081 [ D loss: 0.301033, acc.: 91%] [G loss: 2.649656]\n",
            "2082 [ D loss: 0.532890, acc.: 70%] [G loss: 3.351794]\n",
            "2083 [ D loss: 0.458811, acc.: 83%] [G loss: 1.948646]\n",
            "2084 [ D loss: 0.417706, acc.: 82%] [G loss: 2.735510]\n",
            "2085 [ D loss: 0.294511, acc.: 91%] [G loss: 3.758145]\n",
            "2086 [ D loss: 0.487572, acc.: 73%] [G loss: 1.967478]\n",
            "2087 [ D loss: 0.399841, acc.: 84%] [G loss: 2.544684]\n",
            "2088 [ D loss: 0.370001, acc.: 85%] [G loss: 2.266429]\n",
            "2089 [ D loss: 0.335568, acc.: 90%] [G loss: 4.153997]\n",
            "2090 [ D loss: 0.328147, acc.: 87%] [G loss: 10.181605]\n",
            "2091 [ D loss: 0.379007, acc.: 84%] [G loss: 4.540827]\n",
            "2092 [ D loss: 0.293466, acc.: 90%] [G loss: 3.284317]\n",
            "2093 [ D loss: 0.354782, acc.: 86%] [G loss: 5.437975]\n",
            "2094 [ D loss: 0.315573, acc.: 86%] [G loss: 6.697602]\n",
            "2095 [ D loss: 0.309061, acc.: 83%] [G loss: 4.742658]\n",
            "2096 [ D loss: 0.297704, acc.: 89%] [G loss: 4.452220]\n",
            "2097 [ D loss: 0.359174, acc.: 83%] [G loss: 3.518340]\n",
            "2098 [ D loss: 0.445394, acc.: 77%] [G loss: 2.924674]\n",
            "2099 [ D loss: 0.343029, acc.: 89%] [G loss: 3.664619]\n",
            "2100 [ D loss: 0.344473, acc.: 87%] [G loss: 2.776582]\n",
            "2101 [ D loss: 0.400903, acc.: 81%] [G loss: 4.001188]\n",
            "2102 [ D loss: 0.219191, acc.: 94%] [G loss: 5.013697]\n",
            "2103 [ D loss: 0.423484, acc.: 79%] [G loss: 4.259121]\n",
            "2104 [ D loss: 0.239529, acc.: 92%] [G loss: 4.473077]\n",
            "2105 [ D loss: 0.258119, acc.: 91%] [G loss: 3.438755]\n",
            "2106 [ D loss: 0.362030, acc.: 80%] [G loss: 2.998435]\n",
            "2107 [ D loss: 0.359319, acc.: 82%] [G loss: 3.459879]\n",
            "2108 [ D loss: 0.471531, acc.: 71%] [G loss: 1.789036]\n",
            "2109 [ D loss: 0.351610, acc.: 90%] [G loss: 3.198542]\n",
            "2110 [ D loss: 0.454502, acc.: 77%] [G loss: 2.367594]\n",
            "2111 [ D loss: 0.402506, acc.: 91%] [G loss: 2.645684]\n",
            "2112 [ D loss: 0.354506, acc.: 95%] [G loss: 2.562197]\n",
            "2113 [ D loss: 0.393346, acc.: 87%] [G loss: 2.391658]\n",
            "2114 [ D loss: 0.333592, acc.: 87%] [G loss: 3.490303]\n",
            "2115 [ D loss: 0.153452, acc.: 99%] [G loss: 4.895962]\n",
            "2116 [ D loss: 0.428964, acc.: 77%] [G loss: 2.438352]\n",
            "2117 [ D loss: 0.198581, acc.: 94%] [G loss: 4.449883]\n",
            "2118 [ D loss: 0.515481, acc.: 69%] [G loss: 1.677555]\n",
            "2119 [ D loss: 0.323948, acc.: 93%] [G loss: 4.065254]\n",
            "2120 [ D loss: 0.260026, acc.: 91%] [G loss: 3.228853]\n",
            "2121 [ D loss: 0.360418, acc.: 87%] [G loss: 2.487679]\n",
            "2122 [ D loss: 0.395886, acc.: 85%] [G loss: 3.394403]\n",
            "2123 [ D loss: 0.415110, acc.: 76%] [G loss: 2.226718]\n",
            "2124 [ D loss: 0.372320, acc.: 84%] [G loss: 5.609315]\n",
            "2125 [ D loss: 0.356610, acc.: 84%] [G loss: 4.607303]\n",
            "2126 [ D loss: 0.315349, acc.: 88%] [G loss: 5.005437]\n",
            "2127 [ D loss: 0.278985, acc.: 91%] [G loss: 3.921481]\n",
            "2128 [ D loss: 0.368671, acc.: 85%] [G loss: 2.839170]\n",
            "2129 [ D loss: 0.279206, acc.: 89%] [G loss: 4.159585]\n",
            "2130 [ D loss: 0.511313, acc.: 72%] [G loss: 1.779660]\n",
            "2131 [ D loss: 0.355049, acc.: 89%] [G loss: 2.511637]\n",
            "2132 [ D loss: 0.351352, acc.: 88%] [G loss: 2.602611]\n",
            "2133 [ D loss: 0.259240, acc.: 92%] [G loss: 4.623621]\n",
            "2134 [ D loss: 0.385360, acc.: 79%] [G loss: 2.214093]\n",
            "2135 [ D loss: 0.254119, acc.: 92%] [G loss: 4.156871]\n",
            "2136 [ D loss: 0.419173, acc.: 80%] [G loss: 1.954595]\n",
            "2137 [ D loss: 0.324280, acc.: 90%] [G loss: 3.084814]\n",
            "2138 [ D loss: 0.406757, acc.: 84%] [G loss: 2.422703]\n",
            "2139 [ D loss: 0.376238, acc.: 84%] [G loss: 2.522931]\n",
            "2140 [ D loss: 0.337035, acc.: 86%] [G loss: 2.450377]\n",
            "2141 [ D loss: 0.340626, acc.: 88%] [G loss: 3.250720]\n",
            "2142 [ D loss: 0.311009, acc.: 88%] [G loss: 4.410061]\n",
            "2143 [ D loss: 0.461785, acc.: 73%] [G loss: 2.037238]\n",
            "2144 [ D loss: 0.419800, acc.: 77%] [G loss: 2.807413]\n",
            "2145 [ D loss: 0.434865, acc.: 78%] [G loss: 2.345273]\n",
            "2146 [ D loss: 0.408429, acc.: 83%] [G loss: 2.976676]\n",
            "2147 [ D loss: 0.469828, acc.: 79%] [G loss: 3.484951]\n",
            "2148 [ D loss: 0.440059, acc.: 77%] [G loss: 2.253081]\n",
            "2149 [ D loss: 0.439098, acc.: 79%] [G loss: 2.598322]\n",
            "2150 [ D loss: 0.339738, acc.: 88%] [G loss: 2.942238]\n",
            "2151 [ D loss: 0.507116, acc.: 77%] [G loss: 2.328978]\n",
            "2152 [ D loss: 0.292380, acc.: 91%] [G loss: 4.228648]\n",
            "2153 [ D loss: 0.493165, acc.: 78%] [G loss: 2.598845]\n",
            "2154 [ D loss: 0.452093, acc.: 77%] [G loss: 4.159245]\n",
            "2155 [ D loss: 0.263325, acc.: 91%] [G loss: 5.514252]\n",
            "2156 [ D loss: 0.273737, acc.: 91%] [G loss: 3.808266]\n",
            "2157 [ D loss: 0.286633, acc.: 88%] [G loss: 4.962420]\n",
            "2158 [ D loss: 0.449581, acc.: 77%] [G loss: 3.352970]\n",
            "2159 [ D loss: 0.444357, acc.: 83%] [G loss: 3.181912]\n",
            "2160 [ D loss: 0.301943, acc.: 89%] [G loss: 3.373681]\n",
            "2161 [ D loss: 0.401520, acc.: 80%] [G loss: 2.720758]\n",
            "2162 [ D loss: 0.338438, acc.: 84%] [G loss: 3.849456]\n",
            "2163 [ D loss: 0.329753, acc.: 89%] [G loss: 3.334050]\n",
            "2164 [ D loss: 0.518284, acc.: 69%] [G loss: 3.490470]\n",
            "2165 [ D loss: 0.271568, acc.: 91%] [G loss: 5.012130]\n",
            "2166 [ D loss: 0.466179, acc.: 73%] [G loss: 2.600635]\n",
            "2167 [ D loss: 0.393210, acc.: 85%] [G loss: 2.089337]\n",
            "2168 [ D loss: 0.449396, acc.: 80%] [G loss: 2.168888]\n",
            "2169 [ D loss: 0.413961, acc.: 85%] [G loss: 4.231307]\n",
            "2170 [ D loss: 0.424435, acc.: 84%] [G loss: 2.418853]\n",
            "2171 [ D loss: 0.373367, acc.: 82%] [G loss: 2.931786]\n",
            "2172 [ D loss: 0.250981, acc.: 91%] [G loss: 4.077822]\n",
            "2173 [ D loss: 0.328928, acc.: 88%] [G loss: 3.946612]\n",
            "2174 [ D loss: 0.206376, acc.: 95%] [G loss: 3.639496]\n",
            "2175 [ D loss: 0.402215, acc.: 80%] [G loss: 3.507849]\n",
            "2176 [ D loss: 0.213594, acc.: 94%] [G loss: 7.857601]\n",
            "2177 [ D loss: 0.340140, acc.: 86%] [G loss: 2.794862]\n",
            "2178 [ D loss: 0.290904, acc.: 89%] [G loss: 5.754818]\n",
            "2179 [ D loss: 0.215386, acc.: 94%] [G loss: 4.293960]\n",
            "2180 [ D loss: 0.371274, acc.: 84%] [G loss: 2.572379]\n",
            "2181 [ D loss: 0.397756, acc.: 80%] [G loss: 4.213459]\n",
            "2182 [ D loss: 0.400931, acc.: 76%] [G loss: 2.759861]\n",
            "2183 [ D loss: 0.318520, acc.: 91%] [G loss: 3.302219]\n",
            "2184 [ D loss: 0.310340, acc.: 91%] [G loss: 4.966972]\n",
            "2185 [ D loss: 0.415474, acc.: 77%] [G loss: 3.182444]\n",
            "2186 [ D loss: 0.510191, acc.: 70%] [G loss: 2.066702]\n",
            "2187 [ D loss: 0.296984, acc.: 95%] [G loss: 3.306424]\n",
            "2188 [ D loss: 0.325705, acc.: 91%] [G loss: 4.032841]\n",
            "2189 [ D loss: 0.505386, acc.: 72%] [G loss: 3.600744]\n",
            "2190 [ D loss: 0.257122, acc.: 95%] [G loss: 5.542439]\n",
            "2191 [ D loss: 0.276619, acc.: 91%] [G loss: 3.234274]\n",
            "2192 [ D loss: 0.429422, acc.: 77%] [G loss: 2.511863]\n",
            "2193 [ D loss: 0.363474, acc.: 87%] [G loss: 3.147848]\n",
            "2194 [ D loss: 0.239694, acc.: 96%] [G loss: 4.021956]\n",
            "2195 [ D loss: 0.427730, acc.: 75%] [G loss: 2.859319]\n",
            "2196 [ D loss: 0.288422, acc.: 90%] [G loss: 2.970322]\n",
            "2197 [ D loss: 0.267177, acc.: 97%] [G loss: 3.414372]\n",
            "2198 [ D loss: 0.223443, acc.: 93%] [G loss: 3.834877]\n",
            "2199 [ D loss: 0.243113, acc.: 92%] [G loss: 4.310366]\n",
            "2200 [ D loss: 0.332987, acc.: 86%] [G loss: 3.094710]\n",
            "2201 [ D loss: 0.270445, acc.: 95%] [G loss: 2.927834]\n",
            "2202 [ D loss: 0.366671, acc.: 84%] [G loss: 3.657053]\n",
            "2203 [ D loss: 0.268453, acc.: 88%] [G loss: 4.886860]\n",
            "2204 [ D loss: 0.381048, acc.: 82%] [G loss: 2.430686]\n",
            "2205 [ D loss: 0.334841, acc.: 90%] [G loss: 3.232882]\n",
            "2206 [ D loss: 0.231755, acc.: 95%] [G loss: 4.277470]\n",
            "2207 [ D loss: 0.388095, acc.: 84%] [G loss: 2.584294]\n",
            "2208 [ D loss: 0.410338, acc.: 83%] [G loss: 5.040400]\n",
            "2209 [ D loss: 0.305937, acc.: 91%] [G loss: 2.842731]\n",
            "2210 [ D loss: 0.379107, acc.: 86%] [G loss: 2.465257]\n",
            "2211 [ D loss: 0.326075, acc.: 91%] [G loss: 3.151438]\n",
            "2212 [ D loss: 0.379292, acc.: 84%] [G loss: 3.175374]\n",
            "2213 [ D loss: 0.307811, acc.: 93%] [G loss: 3.483721]\n",
            "2214 [ D loss: 0.488661, acc.: 80%] [G loss: 2.464445]\n",
            "2215 [ D loss: 0.480550, acc.: 78%] [G loss: 2.062649]\n",
            "2216 [ D loss: 0.345095, acc.: 95%] [G loss: 2.429200]\n",
            "2217 [ D loss: 0.277875, acc.: 90%] [G loss: 3.750364]\n",
            "2218 [ D loss: 0.265654, acc.: 91%] [G loss: 3.146735]\n",
            "2219 [ D loss: 0.383945, acc.: 82%] [G loss: 2.760196]\n",
            "2220 [ D loss: 0.426563, acc.: 77%] [G loss: 3.435696]\n",
            "2221 [ D loss: 0.230269, acc.: 96%] [G loss: 4.239020]\n",
            "2222 [ D loss: 0.298278, acc.: 94%] [G loss: 7.671932]\n",
            "2223 [ D loss: 0.193967, acc.: 95%] [G loss: 5.904379]\n",
            "2224 [ D loss: 0.231849, acc.: 90%] [G loss: 3.382136]\n",
            "2225 [ D loss: 0.346597, acc.: 90%] [G loss: 2.527968]\n",
            "2226 [ D loss: 0.287669, acc.: 90%] [G loss: 3.902228]\n",
            "2227 [ D loss: 0.345718, acc.: 88%] [G loss: 3.033336]\n",
            "2228 [ D loss: 0.283344, acc.: 89%] [G loss: 3.211246]\n",
            "2229 [ D loss: 0.354815, acc.: 84%] [G loss: 4.310785]\n",
            "2230 [ D loss: 0.261145, acc.: 95%] [G loss: 5.043736]\n",
            "2231 [ D loss: 0.286674, acc.: 89%] [G loss: 2.917074]\n",
            "2232 [ D loss: 0.247348, acc.: 95%] [G loss: 2.771936]\n",
            "2233 [ D loss: 0.414509, acc.: 80%] [G loss: 2.336447]\n",
            "2234 [ D loss: 0.316261, acc.: 92%] [G loss: 2.967758]\n",
            "2235 [ D loss: 0.434375, acc.: 79%] [G loss: 2.211324]\n",
            "2236 [ D loss: 0.351403, acc.: 91%] [G loss: 2.430111]\n",
            "2237 [ D loss: 0.467462, acc.: 75%] [G loss: 2.036078]\n",
            "2238 [ D loss: 0.238794, acc.: 99%] [G loss: 2.954713]\n",
            "2239 [ D loss: 0.272626, acc.: 95%] [G loss: 2.861788]\n",
            "2240 [ D loss: 0.322348, acc.: 89%] [G loss: 2.646288]\n",
            "2241 [ D loss: 0.329915, acc.: 89%] [G loss: 3.220652]\n",
            "2242 [ D loss: 0.352087, acc.: 89%] [G loss: 2.802042]\n",
            "2243 [ D loss: 0.284628, acc.: 93%] [G loss: 3.992878]\n",
            "2244 [ D loss: 0.277663, acc.: 94%] [G loss: 4.174671]\n",
            "2245 [ D loss: 0.254964, acc.: 94%] [G loss: 3.012229]\n",
            "2246 [ D loss: 0.517216, acc.: 66%] [G loss: 2.086510]\n",
            "2247 [ D loss: 0.282018, acc.: 95%] [G loss: 2.841848]\n",
            "2248 [ D loss: 0.433020, acc.: 82%] [G loss: 2.216690]\n",
            "2249 [ D loss: 0.359021, acc.: 94%] [G loss: 2.256115]\n",
            "2250 [ D loss: 0.455090, acc.: 80%] [G loss: 1.928192]\n",
            "2251 [ D loss: 0.331190, acc.: 95%] [G loss: 3.271358]\n",
            "2252 [ D loss: 0.325878, acc.: 88%] [G loss: 5.242931]\n",
            "2253 [ D loss: 0.229162, acc.: 93%] [G loss: 2.417018]\n",
            "2254 [ D loss: 0.180737, acc.: 98%] [G loss: 6.050045]\n",
            "2255 [ D loss: 0.391548, acc.: 77%] [G loss: 3.148787]\n",
            "2256 [ D loss: 0.331518, acc.: 85%] [G loss: 3.992879]\n",
            "2257 [ D loss: 0.252754, acc.: 93%] [G loss: 3.740305]\n",
            "2258 [ D loss: 0.352418, acc.: 88%] [G loss: 2.847737]\n",
            "2259 [ D loss: 0.284252, acc.: 91%] [G loss: 2.466888]\n",
            "2260 [ D loss: 0.300609, acc.: 94%] [G loss: 3.469597]\n",
            "2261 [ D loss: 0.349544, acc.: 85%] [G loss: 2.708965]\n",
            "2262 [ D loss: 0.338708, acc.: 84%] [G loss: 2.749224]\n",
            "2263 [ D loss: 0.445683, acc.: 76%] [G loss: 2.258028]\n",
            "2264 [ D loss: 0.332707, acc.: 88%] [G loss: 2.801865]\n",
            "2265 [ D loss: 0.412081, acc.: 84%] [G loss: 2.507334]\n",
            "2266 [ D loss: 0.331696, acc.: 91%] [G loss: 2.916612]\n",
            "2267 [ D loss: 0.269228, acc.: 91%] [G loss: 2.370809]\n",
            "2268 [ D loss: 0.234454, acc.: 94%] [G loss: 3.597867]\n",
            "2269 [ D loss: 0.237672, acc.: 91%] [G loss: 4.672178]\n",
            "2270 [ D loss: 0.408253, acc.: 79%] [G loss: 2.579118]\n",
            "2271 [ D loss: 0.292984, acc.: 92%] [G loss: 3.400349]\n",
            "2272 [ D loss: 0.262309, acc.: 94%] [G loss: 3.644559]\n",
            "2273 [ D loss: 0.302912, acc.: 91%] [G loss: 3.051640]\n",
            "2274 [ D loss: 0.336771, acc.: 89%] [G loss: 3.403133]\n",
            "2275 [ D loss: 0.310684, acc.: 89%] [G loss: 3.439254]\n",
            "2276 [ D loss: 0.465387, acc.: 77%] [G loss: 2.131121]\n",
            "2277 [ D loss: 0.262244, acc.: 93%] [G loss: 2.934566]\n",
            "2278 [ D loss: 0.399839, acc.: 83%] [G loss: 2.589778]\n",
            "2279 [ D loss: 0.407724, acc.: 80%] [G loss: 2.687813]\n",
            "2280 [ D loss: 0.336300, acc.: 86%] [G loss: 3.063002]\n",
            "2281 [ D loss: 0.405227, acc.: 80%] [G loss: 2.691578]\n",
            "2282 [ D loss: 0.407892, acc.: 80%] [G loss: 2.075467]\n",
            "2283 [ D loss: 0.330070, acc.: 90%] [G loss: 3.673122]\n",
            "2284 [ D loss: 0.304816, acc.: 88%] [G loss: 5.385715]\n",
            "2285 [ D loss: 0.363161, acc.: 83%] [G loss: 3.894010]\n",
            "2286 [ D loss: 0.483251, acc.: 74%] [G loss: 2.088220]\n",
            "2287 [ D loss: 0.368488, acc.: 84%] [G loss: 3.174023]\n",
            "2288 [ D loss: 0.344029, acc.: 89%] [G loss: 2.700571]\n",
            "2289 [ D loss: 0.295867, acc.: 91%] [G loss: 3.250941]\n",
            "2290 [ D loss: 0.274827, acc.: 92%] [G loss: 3.013119]\n",
            "2291 [ D loss: 0.309093, acc.: 85%] [G loss: 4.131079]\n",
            "2292 [ D loss: 0.396464, acc.: 83%] [G loss: 4.008093]\n",
            "2293 [ D loss: 0.241026, acc.: 90%] [G loss: 3.573739]\n",
            "2294 [ D loss: 0.329310, acc.: 85%] [G loss: 5.216218]\n",
            "2295 [ D loss: 0.293289, acc.: 92%] [G loss: 2.443855]\n",
            "2296 [ D loss: 0.297803, acc.: 91%] [G loss: 3.211677]\n",
            "2297 [ D loss: 0.484021, acc.: 77%] [G loss: 2.467971]\n",
            "2298 [ D loss: 0.560793, acc.: 70%] [G loss: 3.573174]\n",
            "2299 [ D loss: 0.267943, acc.: 93%] [G loss: 4.959897]\n",
            "2300 [ D loss: 0.389337, acc.: 78%] [G loss: 3.889842]\n",
            "2301 [ D loss: 0.285048, acc.: 90%] [G loss: 4.348950]\n",
            "2302 [ D loss: 0.254701, acc.: 93%] [G loss: 3.925856]\n",
            "2303 [ D loss: 0.487016, acc.: 72%] [G loss: 3.606731]\n",
            "2304 [ D loss: 0.442515, acc.: 73%] [G loss: 4.919580]\n",
            "2305 [ D loss: 0.354446, acc.: 84%] [G loss: 3.835467]\n",
            "2306 [ D loss: 0.327039, acc.: 88%] [G loss: 4.299503]\n",
            "2307 [ D loss: 0.464375, acc.: 77%] [G loss: 2.301833]\n",
            "2308 [ D loss: 0.350924, acc.: 88%] [G loss: 4.138016]\n",
            "2309 [ D loss: 0.388521, acc.: 90%] [G loss: 3.148615]\n",
            "2310 [ D loss: 0.269803, acc.: 92%] [G loss: 4.279241]\n",
            "2311 [ D loss: 0.216898, acc.: 95%] [G loss: 3.423823]\n",
            "2312 [ D loss: 0.375620, acc.: 83%] [G loss: 2.990929]\n",
            "2313 [ D loss: 0.345579, acc.: 86%] [G loss: 7.068573]\n",
            "2314 [ D loss: 0.417100, acc.: 82%] [G loss: 2.663495]\n",
            "2315 [ D loss: 0.309388, acc.: 91%] [G loss: 8.484352]\n",
            "2316 [ D loss: 0.234718, acc.: 92%] [G loss: 5.501186]\n",
            "2317 [ D loss: 0.398255, acc.: 84%] [G loss: 3.263909]\n",
            "2318 [ D loss: 0.245571, acc.: 89%] [G loss: 3.225314]\n",
            "2319 [ D loss: 0.340186, acc.: 89%] [G loss: 3.250484]\n",
            "2320 [ D loss: 0.430397, acc.: 78%] [G loss: 2.553277]\n",
            "2321 [ D loss: 0.266476, acc.: 94%] [G loss: 3.336810]\n",
            "2322 [ D loss: 0.319444, acc.: 88%] [G loss: 3.496806]\n",
            "2323 [ D loss: 0.485365, acc.: 75%] [G loss: 2.333632]\n",
            "2324 [ D loss: 0.302344, acc.: 89%] [G loss: 3.871753]\n",
            "2325 [ D loss: 0.309085, acc.: 89%] [G loss: 2.863848]\n",
            "2326 [ D loss: 0.404853, acc.: 80%] [G loss: 2.926852]\n",
            "2327 [ D loss: 0.285342, acc.: 94%] [G loss: 3.799062]\n",
            "2328 [ D loss: 0.340855, acc.: 87%] [G loss: 3.547000]\n",
            "2329 [ D loss: 0.270558, acc.: 88%] [G loss: 3.779061]\n",
            "2330 [ D loss: 0.369016, acc.: 87%] [G loss: 2.414578]\n",
            "2331 [ D loss: 0.235204, acc.: 95%] [G loss: 5.749502]\n",
            "2332 [ D loss: 0.392759, acc.: 85%] [G loss: 2.938783]\n",
            "2333 [ D loss: 0.222207, acc.: 96%] [G loss: 3.040074]\n",
            "2334 [ D loss: 0.397098, acc.: 83%] [G loss: 4.569120]\n",
            "2335 [ D loss: 0.390797, acc.: 84%] [G loss: 2.716713]\n",
            "2336 [ D loss: 0.309615, acc.: 94%] [G loss: 2.411209]\n",
            "2337 [ D loss: 0.412586, acc.: 86%] [G loss: 2.694788]\n",
            "2338 [ D loss: 0.323879, acc.: 89%] [G loss: 3.202624]\n",
            "2339 [ D loss: 0.256592, acc.: 94%] [G loss: 3.164164]\n",
            "2340 [ D loss: 0.220857, acc.: 96%] [G loss: 3.368119]\n",
            "2341 [ D loss: 0.408110, acc.: 87%] [G loss: 2.873489]\n",
            "2342 [ D loss: 0.232669, acc.: 98%] [G loss: 3.664204]\n",
            "2343 [ D loss: 0.240538, acc.: 94%] [G loss: 2.583506]\n",
            "2344 [ D loss: 0.219837, acc.: 95%] [G loss: 5.074063]\n",
            "2345 [ D loss: 0.285268, acc.: 87%] [G loss: 2.838579]\n",
            "2346 [ D loss: 0.412544, acc.: 77%] [G loss: 3.642922]\n",
            "2347 [ D loss: 0.303057, acc.: 86%] [G loss: 6.191362]\n",
            "2348 [ D loss: 0.394757, acc.: 77%] [G loss: 2.924986]\n",
            "2349 [ D loss: 0.250865, acc.: 91%] [G loss: 4.815496]\n",
            "2350 [ D loss: 0.395123, acc.: 79%] [G loss: 5.957886]\n",
            "2351 [ D loss: 0.172734, acc.: 96%] [G loss: 9.377534]\n",
            "2352 [ D loss: 0.233124, acc.: 94%] [G loss: 4.751684]\n",
            "2353 [ D loss: 0.193957, acc.: 93%] [G loss: 5.836757]\n",
            "2354 [ D loss: 0.253706, acc.: 91%] [G loss: 4.753096]\n",
            "2355 [ D loss: 0.314979, acc.: 84%] [G loss: 3.772590]\n",
            "2356 [ D loss: 0.311632, acc.: 87%] [G loss: 4.503671]\n",
            "2357 [ D loss: 0.286860, acc.: 88%] [G loss: 4.492596]\n",
            "2358 [ D loss: 0.350345, acc.: 89%] [G loss: 2.621533]\n",
            "2359 [ D loss: 0.307132, acc.: 91%] [G loss: 3.055065]\n",
            "2360 [ D loss: 0.293214, acc.: 92%] [G loss: 3.909561]\n",
            "2361 [ D loss: 0.271333, acc.: 92%] [G loss: 4.692950]\n",
            "2362 [ D loss: 0.308603, acc.: 95%] [G loss: 3.499937]\n",
            "2363 [ D loss: 0.325380, acc.: 88%] [G loss: 2.395048]\n",
            "2364 [ D loss: 0.229071, acc.: 97%] [G loss: 4.883431]\n",
            "2365 [ D loss: 0.255164, acc.: 97%] [G loss: 2.875915]\n",
            "2366 [ D loss: 0.391091, acc.: 83%] [G loss: 2.671943]\n",
            "2367 [ D loss: 0.258272, acc.: 90%] [G loss: 2.941391]\n",
            "2368 [ D loss: 0.336044, acc.: 88%] [G loss: 3.299658]\n",
            "2369 [ D loss: 0.308441, acc.: 91%] [G loss: 4.501208]\n",
            "2370 [ D loss: 0.282677, acc.: 93%] [G loss: 3.634382]\n",
            "2371 [ D loss: 0.276706, acc.: 93%] [G loss: 3.270387]\n",
            "2372 [ D loss: 0.366248, acc.: 86%] [G loss: 3.037346]\n",
            "2373 [ D loss: 0.229597, acc.: 95%] [G loss: 3.550644]\n",
            "2374 [ D loss: 0.280012, acc.: 93%] [G loss: 3.260881]\n",
            "2375 [ D loss: 0.322204, acc.: 93%] [G loss: 2.070431]\n",
            "2376 [ D loss: 0.292176, acc.: 92%] [G loss: 3.476989]\n",
            "2377 [ D loss: 0.270046, acc.: 95%] [G loss: 3.292346]\n",
            "2378 [ D loss: 0.432877, acc.: 82%] [G loss: 2.443072]\n",
            "2379 [ D loss: 0.333674, acc.: 91%] [G loss: 2.734755]\n",
            "2380 [ D loss: 0.316955, acc.: 88%] [G loss: 5.192122]\n",
            "2381 [ D loss: 0.382467, acc.: 87%] [G loss: 2.561322]\n",
            "2382 [ D loss: 0.299092, acc.: 95%] [G loss: 3.130536]\n",
            "2383 [ D loss: 0.328681, acc.: 92%] [G loss: 2.746769]\n",
            "2384 [ D loss: 0.354953, acc.: 84%] [G loss: 3.965422]\n",
            "2385 [ D loss: 0.318084, acc.: 88%] [G loss: 2.040533]\n",
            "2386 [ D loss: 0.361934, acc.: 90%] [G loss: 2.966888]\n",
            "2387 [ D loss: 0.240319, acc.: 91%] [G loss: 4.717285]\n",
            "2388 [ D loss: 0.317534, acc.: 89%] [G loss: 2.947575]\n",
            "2389 [ D loss: 0.249433, acc.: 92%] [G loss: 5.264397]\n",
            "2390 [ D loss: 0.219663, acc.: 91%] [G loss: 10.460644]\n",
            "2391 [ D loss: 0.216460, acc.: 95%] [G loss: 4.911978]\n",
            "2392 [ D loss: 0.210556, acc.: 92%] [G loss: 3.481441]\n",
            "2393 [ D loss: 0.225432, acc.: 92%] [G loss: 5.619854]\n",
            "2394 [ D loss: 0.280380, acc.: 85%] [G loss: 5.207035]\n",
            "2395 [ D loss: 0.206897, acc.: 93%] [G loss: 4.843714]\n",
            "2396 [ D loss: 0.162615, acc.: 95%] [G loss: 7.884556]\n",
            "2397 [ D loss: 0.285918, acc.: 88%] [G loss: 5.899822]\n",
            "2398 [ D loss: 0.235161, acc.: 91%] [G loss: 3.758247]\n",
            "2399 [ D loss: 0.285032, acc.: 91%] [G loss: 3.245009]\n",
            "2400 [ D loss: 0.326733, acc.: 85%] [G loss: 3.236495]\n",
            "2401 [ D loss: 0.346245, acc.: 86%] [G loss: 3.122751]\n",
            "2402 [ D loss: 0.359482, acc.: 85%] [G loss: 2.576654]\n",
            "2403 [ D loss: 0.442108, acc.: 71%] [G loss: 2.149510]\n",
            "2404 [ D loss: 0.380092, acc.: 87%] [G loss: 2.057215]\n",
            "2405 [ D loss: 0.351402, acc.: 89%] [G loss: 3.329576]\n",
            "2406 [ D loss: 0.380057, acc.: 83%] [G loss: 3.288961]\n",
            "2407 [ D loss: 0.343585, acc.: 92%] [G loss: 2.405027]\n",
            "2408 [ D loss: 0.334504, acc.: 90%] [G loss: 3.760922]\n",
            "2409 [ D loss: 0.291282, acc.: 90%] [G loss: 2.251354]\n",
            "2410 [ D loss: 0.305042, acc.: 91%] [G loss: 5.191839]\n",
            "2411 [ D loss: 0.250106, acc.: 91%] [G loss: 3.731192]\n",
            "2412 [ D loss: 0.376103, acc.: 83%] [G loss: 4.133855]\n",
            "2413 [ D loss: 0.265900, acc.: 94%] [G loss: 2.565893]\n",
            "2414 [ D loss: 0.242917, acc.: 93%] [G loss: 4.484735]\n",
            "2415 [ D loss: 0.268924, acc.: 88%] [G loss: 5.941097]\n",
            "2416 [ D loss: 0.259022, acc.: 90%] [G loss: 3.417899]\n",
            "2417 [ D loss: 0.394952, acc.: 82%] [G loss: 3.463301]\n",
            "2418 [ D loss: 0.483333, acc.: 75%] [G loss: 3.193919]\n",
            "2419 [ D loss: 0.351283, acc.: 91%] [G loss: 2.311603]\n",
            "2420 [ D loss: 0.310630, acc.: 91%] [G loss: 2.339862]\n",
            "2421 [ D loss: 0.413399, acc.: 91%] [G loss: 2.407596]\n",
            "2422 [ D loss: 0.369380, acc.: 89%] [G loss: 2.743501]\n",
            "2423 [ D loss: 0.216136, acc.: 93%] [G loss: 4.421412]\n",
            "2424 [ D loss: 0.300012, acc.: 91%] [G loss: 3.175604]\n",
            "2425 [ D loss: 0.229533, acc.: 96%] [G loss: 3.052904]\n",
            "2426 [ D loss: 0.268567, acc.: 95%] [G loss: 3.349685]\n",
            "2427 [ D loss: 0.233149, acc.: 95%] [G loss: 2.881480]\n",
            "2428 [ D loss: 0.269585, acc.: 92%] [G loss: 3.787641]\n",
            "2429 [ D loss: 0.220968, acc.: 93%] [G loss: 4.068930]\n",
            "2430 [ D loss: 0.277669, acc.: 93%] [G loss: 3.166349]\n",
            "2431 [ D loss: 0.337993, acc.: 82%] [G loss: 3.176278]\n",
            "2432 [ D loss: 0.267136, acc.: 95%] [G loss: 3.655891]\n",
            "2433 [ D loss: 0.373925, acc.: 86%] [G loss: 2.073724]\n",
            "2434 [ D loss: 0.419841, acc.: 84%] [G loss: 2.662427]\n",
            "2435 [ D loss: 0.420789, acc.: 86%] [G loss: 2.866689]\n",
            "2436 [ D loss: 0.459417, acc.: 79%] [G loss: 3.717223]\n",
            "2437 [ D loss: 0.423516, acc.: 77%] [G loss: 2.894077]\n",
            "2438 [ D loss: 0.367647, acc.: 83%] [G loss: 2.759437]\n",
            "2439 [ D loss: 0.338890, acc.: 86%] [G loss: 3.210752]\n",
            "2440 [ D loss: 0.367450, acc.: 88%] [G loss: 5.255774]\n",
            "2441 [ D loss: 0.174970, acc.: 99%] [G loss: 3.303170]\n",
            "2442 [ D loss: 0.315082, acc.: 87%] [G loss: 3.458632]\n",
            "2443 [ D loss: 0.235938, acc.: 94%] [G loss: 2.849532]\n",
            "2444 [ D loss: 0.344937, acc.: 89%] [G loss: 6.872341]\n",
            "2445 [ D loss: 0.295365, acc.: 95%] [G loss: 2.625974]\n",
            "2446 [ D loss: 0.420072, acc.: 84%] [G loss: 3.967298]\n",
            "2447 [ D loss: 0.301759, acc.: 88%] [G loss: 4.293785]\n",
            "2448 [ D loss: 0.324185, acc.: 87%] [G loss: 5.425402]\n",
            "2449 [ D loss: 0.243100, acc.: 91%] [G loss: 4.086002]\n",
            "2450 [ D loss: 0.500354, acc.: 73%] [G loss: 3.555603]\n",
            "2451 [ D loss: 0.275541, acc.: 91%] [G loss: 4.822550]\n",
            "2452 [ D loss: 0.358828, acc.: 84%] [G loss: 2.823786]\n",
            "2453 [ D loss: 0.329999, acc.: 95%] [G loss: 2.195357]\n",
            "2454 [ D loss: 0.337668, acc.: 92%] [G loss: 2.667603]\n",
            "2455 [ D loss: 0.244379, acc.: 95%] [G loss: 4.003762]\n",
            "2456 [ D loss: 0.332795, acc.: 93%] [G loss: 4.103321]\n",
            "2457 [ D loss: 0.193513, acc.: 95%] [G loss: 5.538160]\n",
            "2458 [ D loss: 0.229603, acc.: 90%] [G loss: 5.980170]\n",
            "2459 [ D loss: 0.222392, acc.: 94%] [G loss: 3.265010]\n",
            "2460 [ D loss: 0.249464, acc.: 94%] [G loss: 6.581609]\n",
            "2461 [ D loss: 0.304105, acc.: 88%] [G loss: 3.887443]\n",
            "2462 [ D loss: 0.267910, acc.: 91%] [G loss: 7.593765]\n",
            "2463 [ D loss: 0.252429, acc.: 95%] [G loss: 3.238241]\n",
            "2464 [ D loss: 0.323457, acc.: 83%] [G loss: 4.925901]\n",
            "2465 [ D loss: 0.409287, acc.: 85%] [G loss: 2.694009]\n",
            "2466 [ D loss: 0.422117, acc.: 77%] [G loss: 4.331178]\n",
            "2467 [ D loss: 0.440463, acc.: 82%] [G loss: 3.324924]\n",
            "2468 [ D loss: 0.264563, acc.: 91%] [G loss: 5.444478]\n",
            "2469 [ D loss: 0.292319, acc.: 90%] [G loss: 6.993785]\n",
            "2470 [ D loss: 0.295258, acc.: 92%] [G loss: 8.313539]\n",
            "2471 [ D loss: 0.247451, acc.: 93%] [G loss: 3.164569]\n",
            "2472 [ D loss: 0.310239, acc.: 91%] [G loss: 3.268166]\n",
            "2473 [ D loss: 0.250229, acc.: 95%] [G loss: 3.416343]\n",
            "2474 [ D loss: 0.262437, acc.: 94%] [G loss: 3.366043]\n",
            "2475 [ D loss: 0.422254, acc.: 73%] [G loss: 3.007926]\n",
            "2476 [ D loss: 0.312954, acc.: 91%] [G loss: 4.199664]\n",
            "2477 [ D loss: 0.400221, acc.: 84%] [G loss: 2.943650]\n",
            "2478 [ D loss: 0.371651, acc.: 85%] [G loss: 3.643193]\n",
            "2479 [ D loss: 0.309946, acc.: 89%] [G loss: 3.623268]\n",
            "2480 [ D loss: 0.450519, acc.: 77%] [G loss: 2.361519]\n",
            "2481 [ D loss: 0.314413, acc.: 90%] [G loss: 3.128250]\n",
            "2482 [ D loss: 0.334341, acc.: 89%] [G loss: 2.880805]\n",
            "2483 [ D loss: 0.310000, acc.: 95%] [G loss: 2.478491]\n",
            "2484 [ D loss: 0.440522, acc.: 85%] [G loss: 2.505535]\n",
            "2485 [ D loss: 0.322161, acc.: 92%] [G loss: 2.661432]\n",
            "2486 [ D loss: 0.462655, acc.: 83%] [G loss: 2.444376]\n",
            "2487 [ D loss: 0.338037, acc.: 91%] [G loss: 2.828107]\n",
            "2488 [ D loss: 0.319288, acc.: 92%] [G loss: 3.356255]\n",
            "2489 [ D loss: 0.294871, acc.: 94%] [G loss: 4.253906]\n",
            "2490 [ D loss: 0.254039, acc.: 92%] [G loss: 4.682735]\n",
            "2491 [ D loss: 0.259770, acc.: 91%] [G loss: 3.714832]\n",
            "2492 [ D loss: 0.236596, acc.: 93%] [G loss: 6.153848]\n",
            "2493 [ D loss: 0.196126, acc.: 94%] [G loss: 6.074154]\n",
            "2494 [ D loss: 0.122675, acc.: 98%] [G loss: 12.007834]\n",
            "2495 [ D loss: 0.161650, acc.: 95%] [G loss: 6.966527]\n",
            "2496 [ D loss: 0.161761, acc.: 95%] [G loss: 8.756176]\n",
            "2497 [ D loss: 0.214188, acc.: 91%] [G loss: 4.259438]\n",
            "2498 [ D loss: 0.152467, acc.: 96%] [G loss: 3.706744]\n",
            "2499 [ D loss: 0.213117, acc.: 91%] [G loss: 6.460380]\n",
            "2500 [ D loss: 0.224326, acc.: 90%] [G loss: 4.301072]\n",
            "2501 [ D loss: 0.257453, acc.: 92%] [G loss: 4.364104]\n",
            "2502 [ D loss: 0.424246, acc.: 82%] [G loss: 2.753505]\n",
            "2503 [ D loss: 0.322262, acc.: 93%] [G loss: 3.650133]\n",
            "2504 [ D loss: 0.246955, acc.: 92%] [G loss: 7.879987]\n",
            "2505 [ D loss: 0.168903, acc.: 95%] [G loss: 3.789747]\n",
            "2506 [ D loss: 0.197238, acc.: 91%] [G loss: 3.341623]\n",
            "2507 [ D loss: 0.319190, acc.: 84%] [G loss: 4.137306]\n",
            "2508 [ D loss: 0.149655, acc.: 98%] [G loss: 5.054311]\n",
            "2509 [ D loss: 0.253540, acc.: 96%] [G loss: 3.140918]\n",
            "2510 [ D loss: 0.252388, acc.: 95%] [G loss: 2.649498]\n",
            "2511 [ D loss: 0.255258, acc.: 91%] [G loss: 3.882514]\n",
            "2512 [ D loss: 0.365399, acc.: 87%] [G loss: 3.241990]\n",
            "2513 [ D loss: 0.290789, acc.: 98%] [G loss: 4.461980]\n",
            "2514 [ D loss: 0.293842, acc.: 91%] [G loss: 3.554399]\n",
            "2515 [ D loss: 0.384491, acc.: 89%] [G loss: 4.230372]\n",
            "2516 [ D loss: 0.332260, acc.: 88%] [G loss: 3.719275]\n",
            "2517 [ D loss: 0.214843, acc.: 94%] [G loss: 8.750154]\n",
            "2518 [ D loss: 0.210441, acc.: 94%] [G loss: 6.470571]\n",
            "2519 [ D loss: 0.206602, acc.: 92%] [G loss: 4.287479]\n",
            "2520 [ D loss: 0.253213, acc.: 91%] [G loss: 7.073821]\n",
            "2521 [ D loss: 0.166738, acc.: 99%] [G loss: 4.907599]\n",
            "2522 [ D loss: 0.260984, acc.: 95%] [G loss: 3.093729]\n",
            "2523 [ D loss: 0.229020, acc.: 96%] [G loss: 4.445388]\n",
            "2524 [ D loss: 0.151980, acc.: 98%] [G loss: 5.804642]\n",
            "2525 [ D loss: 0.295357, acc.: 92%] [G loss: 4.465632]\n",
            "2526 [ D loss: 0.242101, acc.: 93%] [G loss: 3.130772]\n",
            "2527 [ D loss: 0.384616, acc.: 86%] [G loss: 2.844179]\n",
            "2528 [ D loss: 0.286182, acc.: 89%] [G loss: 5.215203]\n",
            "2529 [ D loss: 0.261297, acc.: 95%] [G loss: 8.132670]\n",
            "2530 [ D loss: 0.181396, acc.: 99%] [G loss: 3.342049]\n",
            "2531 [ D loss: 0.225031, acc.: 92%] [G loss: 4.202279]\n",
            "2532 [ D loss: 0.372239, acc.: 82%] [G loss: 3.574415]\n",
            "2533 [ D loss: 0.272080, acc.: 93%] [G loss: 4.863823]\n",
            "2534 [ D loss: 0.305168, acc.: 86%] [G loss: 3.479296]\n",
            "2535 [ D loss: 0.339087, acc.: 80%] [G loss: 4.180367]\n",
            "2536 [ D loss: 0.229039, acc.: 94%] [G loss: 5.602456]\n",
            "2537 [ D loss: 0.360898, acc.: 84%] [G loss: 3.782279]\n",
            "2538 [ D loss: 0.402395, acc.: 87%] [G loss: 2.955585]\n",
            "2539 [ D loss: 0.280267, acc.: 91%] [G loss: 4.512503]\n",
            "2540 [ D loss: 0.233830, acc.: 93%] [G loss: 5.033018]\n",
            "2541 [ D loss: 0.324657, acc.: 84%] [G loss: 6.285016]\n",
            "2542 [ D loss: 0.225798, acc.: 91%] [G loss: 8.053695]\n",
            "2543 [ D loss: 0.235166, acc.: 93%] [G loss: 4.869851]\n",
            "2544 [ D loss: 0.317943, acc.: 90%] [G loss: 4.239654]\n",
            "2545 [ D loss: 0.254118, acc.: 90%] [G loss: 4.417616]\n",
            "2546 [ D loss: 0.476624, acc.: 83%] [G loss: 2.362827]\n",
            "2547 [ D loss: 0.300939, acc.: 92%] [G loss: 4.324402]\n",
            "2548 [ D loss: 0.264438, acc.: 93%] [G loss: 4.059134]\n",
            "2549 [ D loss: 0.271324, acc.: 91%] [G loss: 2.799948]\n",
            "2550 [ D loss: 0.435228, acc.: 79%] [G loss: 2.400680]\n",
            "2551 [ D loss: 0.312167, acc.: 91%] [G loss: 3.640102]\n",
            "2552 [ D loss: 0.275024, acc.: 91%] [G loss: 3.706057]\n",
            "2553 [ D loss: 0.303218, acc.: 86%] [G loss: 3.614499]\n",
            "2554 [ D loss: 0.234086, acc.: 96%] [G loss: 5.773882]\n",
            "2555 [ D loss: 0.338704, acc.: 88%] [G loss: 3.378585]\n",
            "2556 [ D loss: 0.230625, acc.: 92%] [G loss: 3.305172]\n",
            "2557 [ D loss: 0.316178, acc.: 89%] [G loss: 2.931112]\n",
            "2558 [ D loss: 0.235147, acc.: 95%] [G loss: 3.381338]\n",
            "2559 [ D loss: 0.333772, acc.: 88%] [G loss: 3.000604]\n",
            "2560 [ D loss: 0.391324, acc.: 84%] [G loss: 5.336067]\n",
            "2561 [ D loss: 0.190031, acc.: 92%] [G loss: 5.378761]\n",
            "2562 [ D loss: 0.222312, acc.: 92%] [G loss: 3.385511]\n",
            "2563 [ D loss: 0.284126, acc.: 91%] [G loss: 6.286192]\n",
            "2564 [ D loss: 0.308315, acc.: 88%] [G loss: 3.827272]\n",
            "2565 [ D loss: 0.231361, acc.: 98%] [G loss: 6.091363]\n",
            "2566 [ D loss: 0.353893, acc.: 89%] [G loss: 3.567191]\n",
            "2567 [ D loss: 0.186908, acc.: 96%] [G loss: 6.776127]\n",
            "2568 [ D loss: 0.192752, acc.: 93%] [G loss: 4.991035]\n",
            "2569 [ D loss: 0.200609, acc.: 95%] [G loss: 5.225311]\n",
            "2570 [ D loss: 0.300875, acc.: 88%] [G loss: 3.383251]\n",
            "2571 [ D loss: 0.249935, acc.: 93%] [G loss: 6.275815]\n",
            "2572 [ D loss: 0.324671, acc.: 93%] [G loss: 2.738863]\n",
            "2573 [ D loss: 0.181664, acc.: 98%] [G loss: 3.944155]\n",
            "2574 [ D loss: 0.317435, acc.: 87%] [G loss: 3.508053]\n",
            "2575 [ D loss: 0.263591, acc.: 88%] [G loss: 3.942096]\n",
            "2576 [ D loss: 0.284977, acc.: 90%] [G loss: 2.967038]\n",
            "2577 [ D loss: 0.396304, acc.: 88%] [G loss: 3.075625]\n",
            "2578 [ D loss: 0.279075, acc.: 91%] [G loss: 4.109476]\n",
            "2579 [ D loss: 0.331931, acc.: 94%] [G loss: 5.854111]\n",
            "2580 [ D loss: 0.226059, acc.: 94%] [G loss: 3.195934]\n",
            "2581 [ D loss: 0.232002, acc.: 93%] [G loss: 2.982840]\n",
            "2582 [ D loss: 0.308023, acc.: 92%] [G loss: 3.007620]\n",
            "2583 [ D loss: 0.430048, acc.: 81%] [G loss: 8.093167]\n",
            "2584 [ D loss: 0.398177, acc.: 79%] [G loss: 3.610164]\n",
            "2585 [ D loss: 0.339722, acc.: 83%] [G loss: 2.811275]\n",
            "2586 [ D loss: 0.247781, acc.: 91%] [G loss: 3.959820]\n",
            "2587 [ D loss: 0.315242, acc.: 91%] [G loss: 3.332478]\n",
            "2588 [ D loss: 0.310703, acc.: 87%] [G loss: 2.651655]\n",
            "2589 [ D loss: 0.233702, acc.: 94%] [G loss: 3.495475]\n",
            "2590 [ D loss: 0.278095, acc.: 92%] [G loss: 3.230989]\n",
            "2591 [ D loss: 0.396410, acc.: 84%] [G loss: 1.977786]\n",
            "2592 [ D loss: 0.374637, acc.: 90%] [G loss: 3.803074]\n",
            "2593 [ D loss: 0.242467, acc.: 95%] [G loss: 5.808510]\n",
            "2594 [ D loss: 0.453988, acc.: 75%] [G loss: 3.910131]\n",
            "2595 [ D loss: 0.262686, acc.: 98%] [G loss: 3.185718]\n",
            "2596 [ D loss: 0.287081, acc.: 93%] [G loss: 3.875853]\n",
            "2597 [ D loss: 0.268743, acc.: 94%] [G loss: 4.098417]\n",
            "2598 [ D loss: 0.385467, acc.: 81%] [G loss: 2.337719]\n",
            "2599 [ D loss: 0.292216, acc.: 94%] [G loss: 3.001361]\n",
            "2600 [ D loss: 0.332799, acc.: 88%] [G loss: 3.297781]\n",
            "2601 [ D loss: 0.188945, acc.: 95%] [G loss: 4.177658]\n",
            "2602 [ D loss: 0.274920, acc.: 93%] [G loss: 2.738158]\n",
            "2603 [ D loss: 0.349218, acc.: 91%] [G loss: 3.641906]\n",
            "2604 [ D loss: 0.268392, acc.: 91%] [G loss: 6.049353]\n",
            "2605 [ D loss: 0.491651, acc.: 73%] [G loss: 2.594847]\n",
            "2606 [ D loss: 0.184789, acc.: 96%] [G loss: 5.391203]\n",
            "2607 [ D loss: 0.279553, acc.: 93%] [G loss: 3.478116]\n",
            "2608 [ D loss: 0.356190, acc.: 88%] [G loss: 3.156632]\n",
            "2609 [ D loss: 0.283932, acc.: 94%] [G loss: 4.588653]\n",
            "2610 [ D loss: 0.220836, acc.: 97%] [G loss: 3.968395]\n",
            "2611 [ D loss: 0.293342, acc.: 90%] [G loss: 3.942886]\n",
            "2612 [ D loss: 0.264191, acc.: 96%] [G loss: 3.746098]\n",
            "2613 [ D loss: 0.345808, acc.: 87%] [G loss: 3.441440]\n",
            "2614 [ D loss: 0.305444, acc.: 95%] [G loss: 3.094853]\n",
            "2615 [ D loss: 0.334744, acc.: 91%] [G loss: 3.791760]\n",
            "2616 [ D loss: 0.236751, acc.: 96%] [G loss: 4.328433]\n",
            "2617 [ D loss: 0.204177, acc.: 97%] [G loss: 4.442676]\n",
            "2618 [ D loss: 0.216617, acc.: 97%] [G loss: 3.075073]\n",
            "2619 [ D loss: 0.351128, acc.: 86%] [G loss: 3.223595]\n",
            "2620 [ D loss: 0.235068, acc.: 95%] [G loss: 3.180437]\n",
            "2621 [ D loss: 0.314856, acc.: 92%] [G loss: 3.394665]\n",
            "2622 [ D loss: 0.369054, acc.: 87%] [G loss: 3.517973]\n",
            "2623 [ D loss: 0.297455, acc.: 95%] [G loss: 2.423393]\n",
            "2624 [ D loss: 0.305583, acc.: 94%] [G loss: 2.606865]\n",
            "2625 [ D loss: 0.291592, acc.: 93%] [G loss: 3.257747]\n",
            "2626 [ D loss: 0.347866, acc.: 90%] [G loss: 2.792328]\n",
            "2627 [ D loss: 0.311342, acc.: 88%] [G loss: 3.875431]\n",
            "2628 [ D loss: 0.358776, acc.: 85%] [G loss: 2.262446]\n",
            "2629 [ D loss: 0.262540, acc.: 95%] [G loss: 4.430307]\n",
            "2630 [ D loss: 0.332548, acc.: 88%] [G loss: 2.958918]\n",
            "2631 [ D loss: 0.279259, acc.: 91%] [G loss: 3.695010]\n",
            "2632 [ D loss: 0.333346, acc.: 89%] [G loss: 4.144141]\n",
            "2633 [ D loss: 0.193881, acc.: 95%] [G loss: 5.178316]\n",
            "2634 [ D loss: 0.214744, acc.: 95%] [G loss: 4.170692]\n",
            "2635 [ D loss: 0.399537, acc.: 81%] [G loss: 3.139840]\n",
            "2636 [ D loss: 0.334360, acc.: 88%] [G loss: 3.616647]\n",
            "2637 [ D loss: 0.381210, acc.: 87%] [G loss: 2.289580]\n",
            "2638 [ D loss: 0.277193, acc.: 95%] [G loss: 4.000324]\n",
            "2639 [ D loss: 0.228490, acc.: 91%] [G loss: 5.106610]\n",
            "2640 [ D loss: 0.361823, acc.: 84%] [G loss: 2.925422]\n",
            "2641 [ D loss: 0.226021, acc.: 95%] [G loss: 6.535660]\n",
            "2642 [ D loss: 0.318736, acc.: 87%] [G loss: 8.935153]\n",
            "2643 [ D loss: 0.284090, acc.: 86%] [G loss: 4.169492]\n",
            "2644 [ D loss: 0.420140, acc.: 83%] [G loss: 2.528817]\n",
            "2645 [ D loss: 0.216010, acc.: 94%] [G loss: 4.436917]\n",
            "2646 [ D loss: 0.320042, acc.: 84%] [G loss: 2.846247]\n",
            "2647 [ D loss: 0.283589, acc.: 93%] [G loss: 4.386195]\n",
            "2648 [ D loss: 0.327360, acc.: 90%] [G loss: 2.876227]\n",
            "2649 [ D loss: 0.282881, acc.: 94%] [G loss: 3.215898]\n",
            "2650 [ D loss: 0.265634, acc.: 93%] [G loss: 4.000400]\n",
            "2651 [ D loss: 0.353217, acc.: 90%] [G loss: 2.678639]\n",
            "2652 [ D loss: 0.249106, acc.: 95%] [G loss: 4.897720]\n",
            "2653 [ D loss: 0.314151, acc.: 89%] [G loss: 3.635160]\n",
            "2654 [ D loss: 0.332528, acc.: 86%] [G loss: 2.904473]\n",
            "2655 [ D loss: 0.368260, acc.: 85%] [G loss: 3.291707]\n",
            "2656 [ D loss: 0.319282, acc.: 91%] [G loss: 3.747741]\n",
            "2657 [ D loss: 0.229603, acc.: 95%] [G loss: 4.209527]\n",
            "2658 [ D loss: 0.263120, acc.: 89%] [G loss: 7.366350]\n",
            "2659 [ D loss: 0.160796, acc.: 96%] [G loss: 11.249022]\n",
            "2660 [ D loss: 0.145511, acc.: 96%] [G loss: 9.017941]\n",
            "2661 [ D loss: 0.315904, acc.: 85%] [G loss: 4.156846]\n",
            "2662 [ D loss: 0.153249, acc.: 95%] [G loss: 5.025176]\n",
            "2663 [ D loss: 0.225950, acc.: 93%] [G loss: 3.477701]\n",
            "2664 [ D loss: 0.221180, acc.: 90%] [G loss: 5.307906]\n",
            "2665 [ D loss: 0.103501, acc.: 99%] [G loss: 7.201294]\n",
            "2666 [ D loss: 0.172433, acc.: 95%] [G loss: 5.882612]\n",
            "2667 [ D loss: 0.142454, acc.: 95%] [G loss: 4.447948]\n",
            "2668 [ D loss: 0.433751, acc.: 77%] [G loss: 3.441505]\n",
            "2669 [ D loss: 0.389207, acc.: 81%] [G loss: 3.220846]\n",
            "2670 [ D loss: 0.367926, acc.: 87%] [G loss: 3.868980]\n",
            "2671 [ D loss: 0.324284, acc.: 85%] [G loss: 3.618256]\n",
            "2672 [ D loss: 0.354257, acc.: 78%] [G loss: 3.953505]\n",
            "2673 [ D loss: 0.333551, acc.: 91%] [G loss: 2.788270]\n",
            "2674 [ D loss: 0.272789, acc.: 88%] [G loss: 4.267383]\n",
            "2675 [ D loss: 0.278739, acc.: 95%] [G loss: 4.844782]\n",
            "2676 [ D loss: 0.237551, acc.: 88%] [G loss: 5.116429]\n",
            "2677 [ D loss: 0.187639, acc.: 94%] [G loss: 3.365409]\n",
            "2678 [ D loss: 0.358485, acc.: 82%] [G loss: 6.655354]\n",
            "2679 [ D loss: 0.167006, acc.: 96%] [G loss: 5.960306]\n",
            "2680 [ D loss: 0.282353, acc.: 88%] [G loss: 5.858479]\n",
            "2681 [ D loss: 0.216277, acc.: 94%] [G loss: 6.028555]\n",
            "2682 [ D loss: 0.455735, acc.: 74%] [G loss: 4.041694]\n",
            "2683 [ D loss: 0.237268, acc.: 92%] [G loss: 5.600613]\n",
            "2684 [ D loss: 0.302321, acc.: 88%] [G loss: 4.443173]\n",
            "2685 [ D loss: 0.171666, acc.: 96%] [G loss: 4.847656]\n",
            "2686 [ D loss: 0.236496, acc.: 88%] [G loss: 4.860227]\n",
            "2687 [ D loss: 0.263907, acc.: 90%] [G loss: 3.206941]\n",
            "2688 [ D loss: 0.222715, acc.: 96%] [G loss: 3.200610]\n",
            "2689 [ D loss: 0.412588, acc.: 82%] [G loss: 2.470972]\n",
            "2690 [ D loss: 0.316778, acc.: 91%] [G loss: 2.849903]\n",
            "2691 [ D loss: 0.307243, acc.: 91%] [G loss: 3.129173]\n",
            "2692 [ D loss: 0.314321, acc.: 92%] [G loss: 2.427248]\n",
            "2693 [ D loss: 0.273320, acc.: 92%] [G loss: 3.020756]\n",
            "2694 [ D loss: 0.392544, acc.: 79%] [G loss: 2.945565]\n",
            "2695 [ D loss: 0.402191, acc.: 84%] [G loss: 2.742584]\n",
            "2696 [ D loss: 0.251704, acc.: 95%] [G loss: 3.003025]\n",
            "2697 [ D loss: 0.335448, acc.: 87%] [G loss: 3.124688]\n",
            "2698 [ D loss: 0.301529, acc.: 92%] [G loss: 4.485135]\n",
            "2699 [ D loss: 0.301130, acc.: 88%] [G loss: 4.060202]\n",
            "2700 [ D loss: 0.296613, acc.: 84%] [G loss: 4.443849]\n",
            "2701 [ D loss: 0.210120, acc.: 91%] [G loss: 3.049659]\n",
            "2702 [ D loss: 0.285496, acc.: 88%] [G loss: 4.553411]\n",
            "2703 [ D loss: 0.358761, acc.: 85%] [G loss: 3.642660]\n",
            "2704 [ D loss: 0.204213, acc.: 95%] [G loss: 4.846927]\n",
            "2705 [ D loss: 0.233229, acc.: 96%] [G loss: 4.453926]\n",
            "2706 [ D loss: 0.319420, acc.: 88%] [G loss: 3.555048]\n",
            "2707 [ D loss: 0.254462, acc.: 95%] [G loss: 2.927919]\n",
            "2708 [ D loss: 0.433699, acc.: 81%] [G loss: 2.551474]\n",
            "2709 [ D loss: 0.260346, acc.: 97%] [G loss: 3.213373]\n",
            "2710 [ D loss: 0.389336, acc.: 83%] [G loss: 3.184897]\n",
            "2711 [ D loss: 0.290995, acc.: 88%] [G loss: 3.532896]\n",
            "2712 [ D loss: 0.223308, acc.: 94%] [G loss: 4.022967]\n",
            "2713 [ D loss: 0.221843, acc.: 95%] [G loss: 4.963232]\n",
            "2714 [ D loss: 0.241948, acc.: 92%] [G loss: 3.232556]\n",
            "2715 [ D loss: 0.240658, acc.: 91%] [G loss: 5.847392]\n",
            "2716 [ D loss: 0.204413, acc.: 93%] [G loss: 4.880569]\n",
            "2717 [ D loss: 0.389958, acc.: 79%] [G loss: 4.386508]\n",
            "2718 [ D loss: 0.295376, acc.: 92%] [G loss: 4.789895]\n",
            "2719 [ D loss: 0.204211, acc.: 95%] [G loss: 6.105096]\n",
            "2720 [ D loss: 0.260080, acc.: 90%] [G loss: 5.961592]\n",
            "2721 [ D loss: 0.184599, acc.: 98%] [G loss: 4.684151]\n",
            "2722 [ D loss: 0.268972, acc.: 91%] [G loss: 3.396961]\n",
            "2723 [ D loss: 0.184118, acc.: 96%] [G loss: 6.899689]\n",
            "2724 [ D loss: 0.255515, acc.: 93%] [G loss: 3.516681]\n",
            "2725 [ D loss: 0.242343, acc.: 89%] [G loss: 3.623277]\n",
            "2726 [ D loss: 0.256668, acc.: 92%] [G loss: 6.005606]\n",
            "2727 [ D loss: 0.173564, acc.: 98%] [G loss: 9.099003]\n",
            "2728 [ D loss: 0.170190, acc.: 93%] [G loss: 11.055614]\n",
            "2729 [ D loss: 0.181074, acc.: 95%] [G loss: 12.041985]\n",
            "2730 [ D loss: 0.135152, acc.: 96%] [G loss: 9.264122]\n",
            "2731 [ D loss: 0.098428, acc.: 95%] [G loss: 10.449134]\n",
            "2732 [ D loss: 0.088579, acc.: 97%] [G loss: 9.402512]\n",
            "2733 [ D loss: 0.140300, acc.: 95%] [G loss: 8.263344]\n",
            "2734 [ D loss: 0.236021, acc.: 90%] [G loss: 6.334705]\n",
            "2735 [ D loss: 0.463208, acc.: 75%] [G loss: 6.500360]\n",
            "2736 [ D loss: 0.160836, acc.: 95%] [G loss: 4.851397]\n",
            "2737 [ D loss: 0.321885, acc.: 87%] [G loss: 4.954910]\n",
            "2738 [ D loss: 0.239784, acc.: 92%] [G loss: 4.045239]\n",
            "2739 [ D loss: 0.438301, acc.: 80%] [G loss: 3.660806]\n",
            "2740 [ D loss: 0.229044, acc.: 93%] [G loss: 6.485992]\n",
            "2741 [ D loss: 0.276599, acc.: 91%] [G loss: 3.450817]\n",
            "2742 [ D loss: 0.253835, acc.: 91%] [G loss: 5.626981]\n",
            "2743 [ D loss: 0.234835, acc.: 91%] [G loss: 6.603166]\n",
            "2744 [ D loss: 0.228750, acc.: 94%] [G loss: 7.702371]\n",
            "2745 [ D loss: 0.262667, acc.: 89%] [G loss: 4.398560]\n",
            "2746 [ D loss: 0.186511, acc.: 94%] [G loss: 6.590520]\n",
            "2747 [ D loss: 0.243834, acc.: 91%] [G loss: 5.642421]\n",
            "2748 [ D loss: 0.348743, acc.: 84%] [G loss: 4.117283]\n",
            "2749 [ D loss: 0.280717, acc.: 92%] [G loss: 7.144970]\n",
            "2750 [ D loss: 0.216068, acc.: 93%] [G loss: 4.899573]\n",
            "2751 [ D loss: 0.242875, acc.: 91%] [G loss: 3.781745]\n",
            "2752 [ D loss: 0.193117, acc.: 95%] [G loss: 4.860183]\n",
            "2753 [ D loss: 0.188535, acc.: 95%] [G loss: 6.894610]\n",
            "2754 [ D loss: 0.215052, acc.: 93%] [G loss: 4.547004]\n",
            "2755 [ D loss: 0.256689, acc.: 90%] [G loss: 4.438949]\n",
            "2756 [ D loss: 0.168950, acc.: 96%] [G loss: 4.742537]\n",
            "2757 [ D loss: 0.179842, acc.: 96%] [G loss: 4.745098]\n",
            "2758 [ D loss: 0.370581, acc.: 78%] [G loss: 3.818227]\n",
            "2759 [ D loss: 0.367279, acc.: 83%] [G loss: 4.594432]\n",
            "2760 [ D loss: 0.383583, acc.: 81%] [G loss: 3.585456]\n",
            "2761 [ D loss: 0.277177, acc.: 94%] [G loss: 6.740906]\n",
            "2762 [ D loss: 0.507177, acc.: 69%] [G loss: 4.281055]\n",
            "2763 [ D loss: 0.178785, acc.: 93%] [G loss: 8.798120]\n",
            "2764 [ D loss: 0.062370, acc.: 98%] [G loss: 6.940254]\n",
            "2765 [ D loss: 0.281123, acc.: 88%] [G loss: 4.600084]\n",
            "2766 [ D loss: 0.220681, acc.: 89%] [G loss: 5.236922]\n",
            "2767 [ D loss: 0.291042, acc.: 91%] [G loss: 3.865486]\n",
            "2768 [ D loss: 0.183178, acc.: 95%] [G loss: 6.108350]\n",
            "2769 [ D loss: 0.218580, acc.: 93%] [G loss: 4.540193]\n",
            "2770 [ D loss: 0.133137, acc.: 98%] [G loss: 6.511341]\n",
            "2771 [ D loss: 0.221650, acc.: 91%] [G loss: 4.694306]\n",
            "2772 [ D loss: 0.173311, acc.: 91%] [G loss: 5.348595]\n",
            "2773 [ D loss: 0.176168, acc.: 96%] [G loss: 5.429051]\n",
            "2774 [ D loss: 0.285757, acc.: 86%] [G loss: 2.917362]\n",
            "2775 [ D loss: 0.263964, acc.: 89%] [G loss: 3.572855]\n",
            "2776 [ D loss: 0.420849, acc.: 82%] [G loss: 2.763490]\n",
            "2777 [ D loss: 0.275604, acc.: 94%] [G loss: 5.486638]\n",
            "2778 [ D loss: 0.259928, acc.: 94%] [G loss: 4.848981]\n",
            "2779 [ D loss: 0.314203, acc.: 88%] [G loss: 4.656922]\n",
            "2780 [ D loss: 0.353150, acc.: 85%] [G loss: 3.069863]\n",
            "2781 [ D loss: 0.203918, acc.: 96%] [G loss: 3.637913]\n",
            "2782 [ D loss: 0.253970, acc.: 94%] [G loss: 3.569089]\n",
            "2783 [ D loss: 0.273021, acc.: 91%] [G loss: 3.541562]\n",
            "2784 [ D loss: 0.224277, acc.: 96%] [G loss: 4.350150]\n",
            "2785 [ D loss: 0.268242, acc.: 93%] [G loss: 2.503245]\n",
            "2786 [ D loss: 0.191517, acc.: 97%] [G loss: 2.936996]\n",
            "2787 [ D loss: 0.371448, acc.: 86%] [G loss: 3.624807]\n",
            "2788 [ D loss: 0.295037, acc.: 91%] [G loss: 4.188732]\n",
            "2789 [ D loss: 0.407716, acc.: 85%] [G loss: 2.622178]\n",
            "2790 [ D loss: 0.273926, acc.: 92%] [G loss: 3.743047]\n",
            "2791 [ D loss: 0.395784, acc.: 84%] [G loss: 4.312852]\n",
            "2792 [ D loss: 0.268537, acc.: 95%] [G loss: 3.223963]\n",
            "2793 [ D loss: 0.286787, acc.: 91%] [G loss: 2.992549]\n",
            "2794 [ D loss: 0.254350, acc.: 93%] [G loss: 4.443947]\n",
            "2795 [ D loss: 0.240738, acc.: 97%] [G loss: 3.235578]\n",
            "2796 [ D loss: 0.308831, acc.: 95%] [G loss: 2.723378]\n",
            "2797 [ D loss: 0.227085, acc.: 95%] [G loss: 3.212396]\n",
            "2798 [ D loss: 0.426174, acc.: 82%] [G loss: 3.211639]\n",
            "2799 [ D loss: 0.246191, acc.: 95%] [G loss: 2.735407]\n",
            "2800 [ D loss: 0.271756, acc.: 91%] [G loss: 3.580948]\n",
            "2801 [ D loss: 0.273669, acc.: 93%] [G loss: 2.524141]\n",
            "2802 [ D loss: 0.298852, acc.: 93%] [G loss: 4.124205]\n",
            "2803 [ D loss: 0.382976, acc.: 81%] [G loss: 3.846777]\n",
            "2804 [ D loss: 0.272598, acc.: 93%] [G loss: 4.639787]\n",
            "2805 [ D loss: 0.304177, acc.: 89%] [G loss: 3.880068]\n",
            "2806 [ D loss: 0.435032, acc.: 79%] [G loss: 2.794078]\n",
            "2807 [ D loss: 0.276398, acc.: 95%] [G loss: 2.995540]\n",
            "2808 [ D loss: 0.343365, acc.: 90%] [G loss: 4.103936]\n",
            "2809 [ D loss: 0.278434, acc.: 95%] [G loss: 4.016913]\n",
            "2810 [ D loss: 0.192683, acc.: 96%] [G loss: 4.034184]\n",
            "2811 [ D loss: 0.227246, acc.: 91%] [G loss: 6.070363]\n",
            "2812 [ D loss: 0.227696, acc.: 93%] [G loss: 6.487241]\n",
            "2813 [ D loss: 0.143673, acc.: 98%] [G loss: 2.971652]\n",
            "2814 [ D loss: 0.232872, acc.: 91%] [G loss: 5.366705]\n",
            "2815 [ D loss: 0.190808, acc.: 98%] [G loss: 4.977740]\n",
            "2816 [ D loss: 0.199521, acc.: 95%] [G loss: 4.056323]\n",
            "2817 [ D loss: 0.218870, acc.: 96%] [G loss: 4.447293]\n",
            "2818 [ D loss: 0.215359, acc.: 93%] [G loss: 4.244581]\n",
            "2819 [ D loss: 0.248791, acc.: 92%] [G loss: 2.627801]\n",
            "2820 [ D loss: 0.182091, acc.: 95%] [G loss: 3.567335]\n",
            "2821 [ D loss: 0.274139, acc.: 95%] [G loss: 4.380141]\n",
            "2822 [ D loss: 0.262380, acc.: 88%] [G loss: 5.740417]\n",
            "2823 [ D loss: 0.296405, acc.: 90%] [G loss: 4.166501]\n",
            "2824 [ D loss: 0.208243, acc.: 95%] [G loss: 3.358917]\n",
            "2825 [ D loss: 0.256101, acc.: 91%] [G loss: 2.854244]\n",
            "2826 [ D loss: 0.366396, acc.: 84%] [G loss: 3.367662]\n",
            "2827 [ D loss: 0.327957, acc.: 84%] [G loss: 5.592670]\n",
            "2828 [ D loss: 0.477688, acc.: 74%] [G loss: 4.220749]\n",
            "2829 [ D loss: 0.204754, acc.: 96%] [G loss: 5.465205]\n",
            "2830 [ D loss: 0.220538, acc.: 95%] [G loss: 3.366130]\n",
            "2831 [ D loss: 0.206748, acc.: 95%] [G loss: 5.141466]\n",
            "2832 [ D loss: 0.312153, acc.: 92%] [G loss: 3.434443]\n",
            "2833 [ D loss: 0.314442, acc.: 90%] [G loss: 2.695873]\n",
            "2834 [ D loss: 0.325307, acc.: 90%] [G loss: 3.633354]\n",
            "2835 [ D loss: 0.187030, acc.: 95%] [G loss: 4.724045]\n",
            "2836 [ D loss: 0.243302, acc.: 96%] [G loss: 5.601502]\n",
            "2837 [ D loss: 0.214075, acc.: 94%] [G loss: 2.741817]\n",
            "2838 [ D loss: 0.233065, acc.: 95%] [G loss: 4.662241]\n",
            "2839 [ D loss: 0.222533, acc.: 96%] [G loss: 3.094165]\n",
            "2840 [ D loss: 0.204092, acc.: 98%] [G loss: 4.395246]\n",
            "2841 [ D loss: 0.238318, acc.: 95%] [G loss: 3.107419]\n",
            "2842 [ D loss: 0.243732, acc.: 91%] [G loss: 3.016489]\n",
            "2843 [ D loss: 0.237514, acc.: 92%] [G loss: 4.178314]\n",
            "2844 [ D loss: 0.161959, acc.: 95%] [G loss: 7.564268]\n",
            "2845 [ D loss: 0.175839, acc.: 92%] [G loss: 6.556440]\n",
            "2846 [ D loss: 0.207902, acc.: 92%] [G loss: 7.232716]\n",
            "2847 [ D loss: 0.120415, acc.: 99%] [G loss: 7.019068]\n",
            "2848 [ D loss: 0.213545, acc.: 95%] [G loss: 3.924959]\n",
            "2849 [ D loss: 0.274173, acc.: 90%] [G loss: 3.119502]\n",
            "2850 [ D loss: 0.258278, acc.: 92%] [G loss: 3.721890]\n",
            "2851 [ D loss: 0.297007, acc.: 91%] [G loss: 4.781995]\n",
            "2852 [ D loss: 0.273859, acc.: 95%] [G loss: 3.038540]\n",
            "2853 [ D loss: 0.238711, acc.: 95%] [G loss: 3.118585]\n",
            "2854 [ D loss: 0.181281, acc.: 96%] [G loss: 2.451336]\n",
            "2855 [ D loss: 0.110916, acc.: 99%] [G loss: 8.816748]\n",
            "2856 [ D loss: 0.278913, acc.: 88%] [G loss: 3.644598]\n",
            "2857 [ D loss: 0.211724, acc.: 95%] [G loss: 6.608829]\n",
            "2858 [ D loss: 0.193634, acc.: 95%] [G loss: 2.763668]\n",
            "2859 [ D loss: 0.283502, acc.: 88%] [G loss: 3.333714]\n",
            "2860 [ D loss: 0.247951, acc.: 95%] [G loss: 3.090688]\n",
            "2861 [ D loss: 0.235228, acc.: 95%] [G loss: 5.913353]\n",
            "2862 [ D loss: 0.150775, acc.: 97%] [G loss: 6.644478]\n",
            "2863 [ D loss: 0.355471, acc.: 80%] [G loss: 3.879417]\n",
            "2864 [ D loss: 0.236127, acc.: 93%] [G loss: 2.620619]\n",
            "2865 [ D loss: 0.209322, acc.: 95%] [G loss: 9.773143]\n",
            "2866 [ D loss: 0.239990, acc.: 91%] [G loss: 3.394284]\n",
            "2867 [ D loss: 0.181793, acc.: 95%] [G loss: 4.832092]\n",
            "2868 [ D loss: 0.253998, acc.: 92%] [G loss: 4.065949]\n",
            "2869 [ D loss: 0.185255, acc.: 97%] [G loss: 4.927833]\n",
            "2870 [ D loss: 0.390397, acc.: 85%] [G loss: 3.270990]\n",
            "2871 [ D loss: 0.202491, acc.: 94%] [G loss: 3.392759]\n",
            "2872 [ D loss: 0.264155, acc.: 88%] [G loss: 4.191942]\n",
            "2873 [ D loss: 0.287383, acc.: 91%] [G loss: 3.616876]\n",
            "2874 [ D loss: 0.301047, acc.: 91%] [G loss: 3.296813]\n",
            "2875 [ D loss: 0.213259, acc.: 93%] [G loss: 3.686222]\n",
            "2876 [ D loss: 0.372423, acc.: 86%] [G loss: 3.145897]\n",
            "2877 [ D loss: 0.311354, acc.: 87%] [G loss: 5.874755]\n",
            "2878 [ D loss: 0.239466, acc.: 92%] [G loss: 6.752369]\n",
            "2879 [ D loss: 0.296047, acc.: 88%] [G loss: 4.800371]\n",
            "2880 [ D loss: 0.228483, acc.: 92%] [G loss: 3.833503]\n",
            "2881 [ D loss: 0.268582, acc.: 89%] [G loss: 3.020880]\n",
            "2882 [ D loss: 0.304418, acc.: 92%] [G loss: 3.129072]\n",
            "2883 [ D loss: 0.225606, acc.: 96%] [G loss: 3.115690]\n",
            "2884 [ D loss: 0.172515, acc.: 98%] [G loss: 4.569754]\n",
            "2885 [ D loss: 0.241624, acc.: 95%] [G loss: 2.585313]\n",
            "2886 [ D loss: 0.251069, acc.: 91%] [G loss: 3.389684]\n",
            "2887 [ D loss: 0.275858, acc.: 91%] [G loss: 4.980514]\n",
            "2888 [ D loss: 0.295053, acc.: 90%] [G loss: 4.463287]\n",
            "2889 [ D loss: 0.328316, acc.: 88%] [G loss: 2.611833]\n",
            "2890 [ D loss: 0.317133, acc.: 91%] [G loss: 2.613565]\n",
            "2891 [ D loss: 0.303598, acc.: 92%] [G loss: 4.063726]\n",
            "2892 [ D loss: 0.349414, acc.: 88%] [G loss: 3.901838]\n",
            "2893 [ D loss: 0.230210, acc.: 96%] [G loss: 3.776812]\n",
            "2894 [ D loss: 0.256237, acc.: 91%] [G loss: 3.055328]\n",
            "2895 [ D loss: 0.253114, acc.: 92%] [G loss: 3.138593]\n",
            "2896 [ D loss: 0.287381, acc.: 95%] [G loss: 3.107337]\n",
            "2897 [ D loss: 0.234835, acc.: 95%] [G loss: 4.337414]\n",
            "2898 [ D loss: 0.223200, acc.: 95%] [G loss: 5.700660]\n",
            "2899 [ D loss: 0.282220, acc.: 91%] [G loss: 4.447643]\n",
            "2900 [ D loss: 0.280237, acc.: 91%] [G loss: 3.531916]\n",
            "2901 [ D loss: 0.298322, acc.: 92%] [G loss: 3.361827]\n",
            "2902 [ D loss: 0.253771, acc.: 96%] [G loss: 2.976352]\n",
            "2903 [ D loss: 0.321338, acc.: 89%] [G loss: 3.073079]\n",
            "2904 [ D loss: 0.247367, acc.: 92%] [G loss: 3.912065]\n",
            "2905 [ D loss: 0.295742, acc.: 92%] [G loss: 3.434224]\n",
            "2906 [ D loss: 0.330522, acc.: 84%] [G loss: 3.322441]\n",
            "2907 [ D loss: 0.248114, acc.: 95%] [G loss: 4.567043]\n",
            "2908 [ D loss: 0.224799, acc.: 95%] [G loss: 5.615726]\n",
            "2909 [ D loss: 0.242699, acc.: 93%] [G loss: 3.868205]\n",
            "2910 [ D loss: 0.207592, acc.: 96%] [G loss: 3.333803]\n",
            "2911 [ D loss: 0.346556, acc.: 84%] [G loss: 4.492383]\n",
            "2912 [ D loss: 0.246402, acc.: 93%] [G loss: 5.712944]\n",
            "2913 [ D loss: 0.390423, acc.: 81%] [G loss: 2.710585]\n",
            "2914 [ D loss: 0.235668, acc.: 96%] [G loss: 4.922547]\n",
            "2915 [ D loss: 0.200793, acc.: 94%] [G loss: 5.969225]\n",
            "2916 [ D loss: 0.185637, acc.: 94%] [G loss: 5.113470]\n",
            "2917 [ D loss: 0.303708, acc.: 85%] [G loss: 5.814337]\n",
            "2918 [ D loss: 0.115740, acc.: 100%] [G loss: 6.866749]\n",
            "2919 [ D loss: 0.184548, acc.: 95%] [G loss: 11.462431]\n",
            "2920 [ D loss: 0.184711, acc.: 92%] [G loss: 8.360126]\n",
            "2921 [ D loss: 0.143714, acc.: 96%] [G loss: 10.121069]\n",
            "2922 [ D loss: 0.209320, acc.: 90%] [G loss: 5.072733]\n",
            "2923 [ D loss: 0.151371, acc.: 94%] [G loss: 8.683094]\n",
            "2924 [ D loss: 0.156188, acc.: 95%] [G loss: 6.125671]\n",
            "2925 [ D loss: 0.216471, acc.: 93%] [G loss: 4.782012]\n",
            "2926 [ D loss: 0.242691, acc.: 94%] [G loss: 6.114434]\n",
            "2927 [ D loss: 0.252179, acc.: 90%] [G loss: 3.972346]\n",
            "2928 [ D loss: 0.160828, acc.: 96%] [G loss: 5.727122]\n",
            "2929 [ D loss: 0.281136, acc.: 91%] [G loss: 8.915707]\n",
            "2930 [ D loss: 0.161908, acc.: 95%] [G loss: 6.433158]\n",
            "2931 [ D loss: 0.243358, acc.: 93%] [G loss: 3.542702]\n",
            "2932 [ D loss: 0.293638, acc.: 89%] [G loss: 4.241344]\n",
            "2933 [ D loss: 0.128254, acc.: 98%] [G loss: 4.554842]\n",
            "2934 [ D loss: 0.228537, acc.: 94%] [G loss: 3.456788]\n",
            "2935 [ D loss: 0.167995, acc.: 95%] [G loss: 7.868976]\n",
            "2936 [ D loss: 0.184745, acc.: 95%] [G loss: 3.268618]\n",
            "2937 [ D loss: 0.193411, acc.: 93%] [G loss: 6.603086]\n",
            "2938 [ D loss: 0.342492, acc.: 86%] [G loss: 3.269062]\n",
            "2939 [ D loss: 0.150502, acc.: 98%] [G loss: 4.087626]\n",
            "2940 [ D loss: 0.238367, acc.: 93%] [G loss: 4.784699]\n",
            "2941 [ D loss: 0.241597, acc.: 95%] [G loss: 3.556844]\n",
            "2942 [ D loss: 0.195543, acc.: 95%] [G loss: 5.182846]\n",
            "2943 [ D loss: 0.147615, acc.: 96%] [G loss: 3.836215]\n",
            "2944 [ D loss: 0.218975, acc.: 91%] [G loss: 4.497095]\n",
            "2945 [ D loss: 0.222158, acc.: 93%] [G loss: 3.847714]\n",
            "2946 [ D loss: 0.298296, acc.: 93%] [G loss: 3.859683]\n",
            "2947 [ D loss: 0.296580, acc.: 88%] [G loss: 3.182775]\n",
            "2948 [ D loss: 0.389984, acc.: 86%] [G loss: 3.132955]\n",
            "2949 [ D loss: 0.389873, acc.: 85%] [G loss: 4.190091]\n",
            "2950 [ D loss: 0.254034, acc.: 92%] [G loss: 5.155699]\n",
            "2951 [ D loss: 0.221170, acc.: 95%] [G loss: 6.817516]\n",
            "2952 [ D loss: 0.176232, acc.: 94%] [G loss: 4.845751]\n",
            "2953 [ D loss: 0.178368, acc.: 95%] [G loss: 3.454720]\n",
            "2954 [ D loss: 0.282689, acc.: 91%] [G loss: 4.708530]\n",
            "2955 [ D loss: 0.291231, acc.: 93%] [G loss: 3.234150]\n",
            "2956 [ D loss: 0.280593, acc.: 91%] [G loss: 3.792930]\n",
            "2957 [ D loss: 0.289671, acc.: 93%] [G loss: 3.665192]\n",
            "2958 [ D loss: 0.305704, acc.: 93%] [G loss: 4.116156]\n",
            "2959 [ D loss: 0.317356, acc.: 93%] [G loss: 3.123847]\n",
            "2960 [ D loss: 0.267426, acc.: 95%] [G loss: 2.928926]\n",
            "2961 [ D loss: 0.249180, acc.: 98%] [G loss: 3.540359]\n",
            "2962 [ D loss: 0.285316, acc.: 93%] [G loss: 3.136959]\n",
            "2963 [ D loss: 0.294517, acc.: 93%] [G loss: 3.452982]\n",
            "2964 [ D loss: 0.248938, acc.: 94%] [G loss: 3.173585]\n",
            "2965 [ D loss: 0.214629, acc.: 98%] [G loss: 2.836018]\n",
            "2966 [ D loss: 0.344280, acc.: 87%] [G loss: 3.497102]\n",
            "2967 [ D loss: 0.191836, acc.: 98%] [G loss: 4.001513]\n",
            "2968 [ D loss: 0.182959, acc.: 95%] [G loss: 3.093679]\n",
            "2969 [ D loss: 0.351399, acc.: 86%] [G loss: 3.615968]\n",
            "2970 [ D loss: 0.279481, acc.: 88%] [G loss: 5.756557]\n",
            "2971 [ D loss: 0.188396, acc.: 95%] [G loss: 4.865394]\n",
            "2972 [ D loss: 0.223102, acc.: 93%] [G loss: 3.521254]\n",
            "2973 [ D loss: 0.213767, acc.: 93%] [G loss: 2.947315]\n",
            "2974 [ D loss: 0.332854, acc.: 89%] [G loss: 3.175650]\n",
            "2975 [ D loss: 0.226956, acc.: 96%] [G loss: 3.525788]\n",
            "2976 [ D loss: 0.363087, acc.: 84%] [G loss: 3.565179]\n",
            "2977 [ D loss: 0.246366, acc.: 95%] [G loss: 4.402361]\n",
            "2978 [ D loss: 0.288102, acc.: 90%] [G loss: 3.145873]\n",
            "2979 [ D loss: 0.199825, acc.: 97%] [G loss: 4.014269]\n",
            "2980 [ D loss: 0.178870, acc.: 97%] [G loss: 3.941133]\n",
            "2981 [ D loss: 0.183663, acc.: 96%] [G loss: 5.910974]\n",
            "2982 [ D loss: 0.182319, acc.: 95%] [G loss: 3.081433]\n",
            "2983 [ D loss: 0.261872, acc.: 94%] [G loss: 5.333934]\n",
            "2984 [ D loss: 0.308042, acc.: 91%] [G loss: 5.462150]\n",
            "2985 [ D loss: 0.186470, acc.: 97%] [G loss: 4.372172]\n",
            "2986 [ D loss: 0.241460, acc.: 96%] [G loss: 3.660751]\n",
            "2987 [ D loss: 0.195453, acc.: 96%] [G loss: 7.465151]\n",
            "2988 [ D loss: 0.225537, acc.: 95%] [G loss: 3.755168]\n",
            "2989 [ D loss: 0.228180, acc.: 94%] [G loss: 3.887788]\n",
            "2990 [ D loss: 0.200995, acc.: 96%] [G loss: 7.935966]\n",
            "2991 [ D loss: 0.260208, acc.: 92%] [G loss: 5.079649]\n",
            "2992 [ D loss: 0.285935, acc.: 91%] [G loss: 4.016871]\n",
            "2993 [ D loss: 0.331946, acc.: 88%] [G loss: 6.006913]\n",
            "2994 [ D loss: 0.268197, acc.: 95%] [G loss: 6.118808]\n",
            "2995 [ D loss: 0.206236, acc.: 93%] [G loss: 8.008392]\n",
            "2996 [ D loss: 0.174467, acc.: 97%] [G loss: 5.300629]\n",
            "2997 [ D loss: 0.183780, acc.: 94%] [G loss: 5.963445]\n",
            "2998 [ D loss: 0.259898, acc.: 98%] [G loss: 3.791610]\n",
            "2999 [ D loss: 0.249732, acc.: 91%] [G loss: 4.692935]\n",
            "3000 [ D loss: 0.305066, acc.: 94%] [G loss: 3.891619]\n",
            "3001 [ D loss: 0.226629, acc.: 95%] [G loss: 4.208606]\n",
            "3002 [ D loss: 0.308828, acc.: 86%] [G loss: 3.569825]\n",
            "3003 [ D loss: 0.379971, acc.: 84%] [G loss: 3.898252]\n",
            "3004 [ D loss: 0.239894, acc.: 95%] [G loss: 3.724252]\n",
            "3005 [ D loss: 0.308231, acc.: 88%] [G loss: 2.221183]\n",
            "3006 [ D loss: 0.278587, acc.: 91%] [G loss: 3.562459]\n",
            "3007 [ D loss: 0.191487, acc.: 96%] [G loss: 3.858741]\n",
            "3008 [ D loss: 0.291072, acc.: 91%] [G loss: 3.619541]\n",
            "3009 [ D loss: 0.214618, acc.: 95%] [G loss: 4.916090]\n",
            "3010 [ D loss: 0.262260, acc.: 92%] [G loss: 2.753149]\n",
            "3011 [ D loss: 0.261356, acc.: 91%] [G loss: 3.891662]\n",
            "3012 [ D loss: 0.197220, acc.: 95%] [G loss: 4.436607]\n",
            "3013 [ D loss: 0.245858, acc.: 91%] [G loss: 3.962982]\n",
            "3014 [ D loss: 0.320705, acc.: 87%] [G loss: 3.095198]\n",
            "3015 [ D loss: 0.226631, acc.: 98%] [G loss: 4.324482]\n",
            "3016 [ D loss: 0.269306, acc.: 96%] [G loss: 2.956029]\n",
            "3017 [ D loss: 0.219182, acc.: 95%] [G loss: 3.639960]\n",
            "3018 [ D loss: 0.198904, acc.: 92%] [G loss: 3.347134]\n",
            "3019 [ D loss: 0.276004, acc.: 91%] [G loss: 8.270250]\n",
            "3020 [ D loss: 0.174386, acc.: 96%] [G loss: 6.044096]\n",
            "3021 [ D loss: 0.223529, acc.: 91%] [G loss: 4.954909]\n",
            "3022 [ D loss: 0.142852, acc.: 98%] [G loss: 6.006968]\n",
            "3023 [ D loss: 0.120912, acc.: 97%] [G loss: 8.864224]\n",
            "3024 [ D loss: 0.215230, acc.: 92%] [G loss: 4.005205]\n",
            "3025 [ D loss: 0.164321, acc.: 91%] [G loss: 5.398538]\n",
            "3026 [ D loss: 0.451652, acc.: 77%] [G loss: 3.233015]\n",
            "3027 [ D loss: 0.217264, acc.: 94%] [G loss: 5.272392]\n",
            "3028 [ D loss: 0.218145, acc.: 94%] [G loss: 4.684254]\n",
            "3029 [ D loss: 0.213009, acc.: 94%] [G loss: 5.501663]\n",
            "3030 [ D loss: 0.169971, acc.: 95%] [G loss: 6.351599]\n",
            "3031 [ D loss: 0.145940, acc.: 96%] [G loss: 6.304727]\n",
            "3032 [ D loss: 0.248459, acc.: 91%] [G loss: 3.742251]\n",
            "3033 [ D loss: 0.202856, acc.: 91%] [G loss: 6.699620]\n",
            "3034 [ D loss: 0.245058, acc.: 92%] [G loss: 3.108558]\n",
            "3035 [ D loss: 0.161828, acc.: 95%] [G loss: 7.725694]\n",
            "3036 [ D loss: 0.295046, acc.: 87%] [G loss: 5.185236]\n",
            "3037 [ D loss: 0.221000, acc.: 92%] [G loss: 4.392550]\n",
            "3038 [ D loss: 0.179328, acc.: 95%] [G loss: 3.582524]\n",
            "3039 [ D loss: 0.245225, acc.: 95%] [G loss: 3.932240]\n",
            "3040 [ D loss: 0.275175, acc.: 92%] [G loss: 4.010305]\n",
            "3041 [ D loss: 0.251347, acc.: 92%] [G loss: 4.050473]\n",
            "3042 [ D loss: 0.188315, acc.: 96%] [G loss: 8.068175]\n",
            "3043 [ D loss: 0.324741, acc.: 84%] [G loss: 3.377813]\n",
            "3044 [ D loss: 0.252336, acc.: 92%] [G loss: 4.909014]\n",
            "3045 [ D loss: 0.241996, acc.: 93%] [G loss: 6.061992]\n",
            "3046 [ D loss: 0.209256, acc.: 97%] [G loss: 3.959203]\n",
            "3047 [ D loss: 0.194290, acc.: 93%] [G loss: 5.370626]\n",
            "3048 [ D loss: 0.209833, acc.: 91%] [G loss: 5.338264]\n",
            "3049 [ D loss: 0.304342, acc.: 88%] [G loss: 3.724492]\n",
            "3050 [ D loss: 0.250385, acc.: 89%] [G loss: 5.708082]\n",
            "3051 [ D loss: 0.186562, acc.: 95%] [G loss: 8.109741]\n",
            "3052 [ D loss: 0.426462, acc.: 79%] [G loss: 6.508648]\n",
            "3053 [ D loss: 0.164540, acc.: 96%] [G loss: 4.724599]\n",
            "3054 [ D loss: 0.126385, acc.: 97%] [G loss: 10.342241]\n",
            "3055 [ D loss: 0.127154, acc.: 96%] [G loss: 9.445632]\n",
            "3056 [ D loss: 0.285113, acc.: 86%] [G loss: 5.248899]\n",
            "3057 [ D loss: 0.124910, acc.: 99%] [G loss: 3.721207]\n",
            "3058 [ D loss: 0.244905, acc.: 92%] [G loss: 3.507060]\n",
            "3059 [ D loss: 0.227550, acc.: 95%] [G loss: 4.413322]\n",
            "3060 [ D loss: 0.178745, acc.: 99%] [G loss: 4.008282]\n",
            "3061 [ D loss: 0.266457, acc.: 90%] [G loss: 3.352488]\n",
            "3062 [ D loss: 0.248544, acc.: 95%] [G loss: 2.966590]\n",
            "3063 [ D loss: 0.258987, acc.: 94%] [G loss: 3.031252]\n",
            "3064 [ D loss: 0.198760, acc.: 96%] [G loss: 6.712629]\n",
            "3065 [ D loss: 0.207921, acc.: 94%] [G loss: 2.258894]\n",
            "3066 [ D loss: 0.228555, acc.: 89%] [G loss: 4.393424]\n",
            "3067 [ D loss: 0.237929, acc.: 93%] [G loss: 10.916345]\n",
            "3068 [ D loss: 0.140877, acc.: 97%] [G loss: 5.914602]\n",
            "3069 [ D loss: 0.193735, acc.: 93%] [G loss: 7.751357]\n",
            "3070 [ D loss: 0.120913, acc.: 98%] [G loss: 5.339537]\n",
            "3071 [ D loss: 0.131808, acc.: 99%] [G loss: 3.781320]\n",
            "3072 [ D loss: 0.196402, acc.: 97%] [G loss: 4.153093]\n",
            "3073 [ D loss: 0.209534, acc.: 96%] [G loss: 2.982826]\n",
            "3074 [ D loss: 0.301335, acc.: 91%] [G loss: 3.400785]\n",
            "3075 [ D loss: 0.266142, acc.: 96%] [G loss: 3.743931]\n",
            "3076 [ D loss: 0.277043, acc.: 89%] [G loss: 3.339234]\n",
            "3077 [ D loss: 0.288136, acc.: 87%] [G loss: 3.226600]\n",
            "3078 [ D loss: 0.232902, acc.: 93%] [G loss: 2.974576]\n",
            "3079 [ D loss: 0.247614, acc.: 93%] [G loss: 3.174424]\n",
            "3080 [ D loss: 0.207515, acc.: 96%] [G loss: 3.718732]\n",
            "3081 [ D loss: 0.266347, acc.: 92%] [G loss: 2.929195]\n",
            "3082 [ D loss: 0.228052, acc.: 94%] [G loss: 5.269933]\n",
            "3083 [ D loss: 0.205637, acc.: 93%] [G loss: 5.293011]\n",
            "3084 [ D loss: 0.224391, acc.: 95%] [G loss: 2.810520]\n",
            "3085 [ D loss: 0.285558, acc.: 90%] [G loss: 3.327251]\n",
            "3086 [ D loss: 0.173275, acc.: 95%] [G loss: 5.661801]\n",
            "3087 [ D loss: 0.195880, acc.: 97%] [G loss: 5.864881]\n",
            "3088 [ D loss: 0.215101, acc.: 95%] [G loss: 3.833862]\n",
            "3089 [ D loss: 0.205670, acc.: 94%] [G loss: 3.031885]\n",
            "3090 [ D loss: 0.153445, acc.: 98%] [G loss: 4.154460]\n",
            "3091 [ D loss: 0.301619, acc.: 88%] [G loss: 2.485079]\n",
            "3092 [ D loss: 0.275055, acc.: 91%] [G loss: 3.355550]\n",
            "3093 [ D loss: 0.261187, acc.: 95%] [G loss: 4.012619]\n",
            "3094 [ D loss: 0.388625, acc.: 84%] [G loss: 4.671416]\n",
            "3095 [ D loss: 0.447649, acc.: 79%] [G loss: 2.891198]\n",
            "3096 [ D loss: 0.332496, acc.: 88%] [G loss: 3.866148]\n",
            "3097 [ D loss: 0.227781, acc.: 94%] [G loss: 3.150855]\n",
            "3098 [ D loss: 0.204811, acc.: 96%] [G loss: 3.328794]\n",
            "3099 [ D loss: 0.192074, acc.: 95%] [G loss: 3.442402]\n",
            "3100 [ D loss: 0.276433, acc.: 95%] [G loss: 3.599724]\n",
            "3101 [ D loss: 0.212475, acc.: 94%] [G loss: 3.702043]\n",
            "3102 [ D loss: 0.299929, acc.: 87%] [G loss: 3.407086]\n",
            "3103 [ D loss: 0.192539, acc.: 98%] [G loss: 3.677418]\n",
            "3104 [ D loss: 0.198635, acc.: 95%] [G loss: 3.894822]\n",
            "3105 [ D loss: 0.162211, acc.: 98%] [G loss: 3.982000]\n",
            "3106 [ D loss: 0.228249, acc.: 95%] [G loss: 4.218510]\n",
            "3107 [ D loss: 0.240536, acc.: 93%] [G loss: 3.275307]\n",
            "3108 [ D loss: 0.249491, acc.: 95%] [G loss: 3.578697]\n",
            "3109 [ D loss: 0.318520, acc.: 88%] [G loss: 3.499019]\n",
            "3110 [ D loss: 0.204084, acc.: 95%] [G loss: 3.653768]\n",
            "3111 [ D loss: 0.208312, acc.: 95%] [G loss: 3.438394]\n",
            "3112 [ D loss: 0.180355, acc.: 96%] [G loss: 5.657213]\n",
            "3113 [ D loss: 0.160658, acc.: 98%] [G loss: 5.426259]\n",
            "3114 [ D loss: 0.261287, acc.: 88%] [G loss: 4.701515]\n",
            "3115 [ D loss: 0.211257, acc.: 95%] [G loss: 4.584085]\n",
            "3116 [ D loss: 0.212243, acc.: 95%] [G loss: 4.133995]\n",
            "3117 [ D loss: 0.197558, acc.: 94%] [G loss: 5.108314]\n",
            "3118 [ D loss: 0.266420, acc.: 88%] [G loss: 4.403426]\n",
            "3119 [ D loss: 0.278514, acc.: 92%] [G loss: 4.149303]\n",
            "3120 [ D loss: 0.322228, acc.: 91%] [G loss: 3.385101]\n",
            "3121 [ D loss: 0.194652, acc.: 96%] [G loss: 3.786237]\n",
            "3122 [ D loss: 0.133013, acc.: 96%] [G loss: 5.713834]\n",
            "3123 [ D loss: 0.123149, acc.: 99%] [G loss: 6.701896]\n",
            "3124 [ D loss: 0.323084, acc.: 85%] [G loss: 3.513549]\n",
            "3125 [ D loss: 0.185662, acc.: 94%] [G loss: 5.718736]\n",
            "3126 [ D loss: 0.245181, acc.: 91%] [G loss: 3.699942]\n",
            "3127 [ D loss: 0.223195, acc.: 95%] [G loss: 3.948406]\n",
            "3128 [ D loss: 0.342983, acc.: 86%] [G loss: 3.136488]\n",
            "3129 [ D loss: 0.263494, acc.: 91%] [G loss: 4.214478]\n",
            "3130 [ D loss: 0.141854, acc.: 96%] [G loss: 6.788649]\n",
            "3131 [ D loss: 0.157457, acc.: 95%] [G loss: 5.987708]\n",
            "3132 [ D loss: 0.211230, acc.: 92%] [G loss: 5.160005]\n",
            "3133 [ D loss: 0.304479, acc.: 89%] [G loss: 3.852067]\n",
            "3134 [ D loss: 0.258297, acc.: 91%] [G loss: 3.479424]\n",
            "3135 [ D loss: 0.237604, acc.: 96%] [G loss: 3.764701]\n",
            "3136 [ D loss: 0.185081, acc.: 95%] [G loss: 3.792194]\n",
            "3137 [ D loss: 0.225019, acc.: 94%] [G loss: 2.971167]\n",
            "3138 [ D loss: 0.174217, acc.: 95%] [G loss: 3.669224]\n",
            "3139 [ D loss: 0.188401, acc.: 92%] [G loss: 3.453325]\n",
            "3140 [ D loss: 0.192083, acc.: 93%] [G loss: 3.377218]\n",
            "3141 [ D loss: 0.198975, acc.: 95%] [G loss: 4.811813]\n",
            "3142 [ D loss: 0.140651, acc.: 95%] [G loss: 5.436688]\n",
            "3143 [ D loss: 0.098132, acc.: 97%] [G loss: 5.058591]\n",
            "3144 [ D loss: 0.358134, acc.: 84%] [G loss: 4.693096]\n",
            "3145 [ D loss: 0.171567, acc.: 95%] [G loss: 7.412772]\n",
            "3146 [ D loss: 0.268183, acc.: 91%] [G loss: 3.825299]\n",
            "3147 [ D loss: 0.125224, acc.: 96%] [G loss: 7.001174]\n",
            "3148 [ D loss: 0.188558, acc.: 95%] [G loss: 4.060808]\n",
            "3149 [ D loss: 0.175813, acc.: 97%] [G loss: 4.243494]\n",
            "3150 [ D loss: 0.194130, acc.: 97%] [G loss: 2.993262]\n",
            "3151 [ D loss: 0.297655, acc.: 89%] [G loss: 3.516407]\n",
            "3152 [ D loss: 0.284072, acc.: 93%] [G loss: 3.094521]\n",
            "3153 [ D loss: 0.295109, acc.: 91%] [G loss: 2.985890]\n",
            "3154 [ D loss: 0.191774, acc.: 98%] [G loss: 3.537962]\n",
            "3155 [ D loss: 0.261809, acc.: 90%] [G loss: 5.693578]\n",
            "3156 [ D loss: 0.286389, acc.: 89%] [G loss: 3.264281]\n",
            "3157 [ D loss: 0.204133, acc.: 94%] [G loss: 3.310861]\n",
            "3158 [ D loss: 0.288411, acc.: 91%] [G loss: 5.076874]\n",
            "3159 [ D loss: 0.097737, acc.: 99%] [G loss: 6.016990]\n",
            "3160 [ D loss: 0.188230, acc.: 95%] [G loss: 3.360757]\n",
            "3161 [ D loss: 0.246670, acc.: 92%] [G loss: 3.375352]\n",
            "3162 [ D loss: 0.285227, acc.: 92%] [G loss: 3.786952]\n",
            "3163 [ D loss: 0.197706, acc.: 95%] [G loss: 6.819260]\n",
            "3164 [ D loss: 0.144503, acc.: 96%] [G loss: 5.898910]\n",
            "3165 [ D loss: 0.172724, acc.: 96%] [G loss: 5.110472]\n",
            "3166 [ D loss: 0.177843, acc.: 97%] [G loss: 3.842487]\n",
            "3167 [ D loss: 0.208305, acc.: 92%] [G loss: 4.381640]\n",
            "3168 [ D loss: 0.212943, acc.: 95%] [G loss: 3.976715]\n",
            "3169 [ D loss: 0.247598, acc.: 91%] [G loss: 4.031093]\n",
            "3170 [ D loss: 0.293695, acc.: 90%] [G loss: 3.805199]\n",
            "3171 [ D loss: 0.339645, acc.: 90%] [G loss: 3.168529]\n",
            "3172 [ D loss: 0.249592, acc.: 95%] [G loss: 3.036805]\n",
            "3173 [ D loss: 0.287439, acc.: 92%] [G loss: 3.108702]\n",
            "3174 [ D loss: 0.214791, acc.: 95%] [G loss: 4.174329]\n",
            "3175 [ D loss: 0.225759, acc.: 95%] [G loss: 3.160215]\n",
            "3176 [ D loss: 0.310390, acc.: 89%] [G loss: 3.419878]\n",
            "3177 [ D loss: 0.268281, acc.: 95%] [G loss: 2.818044]\n",
            "3178 [ D loss: 0.229933, acc.: 95%] [G loss: 2.882759]\n",
            "3179 [ D loss: 0.198721, acc.: 95%] [G loss: 3.127946]\n",
            "3180 [ D loss: 0.266656, acc.: 89%] [G loss: 4.102320]\n",
            "3181 [ D loss: 0.239746, acc.: 89%] [G loss: 4.631782]\n",
            "3182 [ D loss: 0.280892, acc.: 88%] [G loss: 7.089431]\n",
            "3183 [ D loss: 0.184271, acc.: 95%] [G loss: 4.944381]\n",
            "3184 [ D loss: 0.190912, acc.: 95%] [G loss: 4.644734]\n",
            "3185 [ D loss: 0.310106, acc.: 90%] [G loss: 4.009818]\n",
            "3186 [ D loss: 0.201293, acc.: 92%] [G loss: 4.210935]\n",
            "3187 [ D loss: 0.158881, acc.: 98%] [G loss: 3.778723]\n",
            "3188 [ D loss: 0.339942, acc.: 87%] [G loss: 3.818045]\n",
            "3189 [ D loss: 0.217217, acc.: 91%] [G loss: 4.798477]\n",
            "3190 [ D loss: 0.169355, acc.: 95%] [G loss: 10.906492]\n",
            "3191 [ D loss: 0.166526, acc.: 94%] [G loss: 4.599636]\n",
            "3192 [ D loss: 0.219035, acc.: 91%] [G loss: 8.201847]\n",
            "3193 [ D loss: 0.129270, acc.: 98%] [G loss: 4.747536]\n",
            "3194 [ D loss: 0.242599, acc.: 94%] [G loss: 3.842720]\n",
            "3195 [ D loss: 0.234808, acc.: 89%] [G loss: 3.854350]\n",
            "3196 [ D loss: 0.166202, acc.: 95%] [G loss: 5.541310]\n",
            "3197 [ D loss: 0.346324, acc.: 85%] [G loss: 4.281443]\n",
            "3198 [ D loss: 0.199333, acc.: 91%] [G loss: 5.169182]\n",
            "3199 [ D loss: 0.239528, acc.: 94%] [G loss: 3.624376]\n",
            "3200 [ D loss: 0.171620, acc.: 98%] [G loss: 3.409603]\n",
            "3201 [ D loss: 0.238687, acc.: 94%] [G loss: 3.496484]\n",
            "3202 [ D loss: 0.235853, acc.: 95%] [G loss: 3.630597]\n",
            "3203 [ D loss: 0.171142, acc.: 95%] [G loss: 4.325020]\n",
            "3204 [ D loss: 0.238789, acc.: 91%] [G loss: 4.038475]\n",
            "3205 [ D loss: 0.226524, acc.: 91%] [G loss: 8.401642]\n",
            "3206 [ D loss: 0.159535, acc.: 95%] [G loss: 5.298930]\n",
            "3207 [ D loss: 0.182241, acc.: 94%] [G loss: 3.866751]\n",
            "3208 [ D loss: 0.260521, acc.: 91%] [G loss: 5.451179]\n",
            "3209 [ D loss: 0.118757, acc.: 98%] [G loss: 7.774396]\n",
            "3210 [ D loss: 0.179014, acc.: 94%] [G loss: 4.034679]\n",
            "3211 [ D loss: 0.195483, acc.: 94%] [G loss: 3.226116]\n",
            "3212 [ D loss: 0.223485, acc.: 94%] [G loss: 4.919787]\n",
            "3213 [ D loss: 0.192422, acc.: 95%] [G loss: 5.142194]\n",
            "3214 [ D loss: 0.191295, acc.: 94%] [G loss: 5.099621]\n",
            "3215 [ D loss: 0.203819, acc.: 95%] [G loss: 9.216085]\n",
            "3216 [ D loss: 0.132441, acc.: 97%] [G loss: 4.194603]\n",
            "3217 [ D loss: 0.181091, acc.: 93%] [G loss: 5.809493]\n",
            "3218 [ D loss: 0.185146, acc.: 94%] [G loss: 5.632866]\n",
            "3219 [ D loss: 0.116635, acc.: 97%] [G loss: 3.756807]\n",
            "3220 [ D loss: 0.110069, acc.: 97%] [G loss: 5.877219]\n",
            "3221 [ D loss: 0.202793, acc.: 91%] [G loss: 3.976899]\n",
            "3222 [ D loss: 0.281264, acc.: 87%] [G loss: 6.031796]\n",
            "3223 [ D loss: 0.226640, acc.: 91%] [G loss: 4.629668]\n",
            "3224 [ D loss: 0.214167, acc.: 94%] [G loss: 4.267398]\n",
            "3225 [ D loss: 0.220332, acc.: 94%] [G loss: 4.081013]\n",
            "3226 [ D loss: 0.319838, acc.: 91%] [G loss: 2.515380]\n",
            "3227 [ D loss: 0.301480, acc.: 91%] [G loss: 3.683644]\n",
            "3228 [ D loss: 0.191941, acc.: 96%] [G loss: 4.469724]\n",
            "3229 [ D loss: 0.170522, acc.: 96%] [G loss: 5.423418]\n",
            "3230 [ D loss: 0.176915, acc.: 95%] [G loss: 6.076771]\n",
            "3231 [ D loss: 0.241205, acc.: 93%] [G loss: 3.995416]\n",
            "3232 [ D loss: 0.286590, acc.: 89%] [G loss: 4.039302]\n",
            "3233 [ D loss: 0.264309, acc.: 95%] [G loss: 4.118940]\n",
            "3234 [ D loss: 0.249065, acc.: 91%] [G loss: 4.178785]\n",
            "3235 [ D loss: 0.161067, acc.: 95%] [G loss: 4.196699]\n",
            "3236 [ D loss: 0.205822, acc.: 95%] [G loss: 5.485499]\n",
            "3237 [ D loss: 0.189373, acc.: 96%] [G loss: 5.885491]\n",
            "3238 [ D loss: 0.222081, acc.: 95%] [G loss: 4.303564]\n",
            "3239 [ D loss: 0.220129, acc.: 92%] [G loss: 3.843930]\n",
            "3240 [ D loss: 0.238975, acc.: 91%] [G loss: 3.270627]\n",
            "3241 [ D loss: 0.186178, acc.: 98%] [G loss: 3.869914]\n",
            "3242 [ D loss: 0.218595, acc.: 91%] [G loss: 3.472373]\n",
            "3243 [ D loss: 0.263937, acc.: 91%] [G loss: 4.047388]\n",
            "3244 [ D loss: 0.117981, acc.: 98%] [G loss: 6.728173]\n",
            "3245 [ D loss: 0.189490, acc.: 94%] [G loss: 8.048855]\n",
            "3246 [ D loss: 0.140531, acc.: 96%] [G loss: 6.203288]\n",
            "3247 [ D loss: 0.192504, acc.: 95%] [G loss: 4.420926]\n",
            "3248 [ D loss: 0.267580, acc.: 90%] [G loss: 5.483779]\n",
            "3249 [ D loss: 0.187161, acc.: 97%] [G loss: 4.885182]\n",
            "3250 [ D loss: 0.196084, acc.: 95%] [G loss: 5.672385]\n",
            "3251 [ D loss: 0.215115, acc.: 91%] [G loss: 9.789286]\n",
            "3252 [ D loss: 0.151511, acc.: 94%] [G loss: 4.029479]\n",
            "3253 [ D loss: 0.203504, acc.: 89%] [G loss: 5.304333]\n",
            "3254 [ D loss: 0.215596, acc.: 91%] [G loss: 4.534033]\n",
            "3255 [ D loss: 0.249364, acc.: 90%] [G loss: 4.799770]\n",
            "3256 [ D loss: 0.211669, acc.: 93%] [G loss: 3.873474]\n",
            "3257 [ D loss: 0.192483, acc.: 95%] [G loss: 4.077147]\n",
            "3258 [ D loss: 0.138307, acc.: 98%] [G loss: 4.709974]\n",
            "3259 [ D loss: 0.152994, acc.: 97%] [G loss: 6.885546]\n",
            "3260 [ D loss: 0.220496, acc.: 91%] [G loss: 4.278258]\n",
            "3261 [ D loss: 0.137394, acc.: 95%] [G loss: 3.735461]\n",
            "3262 [ D loss: 0.263735, acc.: 95%] [G loss: 2.813533]\n",
            "3263 [ D loss: 0.152048, acc.: 97%] [G loss: 4.661394]\n",
            "3264 [ D loss: 0.286458, acc.: 91%] [G loss: 3.245474]\n",
            "3265 [ D loss: 0.217134, acc.: 96%] [G loss: 3.644233]\n",
            "3266 [ D loss: 0.198923, acc.: 96%] [G loss: 3.149460]\n",
            "3267 [ D loss: 0.192261, acc.: 92%] [G loss: 3.700728]\n",
            "3268 [ D loss: 0.188722, acc.: 95%] [G loss: 4.713827]\n",
            "3269 [ D loss: 0.109958, acc.: 97%] [G loss: 6.093267]\n",
            "3270 [ D loss: 0.156660, acc.: 95%] [G loss: 4.129194]\n",
            "3271 [ D loss: 0.173263, acc.: 96%] [G loss: 3.075531]\n",
            "3272 [ D loss: 0.101613, acc.: 98%] [G loss: 4.321042]\n",
            "3273 [ D loss: 0.296437, acc.: 91%] [G loss: 2.968910]\n",
            "3274 [ D loss: 0.215539, acc.: 91%] [G loss: 4.776486]\n",
            "3275 [ D loss: 0.252674, acc.: 93%] [G loss: 4.096633]\n",
            "3276 [ D loss: 0.252790, acc.: 91%] [G loss: 3.046453]\n",
            "3277 [ D loss: 0.239991, acc.: 95%] [G loss: 3.152311]\n",
            "3278 [ D loss: 0.327074, acc.: 89%] [G loss: 3.609582]\n",
            "3279 [ D loss: 0.195240, acc.: 95%] [G loss: 4.697481]\n",
            "3280 [ D loss: 0.163405, acc.: 96%] [G loss: 5.378253]\n",
            "3281 [ D loss: 0.235134, acc.: 90%] [G loss: 5.132976]\n",
            "3282 [ D loss: 0.103015, acc.: 99%] [G loss: 6.577629]\n",
            "3283 [ D loss: 0.174598, acc.: 96%] [G loss: 6.160881]\n",
            "3284 [ D loss: 0.192486, acc.: 94%] [G loss: 4.016526]\n",
            "3285 [ D loss: 0.168096, acc.: 94%] [G loss: 5.776802]\n",
            "3286 [ D loss: 0.152327, acc.: 98%] [G loss: 3.966228]\n",
            "3287 [ D loss: 0.187471, acc.: 96%] [G loss: 3.590229]\n",
            "3288 [ D loss: 0.158932, acc.: 96%] [G loss: 4.629910]\n",
            "3289 [ D loss: 0.269820, acc.: 94%] [G loss: 3.542189]\n",
            "3290 [ D loss: 0.158941, acc.: 96%] [G loss: 3.848407]\n",
            "3291 [ D loss: 0.278935, acc.: 91%] [G loss: 4.473077]\n",
            "3292 [ D loss: 0.191286, acc.: 96%] [G loss: 2.960309]\n",
            "3293 [ D loss: 0.268512, acc.: 89%] [G loss: 3.134742]\n",
            "3294 [ D loss: 0.290832, acc.: 88%] [G loss: 4.421254]\n",
            "3295 [ D loss: 0.302685, acc.: 88%] [G loss: 3.763998]\n",
            "3296 [ D loss: 0.226779, acc.: 93%] [G loss: 4.149893]\n",
            "3297 [ D loss: 0.193449, acc.: 95%] [G loss: 5.950779]\n",
            "3298 [ D loss: 0.192342, acc.: 94%] [G loss: 4.195396]\n",
            "3299 [ D loss: 0.146392, acc.: 94%] [G loss: 4.564730]\n",
            "3300 [ D loss: 0.142417, acc.: 95%] [G loss: 5.839300]\n",
            "3301 [ D loss: 0.279599, acc.: 87%] [G loss: 3.457857]\n",
            "3302 [ D loss: 0.154138, acc.: 97%] [G loss: 5.314796]\n",
            "3303 [ D loss: 0.213201, acc.: 91%] [G loss: 4.708907]\n",
            "3304 [ D loss: 0.140675, acc.: 97%] [G loss: 5.302845]\n",
            "3305 [ D loss: 0.182867, acc.: 97%] [G loss: 3.496650]\n",
            "3306 [ D loss: 0.184566, acc.: 95%] [G loss: 4.157501]\n",
            "3307 [ D loss: 0.160711, acc.: 95%] [G loss: 4.362277]\n",
            "3308 [ D loss: 0.227457, acc.: 94%] [G loss: 3.612368]\n",
            "3309 [ D loss: 0.146083, acc.: 96%] [G loss: 3.860149]\n",
            "3310 [ D loss: 0.258381, acc.: 88%] [G loss: 4.567736]\n",
            "3311 [ D loss: 0.224784, acc.: 93%] [G loss: 3.785770]\n",
            "3312 [ D loss: 0.170964, acc.: 96%] [G loss: 4.478672]\n",
            "3313 [ D loss: 0.224056, acc.: 93%] [G loss: 3.544566]\n",
            "3314 [ D loss: 0.246149, acc.: 91%] [G loss: 2.694135]\n",
            "3315 [ D loss: 0.256499, acc.: 91%] [G loss: 3.393423]\n",
            "3316 [ D loss: 0.262989, acc.: 94%] [G loss: 6.013654]\n",
            "3317 [ D loss: 0.120326, acc.: 98%] [G loss: 8.732535]\n",
            "3318 [ D loss: 0.137780, acc.: 98%] [G loss: 6.558753]\n",
            "3319 [ D loss: 0.121966, acc.: 94%] [G loss: 4.451267]\n",
            "3320 [ D loss: 0.193578, acc.: 93%] [G loss: 5.102817]\n",
            "3321 [ D loss: 0.156420, acc.: 95%] [G loss: 3.829994]\n",
            "3322 [ D loss: 0.208457, acc.: 94%] [G loss: 3.468246]\n",
            "3323 [ D loss: 0.201402, acc.: 94%] [G loss: 3.309513]\n",
            "3324 [ D loss: 0.263162, acc.: 91%] [G loss: 3.626442]\n",
            "3325 [ D loss: 0.259512, acc.: 91%] [G loss: 3.319820]\n",
            "3326 [ D loss: 0.342626, acc.: 85%] [G loss: 3.738242]\n",
            "3327 [ D loss: 0.183090, acc.: 96%] [G loss: 3.286077]\n",
            "3328 [ D loss: 0.323758, acc.: 89%] [G loss: 3.850209]\n",
            "3329 [ D loss: 0.233094, acc.: 91%] [G loss: 4.686925]\n",
            "3330 [ D loss: 0.318281, acc.: 87%] [G loss: 4.186880]\n",
            "3331 [ D loss: 0.172628, acc.: 95%] [G loss: 4.250844]\n",
            "3332 [ D loss: 0.258074, acc.: 88%] [G loss: 3.349163]\n",
            "3333 [ D loss: 0.202925, acc.: 95%] [G loss: 3.432133]\n",
            "3334 [ D loss: 0.226795, acc.: 94%] [G loss: 3.377147]\n",
            "3335 [ D loss: 0.193907, acc.: 95%] [G loss: 3.773316]\n",
            "3336 [ D loss: 0.291419, acc.: 91%] [G loss: 2.973674]\n",
            "3337 [ D loss: 0.319769, acc.: 88%] [G loss: 3.428782]\n",
            "3338 [ D loss: 0.247799, acc.: 95%] [G loss: 3.438193]\n",
            "3339 [ D loss: 0.261800, acc.: 88%] [G loss: 4.859510]\n",
            "3340 [ D loss: 0.126899, acc.: 98%] [G loss: 5.654615]\n",
            "3341 [ D loss: 0.203598, acc.: 95%] [G loss: 3.649884]\n",
            "3342 [ D loss: 0.267633, acc.: 91%] [G loss: 3.902413]\n",
            "3343 [ D loss: 0.177325, acc.: 98%] [G loss: 3.736392]\n",
            "3344 [ D loss: 0.278101, acc.: 92%] [G loss: 3.894329]\n",
            "3345 [ D loss: 0.319159, acc.: 90%] [G loss: 2.732031]\n",
            "3346 [ D loss: 0.161617, acc.: 98%] [G loss: 3.466448]\n",
            "3347 [ D loss: 0.241527, acc.: 92%] [G loss: 3.426401]\n",
            "3348 [ D loss: 0.200496, acc.: 94%] [G loss: 3.557414]\n",
            "3349 [ D loss: 0.182645, acc.: 97%] [G loss: 3.946936]\n",
            "3350 [ D loss: 0.255096, acc.: 91%] [G loss: 3.190337]\n",
            "3351 [ D loss: 0.235274, acc.: 94%] [G loss: 3.852822]\n",
            "3352 [ D loss: 0.192936, acc.: 93%] [G loss: 4.256856]\n",
            "3353 [ D loss: 0.284116, acc.: 86%] [G loss: 5.322578]\n",
            "3354 [ D loss: 0.264227, acc.: 90%] [G loss: 4.313889]\n",
            "3355 [ D loss: 0.154484, acc.: 96%] [G loss: 4.965010]\n",
            "3356 [ D loss: 0.193760, acc.: 96%] [G loss: 5.521259]\n",
            "3357 [ D loss: 0.092900, acc.: 99%] [G loss: 8.098631]\n",
            "3358 [ D loss: 0.143361, acc.: 95%] [G loss: 6.869617]\n",
            "3359 [ D loss: 0.124814, acc.: 98%] [G loss: 6.407209]\n",
            "3360 [ D loss: 0.093339, acc.: 98%] [G loss: 9.194095]\n",
            "3361 [ D loss: 0.161368, acc.: 95%] [G loss: 8.300211]\n",
            "3362 [ D loss: 0.139594, acc.: 95%] [G loss: 5.304481]\n",
            "3363 [ D loss: 0.151818, acc.: 94%] [G loss: 6.391086]\n",
            "3364 [ D loss: 0.216202, acc.: 92%] [G loss: 4.332153]\n",
            "3365 [ D loss: 0.255571, acc.: 88%] [G loss: 4.157584]\n",
            "3366 [ D loss: 0.191330, acc.: 96%] [G loss: 5.007079]\n",
            "3367 [ D loss: 0.242887, acc.: 92%] [G loss: 3.868000]\n",
            "3368 [ D loss: 0.289291, acc.: 87%] [G loss: 2.919841]\n",
            "3369 [ D loss: 0.210511, acc.: 95%] [G loss: 9.055614]\n",
            "3370 [ D loss: 0.176041, acc.: 96%] [G loss: 3.461785]\n",
            "3371 [ D loss: 0.264734, acc.: 91%] [G loss: 4.388407]\n",
            "3372 [ D loss: 0.160462, acc.: 95%] [G loss: 5.466696]\n",
            "3373 [ D loss: 0.162404, acc.: 94%] [G loss: 6.536983]\n",
            "3374 [ D loss: 0.139662, acc.: 97%] [G loss: 4.866048]\n",
            "3375 [ D loss: 0.119081, acc.: 99%] [G loss: 5.506499]\n",
            "3376 [ D loss: 0.251679, acc.: 91%] [G loss: 5.647567]\n",
            "3377 [ D loss: 0.147543, acc.: 97%] [G loss: 10.911639]\n",
            "3378 [ D loss: 0.141930, acc.: 95%] [G loss: 4.930881]\n",
            "3379 [ D loss: 0.136795, acc.: 95%] [G loss: 5.455723]\n",
            "3380 [ D loss: 0.210769, acc.: 94%] [G loss: 4.923947]\n",
            "3381 [ D loss: 0.169638, acc.: 97%] [G loss: 4.478101]\n",
            "3382 [ D loss: 0.206990, acc.: 93%] [G loss: 4.564862]\n",
            "3383 [ D loss: 0.289610, acc.: 91%] [G loss: 4.477252]\n",
            "3384 [ D loss: 0.276493, acc.: 91%] [G loss: 4.928923]\n",
            "3385 [ D loss: 0.306255, acc.: 89%] [G loss: 5.366112]\n",
            "3386 [ D loss: 0.196551, acc.: 95%] [G loss: 3.736051]\n",
            "3387 [ D loss: 0.223728, acc.: 91%] [G loss: 3.868020]\n",
            "3388 [ D loss: 0.197622, acc.: 94%] [G loss: 3.983585]\n",
            "3389 [ D loss: 0.122561, acc.: 97%] [G loss: 4.649096]\n",
            "3390 [ D loss: 0.160142, acc.: 97%] [G loss: 3.702904]\n",
            "3391 [ D loss: 0.255592, acc.: 93%] [G loss: 5.254432]\n",
            "3392 [ D loss: 0.199276, acc.: 92%] [G loss: 3.670198]\n",
            "3393 [ D loss: 0.339763, acc.: 80%] [G loss: 3.354097]\n",
            "3394 [ D loss: 0.156267, acc.: 98%] [G loss: 6.445521]\n",
            "3395 [ D loss: 0.125975, acc.: 98%] [G loss: 5.811012]\n",
            "3396 [ D loss: 0.204240, acc.: 96%] [G loss: 6.494446]\n",
            "3397 [ D loss: 0.245466, acc.: 92%] [G loss: 4.244791]\n",
            "3398 [ D loss: 0.192318, acc.: 93%] [G loss: 6.293273]\n",
            "3399 [ D loss: 0.164794, acc.: 95%] [G loss: 3.782769]\n",
            "3400 [ D loss: 0.144996, acc.: 95%] [G loss: 4.541708]\n",
            "3401 [ D loss: 0.261528, acc.: 93%] [G loss: 4.690662]\n",
            "3402 [ D loss: 0.353686, acc.: 86%] [G loss: 4.842620]\n",
            "3403 [ D loss: 0.225933, acc.: 95%] [G loss: 4.949137]\n",
            "3404 [ D loss: 0.167010, acc.: 98%] [G loss: 4.474027]\n",
            "3405 [ D loss: 0.241496, acc.: 91%] [G loss: 3.362258]\n",
            "3406 [ D loss: 0.160580, acc.: 95%] [G loss: 4.093240]\n",
            "3407 [ D loss: 0.243833, acc.: 93%] [G loss: 3.684179]\n",
            "3408 [ D loss: 0.302455, acc.: 88%] [G loss: 4.980086]\n",
            "3409 [ D loss: 0.229352, acc.: 89%] [G loss: 4.234537]\n",
            "3410 [ D loss: 0.170644, acc.: 94%] [G loss: 4.702522]\n",
            "3411 [ D loss: 0.124791, acc.: 96%] [G loss: 3.832498]\n",
            "3412 [ D loss: 0.213003, acc.: 90%] [G loss: 5.601300]\n",
            "3413 [ D loss: 0.101584, acc.: 98%] [G loss: 6.147055]\n",
            "3414 [ D loss: 0.144524, acc.: 97%] [G loss: 4.851906]\n",
            "3415 [ D loss: 0.173784, acc.: 97%] [G loss: 3.883772]\n",
            "3416 [ D loss: 0.145790, acc.: 97%] [G loss: 5.018346]\n",
            "3417 [ D loss: 0.177714, acc.: 95%] [G loss: 6.785697]\n",
            "3418 [ D loss: 0.133126, acc.: 97%] [G loss: 5.912991]\n",
            "3419 [ D loss: 0.222238, acc.: 92%] [G loss: 4.280564]\n",
            "3420 [ D loss: 0.170308, acc.: 95%] [G loss: 4.714113]\n",
            "3421 [ D loss: 0.221646, acc.: 93%] [G loss: 5.784301]\n",
            "3422 [ D loss: 0.154753, acc.: 96%] [G loss: 5.422820]\n",
            "3423 [ D loss: 0.221762, acc.: 92%] [G loss: 5.214252]\n",
            "3424 [ D loss: 0.186501, acc.: 93%] [G loss: 4.815634]\n",
            "3425 [ D loss: 0.201989, acc.: 94%] [G loss: 4.716991]\n",
            "3426 [ D loss: 0.250777, acc.: 91%] [G loss: 4.952553]\n",
            "3427 [ D loss: 0.193236, acc.: 92%] [G loss: 4.786454]\n",
            "3428 [ D loss: 0.307885, acc.: 83%] [G loss: 5.891585]\n",
            "3429 [ D loss: 0.322146, acc.: 85%] [G loss: 5.674048]\n",
            "3430 [ D loss: 0.222221, acc.: 90%] [G loss: 4.510838]\n",
            "3431 [ D loss: 0.122119, acc.: 98%] [G loss: 4.978803]\n",
            "3432 [ D loss: 0.160750, acc.: 96%] [G loss: 6.451021]\n",
            "3433 [ D loss: 0.186756, acc.: 95%] [G loss: 5.569367]\n",
            "3434 [ D loss: 0.162732, acc.: 93%] [G loss: 5.984581]\n",
            "3435 [ D loss: 0.161781, acc.: 95%] [G loss: 6.948436]\n",
            "3436 [ D loss: 0.160870, acc.: 93%] [G loss: 7.362822]\n",
            "3437 [ D loss: 0.130366, acc.: 97%] [G loss: 4.777575]\n",
            "3438 [ D loss: 0.131509, acc.: 97%] [G loss: 8.967852]\n",
            "3439 [ D loss: 0.359342, acc.: 85%] [G loss: 4.157253]\n",
            "3440 [ D loss: 0.214594, acc.: 91%] [G loss: 4.712596]\n",
            "3441 [ D loss: 0.200839, acc.: 94%] [G loss: 3.894956]\n",
            "3442 [ D loss: 0.246838, acc.: 91%] [G loss: 7.115601]\n",
            "3443 [ D loss: 0.177853, acc.: 95%] [G loss: 6.632829]\n",
            "3444 [ D loss: 0.163177, acc.: 93%] [G loss: 4.665108]\n",
            "3445 [ D loss: 0.125957, acc.: 98%] [G loss: 4.601291]\n",
            "3446 [ D loss: 0.086447, acc.: 98%] [G loss: 5.665265]\n",
            "3447 [ D loss: 0.235136, acc.: 90%] [G loss: 4.396847]\n",
            "3448 [ D loss: 0.267621, acc.: 94%] [G loss: 4.166172]\n",
            "3449 [ D loss: 0.210674, acc.: 93%] [G loss: 6.401627]\n",
            "3450 [ D loss: 0.267847, acc.: 90%] [G loss: 4.980636]\n",
            "3451 [ D loss: 0.331569, acc.: 87%] [G loss: 4.376949]\n",
            "3452 [ D loss: 0.240973, acc.: 91%] [G loss: 4.636404]\n",
            "3453 [ D loss: 0.195319, acc.: 94%] [G loss: 4.507257]\n",
            "3454 [ D loss: 0.217165, acc.: 91%] [G loss: 4.668723]\n",
            "3455 [ D loss: 0.166710, acc.: 96%] [G loss: 4.008657]\n",
            "3456 [ D loss: 0.155311, acc.: 98%] [G loss: 3.527552]\n",
            "3457 [ D loss: 0.124018, acc.: 98%] [G loss: 4.345490]\n",
            "3458 [ D loss: 0.262504, acc.: 92%] [G loss: 4.578157]\n",
            "3459 [ D loss: 0.173647, acc.: 97%] [G loss: 2.911377]\n",
            "3460 [ D loss: 0.176951, acc.: 95%] [G loss: 3.569341]\n",
            "3461 [ D loss: 0.259361, acc.: 92%] [G loss: 3.961885]\n",
            "3462 [ D loss: 0.143040, acc.: 98%] [G loss: 3.453076]\n",
            "3463 [ D loss: 0.207243, acc.: 93%] [G loss: 4.408743]\n",
            "3464 [ D loss: 0.174306, acc.: 96%] [G loss: 3.686885]\n",
            "3465 [ D loss: 0.202124, acc.: 92%] [G loss: 5.335159]\n",
            "3466 [ D loss: 0.180122, acc.: 94%] [G loss: 4.010873]\n",
            "3467 [ D loss: 0.240257, acc.: 93%] [G loss: 3.833994]\n",
            "3468 [ D loss: 0.207586, acc.: 93%] [G loss: 3.796833]\n",
            "3469 [ D loss: 0.336395, acc.: 85%] [G loss: 3.771843]\n",
            "3470 [ D loss: 0.250629, acc.: 92%] [G loss: 3.841948]\n",
            "3471 [ D loss: 0.264999, acc.: 91%] [G loss: 3.507924]\n",
            "3472 [ D loss: 0.192098, acc.: 95%] [G loss: 4.073804]\n",
            "3473 [ D loss: 0.188265, acc.: 95%] [G loss: 4.386993]\n",
            "3474 [ D loss: 0.206838, acc.: 95%] [G loss: 3.712211]\n",
            "3475 [ D loss: 0.199465, acc.: 98%] [G loss: 4.777348]\n",
            "3476 [ D loss: 0.145345, acc.: 98%] [G loss: 3.659348]\n",
            "3477 [ D loss: 0.084354, acc.: 99%] [G loss: 4.408261]\n",
            "3478 [ D loss: 0.246660, acc.: 92%] [G loss: 3.623281]\n",
            "3479 [ D loss: 0.197119, acc.: 96%] [G loss: 4.358129]\n",
            "3480 [ D loss: 0.159260, acc.: 97%] [G loss: 4.651803]\n",
            "3481 [ D loss: 0.187754, acc.: 97%] [G loss: 4.390017]\n",
            "3482 [ D loss: 0.275493, acc.: 88%] [G loss: 4.043881]\n",
            "3483 [ D loss: 0.183982, acc.: 95%] [G loss: 3.198499]\n",
            "3484 [ D loss: 0.110821, acc.: 97%] [G loss: 6.922644]\n",
            "3485 [ D loss: 0.175093, acc.: 95%] [G loss: 7.254492]\n",
            "3486 [ D loss: 0.126771, acc.: 96%] [G loss: 5.509295]\n",
            "3487 [ D loss: 0.225378, acc.: 91%] [G loss: 6.337946]\n",
            "3488 [ D loss: 0.145321, acc.: 95%] [G loss: 4.752423]\n",
            "3489 [ D loss: 0.149489, acc.: 95%] [G loss: 3.536919]\n",
            "3490 [ D loss: 0.211662, acc.: 95%] [G loss: 3.086254]\n",
            "3491 [ D loss: 0.197469, acc.: 95%] [G loss: 3.545710]\n",
            "3492 [ D loss: 0.242686, acc.: 95%] [G loss: 4.035692]\n",
            "3493 [ D loss: 0.268690, acc.: 91%] [G loss: 6.180559]\n",
            "3494 [ D loss: 0.222742, acc.: 94%] [G loss: 4.818377]\n",
            "3495 [ D loss: 0.247704, acc.: 93%] [G loss: 3.373321]\n",
            "3496 [ D loss: 0.189400, acc.: 97%] [G loss: 5.704338]\n",
            "3497 [ D loss: 0.177882, acc.: 91%] [G loss: 4.308179]\n",
            "3498 [ D loss: 0.181615, acc.: 94%] [G loss: 5.397843]\n",
            "3499 [ D loss: 0.160203, acc.: 92%] [G loss: 6.662207]\n",
            "3500 [ D loss: 0.128676, acc.: 98%] [G loss: 4.319620]\n",
            "3501 [ D loss: 0.220254, acc.: 95%] [G loss: 9.829813]\n",
            "3502 [ D loss: 0.133941, acc.: 96%] [G loss: 5.259779]\n",
            "3503 [ D loss: 0.228406, acc.: 95%] [G loss: 6.445179]\n",
            "3504 [ D loss: 0.155151, acc.: 97%] [G loss: 9.600002]\n",
            "3505 [ D loss: 0.100986, acc.: 99%] [G loss: 6.369906]\n",
            "3506 [ D loss: 0.161873, acc.: 95%] [G loss: 4.024603]\n",
            "3507 [ D loss: 0.130166, acc.: 98%] [G loss: 4.350850]\n",
            "3508 [ D loss: 0.248448, acc.: 96%] [G loss: 4.432503]\n",
            "3509 [ D loss: 0.187853, acc.: 93%] [G loss: 4.724773]\n",
            "3510 [ D loss: 0.232244, acc.: 93%] [G loss: 9.077284]\n",
            "3511 [ D loss: 0.342960, acc.: 80%] [G loss: 4.011251]\n",
            "3512 [ D loss: 0.093325, acc.: 97%] [G loss: 8.935739]\n",
            "3513 [ D loss: 0.166222, acc.: 96%] [G loss: 8.888574]\n",
            "3514 [ D loss: 0.146516, acc.: 94%] [G loss: 5.394256]\n",
            "3515 [ D loss: 0.107241, acc.: 98%] [G loss: 4.852707]\n",
            "3516 [ D loss: 0.215176, acc.: 92%] [G loss: 4.203518]\n",
            "3517 [ D loss: 0.155090, acc.: 98%] [G loss: 4.420174]\n",
            "3518 [ D loss: 0.243516, acc.: 93%] [G loss: 4.295762]\n",
            "3519 [ D loss: 0.189681, acc.: 95%] [G loss: 6.493191]\n",
            "3520 [ D loss: 0.176376, acc.: 95%] [G loss: 4.638927]\n",
            "3521 [ D loss: 0.165047, acc.: 97%] [G loss: 6.247147]\n",
            "3522 [ D loss: 0.164872, acc.: 97%] [G loss: 5.530881]\n",
            "3523 [ D loss: 0.243918, acc.: 91%] [G loss: 4.651710]\n",
            "3524 [ D loss: 0.147794, acc.: 98%] [G loss: 5.012098]\n",
            "3525 [ D loss: 0.220676, acc.: 91%] [G loss: 3.444526]\n",
            "3526 [ D loss: 0.207748, acc.: 93%] [G loss: 3.875916]\n",
            "3527 [ D loss: 0.244511, acc.: 91%] [G loss: 3.519769]\n",
            "3528 [ D loss: 0.147520, acc.: 97%] [G loss: 4.750991]\n",
            "3529 [ D loss: 0.285175, acc.: 88%] [G loss: 5.705066]\n",
            "3530 [ D loss: 0.278173, acc.: 88%] [G loss: 3.588744]\n",
            "3531 [ D loss: 0.260280, acc.: 88%] [G loss: 3.609165]\n",
            "3532 [ D loss: 0.262715, acc.: 90%] [G loss: 4.406941]\n",
            "3533 [ D loss: 0.197171, acc.: 92%] [G loss: 3.948707]\n",
            "3534 [ D loss: 0.235783, acc.: 95%] [G loss: 3.731481]\n",
            "3535 [ D loss: 0.196600, acc.: 94%] [G loss: 3.348572]\n",
            "3536 [ D loss: 0.174705, acc.: 95%] [G loss: 3.821019]\n",
            "3537 [ D loss: 0.309365, acc.: 87%] [G loss: 4.859555]\n",
            "3538 [ D loss: 0.238192, acc.: 91%] [G loss: 3.072405]\n",
            "3539 [ D loss: 0.226840, acc.: 95%] [G loss: 4.341944]\n",
            "3540 [ D loss: 0.098696, acc.: 98%] [G loss: 5.667385]\n",
            "3541 [ D loss: 0.161158, acc.: 96%] [G loss: 6.720301]\n",
            "3542 [ D loss: 0.107227, acc.: 98%] [G loss: 5.549086]\n",
            "3543 [ D loss: 0.114825, acc.: 98%] [G loss: 4.355425]\n",
            "3544 [ D loss: 0.083214, acc.: 99%] [G loss: 4.280460]\n",
            "3545 [ D loss: 0.126650, acc.: 98%] [G loss: 7.096698]\n",
            "3546 [ D loss: 0.112413, acc.: 98%] [G loss: 4.272450]\n",
            "3547 [ D loss: 0.141554, acc.: 98%] [G loss: 4.267451]\n",
            "3548 [ D loss: 0.200250, acc.: 94%] [G loss: 3.943110]\n",
            "3549 [ D loss: 0.171134, acc.: 98%] [G loss: 3.587710]\n",
            "3550 [ D loss: 0.144614, acc.: 96%] [G loss: 4.370907]\n",
            "3551 [ D loss: 0.210088, acc.: 94%] [G loss: 4.532173]\n",
            "3552 [ D loss: 0.159428, acc.: 97%] [G loss: 3.850717]\n",
            "3553 [ D loss: 0.253217, acc.: 94%] [G loss: 3.792339]\n",
            "3554 [ D loss: 0.213608, acc.: 95%] [G loss: 4.422994]\n",
            "3555 [ D loss: 0.219579, acc.: 92%] [G loss: 2.956249]\n",
            "3556 [ D loss: 0.248416, acc.: 92%] [G loss: 3.209897]\n",
            "3557 [ D loss: 0.172605, acc.: 96%] [G loss: 2.886547]\n",
            "3558 [ D loss: 0.182141, acc.: 95%] [G loss: 3.715654]\n",
            "3559 [ D loss: 0.206350, acc.: 93%] [G loss: 3.007467]\n",
            "3560 [ D loss: 0.285052, acc.: 89%] [G loss: 2.876824]\n",
            "3561 [ D loss: 0.189354, acc.: 93%] [G loss: 3.630064]\n",
            "3562 [ D loss: 0.244569, acc.: 94%] [G loss: 3.848556]\n",
            "3563 [ D loss: 0.219808, acc.: 91%] [G loss: 4.243778]\n",
            "3564 [ D loss: 0.355029, acc.: 82%] [G loss: 4.346293]\n",
            "3565 [ D loss: 0.250000, acc.: 94%] [G loss: 5.741761]\n",
            "3566 [ D loss: 0.213922, acc.: 92%] [G loss: 4.249665]\n",
            "3567 [ D loss: 0.195999, acc.: 95%] [G loss: 3.536791]\n",
            "3568 [ D loss: 0.176347, acc.: 96%] [G loss: 6.620429]\n",
            "3569 [ D loss: 0.177972, acc.: 95%] [G loss: 8.178512]\n",
            "3570 [ D loss: 0.163046, acc.: 93%] [G loss: 5.211235]\n",
            "3571 [ D loss: 0.153263, acc.: 96%] [G loss: 6.951345]\n",
            "3572 [ D loss: 0.094394, acc.: 97%] [G loss: 5.427874]\n",
            "3573 [ D loss: 0.046476, acc.: 98%] [G loss: 5.829929]\n",
            "3574 [ D loss: 0.167774, acc.: 93%] [G loss: 6.914952]\n",
            "3575 [ D loss: 0.119231, acc.: 96%] [G loss: 5.412908]\n",
            "3576 [ D loss: 0.094925, acc.: 95%] [G loss: 8.077629]\n",
            "3577 [ D loss: 0.187517, acc.: 91%] [G loss: 4.178385]\n",
            "3578 [ D loss: 0.177109, acc.: 95%] [G loss: 3.713567]\n",
            "3579 [ D loss: 0.206027, acc.: 92%] [G loss: 3.923319]\n",
            "3580 [ D loss: 0.215808, acc.: 95%] [G loss: 3.697840]\n",
            "3581 [ D loss: 0.125496, acc.: 98%] [G loss: 3.684971]\n",
            "3582 [ D loss: 0.267629, acc.: 91%] [G loss: 3.104335]\n",
            "3583 [ D loss: 0.220219, acc.: 94%] [G loss: 3.635303]\n",
            "3584 [ D loss: 0.155480, acc.: 98%] [G loss: 4.185568]\n",
            "3585 [ D loss: 0.138883, acc.: 96%] [G loss: 4.871822]\n",
            "3586 [ D loss: 0.230470, acc.: 93%] [G loss: 3.725653]\n",
            "3587 [ D loss: 0.214797, acc.: 92%] [G loss: 3.493965]\n",
            "3588 [ D loss: 0.151597, acc.: 97%] [G loss: 4.706709]\n",
            "3589 [ D loss: 0.154740, acc.: 94%] [G loss: 4.989191]\n",
            "3590 [ D loss: 0.222591, acc.: 94%] [G loss: 3.880773]\n",
            "3591 [ D loss: 0.154464, acc.: 97%] [G loss: 4.752237]\n",
            "3592 [ D loss: 0.173467, acc.: 94%] [G loss: 6.832315]\n",
            "3593 [ D loss: 0.257153, acc.: 88%] [G loss: 7.764389]\n",
            "3594 [ D loss: 0.169694, acc.: 97%] [G loss: 6.158246]\n",
            "3595 [ D loss: 0.138843, acc.: 97%] [G loss: 5.433144]\n",
            "3596 [ D loss: 0.148173, acc.: 95%] [G loss: 5.636755]\n",
            "3597 [ D loss: 0.241504, acc.: 93%] [G loss: 5.919725]\n",
            "3598 [ D loss: 0.146910, acc.: 96%] [G loss: 4.848925]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bgbo8tXb-NQP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 15000 iteration\n",
        "generated_img = model.generator.predict(np.random.normal(0, 1, (10, 100)))\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 2))\n",
        "n =10\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(1, n, i + 1)\n",
        "    plt.imshow(np.squeeze(generated_img[i]))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZRY7ibCt-OP_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = GAN()\n",
        "model.train(epochs=20000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p9O4uVAK-Rsk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 20000 iteration\n",
        "generated_img = model.generator.predict(np.random.normal(0, 1, (10, 100)))\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 2))\n",
        "n =10\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(1, n, i + 1)\n",
        "    plt.imshow(np.squeeze(generated_img[i]))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8hRZtN3g-TIs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}